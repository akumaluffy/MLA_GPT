Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Training with 1 GPUs
2025-04-25 12:19:13,683 - transformer_training - INFO - Tokenizing dataset...
2025-04-25 12:19:14,195 - transformer_training - INFO - Chunking dataset...
Chunking (num_proc=96):   0%|          | 0/2530 [00:00<?, ? examples/s]Chunking (num_proc=96):   3%|▎         | 81/2530 [00:00<00:03, 616.56 examples/s]Chunking (num_proc=96):  22%|██▏       | 567/2530 [00:00<00:00, 2786.65 examples/s]Chunking (num_proc=96):  86%|████████▌ | 2166/2530 [00:00<00:00, 8344.43 examples/s]Chunking (num_proc=96): 100%|██████████| 2530/2530 [00:00<00:00, 5929.26 examples/s]
Chunking (num_proc=96):   0%|          | 0/1014942 [00:00<?, ? examples/s]Chunking (num_proc=96):   0%|          | 3072/1014942 [00:00<00:34, 29352.98 examples/s]Chunking (num_proc=96):   2%|▏         | 19456/1014942 [00:00<00:09, 106124.90 examples/s]Chunking (num_proc=96):   3%|▎         | 30208/1014942 [00:00<00:09, 101543.64 examples/s]Chunking (num_proc=96):   5%|▍         | 46592/1014942 [00:00<00:07, 124473.03 examples/s]Chunking (num_proc=96):   6%|▌         | 59392/1014942 [00:00<00:09, 97127.49 examples/s] Chunking (num_proc=96):   7%|▋         | 70144/1014942 [00:00<00:12, 78414.41 examples/s]Chunking (num_proc=96):   8%|▊         | 79360/1014942 [00:01<00:17, 54618.99 examples/s]Chunking (num_proc=96):   9%|▊         | 86528/1014942 [00:01<00:16, 57317.19 examples/s]Chunking (num_proc=96):  10%|▉         | 96768/1014942 [00:01<00:15, 57601.70 examples/s]Chunking (num_proc=96):  10%|█         | 103424/1014942 [00:01<00:18, 49165.72 examples/s]Chunking (num_proc=96):  11%|█         | 109056/1014942 [00:01<00:18, 50231.35 examples/s]Chunking (num_proc=96):  12%|█▏        | 117760/1014942 [00:01<00:15, 57746.99 examples/s]Chunking (num_proc=96):  12%|█▏        | 124416/1014942 [00:02<00:18, 47904.57 examples/s]Chunking (num_proc=96):  13%|█▎        | 131584/1014942 [00:02<00:16, 52529.97 examples/s]Chunking (num_proc=96):  14%|█▎        | 137728/1014942 [00:02<00:22, 38444.31 examples/s]Chunking (num_proc=96):  14%|█▍        | 142848/1014942 [00:02<00:21, 39858.04 examples/s]Chunking (num_proc=96):  15%|█▍        | 147968/1014942 [00:02<00:25, 34382.52 examples/s]Chunking (num_proc=96):  15%|█▍        | 152064/1014942 [00:02<00:32, 26523.49 examples/s]Chunking (num_proc=96):  15%|█▌        | 157184/1014942 [00:03<00:27, 30741.73 examples/s]Chunking (num_proc=96):  16%|█▌        | 163328/1014942 [00:03<00:23, 36724.83 examples/s]Chunking (num_proc=96):  17%|█▋        | 175616/1014942 [00:03<00:15, 55253.79 examples/s]Chunking (num_proc=96):  31%|███       | 313344/1014942 [00:03<00:01, 368843.40 examples/s]Chunking (num_proc=96):  70%|███████   | 713728/1014942 [00:03<00:00, 1288694.56 examples/s]Chunking (num_proc=96):  91%|█████████▏| 926385/1014942 [00:03<00:00, 1507449.60 examples/s]Chunking (num_proc=96): 100%|██████████| 1014942/1014942 [00:03<00:00, 267534.40 examples/s]
Chunking (num_proc=96):   0%|          | 0/2163 [00:00<?, ? examples/s]Chunking (num_proc=96):   1%|          | 23/2163 [00:00<00:15, 139.07 examples/s]Chunking (num_proc=96):  50%|████▉     | 1081/2163 [00:00<00:00, 4977.62 examples/s]Chunking (num_proc=96): 100%|██████████| 2163/2163 [00:00<00:00, 5085.69 examples/s]
Filter:   0%|          | 0/478 [00:00<?, ? examples/s]Filter: 100%|██████████| 478/478 [00:00<00:00, 5856.89 examples/s]
Filter:   0%|          | 0/219950 [00:00<?, ? examples/s]Filter:   0%|          | 1000/219950 [00:00<00:32, 6697.74 examples/s]Filter:   1%|          | 2000/219950 [00:00<00:33, 6474.10 examples/s]Filter:   1%|▏         | 3000/219950 [00:00<00:32, 6753.51 examples/s]Filter:   2%|▏         | 4000/219950 [00:00<00:31, 6924.43 examples/s]Filter:   2%|▏         | 5000/219950 [00:00<00:30, 6975.51 examples/s]Filter:   3%|▎         | 6000/219950 [00:00<00:29, 7144.94 examples/s]Filter:   3%|▎         | 7000/219950 [00:00<00:29, 7217.72 examples/s]Filter:   4%|▎         | 8000/219950 [00:01<00:29, 7271.86 examples/s]Filter:   4%|▍         | 9000/219950 [00:01<00:30, 6805.50 examples/s]Filter:   5%|▍         | 10000/219950 [00:01<00:36, 5796.72 examples/s]Filter:   5%|▌         | 11000/219950 [00:01<00:34, 6127.59 examples/s]Filter:   5%|▌         | 12000/219950 [00:01<00:32, 6463.86 examples/s]Filter:   6%|▌         | 13000/219950 [00:01<00:30, 6740.85 examples/s]Filter:   6%|▋         | 14000/219950 [00:02<00:29, 6927.71 examples/s]Filter:   7%|▋         | 15000/219950 [00:02<00:29, 7067.14 examples/s]Filter:   7%|▋         | 16000/219950 [00:02<00:28, 7168.24 examples/s]Filter:   8%|▊         | 17000/219950 [00:02<00:28, 7238.01 examples/s]Filter:   8%|▊         | 18000/219950 [00:02<00:27, 7307.65 examples/s]Filter:   9%|▊         | 19000/219950 [00:02<00:27, 7348.70 examples/s]Filter:   9%|▉         | 20000/219950 [00:02<00:27, 7358.75 examples/s]Filter:  10%|▉         | 21000/219950 [00:03<00:27, 7316.63 examples/s]Filter:  10%|█         | 22000/219950 [00:03<00:27, 7258.18 examples/s]Filter:  10%|█         | 23000/219950 [00:03<00:26, 7307.76 examples/s]Filter:  11%|█         | 24000/219950 [00:03<00:26, 7369.45 examples/s]Filter:  11%|█▏        | 25000/219950 [00:03<00:26, 7413.29 examples/s]Filter:  12%|█▏        | 26000/219950 [00:03<00:26, 7452.80 examples/s]Filter:  12%|█▏        | 27000/219950 [00:03<00:25, 7486.80 examples/s]Filter:  13%|█▎        | 28000/219950 [00:03<00:25, 7431.61 examples/s]Filter:  13%|█▎        | 29000/219950 [00:04<00:25, 7445.63 examples/s]Filter:  14%|█▎        | 30000/219950 [00:04<00:25, 7440.83 examples/s]Filter:  14%|█▍        | 31000/219950 [00:04<00:25, 7413.12 examples/s]Filter:  15%|█▍        | 32000/219950 [00:04<00:25, 7416.52 examples/s]Filter:  15%|█▌        | 33000/219950 [00:04<00:25, 7422.66 examples/s]Filter:  15%|█▌        | 34000/219950 [00:04<00:25, 7412.30 examples/s]Filter:  16%|█▌        | 35000/219950 [00:04<00:24, 7406.66 examples/s]Filter:  16%|█▋        | 36000/219950 [00:05<00:24, 7405.21 examples/s]Filter:  17%|█▋        | 37000/219950 [00:05<00:25, 7302.32 examples/s]Filter:  17%|█▋        | 38000/219950 [00:05<00:24, 7315.71 examples/s]Filter:  18%|█▊        | 39000/219950 [00:05<00:24, 7358.56 examples/s]Filter:  18%|█▊        | 40000/219950 [00:05<00:24, 7365.70 examples/s]Filter:  19%|█▊        | 41000/219950 [00:05<00:24, 7400.80 examples/s]Filter:  19%|█▉        | 42000/219950 [00:05<00:23, 7425.17 examples/s]Filter:  20%|█▉        | 43000/219950 [00:05<00:23, 7450.57 examples/s]Filter:  20%|██        | 44000/219950 [00:06<00:23, 7449.58 examples/s]Filter:  20%|██        | 45000/219950 [00:06<00:23, 7481.95 examples/s]Filter:  21%|██        | 46000/219950 [00:06<00:23, 7460.06 examples/s]Filter:  21%|██▏       | 47000/219950 [00:06<00:23, 7474.14 examples/s]Filter:  22%|██▏       | 48000/219950 [00:06<00:23, 7450.47 examples/s]Filter:  22%|██▏       | 49000/219950 [00:06<00:22, 7480.86 examples/s]Filter:  23%|██▎       | 50000/219950 [00:06<00:22, 7499.39 examples/s]Filter:  23%|██▎       | 51000/219950 [00:07<00:22, 7482.73 examples/s]Filter:  24%|██▎       | 52000/219950 [00:07<00:22, 7459.45 examples/s]Filter:  24%|██▍       | 53000/219950 [00:07<00:22, 7468.83 examples/s]Filter:  25%|██▍       | 54000/219950 [00:07<00:22, 7468.25 examples/s]Filter:  25%|██▌       | 55000/219950 [00:07<00:22, 7461.79 examples/s]Filter:  25%|██▌       | 56000/219950 [00:07<00:22, 7433.28 examples/s]Filter:  26%|██▌       | 57000/219950 [00:07<00:21, 7460.76 examples/s]Filter:  26%|██▋       | 58000/219950 [00:08<00:21, 7424.19 examples/s]Filter:  27%|██▋       | 59000/219950 [00:08<00:21, 7400.92 examples/s]Filter:  27%|██▋       | 60000/219950 [00:08<00:21, 7401.23 examples/s]Filter:  28%|██▊       | 61000/219950 [00:08<00:21, 7402.77 examples/s]Filter:  28%|██▊       | 62000/219950 [00:08<00:21, 7406.03 examples/s]Filter:  29%|██▊       | 63000/219950 [00:08<00:21, 7402.72 examples/s]Filter:  29%|██▉       | 64000/219950 [00:08<00:21, 7412.72 examples/s]Filter:  30%|██▉       | 65000/219950 [00:08<00:21, 7360.33 examples/s]Filter:  30%|███       | 66000/219950 [00:09<00:21, 7324.56 examples/s]Filter:  30%|███       | 67000/219950 [00:09<00:21, 7229.39 examples/s]Filter:  31%|███       | 68000/219950 [00:09<00:20, 7276.51 examples/s]Filter:  31%|███▏      | 69000/219950 [00:09<00:20, 7334.13 examples/s]Filter:  32%|███▏      | 70000/219950 [00:09<00:20, 7376.30 examples/s]Filter:  32%|███▏      | 71000/219950 [00:09<00:20, 7355.84 examples/s]Filter:  33%|███▎      | 72000/219950 [00:09<00:20, 7378.71 examples/s]Filter:  33%|███▎      | 73000/219950 [00:10<00:19, 7377.55 examples/s]Filter:  34%|███▎      | 74000/219950 [00:10<00:19, 7352.90 examples/s]Filter:  34%|███▍      | 75000/219950 [00:10<00:19, 7303.52 examples/s]Filter:  35%|███▍      | 76000/219950 [00:10<00:19, 7301.22 examples/s]Filter:  35%|███▌      | 77000/219950 [00:10<00:19, 7337.92 examples/s]Filter:  35%|███▌      | 78000/219950 [00:10<00:19, 7364.03 examples/s]Filter:  36%|███▌      | 79000/219950 [00:10<00:19, 7388.56 examples/s]Filter:  36%|███▋      | 80000/219950 [00:10<00:19, 7345.16 examples/s]Filter:  37%|███▋      | 81000/219950 [00:11<00:18, 7355.62 examples/s]Filter:  37%|███▋      | 82000/219950 [00:11<00:18, 7319.68 examples/s]Filter:  38%|███▊      | 83000/219950 [00:11<00:18, 7344.23 examples/s]Filter:  38%|███▊      | 84000/219950 [00:11<00:18, 7356.37 examples/s]Filter:  39%|███▊      | 85000/219950 [00:11<00:18, 7295.71 examples/s]Filter:  39%|███▉      | 86000/219950 [00:11<00:18, 7245.49 examples/s]Filter:  40%|███▉      | 87000/219950 [00:11<00:18, 7274.35 examples/s]Filter:  40%|████      | 88000/219950 [00:12<00:17, 7339.89 examples/s]Filter:  40%|████      | 89000/219950 [00:12<00:17, 7410.56 examples/s]Filter:  41%|████      | 90000/219950 [00:12<00:17, 7435.36 examples/s]Filter:  41%|████▏     | 91000/219950 [00:12<00:17, 7464.30 examples/s]Filter:  42%|████▏     | 92000/219950 [00:12<00:17, 7481.77 examples/s]Filter:  42%|████▏     | 93000/219950 [00:12<00:16, 7495.41 examples/s]Filter:  43%|████▎     | 94000/219950 [00:12<00:16, 7483.22 examples/s]Filter:  43%|████▎     | 95000/219950 [00:13<00:16, 7440.10 examples/s]Filter:  44%|████▎     | 96000/219950 [00:13<00:16, 7407.97 examples/s]Filter:  44%|████▍     | 97000/219950 [00:13<00:16, 7443.06 examples/s]Filter:  45%|████▍     | 98000/219950 [00:13<00:16, 7480.07 examples/s]Filter:  45%|████▌     | 99000/219950 [00:13<00:16, 7481.47 examples/s]Filter:  45%|████▌     | 100000/219950 [00:13<00:16, 7493.27 examples/s]Filter:  46%|████▌     | 101000/219950 [00:13<00:15, 7509.90 examples/s]Filter:  46%|████▋     | 102000/219950 [00:13<00:15, 7517.65 examples/s]Filter:  47%|████▋     | 103000/219950 [00:14<00:15, 7514.46 examples/s]Filter:  47%|████▋     | 104000/219950 [00:14<00:15, 7519.13 examples/s]Filter:  48%|████▊     | 105000/219950 [00:14<00:15, 7514.45 examples/s]Filter:  48%|████▊     | 106000/219950 [00:14<00:15, 7503.14 examples/s]Filter:  49%|████▊     | 107000/219950 [00:14<00:15, 7485.17 examples/s]Filter:  49%|████▉     | 108000/219950 [00:14<00:14, 7495.51 examples/s]Filter:  50%|████▉     | 109000/219950 [00:14<00:14, 7504.98 examples/s]Filter:  50%|█████     | 110000/219950 [00:15<00:14, 7436.09 examples/s]Filter:  50%|█████     | 111000/219950 [00:15<00:14, 7457.66 examples/s]Filter:  51%|█████     | 112000/219950 [00:15<00:14, 7454.77 examples/s]Filter:  51%|█████▏    | 113000/219950 [00:15<00:14, 7478.36 examples/s]Filter:  52%|█████▏    | 114000/219950 [00:15<00:14, 7469.84 examples/s]Filter:  52%|█████▏    | 115000/219950 [00:15<00:14, 7396.82 examples/s]Filter:  53%|█████▎    | 116000/219950 [00:15<00:14, 7355.41 examples/s]Filter:  53%|█████▎    | 117000/219950 [00:15<00:13, 7381.53 examples/s]Filter:  54%|█████▎    | 118000/219950 [00:16<00:13, 7412.66 examples/s]Filter:  54%|█████▍    | 119000/219950 [00:16<00:13, 7457.21 examples/s]Filter:  55%|█████▍    | 120000/219950 [00:16<00:13, 7481.68 examples/s]Filter:  55%|█████▌    | 121000/219950 [00:16<00:13, 7426.20 examples/s]Filter:  55%|█████▌    | 122000/219950 [00:16<00:13, 7409.35 examples/s]Filter:  56%|█████▌    | 123000/219950 [00:16<00:13, 7420.81 examples/s]Filter:  56%|█████▋    | 124000/219950 [00:16<00:13, 6862.23 examples/s]Filter:  57%|█████▋    | 125000/219950 [00:17<00:13, 6794.86 examples/s]Filter:  57%|█████▋    | 126000/219950 [00:17<00:13, 6961.88 examples/s]Filter:  58%|█████▊    | 127000/219950 [00:17<00:13, 7109.95 examples/s]Filter:  58%|█████▊    | 128000/219950 [00:17<00:12, 7232.10 examples/s]Filter:  59%|█████▊    | 129000/219950 [00:17<00:12, 7312.75 examples/s]Filter:  59%|█████▉    | 130000/219950 [00:17<00:12, 7379.09 examples/s]Filter:  60%|█████▉    | 131000/219950 [00:17<00:11, 7424.16 examples/s]Filter:  60%|██████    | 132000/219950 [00:18<00:11, 7449.80 examples/s]Filter:  60%|██████    | 133000/219950 [00:18<00:11, 7394.10 examples/s]Filter:  61%|██████    | 134000/219950 [00:18<00:11, 7421.04 examples/s]Filter:  61%|██████▏   | 135000/219950 [00:18<00:11, 7461.26 examples/s]Filter:  62%|██████▏   | 136000/219950 [00:18<00:11, 7487.57 examples/s]Filter:  62%|██████▏   | 137000/219950 [00:18<00:11, 7459.11 examples/s]Filter:  63%|██████▎   | 138000/219950 [00:18<00:11, 7444.16 examples/s]Filter:  63%|██████▎   | 139000/219950 [00:18<00:10, 7393.91 examples/s]Filter:  64%|██████▎   | 140000/219950 [00:19<00:10, 7399.06 examples/s]Filter:  64%|██████▍   | 141000/219950 [00:19<00:10, 7426.92 examples/s]Filter:  65%|██████▍   | 142000/219950 [00:19<00:10, 7450.22 examples/s]Filter:  65%|██████▌   | 143000/219950 [00:19<00:10, 7437.83 examples/s]Filter:  65%|██████▌   | 144000/219950 [00:19<00:10, 7455.20 examples/s]Filter:  66%|██████▌   | 145000/219950 [00:19<00:10, 7472.73 examples/s]Filter:  66%|██████▋   | 146000/219950 [00:19<00:09, 7477.87 examples/s]Filter:  67%|██████▋   | 147000/219950 [00:20<00:09, 7460.99 examples/s]Filter:  67%|██████▋   | 148000/219950 [00:20<00:09, 7365.02 examples/s]Filter:  68%|██████▊   | 149000/219950 [00:20<00:09, 7301.23 examples/s]Filter:  68%|██████▊   | 150000/219950 [00:20<00:09, 7322.66 examples/s]Filter:  69%|██████▊   | 151000/219950 [00:20<00:09, 7337.10 examples/s]Filter:  69%|██████▉   | 152000/219950 [00:20<00:11, 6038.30 examples/s]Filter:  70%|██████▉   | 153000/219950 [00:20<00:10, 6409.19 examples/s]Filter:  70%|███████   | 154000/219950 [00:21<00:09, 6660.84 examples/s]Filter:  70%|███████   | 155000/219950 [00:21<00:09, 6800.45 examples/s]Filter:  71%|███████   | 156000/219950 [00:21<00:09, 6993.36 examples/s]Filter:  71%|███████▏  | 157000/219950 [00:21<00:08, 7135.52 examples/s]Filter:  72%|███████▏  | 158000/219950 [00:21<00:08, 7254.20 examples/s]Filter:  72%|███████▏  | 159000/219950 [00:21<00:08, 7342.60 examples/s]Filter:  73%|███████▎  | 160000/219950 [00:21<00:08, 7409.79 examples/s]Filter:  73%|███████▎  | 161000/219950 [00:22<00:07, 7398.57 examples/s]Filter:  74%|███████▎  | 162000/219950 [00:22<00:07, 7432.16 examples/s]Filter:  74%|███████▍  | 163000/219950 [00:22<00:07, 7454.59 examples/s]Filter:  75%|███████▍  | 164000/219950 [00:22<00:07, 7467.61 examples/s]Filter:  75%|███████▌  | 165000/219950 [00:22<00:07, 7462.19 examples/s]Filter:  75%|███████▌  | 166000/219950 [00:22<00:07, 7484.68 examples/s]Filter:  76%|███████▌  | 167000/219950 [00:22<00:07, 7497.05 examples/s]Filter:  76%|███████▋  | 168000/219950 [00:22<00:06, 7492.29 examples/s]Filter:  77%|███████▋  | 169000/219950 [00:23<00:06, 7483.54 examples/s]Filter:  77%|███████▋  | 170000/219950 [00:23<00:06, 7490.77 examples/s]Filter:  78%|███████▊  | 171000/219950 [00:23<00:06, 7478.35 examples/s]Filter:  78%|███████▊  | 172000/219950 [00:23<00:06, 7483.95 examples/s]Filter:  79%|███████▊  | 173000/219950 [00:23<00:06, 7497.65 examples/s]Filter:  79%|███████▉  | 174000/219950 [00:23<00:06, 7504.48 examples/s]Filter:  80%|███████▉  | 175000/219950 [00:23<00:05, 7523.04 examples/s]Filter:  80%|████████  | 176000/219950 [00:24<00:05, 7519.20 examples/s]Filter:  80%|████████  | 177000/219950 [00:24<00:05, 7513.11 examples/s]Filter:  81%|████████  | 178000/219950 [00:24<00:05, 7506.65 examples/s]Filter:  81%|████████▏ | 179000/219950 [00:24<00:05, 7512.10 examples/s]Filter:  82%|████████▏ | 180000/219950 [00:24<00:05, 7503.35 examples/s]Filter:  82%|████████▏ | 181000/219950 [00:24<00:05, 7505.78 examples/s]Filter:  83%|████████▎ | 182000/219950 [00:24<00:05, 7496.35 examples/s]Filter:  83%|████████▎ | 183000/219950 [00:24<00:04, 7500.63 examples/s]Filter:  84%|████████▎ | 184000/219950 [00:25<00:04, 7498.97 examples/s]Filter:  84%|████████▍ | 185000/219950 [00:25<00:04, 7482.95 examples/s]Filter:  85%|████████▍ | 186000/219950 [00:25<00:04, 7472.41 examples/s]Filter:  85%|████████▌ | 187000/219950 [00:25<00:04, 7479.88 examples/s]Filter:  85%|████████▌ | 188000/219950 [00:25<00:04, 7463.83 examples/s]Filter:  86%|████████▌ | 189000/219950 [00:25<00:04, 7495.39 examples/s]Filter:  86%|████████▋ | 190000/219950 [00:25<00:03, 7487.71 examples/s]Filter:  87%|████████▋ | 191000/219950 [00:26<00:03, 7494.88 examples/s]Filter:  87%|████████▋ | 192000/219950 [00:26<00:03, 7481.38 examples/s]Filter:  88%|████████▊ | 193000/219950 [00:26<00:03, 7502.86 examples/s]Filter:  88%|████████▊ | 194000/219950 [00:26<00:03, 7475.08 examples/s]Filter:  89%|████████▊ | 195000/219950 [00:26<00:03, 7460.03 examples/s]Filter:  89%|████████▉ | 196000/219950 [00:26<00:03, 7461.70 examples/s]Filter:  90%|████████▉ | 197000/219950 [00:26<00:03, 7492.69 examples/s]Filter:  90%|█████████ | 198000/219950 [00:26<00:02, 7510.08 examples/s]Filter:  90%|█████████ | 199000/219950 [00:27<00:02, 7483.63 examples/s]Filter:  91%|█████████ | 200000/219950 [00:27<00:02, 7486.21 examples/s]Filter:  91%|█████████▏| 201000/219950 [00:27<00:02, 7495.27 examples/s]Filter:  92%|█████████▏| 202000/219950 [00:27<00:02, 7489.26 examples/s]Filter:  92%|█████████▏| 203000/219950 [00:27<00:02, 7475.34 examples/s]Filter:  93%|█████████▎| 204000/219950 [00:27<00:02, 7491.86 examples/s]Filter:  93%|█████████▎| 205000/219950 [00:27<00:01, 7504.46 examples/s]Filter:  94%|█████████▎| 206000/219950 [00:28<00:01, 7503.92 examples/s]Filter:  94%|█████████▍| 207000/219950 [00:28<00:01, 7486.43 examples/s]Filter:  95%|█████████▍| 208000/219950 [00:28<00:01, 7482.36 examples/s]Filter:  95%|█████████▌| 209000/219950 [00:28<00:01, 7482.26 examples/s]Filter:  95%|█████████▌| 210000/219950 [00:28<00:01, 7454.01 examples/s]Filter:  96%|█████████▌| 211000/219950 [00:28<00:01, 7465.11 examples/s]Filter:  96%|█████████▋| 212000/219950 [00:28<00:01, 7489.98 examples/s]Filter:  97%|█████████▋| 213000/219950 [00:28<00:00, 7475.63 examples/s]Filter:  97%|█████████▋| 214000/219950 [00:29<00:00, 7439.46 examples/s]Filter:  98%|█████████▊| 215000/219950 [00:29<00:00, 7450.20 examples/s]Filter:  98%|█████████▊| 216000/219950 [00:29<00:00, 7455.81 examples/s]Filter:  99%|█████████▊| 217000/219950 [00:29<00:00, 7452.33 examples/s]Filter:  99%|█████████▉| 218000/219950 [00:29<00:00, 7456.87 examples/s]Filter: 100%|█████████▉| 219000/219950 [00:29<00:00, 7469.87 examples/s]Filter: 100%|██████████| 219950/219950 [00:29<00:00, 7486.95 examples/s]Filter: 100%|██████████| 219950/219950 [00:29<00:00, 7351.06 examples/s]
Filter:   0%|          | 0/413 [00:00<?, ? examples/s]Filter: 100%|██████████| 413/413 [00:00<00:00, 6881.13 examples/s]
2025-04-25 12:19:51,777 - transformer_training - INFO - Converting to tensors...
2025-04-25 12:20:26,744 - transformer_training - INFO - Train Data: torch.Size([219950, 512]), torch.int64
2025-04-25 12:20:26,744 - transformer_training - INFO - Val Data: torch.Size([413, 512]), torch.int64
2025-04-25 12:20:26,744 - transformer_training - INFO - Test Data: torch.Size([478, 512]), torch.int64
2025-04-25 12:20:26,744 - transformer_training - INFO - Vocabulary size: 25000
Train Data: torch.Size([219950, 512]), torch.int64
Val   Data: torch.Size([413, 512]), torch.int64
Test  Data: torch.Size([478, 512]), torch.int64
Vocabulary size: 25000
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Model initialized with 152,194,984 parameters
Total iterations: 10000
Batches per epoch: 3055
2025-04-25 12:20:32,505 - transformer_training - INFO - Main loop iteration: 0
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 0: loss 10.2901, lr 0.001000, 13073.91 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 0: train loss 10.2919, val loss 10.2843
New best model saved with val loss: 10.2843
2025-04-25 12:20:51,867 - transformer_training - INFO - Main loop iteration: 1
2025-04-25 12:20:52,278 - transformer_training - INFO - Main loop iteration: 2
2025-04-25 12:20:52,727 - transformer_training - INFO - Main loop iteration: 3
2025-04-25 12:20:53,330 - transformer_training - INFO - Main loop iteration: 4
2025-04-25 12:20:53,728 - transformer_training - INFO - Main loop iteration: 5
2025-04-25 12:20:54,188 - transformer_training - INFO - Main loop iteration: 6
2025-04-25 12:20:54,637 - transformer_training - INFO - Main loop iteration: 7
2025-04-25 12:20:55,137 - transformer_training - INFO - Main loop iteration: 8
2025-04-25 12:20:55,536 - transformer_training - INFO - Main loop iteration: 9
2025-04-25 12:20:55,995 - transformer_training - INFO - Main loop iteration: 10
Iter 10: loss 9.4831, lr 0.000004, 82139.89 tokens/sec
2025-04-25 12:20:56,445 - transformer_training - INFO - Main loop iteration: 11
2025-04-25 12:20:56,942 - transformer_training - INFO - Main loop iteration: 12
2025-04-25 12:20:57,342 - transformer_training - INFO - Main loop iteration: 13
2025-04-25 12:20:57,802 - transformer_training - INFO - Main loop iteration: 14
2025-04-25 12:20:58,251 - transformer_training - INFO - Main loop iteration: 15
2025-04-25 12:20:58,748 - transformer_training - INFO - Main loop iteration: 16
2025-04-25 12:20:59,148 - transformer_training - INFO - Main loop iteration: 17
2025-04-25 12:20:59,608 - transformer_training - INFO - Main loop iteration: 18
2025-04-25 12:21:00,057 - transformer_training - INFO - Main loop iteration: 19
2025-04-25 12:21:00,554 - transformer_training - INFO - Main loop iteration: 20
Iter 20: loss 9.2355, lr 0.000010, 92224.29 tokens/sec
2025-04-25 12:21:00,954 - transformer_training - INFO - Main loop iteration: 21
2025-04-25 12:21:01,413 - transformer_training - INFO - Main loop iteration: 22
2025-04-25 12:21:01,863 - transformer_training - INFO - Main loop iteration: 23
2025-04-25 12:21:02,362 - transformer_training - INFO - Main loop iteration: 24
2025-04-25 12:21:02,762 - transformer_training - INFO - Main loop iteration: 25
2025-04-25 12:21:03,223 - transformer_training - INFO - Main loop iteration: 26
2025-04-25 12:21:03,672 - transformer_training - INFO - Main loop iteration: 27
2025-04-25 12:21:04,171 - transformer_training - INFO - Main loop iteration: 28
2025-04-25 12:21:04,571 - transformer_training - INFO - Main loop iteration: 29
2025-04-25 12:21:05,032 - transformer_training - INFO - Main loop iteration: 30
Iter 30: loss 9.0863, lr 0.000014, 82039.00 tokens/sec
2025-04-25 12:21:05,482 - transformer_training - INFO - Main loop iteration: 31
2025-04-25 12:21:05,979 - transformer_training - INFO - Main loop iteration: 32
2025-04-25 12:21:06,380 - transformer_training - INFO - Main loop iteration: 33
2025-04-25 12:21:06,839 - transformer_training - INFO - Main loop iteration: 34
2025-04-25 12:21:07,290 - transformer_training - INFO - Main loop iteration: 35
2025-04-25 12:21:07,787 - transformer_training - INFO - Main loop iteration: 36
2025-04-25 12:21:08,187 - transformer_training - INFO - Main loop iteration: 37
2025-04-25 12:21:08,648 - transformer_training - INFO - Main loop iteration: 38
2025-04-25 12:21:09,098 - transformer_training - INFO - Main loop iteration: 39
2025-04-25 12:21:09,596 - transformer_training - INFO - Main loop iteration: 40
Iter 40: loss 8.8927, lr 0.000020, 92105.63 tokens/sec
2025-04-25 12:21:09,997 - transformer_training - INFO - Main loop iteration: 41
2025-04-25 12:21:10,457 - transformer_training - INFO - Main loop iteration: 42
2025-04-25 12:21:10,906 - transformer_training - INFO - Main loop iteration: 43
2025-04-25 12:21:11,405 - transformer_training - INFO - Main loop iteration: 44
2025-04-25 12:21:11,805 - transformer_training - INFO - Main loop iteration: 45
2025-04-25 12:21:12,265 - transformer_training - INFO - Main loop iteration: 46
2025-04-25 12:21:12,716 - transformer_training - INFO - Main loop iteration: 47
2025-04-25 12:21:13,214 - transformer_training - INFO - Main loop iteration: 48
2025-04-25 12:21:13,614 - transformer_training - INFO - Main loop iteration: 49
2025-04-25 12:21:14,075 - transformer_training - INFO - Main loop iteration: 50
Iter 50: loss 8.8050, lr 0.000024, 82051.97 tokens/sec
2025-04-25 12:21:14,525 - transformer_training - INFO - Main loop iteration: 51
2025-04-25 12:21:15,023 - transformer_training - INFO - Main loop iteration: 52
2025-04-25 12:21:15,423 - transformer_training - INFO - Main loop iteration: 53
2025-04-25 12:21:15,883 - transformer_training - INFO - Main loop iteration: 54
2025-04-25 12:21:16,333 - transformer_training - INFO - Main loop iteration: 55
2025-04-25 12:21:16,832 - transformer_training - INFO - Main loop iteration: 56
2025-04-25 12:21:17,233 - transformer_training - INFO - Main loop iteration: 57
2025-04-25 12:21:17,693 - transformer_training - INFO - Main loop iteration: 58
2025-04-25 12:21:18,143 - transformer_training - INFO - Main loop iteration: 59
2025-04-25 12:21:18,641 - transformer_training - INFO - Main loop iteration: 60
Iter 60: loss 8.7092, lr 0.000030, 92202.18 tokens/sec
2025-04-25 12:21:19,041 - transformer_training - INFO - Main loop iteration: 61
2025-04-25 12:21:19,501 - transformer_training - INFO - Main loop iteration: 62
2025-04-25 12:21:19,951 - transformer_training - INFO - Main loop iteration: 63
2025-04-25 12:21:20,450 - transformer_training - INFO - Main loop iteration: 64
2025-04-25 12:21:20,850 - transformer_training - INFO - Main loop iteration: 65
2025-04-25 12:21:21,312 - transformer_training - INFO - Main loop iteration: 66
2025-04-25 12:21:21,768 - transformer_training - INFO - Main loop iteration: 67
2025-04-25 12:21:22,267 - transformer_training - INFO - Main loop iteration: 68
2025-04-25 12:21:22,668 - transformer_training - INFO - Main loop iteration: 69
2025-04-25 12:21:23,129 - transformer_training - INFO - Main loop iteration: 70
Iter 70: loss 8.6454, lr 0.000034, 81853.94 tokens/sec
2025-04-25 12:21:23,580 - transformer_training - INFO - Main loop iteration: 71
2025-04-25 12:21:24,079 - transformer_training - INFO - Main loop iteration: 72
2025-04-25 12:21:24,480 - transformer_training - INFO - Main loop iteration: 73
2025-04-25 12:21:24,940 - transformer_training - INFO - Main loop iteration: 74
2025-04-25 12:21:25,390 - transformer_training - INFO - Main loop iteration: 75
2025-04-25 12:21:25,889 - transformer_training - INFO - Main loop iteration: 76
2025-04-25 12:21:26,290 - transformer_training - INFO - Main loop iteration: 77
2025-04-25 12:21:26,751 - transformer_training - INFO - Main loop iteration: 78
2025-04-25 12:21:27,201 - transformer_training - INFO - Main loop iteration: 79
2025-04-25 12:21:27,700 - transformer_training - INFO - Main loop iteration: 80
Iter 80: loss 8.5866, lr 0.000040, 91981.69 tokens/sec
2025-04-25 12:21:28,101 - transformer_training - INFO - Main loop iteration: 81
2025-04-25 12:21:28,562 - transformer_training - INFO - Main loop iteration: 82
2025-04-25 12:21:29,012 - transformer_training - INFO - Main loop iteration: 83
2025-04-25 12:21:29,511 - transformer_training - INFO - Main loop iteration: 84
2025-04-25 12:21:29,911 - transformer_training - INFO - Main loop iteration: 85
2025-04-25 12:21:30,372 - transformer_training - INFO - Main loop iteration: 86
2025-04-25 12:21:30,822 - transformer_training - INFO - Main loop iteration: 87
2025-04-25 12:21:31,320 - transformer_training - INFO - Main loop iteration: 88
2025-04-25 12:21:31,721 - transformer_training - INFO - Main loop iteration: 89
2025-04-25 12:21:32,182 - transformer_training - INFO - Main loop iteration: 90
Iter 90: loss 8.5151, lr 0.000044, 81811.41 tokens/sec
2025-04-25 12:21:32,633 - transformer_training - INFO - Main loop iteration: 91
2025-04-25 12:21:33,132 - transformer_training - INFO - Main loop iteration: 92
2025-04-25 12:21:33,533 - transformer_training - INFO - Main loop iteration: 93
2025-04-25 12:21:33,993 - transformer_training - INFO - Main loop iteration: 94
2025-04-25 12:21:34,443 - transformer_training - INFO - Main loop iteration: 95
2025-04-25 12:21:34,941 - transformer_training - INFO - Main loop iteration: 96
2025-04-25 12:21:35,342 - transformer_training - INFO - Main loop iteration: 97
2025-04-25 12:21:35,802 - transformer_training - INFO - Main loop iteration: 98
2025-04-25 12:21:36,252 - transformer_training - INFO - Main loop iteration: 99
2025-04-25 12:21:36,751 - transformer_training - INFO - Main loop iteration: 100
Iter 100: loss 8.4652, lr 0.000050, 91984.64 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 100: train loss 8.3930, val loss 8.3877
New best model saved with val loss: 8.3877
2025-04-25 12:21:55,027 - transformer_training - INFO - Main loop iteration: 101
2025-04-25 12:21:55,441 - transformer_training - INFO - Main loop iteration: 102
2025-04-25 12:21:55,890 - transformer_training - INFO - Main loop iteration: 103
2025-04-25 12:21:56,387 - transformer_training - INFO - Main loop iteration: 104
2025-04-25 12:21:56,788 - transformer_training - INFO - Main loop iteration: 105
2025-04-25 12:21:57,248 - transformer_training - INFO - Main loop iteration: 106
2025-04-25 12:21:57,697 - transformer_training - INFO - Main loop iteration: 107
2025-04-25 12:21:58,196 - transformer_training - INFO - Main loop iteration: 108
2025-04-25 12:21:58,597 - transformer_training - INFO - Main loop iteration: 109
2025-04-25 12:21:59,057 - transformer_training - INFO - Main loop iteration: 110
Iter 110: loss 8.3665, lr 0.000054, 82127.90 tokens/sec
2025-04-25 12:21:59,506 - transformer_training - INFO - Main loop iteration: 111
2025-04-25 12:22:00,005 - transformer_training - INFO - Main loop iteration: 112
2025-04-25 12:22:00,405 - transformer_training - INFO - Main loop iteration: 113
2025-04-25 12:22:00,865 - transformer_training - INFO - Main loop iteration: 114
2025-04-25 12:22:01,315 - transformer_training - INFO - Main loop iteration: 115
2025-04-25 12:22:01,812 - transformer_training - INFO - Main loop iteration: 116
2025-04-25 12:22:02,214 - transformer_training - INFO - Main loop iteration: 117
2025-04-25 12:22:02,674 - transformer_training - INFO - Main loop iteration: 118
2025-04-25 12:22:03,123 - transformer_training - INFO - Main loop iteration: 119
2025-04-25 12:22:03,621 - transformer_training - INFO - Main loop iteration: 120
Iter 120: loss 8.2894, lr 0.000060, 92070.53 tokens/sec
2025-04-25 12:22:04,022 - transformer_training - INFO - Main loop iteration: 121
2025-04-25 12:22:04,481 - transformer_training - INFO - Main loop iteration: 122
2025-04-25 12:22:04,930 - transformer_training - INFO - Main loop iteration: 123
2025-04-25 12:22:05,428 - transformer_training - INFO - Main loop iteration: 124
2025-04-25 12:22:05,829 - transformer_training - INFO - Main loop iteration: 125
2025-04-25 12:22:06,289 - transformer_training - INFO - Main loop iteration: 126
2025-04-25 12:22:06,739 - transformer_training - INFO - Main loop iteration: 127
2025-04-25 12:22:07,236 - transformer_training - INFO - Main loop iteration: 128
2025-04-25 12:22:07,637 - transformer_training - INFO - Main loop iteration: 129
2025-04-25 12:22:08,098 - transformer_training - INFO - Main loop iteration: 130
Iter 130: loss 8.2218, lr 0.000064, 82068.13 tokens/sec
2025-04-25 12:22:08,547 - transformer_training - INFO - Main loop iteration: 131
2025-04-25 12:22:09,045 - transformer_training - INFO - Main loop iteration: 132
2025-04-25 12:22:09,446 - transformer_training - INFO - Main loop iteration: 133
2025-04-25 12:22:09,906 - transformer_training - INFO - Main loop iteration: 134
2025-04-25 12:22:10,355 - transformer_training - INFO - Main loop iteration: 135
2025-04-25 12:22:10,854 - transformer_training - INFO - Main loop iteration: 136
2025-04-25 12:22:11,254 - transformer_training - INFO - Main loop iteration: 137
2025-04-25 12:22:11,716 - transformer_training - INFO - Main loop iteration: 138
2025-04-25 12:22:12,165 - transformer_training - INFO - Main loop iteration: 139
2025-04-25 12:22:12,665 - transformer_training - INFO - Main loop iteration: 140
Iter 140: loss 8.0604, lr 0.000070, 91852.46 tokens/sec
2025-04-25 12:22:13,067 - transformer_training - INFO - Main loop iteration: 141
2025-04-25 12:22:13,527 - transformer_training - INFO - Main loop iteration: 142
2025-04-25 12:22:13,977 - transformer_training - INFO - Main loop iteration: 143
2025-04-25 12:22:14,476 - transformer_training - INFO - Main loop iteration: 144
2025-04-25 12:22:14,877 - transformer_training - INFO - Main loop iteration: 145
2025-04-25 12:22:15,338 - transformer_training - INFO - Main loop iteration: 146
2025-04-25 12:22:15,788 - transformer_training - INFO - Main loop iteration: 147
2025-04-25 12:22:16,286 - transformer_training - INFO - Main loop iteration: 148
2025-04-25 12:22:16,687 - transformer_training - INFO - Main loop iteration: 149
2025-04-25 12:22:17,148 - transformer_training - INFO - Main loop iteration: 150
Iter 150: loss 8.0255, lr 0.000074, 81930.28 tokens/sec
2025-04-25 12:22:17,598 - transformer_training - INFO - Main loop iteration: 151
2025-04-25 12:22:18,097 - transformer_training - INFO - Main loop iteration: 152
2025-04-25 12:22:18,498 - transformer_training - INFO - Main loop iteration: 153
2025-04-25 12:22:18,959 - transformer_training - INFO - Main loop iteration: 154
2025-04-25 12:22:19,409 - transformer_training - INFO - Main loop iteration: 155
2025-04-25 12:22:19,907 - transformer_training - INFO - Main loop iteration: 156
2025-04-25 12:22:20,307 - transformer_training - INFO - Main loop iteration: 157
2025-04-25 12:22:20,769 - transformer_training - INFO - Main loop iteration: 158
2025-04-25 12:22:21,219 - transformer_training - INFO - Main loop iteration: 159
2025-04-25 12:22:21,718 - transformer_training - INFO - Main loop iteration: 160
Iter 160: loss 7.9637, lr 0.000080, 92048.38 tokens/sec
2025-04-25 12:22:22,119 - transformer_training - INFO - Main loop iteration: 161
2025-04-25 12:22:22,579 - transformer_training - INFO - Main loop iteration: 162
2025-04-25 12:22:23,029 - transformer_training - INFO - Main loop iteration: 163
2025-04-25 12:22:23,529 - transformer_training - INFO - Main loop iteration: 164
2025-04-25 12:22:23,930 - transformer_training - INFO - Main loop iteration: 165
2025-04-25 12:22:24,391 - transformer_training - INFO - Main loop iteration: 166
2025-04-25 12:22:24,841 - transformer_training - INFO - Main loop iteration: 167
2025-04-25 12:22:25,339 - transformer_training - INFO - Main loop iteration: 168
2025-04-25 12:22:25,740 - transformer_training - INFO - Main loop iteration: 169
2025-04-25 12:22:26,201 - transformer_training - INFO - Main loop iteration: 170
Iter 170: loss 7.8612, lr 0.000084, 81917.17 tokens/sec
2025-04-25 12:22:26,651 - transformer_training - INFO - Main loop iteration: 171
2025-04-25 12:22:27,149 - transformer_training - INFO - Main loop iteration: 172
2025-04-25 12:22:27,551 - transformer_training - INFO - Main loop iteration: 173
2025-04-25 12:22:28,011 - transformer_training - INFO - Main loop iteration: 174
2025-04-25 12:22:28,462 - transformer_training - INFO - Main loop iteration: 175
2025-04-25 12:22:28,960 - transformer_training - INFO - Main loop iteration: 176
2025-04-25 12:22:29,361 - transformer_training - INFO - Main loop iteration: 177
2025-04-25 12:22:29,821 - transformer_training - INFO - Main loop iteration: 178
2025-04-25 12:22:30,271 - transformer_training - INFO - Main loop iteration: 179
2025-04-25 12:22:30,769 - transformer_training - INFO - Main loop iteration: 180
Iter 180: loss 7.7365, lr 0.000090, 92112.76 tokens/sec
2025-04-25 12:22:31,170 - transformer_training - INFO - Main loop iteration: 181
2025-04-25 12:22:31,630 - transformer_training - INFO - Main loop iteration: 182
2025-04-25 12:22:32,080 - transformer_training - INFO - Main loop iteration: 183
2025-04-25 12:22:32,590 - transformer_training - INFO - Main loop iteration: 184
2025-04-25 12:22:32,997 - transformer_training - INFO - Main loop iteration: 185
2025-04-25 12:22:33,459 - transformer_training - INFO - Main loop iteration: 186
2025-04-25 12:22:33,910 - transformer_training - INFO - Main loop iteration: 187
2025-04-25 12:22:34,409 - transformer_training - INFO - Main loop iteration: 188
2025-04-25 12:22:34,810 - transformer_training - INFO - Main loop iteration: 189
2025-04-25 12:22:35,271 - transformer_training - INFO - Main loop iteration: 190
Iter 190: loss 7.6698, lr 0.000094, 81917.30 tokens/sec
2025-04-25 12:22:35,721 - transformer_training - INFO - Main loop iteration: 191
2025-04-25 12:22:36,219 - transformer_training - INFO - Main loop iteration: 192
2025-04-25 12:22:36,620 - transformer_training - INFO - Main loop iteration: 193
2025-04-25 12:22:37,080 - transformer_training - INFO - Main loop iteration: 194
2025-04-25 12:22:37,531 - transformer_training - INFO - Main loop iteration: 195
2025-04-25 12:22:38,028 - transformer_training - INFO - Main loop iteration: 196
2025-04-25 12:22:38,429 - transformer_training - INFO - Main loop iteration: 197
2025-04-25 12:22:38,890 - transformer_training - INFO - Main loop iteration: 198
2025-04-25 12:22:39,340 - transformer_training - INFO - Main loop iteration: 199
2025-04-25 12:22:39,839 - transformer_training - INFO - Main loop iteration: 200
Iter 200: loss 7.5944, lr 0.000100, 91972.77 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 200: train loss 7.5404, val loss 7.5202
New best model saved with val loss: 7.5202
2025-04-25 12:22:57,859 - transformer_training - INFO - Main loop iteration: 201
2025-04-25 12:22:58,277 - transformer_training - INFO - Main loop iteration: 202
2025-04-25 12:22:58,725 - transformer_training - INFO - Main loop iteration: 203
2025-04-25 12:22:59,223 - transformer_training - INFO - Main loop iteration: 204
2025-04-25 12:22:59,623 - transformer_training - INFO - Main loop iteration: 205
2025-04-25 12:23:00,083 - transformer_training - INFO - Main loop iteration: 206
2025-04-25 12:23:00,533 - transformer_training - INFO - Main loop iteration: 207
2025-04-25 12:23:01,031 - transformer_training - INFO - Main loop iteration: 208
2025-04-25 12:23:01,432 - transformer_training - INFO - Main loop iteration: 209
2025-04-25 12:23:01,893 - transformer_training - INFO - Main loop iteration: 210
Iter 210: loss 7.5078, lr 0.000104, 81996.45 tokens/sec
2025-04-25 12:23:02,343 - transformer_training - INFO - Main loop iteration: 211
2025-04-25 12:23:02,843 - transformer_training - INFO - Main loop iteration: 212
2025-04-25 12:23:03,244 - transformer_training - INFO - Main loop iteration: 213
2025-04-25 12:23:03,704 - transformer_training - INFO - Main loop iteration: 214
2025-04-25 12:23:04,154 - transformer_training - INFO - Main loop iteration: 215
2025-04-25 12:23:04,652 - transformer_training - INFO - Main loop iteration: 216
2025-04-25 12:23:05,053 - transformer_training - INFO - Main loop iteration: 217
2025-04-25 12:23:05,513 - transformer_training - INFO - Main loop iteration: 218
2025-04-25 12:23:05,964 - transformer_training - INFO - Main loop iteration: 219
2025-04-25 12:23:06,462 - transformer_training - INFO - Main loop iteration: 220
Iter 220: loss 7.3850, lr 0.000110, 91992.41 tokens/sec
2025-04-25 12:23:06,863 - transformer_training - INFO - Main loop iteration: 221
2025-04-25 12:23:07,323 - transformer_training - INFO - Main loop iteration: 222
2025-04-25 12:23:07,773 - transformer_training - INFO - Main loop iteration: 223
2025-04-25 12:23:08,272 - transformer_training - INFO - Main loop iteration: 224
2025-04-25 12:23:08,673 - transformer_training - INFO - Main loop iteration: 225
2025-04-25 12:23:09,133 - transformer_training - INFO - Main loop iteration: 226
2025-04-25 12:23:09,583 - transformer_training - INFO - Main loop iteration: 227
2025-04-25 12:23:10,082 - transformer_training - INFO - Main loop iteration: 228
2025-04-25 12:23:10,483 - transformer_training - INFO - Main loop iteration: 229
2025-04-25 12:23:10,943 - transformer_training - INFO - Main loop iteration: 230
Iter 230: loss 7.3369, lr 0.000114, 81974.63 tokens/sec
2025-04-25 12:23:11,393 - transformer_training - INFO - Main loop iteration: 231
2025-04-25 12:23:11,892 - transformer_training - INFO - Main loop iteration: 232
2025-04-25 12:23:12,292 - transformer_training - INFO - Main loop iteration: 233
2025-04-25 12:23:12,753 - transformer_training - INFO - Main loop iteration: 234
2025-04-25 12:23:13,203 - transformer_training - INFO - Main loop iteration: 235
2025-04-25 12:23:13,702 - transformer_training - INFO - Main loop iteration: 236
2025-04-25 12:23:14,102 - transformer_training - INFO - Main loop iteration: 237
2025-04-25 12:23:14,563 - transformer_training - INFO - Main loop iteration: 238
2025-04-25 12:23:15,013 - transformer_training - INFO - Main loop iteration: 239
2025-04-25 12:23:15,511 - transformer_training - INFO - Main loop iteration: 240
Iter 240: loss 7.3394, lr 0.000120, 92077.22 tokens/sec
2025-04-25 12:23:15,912 - transformer_training - INFO - Main loop iteration: 241
2025-04-25 12:23:16,372 - transformer_training - INFO - Main loop iteration: 242
2025-04-25 12:23:16,822 - transformer_training - INFO - Main loop iteration: 243
2025-04-25 12:23:17,320 - transformer_training - INFO - Main loop iteration: 244
2025-04-25 12:23:17,721 - transformer_training - INFO - Main loop iteration: 245
2025-04-25 12:23:18,181 - transformer_training - INFO - Main loop iteration: 246
2025-04-25 12:23:18,632 - transformer_training - INFO - Main loop iteration: 247
2025-04-25 12:23:19,130 - transformer_training - INFO - Main loop iteration: 248
2025-04-25 12:23:19,530 - transformer_training - INFO - Main loop iteration: 249
2025-04-25 12:23:19,991 - transformer_training - INFO - Main loop iteration: 250
Iter 250: loss 7.2503, lr 0.000124, 81989.80 tokens/sec
2025-04-25 12:23:20,441 - transformer_training - INFO - Main loop iteration: 251
2025-04-25 12:23:20,939 - transformer_training - INFO - Main loop iteration: 252
2025-04-25 12:23:21,340 - transformer_training - INFO - Main loop iteration: 253
2025-04-25 12:23:21,800 - transformer_training - INFO - Main loop iteration: 254
2025-04-25 12:23:22,251 - transformer_training - INFO - Main loop iteration: 255
2025-04-25 12:23:22,749 - transformer_training - INFO - Main loop iteration: 256
2025-04-25 12:23:23,150 - transformer_training - INFO - Main loop iteration: 257
2025-04-25 12:23:23,610 - transformer_training - INFO - Main loop iteration: 258
2025-04-25 12:23:24,061 - transformer_training - INFO - Main loop iteration: 259
2025-04-25 12:23:24,666 - transformer_training - INFO - Main loop iteration: 260
Iter 260: loss 7.2589, lr 0.000130, 92167.34 tokens/sec
2025-04-25 12:23:25,067 - transformer_training - INFO - Main loop iteration: 261
2025-04-25 12:23:25,527 - transformer_training - INFO - Main loop iteration: 262
2025-04-25 12:23:25,977 - transformer_training - INFO - Main loop iteration: 263
2025-04-25 12:23:26,475 - transformer_training - INFO - Main loop iteration: 264
2025-04-25 12:23:26,876 - transformer_training - INFO - Main loop iteration: 265
2025-04-25 12:23:27,336 - transformer_training - INFO - Main loop iteration: 266
2025-04-25 12:23:27,786 - transformer_training - INFO - Main loop iteration: 267
2025-04-25 12:23:28,285 - transformer_training - INFO - Main loop iteration: 268
2025-04-25 12:23:28,686 - transformer_training - INFO - Main loop iteration: 269
2025-04-25 12:23:29,146 - transformer_training - INFO - Main loop iteration: 270
Iter 270: loss 7.2533, lr 0.000134, 82005.93 tokens/sec
2025-04-25 12:23:29,596 - transformer_training - INFO - Main loop iteration: 271
2025-04-25 12:23:30,094 - transformer_training - INFO - Main loop iteration: 272
2025-04-25 12:23:30,495 - transformer_training - INFO - Main loop iteration: 273
2025-04-25 12:23:30,956 - transformer_training - INFO - Main loop iteration: 274
2025-04-25 12:23:31,405 - transformer_training - INFO - Main loop iteration: 275
2025-04-25 12:23:31,904 - transformer_training - INFO - Main loop iteration: 276
2025-04-25 12:23:32,305 - transformer_training - INFO - Main loop iteration: 277
2025-04-25 12:23:32,766 - transformer_training - INFO - Main loop iteration: 278
2025-04-25 12:23:33,216 - transformer_training - INFO - Main loop iteration: 279
2025-04-25 12:23:33,715 - transformer_training - INFO - Main loop iteration: 280
Iter 280: loss 7.1630, lr 0.000140, 91972.33 tokens/sec
2025-04-25 12:23:34,116 - transformer_training - INFO - Main loop iteration: 281
2025-04-25 12:23:34,577 - transformer_training - INFO - Main loop iteration: 282
2025-04-25 12:23:35,026 - transformer_training - INFO - Main loop iteration: 283
2025-04-25 12:23:35,525 - transformer_training - INFO - Main loop iteration: 284
2025-04-25 12:23:35,926 - transformer_training - INFO - Main loop iteration: 285
2025-04-25 12:23:36,387 - transformer_training - INFO - Main loop iteration: 286
2025-04-25 12:23:36,838 - transformer_training - INFO - Main loop iteration: 287
2025-04-25 12:23:37,336 - transformer_training - INFO - Main loop iteration: 288
2025-04-25 12:23:37,737 - transformer_training - INFO - Main loop iteration: 289
2025-04-25 12:23:38,198 - transformer_training - INFO - Main loop iteration: 290
Iter 290: loss 7.0848, lr 0.000144, 81912.48 tokens/sec
2025-04-25 12:23:38,649 - transformer_training - INFO - Main loop iteration: 291
2025-04-25 12:23:39,147 - transformer_training - INFO - Main loop iteration: 292
2025-04-25 12:23:39,548 - transformer_training - INFO - Main loop iteration: 293
2025-04-25 12:23:40,009 - transformer_training - INFO - Main loop iteration: 294
2025-04-25 12:23:40,459 - transformer_training - INFO - Main loop iteration: 295
2025-04-25 12:23:40,957 - transformer_training - INFO - Main loop iteration: 296
2025-04-25 12:23:41,358 - transformer_training - INFO - Main loop iteration: 297
2025-04-25 12:23:41,818 - transformer_training - INFO - Main loop iteration: 298
2025-04-25 12:23:42,269 - transformer_training - INFO - Main loop iteration: 299
2025-04-25 12:23:42,769 - transformer_training - INFO - Main loop iteration: 300
Iter 300: loss 7.0884, lr 0.000150, 92042.03 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 300: train loss 7.0748, val loss 7.0634
New best model saved with val loss: 7.0634
2025-04-25 12:24:00,387 - transformer_training - INFO - Main loop iteration: 301
2025-04-25 12:24:00,866 - transformer_training - INFO - Main loop iteration: 302
2025-04-25 12:24:01,279 - transformer_training - INFO - Main loop iteration: 303
2025-04-25 12:24:01,778 - transformer_training - INFO - Main loop iteration: 304
2025-04-25 12:24:02,178 - transformer_training - INFO - Main loop iteration: 305
2025-04-25 12:24:02,638 - transformer_training - INFO - Main loop iteration: 306
2025-04-25 12:24:03,088 - transformer_training - INFO - Main loop iteration: 307
2025-04-25 12:24:03,586 - transformer_training - INFO - Main loop iteration: 308
2025-04-25 12:24:03,987 - transformer_training - INFO - Main loop iteration: 309
2025-04-25 12:24:04,448 - transformer_training - INFO - Main loop iteration: 310
Iter 310: loss 7.1359, lr 0.000154, 82015.85 tokens/sec
2025-04-25 12:24:04,898 - transformer_training - INFO - Main loop iteration: 311
2025-04-25 12:24:05,397 - transformer_training - INFO - Main loop iteration: 312
2025-04-25 12:24:05,797 - transformer_training - INFO - Main loop iteration: 313
2025-04-25 12:24:06,258 - transformer_training - INFO - Main loop iteration: 314
2025-04-25 12:24:06,708 - transformer_training - INFO - Main loop iteration: 315
2025-04-25 12:24:07,206 - transformer_training - INFO - Main loop iteration: 316
2025-04-25 12:24:07,607 - transformer_training - INFO - Main loop iteration: 317
2025-04-25 12:24:08,067 - transformer_training - INFO - Main loop iteration: 318
2025-04-25 12:24:08,518 - transformer_training - INFO - Main loop iteration: 319
2025-04-25 12:24:09,016 - transformer_training - INFO - Main loop iteration: 320
Iter 320: loss 7.0358, lr 0.000160, 92072.39 tokens/sec
2025-04-25 12:24:09,417 - transformer_training - INFO - Main loop iteration: 321
2025-04-25 12:24:09,878 - transformer_training - INFO - Main loop iteration: 322
2025-04-25 12:24:10,328 - transformer_training - INFO - Main loop iteration: 323
2025-04-25 12:24:10,827 - transformer_training - INFO - Main loop iteration: 324
2025-04-25 12:24:11,227 - transformer_training - INFO - Main loop iteration: 325
2025-04-25 12:24:11,688 - transformer_training - INFO - Main loop iteration: 326
2025-04-25 12:24:12,138 - transformer_training - INFO - Main loop iteration: 327
2025-04-25 12:24:12,636 - transformer_training - INFO - Main loop iteration: 328
2025-04-25 12:24:13,037 - transformer_training - INFO - Main loop iteration: 329
2025-04-25 12:24:13,498 - transformer_training - INFO - Main loop iteration: 330
Iter 330: loss 6.9883, lr 0.000164, 81967.63 tokens/sec
2025-04-25 12:24:13,948 - transformer_training - INFO - Main loop iteration: 331
2025-04-25 12:24:14,448 - transformer_training - INFO - Main loop iteration: 332
2025-04-25 12:24:14,848 - transformer_training - INFO - Main loop iteration: 333
2025-04-25 12:24:15,309 - transformer_training - INFO - Main loop iteration: 334
2025-04-25 12:24:15,760 - transformer_training - INFO - Main loop iteration: 335
2025-04-25 12:24:16,259 - transformer_training - INFO - Main loop iteration: 336
2025-04-25 12:24:16,660 - transformer_training - INFO - Main loop iteration: 337
2025-04-25 12:24:17,121 - transformer_training - INFO - Main loop iteration: 338
2025-04-25 12:24:17,571 - transformer_training - INFO - Main loop iteration: 339
2025-04-25 12:24:18,070 - transformer_training - INFO - Main loop iteration: 340
Iter 340: loss 6.9834, lr 0.000170, 91985.79 tokens/sec
2025-04-25 12:24:18,471 - transformer_training - INFO - Main loop iteration: 341
2025-04-25 12:24:18,932 - transformer_training - INFO - Main loop iteration: 342
2025-04-25 12:24:19,383 - transformer_training - INFO - Main loop iteration: 343
2025-04-25 12:24:19,881 - transformer_training - INFO - Main loop iteration: 344
2025-04-25 12:24:20,282 - transformer_training - INFO - Main loop iteration: 345
2025-04-25 12:24:20,743 - transformer_training - INFO - Main loop iteration: 346
2025-04-25 12:24:21,193 - transformer_training - INFO - Main loop iteration: 347
2025-04-25 12:24:21,692 - transformer_training - INFO - Main loop iteration: 348
2025-04-25 12:24:22,093 - transformer_training - INFO - Main loop iteration: 349
2025-04-25 12:24:22,554 - transformer_training - INFO - Main loop iteration: 350
Iter 350: loss 6.9263, lr 0.000174, 81880.34 tokens/sec
2025-04-25 12:24:23,004 - transformer_training - INFO - Main loop iteration: 351
2025-04-25 12:24:23,503 - transformer_training - INFO - Main loop iteration: 352
2025-04-25 12:24:23,904 - transformer_training - INFO - Main loop iteration: 353
2025-04-25 12:24:24,366 - transformer_training - INFO - Main loop iteration: 354
2025-04-25 12:24:24,820 - transformer_training - INFO - Main loop iteration: 355
2025-04-25 12:24:25,319 - transformer_training - INFO - Main loop iteration: 356
2025-04-25 12:24:25,720 - transformer_training - INFO - Main loop iteration: 357
2025-04-25 12:24:26,182 - transformer_training - INFO - Main loop iteration: 358
2025-04-25 12:24:26,632 - transformer_training - INFO - Main loop iteration: 359
2025-04-25 12:24:27,131 - transformer_training - INFO - Main loop iteration: 360
Iter 360: loss 6.8938, lr 0.000180, 91882.91 tokens/sec
2025-04-25 12:24:27,533 - transformer_training - INFO - Main loop iteration: 361
2025-04-25 12:24:27,993 - transformer_training - INFO - Main loop iteration: 362
2025-04-25 12:24:28,444 - transformer_training - INFO - Main loop iteration: 363
2025-04-25 12:24:28,943 - transformer_training - INFO - Main loop iteration: 364
2025-04-25 12:24:29,345 - transformer_training - INFO - Main loop iteration: 365
2025-04-25 12:24:29,806 - transformer_training - INFO - Main loop iteration: 366
2025-04-25 12:24:30,258 - transformer_training - INFO - Main loop iteration: 367
2025-04-25 12:24:30,756 - transformer_training - INFO - Main loop iteration: 368
2025-04-25 12:24:31,157 - transformer_training - INFO - Main loop iteration: 369
2025-04-25 12:24:31,618 - transformer_training - INFO - Main loop iteration: 370
Iter 370: loss 6.8571, lr 0.000184, 81921.47 tokens/sec
2025-04-25 12:24:32,069 - transformer_training - INFO - Main loop iteration: 371
2025-04-25 12:24:32,567 - transformer_training - INFO - Main loop iteration: 372
2025-04-25 12:24:32,969 - transformer_training - INFO - Main loop iteration: 373
2025-04-25 12:24:33,429 - transformer_training - INFO - Main loop iteration: 374
2025-04-25 12:24:33,880 - transformer_training - INFO - Main loop iteration: 375
2025-04-25 12:24:34,380 - transformer_training - INFO - Main loop iteration: 376
2025-04-25 12:24:34,781 - transformer_training - INFO - Main loop iteration: 377
2025-04-25 12:24:35,242 - transformer_training - INFO - Main loop iteration: 378
2025-04-25 12:24:35,693 - transformer_training - INFO - Main loop iteration: 379
2025-04-25 12:24:36,192 - transformer_training - INFO - Main loop iteration: 380
Iter 380: loss 6.8708, lr 0.000190, 91764.42 tokens/sec
2025-04-25 12:24:36,594 - transformer_training - INFO - Main loop iteration: 381
2025-04-25 12:24:37,055 - transformer_training - INFO - Main loop iteration: 382
2025-04-25 12:24:37,506 - transformer_training - INFO - Main loop iteration: 383
2025-04-25 12:24:38,005 - transformer_training - INFO - Main loop iteration: 384
2025-04-25 12:24:38,406 - transformer_training - INFO - Main loop iteration: 385
2025-04-25 12:24:38,867 - transformer_training - INFO - Main loop iteration: 386
2025-04-25 12:24:39,317 - transformer_training - INFO - Main loop iteration: 387
2025-04-25 12:24:39,816 - transformer_training - INFO - Main loop iteration: 388
2025-04-25 12:24:40,217 - transformer_training - INFO - Main loop iteration: 389
2025-04-25 12:24:40,678 - transformer_training - INFO - Main loop iteration: 390
Iter 390: loss 6.7949, lr 0.000194, 81871.58 tokens/sec
2025-04-25 12:24:41,129 - transformer_training - INFO - Main loop iteration: 391
2025-04-25 12:24:41,628 - transformer_training - INFO - Main loop iteration: 392
2025-04-25 12:24:42,029 - transformer_training - INFO - Main loop iteration: 393
2025-04-25 12:24:42,490 - transformer_training - INFO - Main loop iteration: 394
2025-04-25 12:24:42,941 - transformer_training - INFO - Main loop iteration: 395
2025-04-25 12:24:43,440 - transformer_training - INFO - Main loop iteration: 396
2025-04-25 12:24:43,840 - transformer_training - INFO - Main loop iteration: 397
2025-04-25 12:24:44,301 - transformer_training - INFO - Main loop iteration: 398
2025-04-25 12:24:44,752 - transformer_training - INFO - Main loop iteration: 399
2025-04-25 12:24:45,250 - transformer_training - INFO - Main loop iteration: 400
Iter 400: loss 6.7880, lr 0.000200, 92013.60 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 400: train loss 6.7199, val loss 6.7020
New best model saved with val loss: 6.7020
2025-04-25 12:25:03,227 - transformer_training - INFO - Main loop iteration: 401
2025-04-25 12:25:03,645 - transformer_training - INFO - Main loop iteration: 402
2025-04-25 12:25:04,095 - transformer_training - INFO - Main loop iteration: 403
2025-04-25 12:25:04,593 - transformer_training - INFO - Main loop iteration: 404
2025-04-25 12:25:04,993 - transformer_training - INFO - Main loop iteration: 405
2025-04-25 12:25:05,456 - transformer_training - INFO - Main loop iteration: 406
2025-04-25 12:25:05,906 - transformer_training - INFO - Main loop iteration: 407
2025-04-25 12:25:06,404 - transformer_training - INFO - Main loop iteration: 408
2025-04-25 12:25:06,805 - transformer_training - INFO - Main loop iteration: 409
2025-04-25 12:25:07,265 - transformer_training - INFO - Main loop iteration: 410
Iter 410: loss 6.7485, lr 0.000204, 82000.63 tokens/sec
2025-04-25 12:25:07,716 - transformer_training - INFO - Main loop iteration: 411
2025-04-25 12:25:08,214 - transformer_training - INFO - Main loop iteration: 412
2025-04-25 12:25:08,615 - transformer_training - INFO - Main loop iteration: 413
2025-04-25 12:25:09,076 - transformer_training - INFO - Main loop iteration: 414
2025-04-25 12:25:09,526 - transformer_training - INFO - Main loop iteration: 415
2025-04-25 12:25:10,025 - transformer_training - INFO - Main loop iteration: 416
2025-04-25 12:25:10,426 - transformer_training - INFO - Main loop iteration: 417
2025-04-25 12:25:10,887 - transformer_training - INFO - Main loop iteration: 418
2025-04-25 12:25:11,337 - transformer_training - INFO - Main loop iteration: 419
2025-04-25 12:25:11,835 - transformer_training - INFO - Main loop iteration: 420
Iter 420: loss 6.6748, lr 0.000210, 91928.42 tokens/sec
2025-04-25 12:25:12,237 - transformer_training - INFO - Main loop iteration: 421
2025-04-25 12:25:12,698 - transformer_training - INFO - Main loop iteration: 422
2025-04-25 12:25:13,148 - transformer_training - INFO - Main loop iteration: 423
2025-04-25 12:25:13,647 - transformer_training - INFO - Main loop iteration: 424
2025-04-25 12:25:14,047 - transformer_training - INFO - Main loop iteration: 425
2025-04-25 12:25:14,508 - transformer_training - INFO - Main loop iteration: 426
2025-04-25 12:25:14,959 - transformer_training - INFO - Main loop iteration: 427
2025-04-25 12:25:15,457 - transformer_training - INFO - Main loop iteration: 428
2025-04-25 12:25:15,858 - transformer_training - INFO - Main loop iteration: 429
2025-04-25 12:25:16,319 - transformer_training - INFO - Main loop iteration: 430
Iter 430: loss 6.6641, lr 0.000214, 81905.84 tokens/sec
2025-04-25 12:25:16,769 - transformer_training - INFO - Main loop iteration: 431
2025-04-25 12:25:17,267 - transformer_training - INFO - Main loop iteration: 432
2025-04-25 12:25:17,668 - transformer_training - INFO - Main loop iteration: 433
2025-04-25 12:25:18,129 - transformer_training - INFO - Main loop iteration: 434
2025-04-25 12:25:18,580 - transformer_training - INFO - Main loop iteration: 435
2025-04-25 12:25:19,079 - transformer_training - INFO - Main loop iteration: 436
2025-04-25 12:25:19,479 - transformer_training - INFO - Main loop iteration: 437
2025-04-25 12:25:19,940 - transformer_training - INFO - Main loop iteration: 438
2025-04-25 12:25:20,390 - transformer_training - INFO - Main loop iteration: 439
2025-04-25 12:25:20,889 - transformer_training - INFO - Main loop iteration: 440
Iter 440: loss 6.6107, lr 0.000220, 92115.01 tokens/sec
2025-04-25 12:25:21,289 - transformer_training - INFO - Main loop iteration: 441
2025-04-25 12:25:21,750 - transformer_training - INFO - Main loop iteration: 442
2025-04-25 12:25:22,200 - transformer_training - INFO - Main loop iteration: 443
2025-04-25 12:25:22,699 - transformer_training - INFO - Main loop iteration: 444
2025-04-25 12:25:23,100 - transformer_training - INFO - Main loop iteration: 445
2025-04-25 12:25:23,561 - transformer_training - INFO - Main loop iteration: 446
2025-04-25 12:25:24,012 - transformer_training - INFO - Main loop iteration: 447
2025-04-25 12:25:24,511 - transformer_training - INFO - Main loop iteration: 448
2025-04-25 12:25:24,912 - transformer_training - INFO - Main loop iteration: 449
2025-04-25 12:25:25,373 - transformer_training - INFO - Main loop iteration: 450
Iter 450: loss 6.5548, lr 0.000224, 81962.07 tokens/sec
2025-04-25 12:25:25,823 - transformer_training - INFO - Main loop iteration: 451
2025-04-25 12:25:26,322 - transformer_training - INFO - Main loop iteration: 452
2025-04-25 12:25:26,723 - transformer_training - INFO - Main loop iteration: 453
2025-04-25 12:25:27,183 - transformer_training - INFO - Main loop iteration: 454
2025-04-25 12:25:27,634 - transformer_training - INFO - Main loop iteration: 455
2025-04-25 12:25:28,133 - transformer_training - INFO - Main loop iteration: 456
2025-04-25 12:25:28,534 - transformer_training - INFO - Main loop iteration: 457
2025-04-25 12:25:28,996 - transformer_training - INFO - Main loop iteration: 458
2025-04-25 12:25:29,446 - transformer_training - INFO - Main loop iteration: 459
2025-04-25 12:25:29,945 - transformer_training - INFO - Main loop iteration: 460
Iter 460: loss 6.5443, lr 0.000230, 92063.67 tokens/sec
2025-04-25 12:25:30,346 - transformer_training - INFO - Main loop iteration: 461
2025-04-25 12:25:30,807 - transformer_training - INFO - Main loop iteration: 462
2025-04-25 12:25:31,257 - transformer_training - INFO - Main loop iteration: 463
2025-04-25 12:25:31,756 - transformer_training - INFO - Main loop iteration: 464
2025-04-25 12:25:32,160 - transformer_training - INFO - Main loop iteration: 465
2025-04-25 12:25:32,621 - transformer_training - INFO - Main loop iteration: 466
2025-04-25 12:25:33,071 - transformer_training - INFO - Main loop iteration: 467
2025-04-25 12:25:33,570 - transformer_training - INFO - Main loop iteration: 468
2025-04-25 12:25:33,972 - transformer_training - INFO - Main loop iteration: 469
2025-04-25 12:25:34,433 - transformer_training - INFO - Main loop iteration: 470
Iter 470: loss 6.5501, lr 0.000234, 81905.97 tokens/sec
2025-04-25 12:25:34,884 - transformer_training - INFO - Main loop iteration: 471
2025-04-25 12:25:35,382 - transformer_training - INFO - Main loop iteration: 472
2025-04-25 12:25:35,783 - transformer_training - INFO - Main loop iteration: 473
2025-04-25 12:25:36,244 - transformer_training - INFO - Main loop iteration: 474
2025-04-25 12:25:36,695 - transformer_training - INFO - Main loop iteration: 475
2025-04-25 12:25:37,196 - transformer_training - INFO - Main loop iteration: 476
2025-04-25 12:25:37,598 - transformer_training - INFO - Main loop iteration: 477
2025-04-25 12:25:38,059 - transformer_training - INFO - Main loop iteration: 478
2025-04-25 12:25:38,510 - transformer_training - INFO - Main loop iteration: 479
2025-04-25 12:25:39,010 - transformer_training - INFO - Main loop iteration: 480
Iter 480: loss 6.4451, lr 0.000240, 91857.20 tokens/sec
2025-04-25 12:25:39,411 - transformer_training - INFO - Main loop iteration: 481
2025-04-25 12:25:39,873 - transformer_training - INFO - Main loop iteration: 482
2025-04-25 12:25:40,324 - transformer_training - INFO - Main loop iteration: 483
2025-04-25 12:25:40,823 - transformer_training - INFO - Main loop iteration: 484
2025-04-25 12:25:41,224 - transformer_training - INFO - Main loop iteration: 485
2025-04-25 12:25:41,686 - transformer_training - INFO - Main loop iteration: 486
2025-04-25 12:25:42,137 - transformer_training - INFO - Main loop iteration: 487
2025-04-25 12:25:42,636 - transformer_training - INFO - Main loop iteration: 488
2025-04-25 12:25:43,038 - transformer_training - INFO - Main loop iteration: 489
2025-04-25 12:25:43,500 - transformer_training - INFO - Main loop iteration: 490
Iter 490: loss 6.5265, lr 0.000244, 81796.22 tokens/sec
2025-04-25 12:25:43,951 - transformer_training - INFO - Main loop iteration: 491
2025-04-25 12:25:44,450 - transformer_training - INFO - Main loop iteration: 492
2025-04-25 12:25:44,852 - transformer_training - INFO - Main loop iteration: 493
2025-04-25 12:25:45,314 - transformer_training - INFO - Main loop iteration: 494
2025-04-25 12:25:45,764 - transformer_training - INFO - Main loop iteration: 495
2025-04-25 12:25:46,263 - transformer_training - INFO - Main loop iteration: 496
2025-04-25 12:25:46,666 - transformer_training - INFO - Main loop iteration: 497
2025-04-25 12:25:47,127 - transformer_training - INFO - Main loop iteration: 498
2025-04-25 12:25:47,578 - transformer_training - INFO - Main loop iteration: 499
2025-04-25 12:25:48,077 - transformer_training - INFO - Main loop iteration: 500
Iter 500: loss 6.4984, lr 0.000250, 91721.25 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 500: train loss 6.4491, val loss 6.4156
New best model saved with val loss: 6.4156
2025-04-25 12:26:07,606 - transformer_training - INFO - Main loop iteration: 501
2025-04-25 12:26:08,024 - transformer_training - INFO - Main loop iteration: 502
2025-04-25 12:26:08,474 - transformer_training - INFO - Main loop iteration: 503
2025-04-25 12:26:08,973 - transformer_training - INFO - Main loop iteration: 504
2025-04-25 12:26:09,374 - transformer_training - INFO - Main loop iteration: 505
2025-04-25 12:26:09,834 - transformer_training - INFO - Main loop iteration: 506
2025-04-25 12:26:10,284 - transformer_training - INFO - Main loop iteration: 507
2025-04-25 12:26:10,783 - transformer_training - INFO - Main loop iteration: 508
2025-04-25 12:26:11,184 - transformer_training - INFO - Main loop iteration: 509
2025-04-25 12:26:11,644 - transformer_training - INFO - Main loop iteration: 510
Iter 510: loss 6.4673, lr 0.000254, 81681.45 tokens/sec
2025-04-25 12:26:12,096 - transformer_training - INFO - Main loop iteration: 511
2025-04-25 12:26:12,595 - transformer_training - INFO - Main loop iteration: 512
2025-04-25 12:26:12,996 - transformer_training - INFO - Main loop iteration: 513
2025-04-25 12:26:13,456 - transformer_training - INFO - Main loop iteration: 514
2025-04-25 12:26:13,906 - transformer_training - INFO - Main loop iteration: 515
2025-04-25 12:26:14,405 - transformer_training - INFO - Main loop iteration: 516
2025-04-25 12:26:14,805 - transformer_training - INFO - Main loop iteration: 517
2025-04-25 12:26:15,266 - transformer_training - INFO - Main loop iteration: 518
2025-04-25 12:26:15,716 - transformer_training - INFO - Main loop iteration: 519
2025-04-25 12:26:16,217 - transformer_training - INFO - Main loop iteration: 520
Iter 520: loss 6.3680, lr 0.000260, 91927.49 tokens/sec
2025-04-25 12:26:16,618 - transformer_training - INFO - Main loop iteration: 521
2025-04-25 12:26:17,080 - transformer_training - INFO - Main loop iteration: 522
2025-04-25 12:26:17,531 - transformer_training - INFO - Main loop iteration: 523
2025-04-25 12:26:18,030 - transformer_training - INFO - Main loop iteration: 524
2025-04-25 12:26:18,431 - transformer_training - INFO - Main loop iteration: 525
2025-04-25 12:26:18,893 - transformer_training - INFO - Main loop iteration: 526
2025-04-25 12:26:19,343 - transformer_training - INFO - Main loop iteration: 527
2025-04-25 12:26:19,842 - transformer_training - INFO - Main loop iteration: 528
2025-04-25 12:26:20,244 - transformer_training - INFO - Main loop iteration: 529
2025-04-25 12:26:20,705 - transformer_training - INFO - Main loop iteration: 530
Iter 530: loss 6.3515, lr 0.000264, 81901.55 tokens/sec
2025-04-25 12:26:21,155 - transformer_training - INFO - Main loop iteration: 531
2025-04-25 12:26:21,654 - transformer_training - INFO - Main loop iteration: 532
2025-04-25 12:26:22,055 - transformer_training - INFO - Main loop iteration: 533
2025-04-25 12:26:22,516 - transformer_training - INFO - Main loop iteration: 534
2025-04-25 12:26:22,967 - transformer_training - INFO - Main loop iteration: 535
2025-04-25 12:26:23,466 - transformer_training - INFO - Main loop iteration: 536
2025-04-25 12:26:23,868 - transformer_training - INFO - Main loop iteration: 537
2025-04-25 12:26:24,329 - transformer_training - INFO - Main loop iteration: 538
2025-04-25 12:26:24,780 - transformer_training - INFO - Main loop iteration: 539
2025-04-25 12:26:25,279 - transformer_training - INFO - Main loop iteration: 540
Iter 540: loss 6.3303, lr 0.000270, 91766.49 tokens/sec
2025-04-25 12:26:25,682 - transformer_training - INFO - Main loop iteration: 541
2025-04-25 12:26:26,144 - transformer_training - INFO - Main loop iteration: 542
2025-04-25 12:26:26,594 - transformer_training - INFO - Main loop iteration: 543
2025-04-25 12:26:27,094 - transformer_training - INFO - Main loop iteration: 544
2025-04-25 12:26:27,496 - transformer_training - INFO - Main loop iteration: 545
2025-04-25 12:26:27,956 - transformer_training - INFO - Main loop iteration: 546
2025-04-25 12:26:28,407 - transformer_training - INFO - Main loop iteration: 547
2025-04-25 12:26:28,906 - transformer_training - INFO - Main loop iteration: 548
2025-04-25 12:26:29,308 - transformer_training - INFO - Main loop iteration: 549
2025-04-25 12:26:29,769 - transformer_training - INFO - Main loop iteration: 550
Iter 550: loss 6.3877, lr 0.000274, 81721.21 tokens/sec
2025-04-25 12:26:30,221 - transformer_training - INFO - Main loop iteration: 551
2025-04-25 12:26:30,720 - transformer_training - INFO - Main loop iteration: 552
2025-04-25 12:26:31,121 - transformer_training - INFO - Main loop iteration: 553
2025-04-25 12:26:31,583 - transformer_training - INFO - Main loop iteration: 554
2025-04-25 12:26:32,125 - transformer_training - INFO - Main loop iteration: 555
2025-04-25 12:26:32,624 - transformer_training - INFO - Main loop iteration: 556
2025-04-25 12:26:33,026 - transformer_training - INFO - Main loop iteration: 557
2025-04-25 12:26:33,487 - transformer_training - INFO - Main loop iteration: 558
2025-04-25 12:26:33,938 - transformer_training - INFO - Main loop iteration: 559
2025-04-25 12:26:34,438 - transformer_training - INFO - Main loop iteration: 560
Iter 560: loss 6.3668, lr 0.000280, 91869.65 tokens/sec
2025-04-25 12:26:34,840 - transformer_training - INFO - Main loop iteration: 561
2025-04-25 12:26:35,301 - transformer_training - INFO - Main loop iteration: 562
2025-04-25 12:26:35,752 - transformer_training - INFO - Main loop iteration: 563
2025-04-25 12:26:36,251 - transformer_training - INFO - Main loop iteration: 564
2025-04-25 12:26:36,652 - transformer_training - INFO - Main loop iteration: 565
2025-04-25 12:26:37,114 - transformer_training - INFO - Main loop iteration: 566
2025-04-25 12:26:37,565 - transformer_training - INFO - Main loop iteration: 567
2025-04-25 12:26:38,065 - transformer_training - INFO - Main loop iteration: 568
2025-04-25 12:26:38,466 - transformer_training - INFO - Main loop iteration: 569
2025-04-25 12:26:38,928 - transformer_training - INFO - Main loop iteration: 570
Iter 570: loss 6.2547, lr 0.000284, 81822.28 tokens/sec
2025-04-25 12:26:39,379 - transformer_training - INFO - Main loop iteration: 571
2025-04-25 12:26:39,878 - transformer_training - INFO - Main loop iteration: 572
2025-04-25 12:26:40,280 - transformer_training - INFO - Main loop iteration: 573
2025-04-25 12:26:40,741 - transformer_training - INFO - Main loop iteration: 574
2025-04-25 12:26:41,192 - transformer_training - INFO - Main loop iteration: 575
2025-04-25 12:26:41,691 - transformer_training - INFO - Main loop iteration: 576
2025-04-25 12:26:42,093 - transformer_training - INFO - Main loop iteration: 577
2025-04-25 12:26:42,555 - transformer_training - INFO - Main loop iteration: 578
2025-04-25 12:26:43,006 - transformer_training - INFO - Main loop iteration: 579
2025-04-25 12:26:43,506 - transformer_training - INFO - Main loop iteration: 580
Iter 580: loss 6.3267, lr 0.000290, 91819.89 tokens/sec
2025-04-25 12:26:43,908 - transformer_training - INFO - Main loop iteration: 581
2025-04-25 12:26:44,370 - transformer_training - INFO - Main loop iteration: 582
2025-04-25 12:26:44,820 - transformer_training - INFO - Main loop iteration: 583
2025-04-25 12:26:45,320 - transformer_training - INFO - Main loop iteration: 584
2025-04-25 12:26:45,722 - transformer_training - INFO - Main loop iteration: 585
2025-04-25 12:26:46,183 - transformer_training - INFO - Main loop iteration: 586
2025-04-25 12:26:46,634 - transformer_training - INFO - Main loop iteration: 587
2025-04-25 12:26:47,134 - transformer_training - INFO - Main loop iteration: 588
2025-04-25 12:26:47,539 - transformer_training - INFO - Main loop iteration: 589
2025-04-25 12:26:48,000 - transformer_training - INFO - Main loop iteration: 590
Iter 590: loss 6.3049, lr 0.000294, 81752.58 tokens/sec
2025-04-25 12:26:48,452 - transformer_training - INFO - Main loop iteration: 591
2025-04-25 12:26:48,952 - transformer_training - INFO - Main loop iteration: 592
2025-04-25 12:26:49,353 - transformer_training - INFO - Main loop iteration: 593
2025-04-25 12:26:49,814 - transformer_training - INFO - Main loop iteration: 594
2025-04-25 12:26:50,266 - transformer_training - INFO - Main loop iteration: 595
2025-04-25 12:26:50,765 - transformer_training - INFO - Main loop iteration: 596
2025-04-25 12:26:51,167 - transformer_training - INFO - Main loop iteration: 597
2025-04-25 12:26:51,629 - transformer_training - INFO - Main loop iteration: 598
2025-04-25 12:26:52,080 - transformer_training - INFO - Main loop iteration: 599
2025-04-25 12:26:52,579 - transformer_training - INFO - Main loop iteration: 600
Iter 600: loss 6.3070, lr 0.000300, 91717.44 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 600: train loss 6.2521, val loss 6.2183
New best model saved with val loss: 6.2183
2025-04-25 12:27:10,086 - transformer_training - INFO - Main loop iteration: 601
2025-04-25 12:27:10,562 - transformer_training - INFO - Main loop iteration: 602
2025-04-25 12:27:10,974 - transformer_training - INFO - Main loop iteration: 603
2025-04-25 12:27:11,473 - transformer_training - INFO - Main loop iteration: 604
2025-04-25 12:27:11,873 - transformer_training - INFO - Main loop iteration: 605
2025-04-25 12:27:12,334 - transformer_training - INFO - Main loop iteration: 606
2025-04-25 12:27:12,784 - transformer_training - INFO - Main loop iteration: 607
2025-04-25 12:27:13,282 - transformer_training - INFO - Main loop iteration: 608
2025-04-25 12:27:13,682 - transformer_training - INFO - Main loop iteration: 609
2025-04-25 12:27:14,143 - transformer_training - INFO - Main loop iteration: 610
Iter 610: loss 6.2529, lr 0.000304, 81966.76 tokens/sec
2025-04-25 12:27:14,594 - transformer_training - INFO - Main loop iteration: 611
2025-04-25 12:27:15,092 - transformer_training - INFO - Main loop iteration: 612
2025-04-25 12:27:15,492 - transformer_training - INFO - Main loop iteration: 613
2025-04-25 12:27:15,953 - transformer_training - INFO - Main loop iteration: 614
2025-04-25 12:27:16,403 - transformer_training - INFO - Main loop iteration: 615
2025-04-25 12:27:16,902 - transformer_training - INFO - Main loop iteration: 616
2025-04-25 12:27:17,302 - transformer_training - INFO - Main loop iteration: 617
2025-04-25 12:27:17,763 - transformer_training - INFO - Main loop iteration: 618
2025-04-25 12:27:18,213 - transformer_training - INFO - Main loop iteration: 619
2025-04-25 12:27:18,711 - transformer_training - INFO - Main loop iteration: 620
Iter 620: loss 6.2809, lr 0.000310, 92038.19 tokens/sec
2025-04-25 12:27:19,112 - transformer_training - INFO - Main loop iteration: 621
2025-04-25 12:27:19,573 - transformer_training - INFO - Main loop iteration: 622
2025-04-25 12:27:20,023 - transformer_training - INFO - Main loop iteration: 623
2025-04-25 12:27:20,521 - transformer_training - INFO - Main loop iteration: 624
2025-04-25 12:27:20,922 - transformer_training - INFO - Main loop iteration: 625
2025-04-25 12:27:21,383 - transformer_training - INFO - Main loop iteration: 626
2025-04-25 12:27:21,834 - transformer_training - INFO - Main loop iteration: 627
2025-04-25 12:27:22,334 - transformer_training - INFO - Main loop iteration: 628
2025-04-25 12:27:22,734 - transformer_training - INFO - Main loop iteration: 629
2025-04-25 12:27:23,194 - transformer_training - INFO - Main loop iteration: 630
Iter 630: loss 6.2546, lr 0.000314, 81923.59 tokens/sec
2025-04-25 12:27:23,645 - transformer_training - INFO - Main loop iteration: 631
2025-04-25 12:27:24,143 - transformer_training - INFO - Main loop iteration: 632
2025-04-25 12:27:24,544 - transformer_training - INFO - Main loop iteration: 633
2025-04-25 12:27:25,005 - transformer_training - INFO - Main loop iteration: 634
2025-04-25 12:27:25,455 - transformer_training - INFO - Main loop iteration: 635
2025-04-25 12:27:25,955 - transformer_training - INFO - Main loop iteration: 636
2025-04-25 12:27:26,356 - transformer_training - INFO - Main loop iteration: 637
2025-04-25 12:27:26,816 - transformer_training - INFO - Main loop iteration: 638
2025-04-25 12:27:27,267 - transformer_training - INFO - Main loop iteration: 639
2025-04-25 12:27:27,766 - transformer_training - INFO - Main loop iteration: 640
Iter 640: loss 6.2059, lr 0.000320, 92005.99 tokens/sec
2025-04-25 12:27:28,167 - transformer_training - INFO - Main loop iteration: 641
2025-04-25 12:27:28,628 - transformer_training - INFO - Main loop iteration: 642
2025-04-25 12:27:29,078 - transformer_training - INFO - Main loop iteration: 643
2025-04-25 12:27:29,577 - transformer_training - INFO - Main loop iteration: 644
2025-04-25 12:27:29,977 - transformer_training - INFO - Main loop iteration: 645
2025-04-25 12:27:30,438 - transformer_training - INFO - Main loop iteration: 646
2025-04-25 12:27:30,889 - transformer_training - INFO - Main loop iteration: 647
2025-04-25 12:27:31,388 - transformer_training - INFO - Main loop iteration: 648
2025-04-25 12:27:31,789 - transformer_training - INFO - Main loop iteration: 649
2025-04-25 12:27:32,250 - transformer_training - INFO - Main loop iteration: 650
Iter 650: loss 6.1833, lr 0.000324, 81924.07 tokens/sec
2025-04-25 12:27:32,700 - transformer_training - INFO - Main loop iteration: 651
2025-04-25 12:27:33,201 - transformer_training - INFO - Main loop iteration: 652
2025-04-25 12:27:33,602 - transformer_training - INFO - Main loop iteration: 653
2025-04-25 12:27:34,063 - transformer_training - INFO - Main loop iteration: 654
2025-04-25 12:27:34,514 - transformer_training - INFO - Main loop iteration: 655
2025-04-25 12:27:35,014 - transformer_training - INFO - Main loop iteration: 656
2025-04-25 12:27:35,415 - transformer_training - INFO - Main loop iteration: 657
2025-04-25 12:27:35,876 - transformer_training - INFO - Main loop iteration: 658
2025-04-25 12:27:36,326 - transformer_training - INFO - Main loop iteration: 659
2025-04-25 12:27:36,825 - transformer_training - INFO - Main loop iteration: 660
Iter 660: loss 6.1475, lr 0.000330, 92017.87 tokens/sec
2025-04-25 12:27:37,226 - transformer_training - INFO - Main loop iteration: 661
2025-04-25 12:27:37,687 - transformer_training - INFO - Main loop iteration: 662
2025-04-25 12:27:38,137 - transformer_training - INFO - Main loop iteration: 663
2025-04-25 12:27:38,635 - transformer_training - INFO - Main loop iteration: 664
2025-04-25 12:27:39,036 - transformer_training - INFO - Main loop iteration: 665
2025-04-25 12:27:39,497 - transformer_training - INFO - Main loop iteration: 666
2025-04-25 12:27:39,947 - transformer_training - INFO - Main loop iteration: 667
2025-04-25 12:27:40,445 - transformer_training - INFO - Main loop iteration: 668
2025-04-25 12:27:40,847 - transformer_training - INFO - Main loop iteration: 669
2025-04-25 12:27:41,308 - transformer_training - INFO - Main loop iteration: 670
Iter 670: loss 6.2157, lr 0.000334, 81913.87 tokens/sec
2025-04-25 12:27:41,758 - transformer_training - INFO - Main loop iteration: 671
2025-04-25 12:27:42,258 - transformer_training - INFO - Main loop iteration: 672
2025-04-25 12:27:42,658 - transformer_training - INFO - Main loop iteration: 673
2025-04-25 12:27:43,119 - transformer_training - INFO - Main loop iteration: 674
2025-04-25 12:27:43,570 - transformer_training - INFO - Main loop iteration: 675
2025-04-25 12:27:44,068 - transformer_training - INFO - Main loop iteration: 676
2025-04-25 12:27:44,469 - transformer_training - INFO - Main loop iteration: 677
2025-04-25 12:27:44,930 - transformer_training - INFO - Main loop iteration: 678
2025-04-25 12:27:45,383 - transformer_training - INFO - Main loop iteration: 679
2025-04-25 12:27:45,882 - transformer_training - INFO - Main loop iteration: 680
Iter 680: loss 6.1378, lr 0.000340, 91866.48 tokens/sec
2025-04-25 12:27:46,284 - transformer_training - INFO - Main loop iteration: 681
2025-04-25 12:27:46,745 - transformer_training - INFO - Main loop iteration: 682
2025-04-25 12:27:47,197 - transformer_training - INFO - Main loop iteration: 683
2025-04-25 12:27:47,697 - transformer_training - INFO - Main loop iteration: 684
2025-04-25 12:27:48,098 - transformer_training - INFO - Main loop iteration: 685
2025-04-25 12:27:48,559 - transformer_training - INFO - Main loop iteration: 686
2025-04-25 12:27:49,010 - transformer_training - INFO - Main loop iteration: 687
2025-04-25 12:27:49,509 - transformer_training - INFO - Main loop iteration: 688
2025-04-25 12:27:49,911 - transformer_training - INFO - Main loop iteration: 689
2025-04-25 12:27:50,371 - transformer_training - INFO - Main loop iteration: 690
Iter 690: loss 6.1251, lr 0.000344, 81930.37 tokens/sec
2025-04-25 12:27:50,822 - transformer_training - INFO - Main loop iteration: 691
2025-04-25 12:27:51,321 - transformer_training - INFO - Main loop iteration: 692
2025-04-25 12:27:51,722 - transformer_training - INFO - Main loop iteration: 693
2025-04-25 12:27:52,184 - transformer_training - INFO - Main loop iteration: 694
2025-04-25 12:27:52,634 - transformer_training - INFO - Main loop iteration: 695
2025-04-25 12:27:53,134 - transformer_training - INFO - Main loop iteration: 696
2025-04-25 12:27:53,536 - transformer_training - INFO - Main loop iteration: 697
2025-04-25 12:27:53,997 - transformer_training - INFO - Main loop iteration: 698
2025-04-25 12:27:54,447 - transformer_training - INFO - Main loop iteration: 699
2025-04-25 12:27:54,947 - transformer_training - INFO - Main loop iteration: 700
Iter 700: loss 6.1216, lr 0.000350, 91868.94 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 700: train loss 6.0801, val loss 6.0367
New best model saved with val loss: 6.0367
2025-04-25 12:28:12,285 - transformer_training - INFO - Main loop iteration: 701
2025-04-25 12:28:12,766 - transformer_training - INFO - Main loop iteration: 702
2025-04-25 12:28:13,178 - transformer_training - INFO - Main loop iteration: 703
2025-04-25 12:28:13,677 - transformer_training - INFO - Main loop iteration: 704
2025-04-25 12:28:14,078 - transformer_training - INFO - Main loop iteration: 705
2025-04-25 12:28:14,538 - transformer_training - INFO - Main loop iteration: 706
2025-04-25 12:28:14,989 - transformer_training - INFO - Main loop iteration: 707
2025-04-25 12:28:15,487 - transformer_training - INFO - Main loop iteration: 708
2025-04-25 12:28:15,888 - transformer_training - INFO - Main loop iteration: 709
2025-04-25 12:28:16,349 - transformer_training - INFO - Main loop iteration: 710
Iter 710: loss 6.0871, lr 0.000354, 81874.75 tokens/sec
2025-04-25 12:28:16,799 - transformer_training - INFO - Main loop iteration: 711
2025-04-25 12:28:17,298 - transformer_training - INFO - Main loop iteration: 712
2025-04-25 12:28:17,699 - transformer_training - INFO - Main loop iteration: 713
2025-04-25 12:28:18,160 - transformer_training - INFO - Main loop iteration: 714
2025-04-25 12:28:18,611 - transformer_training - INFO - Main loop iteration: 715
2025-04-25 12:28:19,110 - transformer_training - INFO - Main loop iteration: 716
2025-04-25 12:28:19,511 - transformer_training - INFO - Main loop iteration: 717
2025-04-25 12:28:19,972 - transformer_training - INFO - Main loop iteration: 718
2025-04-25 12:28:20,422 - transformer_training - INFO - Main loop iteration: 719
2025-04-25 12:28:20,921 - transformer_training - INFO - Main loop iteration: 720
Iter 720: loss 6.0840, lr 0.000360, 92040.38 tokens/sec
2025-04-25 12:28:21,322 - transformer_training - INFO - Main loop iteration: 721
2025-04-25 12:28:21,782 - transformer_training - INFO - Main loop iteration: 722
2025-04-25 12:28:22,233 - transformer_training - INFO - Main loop iteration: 723
2025-04-25 12:28:22,731 - transformer_training - INFO - Main loop iteration: 724
2025-04-25 12:28:23,132 - transformer_training - INFO - Main loop iteration: 725
2025-04-25 12:28:23,593 - transformer_training - INFO - Main loop iteration: 726
2025-04-25 12:28:24,043 - transformer_training - INFO - Main loop iteration: 727
2025-04-25 12:28:24,542 - transformer_training - INFO - Main loop iteration: 728
2025-04-25 12:28:24,943 - transformer_training - INFO - Main loop iteration: 729
2025-04-25 12:28:25,404 - transformer_training - INFO - Main loop iteration: 730
Iter 730: loss 6.1417, lr 0.000364, 81828.47 tokens/sec
2025-04-25 12:28:25,855 - transformer_training - INFO - Main loop iteration: 731
2025-04-25 12:28:26,354 - transformer_training - INFO - Main loop iteration: 732
2025-04-25 12:28:26,755 - transformer_training - INFO - Main loop iteration: 733
2025-04-25 12:28:27,217 - transformer_training - INFO - Main loop iteration: 734
2025-04-25 12:28:27,667 - transformer_training - INFO - Main loop iteration: 735
2025-04-25 12:28:28,166 - transformer_training - INFO - Main loop iteration: 736
2025-04-25 12:28:28,567 - transformer_training - INFO - Main loop iteration: 737
2025-04-25 12:28:29,028 - transformer_training - INFO - Main loop iteration: 738
2025-04-25 12:28:29,479 - transformer_training - INFO - Main loop iteration: 739
2025-04-25 12:28:29,977 - transformer_training - INFO - Main loop iteration: 740
Iter 740: loss 6.0796, lr 0.000370, 92073.71 tokens/sec
2025-04-25 12:28:30,378 - transformer_training - INFO - Main loop iteration: 741
2025-04-25 12:28:30,839 - transformer_training - INFO - Main loop iteration: 742
2025-04-25 12:28:31,290 - transformer_training - INFO - Main loop iteration: 743
2025-04-25 12:28:31,789 - transformer_training - INFO - Main loop iteration: 744
2025-04-25 12:28:32,191 - transformer_training - INFO - Main loop iteration: 745
2025-04-25 12:28:32,653 - transformer_training - INFO - Main loop iteration: 746
2025-04-25 12:28:33,103 - transformer_training - INFO - Main loop iteration: 747
2025-04-25 12:28:33,602 - transformer_training - INFO - Main loop iteration: 748
2025-04-25 12:28:34,004 - transformer_training - INFO - Main loop iteration: 749
2025-04-25 12:28:34,465 - transformer_training - INFO - Main loop iteration: 750
Iter 750: loss 6.0083, lr 0.000374, 81705.11 tokens/sec
2025-04-25 12:28:34,917 - transformer_training - INFO - Main loop iteration: 751
2025-04-25 12:28:35,416 - transformer_training - INFO - Main loop iteration: 752
2025-04-25 12:28:35,818 - transformer_training - INFO - Main loop iteration: 753
2025-04-25 12:28:36,279 - transformer_training - INFO - Main loop iteration: 754
2025-04-25 12:28:36,730 - transformer_training - INFO - Main loop iteration: 755
2025-04-25 12:28:37,229 - transformer_training - INFO - Main loop iteration: 756
2025-04-25 12:28:37,630 - transformer_training - INFO - Main loop iteration: 757
2025-04-25 12:28:38,092 - transformer_training - INFO - Main loop iteration: 758
2025-04-25 12:28:38,543 - transformer_training - INFO - Main loop iteration: 759
2025-04-25 12:28:39,042 - transformer_training - INFO - Main loop iteration: 760
Iter 760: loss 6.0740, lr 0.000380, 91814.06 tokens/sec
2025-04-25 12:28:39,444 - transformer_training - INFO - Main loop iteration: 761
2025-04-25 12:28:39,905 - transformer_training - INFO - Main loop iteration: 762
2025-04-25 12:28:40,356 - transformer_training - INFO - Main loop iteration: 763
2025-04-25 12:28:40,854 - transformer_training - INFO - Main loop iteration: 764
2025-04-25 12:28:41,256 - transformer_training - INFO - Main loop iteration: 765
2025-04-25 12:28:41,718 - transformer_training - INFO - Main loop iteration: 766
2025-04-25 12:28:42,169 - transformer_training - INFO - Main loop iteration: 767
2025-04-25 12:28:42,667 - transformer_training - INFO - Main loop iteration: 768
2025-04-25 12:28:43,069 - transformer_training - INFO - Main loop iteration: 769
2025-04-25 12:28:43,530 - transformer_training - INFO - Main loop iteration: 770
Iter 770: loss 6.0437, lr 0.000384, 81852.04 tokens/sec
2025-04-25 12:28:43,981 - transformer_training - INFO - Main loop iteration: 771
2025-04-25 12:28:44,480 - transformer_training - INFO - Main loop iteration: 772
2025-04-25 12:28:44,882 - transformer_training - INFO - Main loop iteration: 773
2025-04-25 12:28:45,344 - transformer_training - INFO - Main loop iteration: 774
2025-04-25 12:28:45,795 - transformer_training - INFO - Main loop iteration: 775
2025-04-25 12:28:46,293 - transformer_training - INFO - Main loop iteration: 776
2025-04-25 12:28:46,695 - transformer_training - INFO - Main loop iteration: 777
2025-04-25 12:28:47,157 - transformer_training - INFO - Main loop iteration: 778
2025-04-25 12:28:47,608 - transformer_training - INFO - Main loop iteration: 779
2025-04-25 12:28:48,106 - transformer_training - INFO - Main loop iteration: 780
Iter 780: loss 5.9932, lr 0.000390, 91852.78 tokens/sec
2025-04-25 12:28:48,508 - transformer_training - INFO - Main loop iteration: 781
2025-04-25 12:28:48,969 - transformer_training - INFO - Main loop iteration: 782
2025-04-25 12:28:49,420 - transformer_training - INFO - Main loop iteration: 783
2025-04-25 12:28:49,919 - transformer_training - INFO - Main loop iteration: 784
2025-04-25 12:28:50,321 - transformer_training - INFO - Main loop iteration: 785
2025-04-25 12:28:50,782 - transformer_training - INFO - Main loop iteration: 786
2025-04-25 12:28:51,234 - transformer_training - INFO - Main loop iteration: 787
2025-04-25 12:28:51,734 - transformer_training - INFO - Main loop iteration: 788
2025-04-25 12:28:52,138 - transformer_training - INFO - Main loop iteration: 789
2025-04-25 12:28:52,600 - transformer_training - INFO - Main loop iteration: 790
Iter 790: loss 5.9634, lr 0.000394, 81881.90 tokens/sec
2025-04-25 12:28:53,050 - transformer_training - INFO - Main loop iteration: 791
2025-04-25 12:28:53,549 - transformer_training - INFO - Main loop iteration: 792
2025-04-25 12:28:53,951 - transformer_training - INFO - Main loop iteration: 793
2025-04-25 12:28:54,412 - transformer_training - INFO - Main loop iteration: 794
2025-04-25 12:28:54,863 - transformer_training - INFO - Main loop iteration: 795
2025-04-25 12:28:55,361 - transformer_training - INFO - Main loop iteration: 796
2025-04-25 12:28:55,763 - transformer_training - INFO - Main loop iteration: 797
2025-04-25 12:28:56,224 - transformer_training - INFO - Main loop iteration: 798
2025-04-25 12:28:56,675 - transformer_training - INFO - Main loop iteration: 799
2025-04-25 12:28:57,173 - transformer_training - INFO - Main loop iteration: 800
Iter 800: loss 5.9453, lr 0.000400, 91719.51 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 800: train loss 5.9396, val loss 5.9098
New best model saved with val loss: 5.9098
2025-04-25 12:29:14,554 - transformer_training - INFO - Main loop iteration: 801
2025-04-25 12:29:14,963 - transformer_training - INFO - Main loop iteration: 802
2025-04-25 12:29:15,413 - transformer_training - INFO - Main loop iteration: 803
2025-04-25 12:29:15,913 - transformer_training - INFO - Main loop iteration: 804
2025-04-25 12:29:16,313 - transformer_training - INFO - Main loop iteration: 805
2025-04-25 12:29:16,773 - transformer_training - INFO - Main loop iteration: 806
2025-04-25 12:29:17,224 - transformer_training - INFO - Main loop iteration: 807
2025-04-25 12:29:17,722 - transformer_training - INFO - Main loop iteration: 808
2025-04-25 12:29:18,123 - transformer_training - INFO - Main loop iteration: 809
2025-04-25 12:29:18,584 - transformer_training - INFO - Main loop iteration: 810
Iter 810: loss 5.9870, lr 0.000404, 81483.31 tokens/sec
2025-04-25 12:29:19,037 - transformer_training - INFO - Main loop iteration: 811
2025-04-25 12:29:19,536 - transformer_training - INFO - Main loop iteration: 812
2025-04-25 12:29:19,937 - transformer_training - INFO - Main loop iteration: 813
2025-04-25 12:29:20,398 - transformer_training - INFO - Main loop iteration: 814
2025-04-25 12:29:20,848 - transformer_training - INFO - Main loop iteration: 815
2025-04-25 12:29:21,347 - transformer_training - INFO - Main loop iteration: 816
2025-04-25 12:29:21,749 - transformer_training - INFO - Main loop iteration: 817
2025-04-25 12:29:22,211 - transformer_training - INFO - Main loop iteration: 818
2025-04-25 12:29:22,662 - transformer_training - INFO - Main loop iteration: 819
2025-04-25 12:29:23,161 - transformer_training - INFO - Main loop iteration: 820
Iter 820: loss 5.9829, lr 0.000410, 91871.12 tokens/sec
2025-04-25 12:29:23,563 - transformer_training - INFO - Main loop iteration: 821
2025-04-25 12:29:24,024 - transformer_training - INFO - Main loop iteration: 822
2025-04-25 12:29:24,475 - transformer_training - INFO - Main loop iteration: 823
2025-04-25 12:29:24,973 - transformer_training - INFO - Main loop iteration: 824
2025-04-25 12:29:25,374 - transformer_training - INFO - Main loop iteration: 825
2025-04-25 12:29:25,836 - transformer_training - INFO - Main loop iteration: 826
2025-04-25 12:29:26,286 - transformer_training - INFO - Main loop iteration: 827
2025-04-25 12:29:26,861 - transformer_training - INFO - Main loop iteration: 828
2025-04-25 12:29:27,263 - transformer_training - INFO - Main loop iteration: 829
2025-04-25 12:29:27,724 - transformer_training - INFO - Main loop iteration: 830
Iter 830: loss 5.9399, lr 0.000414, 81896.04 tokens/sec
2025-04-25 12:29:28,175 - transformer_training - INFO - Main loop iteration: 831
2025-04-25 12:29:28,675 - transformer_training - INFO - Main loop iteration: 832
2025-04-25 12:29:29,076 - transformer_training - INFO - Main loop iteration: 833
2025-04-25 12:29:29,537 - transformer_training - INFO - Main loop iteration: 834
2025-04-25 12:29:29,988 - transformer_training - INFO - Main loop iteration: 835
2025-04-25 12:29:30,488 - transformer_training - INFO - Main loop iteration: 836
2025-04-25 12:29:30,890 - transformer_training - INFO - Main loop iteration: 837
2025-04-25 12:29:31,351 - transformer_training - INFO - Main loop iteration: 838
2025-04-25 12:29:31,802 - transformer_training - INFO - Main loop iteration: 839
2025-04-25 12:29:32,302 - transformer_training - INFO - Main loop iteration: 840
Iter 840: loss 5.9497, lr 0.000420, 91843.35 tokens/sec
2025-04-25 12:29:32,704 - transformer_training - INFO - Main loop iteration: 841
2025-04-25 12:29:33,165 - transformer_training - INFO - Main loop iteration: 842
2025-04-25 12:29:33,615 - transformer_training - INFO - Main loop iteration: 843
2025-04-25 12:29:34,115 - transformer_training - INFO - Main loop iteration: 844
2025-04-25 12:29:34,516 - transformer_training - INFO - Main loop iteration: 845
2025-04-25 12:29:34,978 - transformer_training - INFO - Main loop iteration: 846
2025-04-25 12:29:35,430 - transformer_training - INFO - Main loop iteration: 847
2025-04-25 12:29:35,929 - transformer_training - INFO - Main loop iteration: 848
2025-04-25 12:29:36,331 - transformer_training - INFO - Main loop iteration: 849
2025-04-25 12:29:36,792 - transformer_training - INFO - Main loop iteration: 850
Iter 850: loss 5.9362, lr 0.000424, 81884.72 tokens/sec
2025-04-25 12:29:37,243 - transformer_training - INFO - Main loop iteration: 851
2025-04-25 12:29:37,742 - transformer_training - INFO - Main loop iteration: 852
2025-04-25 12:29:38,144 - transformer_training - INFO - Main loop iteration: 853
2025-04-25 12:29:38,606 - transformer_training - INFO - Main loop iteration: 854
2025-04-25 12:29:39,056 - transformer_training - INFO - Main loop iteration: 855
2025-04-25 12:29:39,555 - transformer_training - INFO - Main loop iteration: 856
2025-04-25 12:29:39,957 - transformer_training - INFO - Main loop iteration: 857
2025-04-25 12:29:40,418 - transformer_training - INFO - Main loop iteration: 858
2025-04-25 12:29:40,869 - transformer_training - INFO - Main loop iteration: 859
2025-04-25 12:29:41,368 - transformer_training - INFO - Main loop iteration: 860
Iter 860: loss 5.9048, lr 0.000430, 91729.19 tokens/sec
2025-04-25 12:29:41,771 - transformer_training - INFO - Main loop iteration: 861
2025-04-25 12:29:42,232 - transformer_training - INFO - Main loop iteration: 862
2025-04-25 12:29:42,683 - transformer_training - INFO - Main loop iteration: 863
2025-04-25 12:29:43,182 - transformer_training - INFO - Main loop iteration: 864
2025-04-25 12:29:43,584 - transformer_training - INFO - Main loop iteration: 865
2025-04-25 12:29:44,045 - transformer_training - INFO - Main loop iteration: 866
2025-04-25 12:29:44,496 - transformer_training - INFO - Main loop iteration: 867
2025-04-25 12:29:44,995 - transformer_training - INFO - Main loop iteration: 868
2025-04-25 12:29:45,396 - transformer_training - INFO - Main loop iteration: 869
2025-04-25 12:29:45,858 - transformer_training - INFO - Main loop iteration: 870
Iter 870: loss 5.9390, lr 0.000434, 81880.82 tokens/sec
2025-04-25 12:29:46,309 - transformer_training - INFO - Main loop iteration: 871
2025-04-25 12:29:46,808 - transformer_training - INFO - Main loop iteration: 872
2025-04-25 12:29:47,210 - transformer_training - INFO - Main loop iteration: 873
2025-04-25 12:29:47,671 - transformer_training - INFO - Main loop iteration: 874
2025-04-25 12:29:48,122 - transformer_training - INFO - Main loop iteration: 875
2025-04-25 12:29:48,621 - transformer_training - INFO - Main loop iteration: 876
2025-04-25 12:29:49,022 - transformer_training - INFO - Main loop iteration: 877
2025-04-25 12:29:49,484 - transformer_training - INFO - Main loop iteration: 878
2025-04-25 12:29:49,935 - transformer_training - INFO - Main loop iteration: 879
2025-04-25 12:29:50,434 - transformer_training - INFO - Main loop iteration: 880
Iter 880: loss 5.8500, lr 0.000440, 91677.74 tokens/sec
2025-04-25 12:29:50,836 - transformer_training - INFO - Main loop iteration: 881
2025-04-25 12:29:51,298 - transformer_training - INFO - Main loop iteration: 882
2025-04-25 12:29:51,749 - transformer_training - INFO - Main loop iteration: 883
2025-04-25 12:29:52,249 - transformer_training - INFO - Main loop iteration: 884
2025-04-25 12:29:52,650 - transformer_training - INFO - Main loop iteration: 885
2025-04-25 12:29:53,112 - transformer_training - INFO - Main loop iteration: 886
2025-04-25 12:29:53,563 - transformer_training - INFO - Main loop iteration: 887
2025-04-25 12:29:54,062 - transformer_training - INFO - Main loop iteration: 888
2025-04-25 12:29:54,464 - transformer_training - INFO - Main loop iteration: 889
2025-04-25 12:29:54,925 - transformer_training - INFO - Main loop iteration: 890
Iter 890: loss 5.8795, lr 0.000444, 81804.66 tokens/sec
2025-04-25 12:29:55,376 - transformer_training - INFO - Main loop iteration: 891
2025-04-25 12:29:55,877 - transformer_training - INFO - Main loop iteration: 892
2025-04-25 12:29:56,278 - transformer_training - INFO - Main loop iteration: 893
2025-04-25 12:29:56,740 - transformer_training - INFO - Main loop iteration: 894
2025-04-25 12:29:57,190 - transformer_training - INFO - Main loop iteration: 895
2025-04-25 12:29:57,689 - transformer_training - INFO - Main loop iteration: 896
2025-04-25 12:29:58,091 - transformer_training - INFO - Main loop iteration: 897
2025-04-25 12:29:58,553 - transformer_training - INFO - Main loop iteration: 898
2025-04-25 12:29:59,004 - transformer_training - INFO - Main loop iteration: 899
2025-04-25 12:29:59,503 - transformer_training - INFO - Main loop iteration: 900
Iter 900: loss 5.8035, lr 0.000450, 91797.81 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 900: train loss 5.8204, val loss 5.7898
New best model saved with val loss: 5.7898
2025-04-25 12:30:17,950 - transformer_training - INFO - Main loop iteration: 901
2025-04-25 12:30:18,373 - transformer_training - INFO - Main loop iteration: 902
2025-04-25 12:30:18,823 - transformer_training - INFO - Main loop iteration: 903
2025-04-25 12:30:19,321 - transformer_training - INFO - Main loop iteration: 904
2025-04-25 12:30:19,722 - transformer_training - INFO - Main loop iteration: 905
2025-04-25 12:30:20,184 - transformer_training - INFO - Main loop iteration: 906
2025-04-25 12:30:20,634 - transformer_training - INFO - Main loop iteration: 907
2025-04-25 12:30:21,133 - transformer_training - INFO - Main loop iteration: 908
2025-04-25 12:30:21,534 - transformer_training - INFO - Main loop iteration: 909
2025-04-25 12:30:21,995 - transformer_training - INFO - Main loop iteration: 910
Iter 910: loss 5.8497, lr 0.000454, 81968.24 tokens/sec
2025-04-25 12:30:22,446 - transformer_training - INFO - Main loop iteration: 911
2025-04-25 12:30:22,946 - transformer_training - INFO - Main loop iteration: 912
2025-04-25 12:30:23,347 - transformer_training - INFO - Main loop iteration: 913
2025-04-25 12:30:23,808 - transformer_training - INFO - Main loop iteration: 914
2025-04-25 12:30:24,259 - transformer_training - INFO - Main loop iteration: 915
2025-04-25 12:30:24,758 - transformer_training - INFO - Main loop iteration: 916
2025-04-25 12:30:25,160 - transformer_training - INFO - Main loop iteration: 917
2025-04-25 12:30:25,622 - transformer_training - INFO - Main loop iteration: 918
2025-04-25 12:30:26,073 - transformer_training - INFO - Main loop iteration: 919
2025-04-25 12:30:26,572 - transformer_training - INFO - Main loop iteration: 920
Iter 920: loss 5.7895, lr 0.000460, 91759.24 tokens/sec
2025-04-25 12:30:26,974 - transformer_training - INFO - Main loop iteration: 921
2025-04-25 12:30:27,434 - transformer_training - INFO - Main loop iteration: 922
2025-04-25 12:30:27,887 - transformer_training - INFO - Main loop iteration: 923
2025-04-25 12:30:28,387 - transformer_training - INFO - Main loop iteration: 924
2025-04-25 12:30:28,789 - transformer_training - INFO - Main loop iteration: 925
2025-04-25 12:30:29,249 - transformer_training - INFO - Main loop iteration: 926
2025-04-25 12:30:29,700 - transformer_training - INFO - Main loop iteration: 927
2025-04-25 12:30:30,199 - transformer_training - INFO - Main loop iteration: 928
2025-04-25 12:30:30,600 - transformer_training - INFO - Main loop iteration: 929
2025-04-25 12:30:31,060 - transformer_training - INFO - Main loop iteration: 930
Iter 930: loss 5.8602, lr 0.000464, 81876.39 tokens/sec
2025-04-25 12:30:31,512 - transformer_training - INFO - Main loop iteration: 931
2025-04-25 12:30:32,011 - transformer_training - INFO - Main loop iteration: 932
2025-04-25 12:30:32,412 - transformer_training - INFO - Main loop iteration: 933
2025-04-25 12:30:32,873 - transformer_training - INFO - Main loop iteration: 934
2025-04-25 12:30:33,323 - transformer_training - INFO - Main loop iteration: 935
2025-04-25 12:30:33,823 - transformer_training - INFO - Main loop iteration: 936
2025-04-25 12:30:34,224 - transformer_training - INFO - Main loop iteration: 937
2025-04-25 12:30:34,685 - transformer_training - INFO - Main loop iteration: 938
2025-04-25 12:30:35,135 - transformer_training - INFO - Main loop iteration: 939
2025-04-25 12:30:35,634 - transformer_training - INFO - Main loop iteration: 940
Iter 940: loss 5.8512, lr 0.000470, 91850.60 tokens/sec
2025-04-25 12:30:36,036 - transformer_training - INFO - Main loop iteration: 941
2025-04-25 12:30:36,497 - transformer_training - INFO - Main loop iteration: 942
2025-04-25 12:30:36,948 - transformer_training - INFO - Main loop iteration: 943
2025-04-25 12:30:37,446 - transformer_training - INFO - Main loop iteration: 944
2025-04-25 12:30:37,848 - transformer_training - INFO - Main loop iteration: 945
2025-04-25 12:30:38,309 - transformer_training - INFO - Main loop iteration: 946
2025-04-25 12:30:38,760 - transformer_training - INFO - Main loop iteration: 947
2025-04-25 12:30:39,258 - transformer_training - INFO - Main loop iteration: 948
2025-04-25 12:30:39,660 - transformer_training - INFO - Main loop iteration: 949
2025-04-25 12:30:40,121 - transformer_training - INFO - Main loop iteration: 950
Iter 950: loss 5.8122, lr 0.000474, 81892.27 tokens/sec
2025-04-25 12:30:40,572 - transformer_training - INFO - Main loop iteration: 951
2025-04-25 12:30:41,070 - transformer_training - INFO - Main loop iteration: 952
2025-04-25 12:30:41,472 - transformer_training - INFO - Main loop iteration: 953
2025-04-25 12:30:41,933 - transformer_training - INFO - Main loop iteration: 954
2025-04-25 12:30:42,384 - transformer_training - INFO - Main loop iteration: 955
2025-04-25 12:30:42,884 - transformer_training - INFO - Main loop iteration: 956
2025-04-25 12:30:43,285 - transformer_training - INFO - Main loop iteration: 957
2025-04-25 12:30:43,746 - transformer_training - INFO - Main loop iteration: 958
2025-04-25 12:30:44,197 - transformer_training - INFO - Main loop iteration: 959
2025-04-25 12:30:44,696 - transformer_training - INFO - Main loop iteration: 960
Iter 960: loss 5.8133, lr 0.000480, 91829.93 tokens/sec
2025-04-25 12:30:45,098 - transformer_training - INFO - Main loop iteration: 961
2025-04-25 12:30:45,558 - transformer_training - INFO - Main loop iteration: 962
2025-04-25 12:30:46,010 - transformer_training - INFO - Main loop iteration: 963
2025-04-25 12:30:46,508 - transformer_training - INFO - Main loop iteration: 964
2025-04-25 12:30:46,910 - transformer_training - INFO - Main loop iteration: 965
2025-04-25 12:30:47,371 - transformer_training - INFO - Main loop iteration: 966
2025-04-25 12:30:47,821 - transformer_training - INFO - Main loop iteration: 967
2025-04-25 12:30:48,321 - transformer_training - INFO - Main loop iteration: 968
2025-04-25 12:30:48,723 - transformer_training - INFO - Main loop iteration: 969
2025-04-25 12:30:49,184 - transformer_training - INFO - Main loop iteration: 970
Iter 970: loss 5.7707, lr 0.000484, 81914.61 tokens/sec
2025-04-25 12:30:49,634 - transformer_training - INFO - Main loop iteration: 971
2025-04-25 12:30:50,133 - transformer_training - INFO - Main loop iteration: 972
2025-04-25 12:30:50,535 - transformer_training - INFO - Main loop iteration: 973
2025-04-25 12:30:50,996 - transformer_training - INFO - Main loop iteration: 974
2025-04-25 12:30:51,447 - transformer_training - INFO - Main loop iteration: 975
2025-04-25 12:30:51,946 - transformer_training - INFO - Main loop iteration: 976
2025-04-25 12:30:52,348 - transformer_training - INFO - Main loop iteration: 977
2025-04-25 12:30:52,809 - transformer_training - INFO - Main loop iteration: 978
2025-04-25 12:30:53,260 - transformer_training - INFO - Main loop iteration: 979
2025-04-25 12:30:53,758 - transformer_training - INFO - Main loop iteration: 980
Iter 980: loss 5.8422, lr 0.000490, 91705.26 tokens/sec
2025-04-25 12:30:54,161 - transformer_training - INFO - Main loop iteration: 981
2025-04-25 12:30:54,622 - transformer_training - INFO - Main loop iteration: 982
2025-04-25 12:30:55,073 - transformer_training - INFO - Main loop iteration: 983
2025-04-25 12:30:55,572 - transformer_training - INFO - Main loop iteration: 984
2025-04-25 12:30:55,974 - transformer_training - INFO - Main loop iteration: 985
2025-04-25 12:30:56,437 - transformer_training - INFO - Main loop iteration: 986
2025-04-25 12:30:56,888 - transformer_training - INFO - Main loop iteration: 987
2025-04-25 12:30:57,387 - transformer_training - INFO - Main loop iteration: 988
2025-04-25 12:30:57,788 - transformer_training - INFO - Main loop iteration: 989
2025-04-25 12:30:58,249 - transformer_training - INFO - Main loop iteration: 990
Iter 990: loss 5.7746, lr 0.000494, 81772.25 tokens/sec
2025-04-25 12:30:58,701 - transformer_training - INFO - Main loop iteration: 991
2025-04-25 12:30:59,199 - transformer_training - INFO - Main loop iteration: 992
2025-04-25 12:30:59,601 - transformer_training - INFO - Main loop iteration: 993
2025-04-25 12:31:00,062 - transformer_training - INFO - Main loop iteration: 994
2025-04-25 12:31:00,512 - transformer_training - INFO - Main loop iteration: 995
2025-04-25 12:31:01,011 - transformer_training - INFO - Main loop iteration: 996
2025-04-25 12:31:01,412 - transformer_training - INFO - Main loop iteration: 997
2025-04-25 12:31:01,874 - transformer_training - INFO - Main loop iteration: 998
2025-04-25 12:31:02,325 - transformer_training - INFO - Main loop iteration: 999
2025-04-25 12:31:02,824 - transformer_training - INFO - Main loop iteration: 1000
Iter 1000: loss 5.7734, lr 0.000500, 91814.44 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1000: train loss 5.7006, val loss 5.6688
New best model saved with val loss: 5.6688
2025-04-25 12:31:21,379 - transformer_training - INFO - Main loop iteration: 1001
2025-04-25 12:31:21,794 - transformer_training - INFO - Main loop iteration: 1002
2025-04-25 12:31:22,243 - transformer_training - INFO - Main loop iteration: 1003
2025-04-25 12:31:22,741 - transformer_training - INFO - Main loop iteration: 1004
2025-04-25 12:31:23,141 - transformer_training - INFO - Main loop iteration: 1005
2025-04-25 12:31:23,602 - transformer_training - INFO - Main loop iteration: 1006
2025-04-25 12:31:24,052 - transformer_training - INFO - Main loop iteration: 1007
2025-04-25 12:31:24,550 - transformer_training - INFO - Main loop iteration: 1008
2025-04-25 12:31:24,951 - transformer_training - INFO - Main loop iteration: 1009
2025-04-25 12:31:25,411 - transformer_training - INFO - Main loop iteration: 1010
Iter 1010: loss 5.7341, lr 0.000504, 82000.15 tokens/sec
2025-04-25 12:31:25,861 - transformer_training - INFO - Main loop iteration: 1011
2025-04-25 12:31:26,360 - transformer_training - INFO - Main loop iteration: 1012
2025-04-25 12:31:26,760 - transformer_training - INFO - Main loop iteration: 1013
2025-04-25 12:31:27,221 - transformer_training - INFO - Main loop iteration: 1014
2025-04-25 12:31:27,671 - transformer_training - INFO - Main loop iteration: 1015
2025-04-25 12:31:28,171 - transformer_training - INFO - Main loop iteration: 1016
2025-04-25 12:31:28,572 - transformer_training - INFO - Main loop iteration: 1017
2025-04-25 12:31:29,032 - transformer_training - INFO - Main loop iteration: 1018
2025-04-25 12:31:29,483 - transformer_training - INFO - Main loop iteration: 1019
2025-04-25 12:31:29,982 - transformer_training - INFO - Main loop iteration: 1020
Iter 1020: loss 5.6972, lr 0.000510, 92006.81 tokens/sec
2025-04-25 12:31:30,383 - transformer_training - INFO - Main loop iteration: 1021
2025-04-25 12:31:30,844 - transformer_training - INFO - Main loop iteration: 1022
2025-04-25 12:31:31,294 - transformer_training - INFO - Main loop iteration: 1023
2025-04-25 12:31:31,793 - transformer_training - INFO - Main loop iteration: 1024
2025-04-25 12:31:32,194 - transformer_training - INFO - Main loop iteration: 1025
2025-04-25 12:31:32,655 - transformer_training - INFO - Main loop iteration: 1026
2025-04-25 12:31:33,105 - transformer_training - INFO - Main loop iteration: 1027
2025-04-25 12:31:33,603 - transformer_training - INFO - Main loop iteration: 1028
2025-04-25 12:31:34,004 - transformer_training - INFO - Main loop iteration: 1029
2025-04-25 12:31:34,465 - transformer_training - INFO - Main loop iteration: 1030
Iter 1030: loss 5.7359, lr 0.000514, 81966.94 tokens/sec
2025-04-25 12:31:34,915 - transformer_training - INFO - Main loop iteration: 1031
2025-04-25 12:31:35,413 - transformer_training - INFO - Main loop iteration: 1032
2025-04-25 12:31:35,814 - transformer_training - INFO - Main loop iteration: 1033
2025-04-25 12:31:36,275 - transformer_training - INFO - Main loop iteration: 1034
2025-04-25 12:31:36,725 - transformer_training - INFO - Main loop iteration: 1035
2025-04-25 12:31:37,224 - transformer_training - INFO - Main loop iteration: 1036
2025-04-25 12:31:37,624 - transformer_training - INFO - Main loop iteration: 1037
2025-04-25 12:31:38,085 - transformer_training - INFO - Main loop iteration: 1038
2025-04-25 12:31:38,536 - transformer_training - INFO - Main loop iteration: 1039
2025-04-25 12:31:39,035 - transformer_training - INFO - Main loop iteration: 1040
Iter 1040: loss 5.6442, lr 0.000520, 91930.99 tokens/sec
2025-04-25 12:31:39,436 - transformer_training - INFO - Main loop iteration: 1041
2025-04-25 12:31:39,897 - transformer_training - INFO - Main loop iteration: 1042
2025-04-25 12:31:40,347 - transformer_training - INFO - Main loop iteration: 1043
2025-04-25 12:31:40,846 - transformer_training - INFO - Main loop iteration: 1044
2025-04-25 12:31:41,247 - transformer_training - INFO - Main loop iteration: 1045
2025-04-25 12:31:41,707 - transformer_training - INFO - Main loop iteration: 1046
2025-04-25 12:31:42,158 - transformer_training - INFO - Main loop iteration: 1047
2025-04-25 12:31:42,657 - transformer_training - INFO - Main loop iteration: 1048
2025-04-25 12:31:43,058 - transformer_training - INFO - Main loop iteration: 1049
2025-04-25 12:31:43,518 - transformer_training - INFO - Main loop iteration: 1050
Iter 1050: loss 5.6775, lr 0.000524, 81877.70 tokens/sec
2025-04-25 12:31:43,969 - transformer_training - INFO - Main loop iteration: 1051
2025-04-25 12:31:44,468 - transformer_training - INFO - Main loop iteration: 1052
2025-04-25 12:31:44,869 - transformer_training - INFO - Main loop iteration: 1053
2025-04-25 12:31:45,330 - transformer_training - INFO - Main loop iteration: 1054
2025-04-25 12:31:45,780 - transformer_training - INFO - Main loop iteration: 1055
2025-04-25 12:31:46,279 - transformer_training - INFO - Main loop iteration: 1056
2025-04-25 12:31:46,680 - transformer_training - INFO - Main loop iteration: 1057
2025-04-25 12:31:47,141 - transformer_training - INFO - Main loop iteration: 1058
2025-04-25 12:31:47,591 - transformer_training - INFO - Main loop iteration: 1059
2025-04-25 12:31:48,090 - transformer_training - INFO - Main loop iteration: 1060
Iter 1060: loss 5.7215, lr 0.000530, 91856.28 tokens/sec
2025-04-25 12:31:48,492 - transformer_training - INFO - Main loop iteration: 1061
2025-04-25 12:31:48,953 - transformer_training - INFO - Main loop iteration: 1062
2025-04-25 12:31:49,403 - transformer_training - INFO - Main loop iteration: 1063
2025-04-25 12:31:49,904 - transformer_training - INFO - Main loop iteration: 1064
2025-04-25 12:31:50,306 - transformer_training - INFO - Main loop iteration: 1065
2025-04-25 12:31:50,768 - transformer_training - INFO - Main loop iteration: 1066
2025-04-25 12:31:51,218 - transformer_training - INFO - Main loop iteration: 1067
2025-04-25 12:31:51,717 - transformer_training - INFO - Main loop iteration: 1068
2025-04-25 12:31:52,119 - transformer_training - INFO - Main loop iteration: 1069
2025-04-25 12:31:52,580 - transformer_training - INFO - Main loop iteration: 1070
Iter 1070: loss 5.6689, lr 0.000534, 81958.42 tokens/sec
2025-04-25 12:31:53,031 - transformer_training - INFO - Main loop iteration: 1071
2025-04-25 12:31:53,529 - transformer_training - INFO - Main loop iteration: 1072
2025-04-25 12:31:53,931 - transformer_training - INFO - Main loop iteration: 1073
2025-04-25 12:31:54,391 - transformer_training - INFO - Main loop iteration: 1074
2025-04-25 12:31:54,843 - transformer_training - INFO - Main loop iteration: 1075
2025-04-25 12:31:55,342 - transformer_training - INFO - Main loop iteration: 1076
2025-04-25 12:31:55,743 - transformer_training - INFO - Main loop iteration: 1077
2025-04-25 12:31:56,204 - transformer_training - INFO - Main loop iteration: 1078
2025-04-25 12:31:56,655 - transformer_training - INFO - Main loop iteration: 1079
2025-04-25 12:31:57,154 - transformer_training - INFO - Main loop iteration: 1080
Iter 1080: loss 5.7483, lr 0.000540, 91809.97 tokens/sec
2025-04-25 12:31:57,556 - transformer_training - INFO - Main loop iteration: 1081
2025-04-25 12:31:58,016 - transformer_training - INFO - Main loop iteration: 1082
2025-04-25 12:31:58,469 - transformer_training - INFO - Main loop iteration: 1083
2025-04-25 12:31:58,968 - transformer_training - INFO - Main loop iteration: 1084
2025-04-25 12:31:59,369 - transformer_training - INFO - Main loop iteration: 1085
2025-04-25 12:31:59,830 - transformer_training - INFO - Main loop iteration: 1086
2025-04-25 12:32:00,281 - transformer_training - INFO - Main loop iteration: 1087
2025-04-25 12:32:00,780 - transformer_training - INFO - Main loop iteration: 1088
2025-04-25 12:32:01,182 - transformer_training - INFO - Main loop iteration: 1089
2025-04-25 12:32:01,643 - transformer_training - INFO - Main loop iteration: 1090
Iter 1090: loss 5.7325, lr 0.000544, 81882.60 tokens/sec
2025-04-25 12:32:02,093 - transformer_training - INFO - Main loop iteration: 1091
2025-04-25 12:32:02,592 - transformer_training - INFO - Main loop iteration: 1092
2025-04-25 12:32:02,994 - transformer_training - INFO - Main loop iteration: 1093
2025-04-25 12:32:03,455 - transformer_training - INFO - Main loop iteration: 1094
2025-04-25 12:32:03,905 - transformer_training - INFO - Main loop iteration: 1095
2025-04-25 12:32:04,404 - transformer_training - INFO - Main loop iteration: 1096
2025-04-25 12:32:04,806 - transformer_training - INFO - Main loop iteration: 1097
2025-04-25 12:32:05,266 - transformer_training - INFO - Main loop iteration: 1098
2025-04-25 12:32:05,718 - transformer_training - INFO - Main loop iteration: 1099
2025-04-25 12:32:06,217 - transformer_training - INFO - Main loop iteration: 1100
Iter 1100: loss 5.6282, lr 0.000550, 91899.52 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1100: train loss 5.6076, val loss 5.5677
New best model saved with val loss: 5.5677
2025-04-25 12:32:23,523 - transformer_training - INFO - Main loop iteration: 1101
2025-04-25 12:32:23,939 - transformer_training - INFO - Main loop iteration: 1102
2025-04-25 12:32:24,388 - transformer_training - INFO - Main loop iteration: 1103
2025-04-25 12:32:24,886 - transformer_training - INFO - Main loop iteration: 1104
2025-04-25 12:32:25,286 - transformer_training - INFO - Main loop iteration: 1105
2025-04-25 12:32:25,746 - transformer_training - INFO - Main loop iteration: 1106
2025-04-25 12:32:26,197 - transformer_training - INFO - Main loop iteration: 1107
2025-04-25 12:32:26,696 - transformer_training - INFO - Main loop iteration: 1108
2025-04-25 12:32:27,097 - transformer_training - INFO - Main loop iteration: 1109
2025-04-25 12:32:27,557 - transformer_training - INFO - Main loop iteration: 1110
Iter 1110: loss 5.5909, lr 0.000554, 82131.78 tokens/sec
2025-04-25 12:32:28,008 - transformer_training - INFO - Main loop iteration: 1111
2025-04-25 12:32:28,508 - transformer_training - INFO - Main loop iteration: 1112
2025-04-25 12:32:28,909 - transformer_training - INFO - Main loop iteration: 1113
2025-04-25 12:32:29,369 - transformer_training - INFO - Main loop iteration: 1114
2025-04-25 12:32:29,819 - transformer_training - INFO - Main loop iteration: 1115
2025-04-25 12:32:30,319 - transformer_training - INFO - Main loop iteration: 1116
2025-04-25 12:32:30,719 - transformer_training - INFO - Main loop iteration: 1117
2025-04-25 12:32:31,181 - transformer_training - INFO - Main loop iteration: 1118
2025-04-25 12:32:31,631 - transformer_training - INFO - Main loop iteration: 1119
2025-04-25 12:32:32,131 - transformer_training - INFO - Main loop iteration: 1120
Iter 1120: loss 5.6231, lr 0.000560, 92028.88 tokens/sec
2025-04-25 12:32:32,532 - transformer_training - INFO - Main loop iteration: 1121
2025-04-25 12:32:32,993 - transformer_training - INFO - Main loop iteration: 1122
2025-04-25 12:32:33,528 - transformer_training - INFO - Main loop iteration: 1123
2025-04-25 12:32:34,027 - transformer_training - INFO - Main loop iteration: 1124
2025-04-25 12:32:34,428 - transformer_training - INFO - Main loop iteration: 1125
2025-04-25 12:32:34,889 - transformer_training - INFO - Main loop iteration: 1126
2025-04-25 12:32:35,339 - transformer_training - INFO - Main loop iteration: 1127
2025-04-25 12:32:35,838 - transformer_training - INFO - Main loop iteration: 1128
2025-04-25 12:32:36,239 - transformer_training - INFO - Main loop iteration: 1129
2025-04-25 12:32:36,701 - transformer_training - INFO - Main loop iteration: 1130
Iter 1130: loss 5.6478, lr 0.000564, 81903.50 tokens/sec
2025-04-25 12:32:37,151 - transformer_training - INFO - Main loop iteration: 1131
2025-04-25 12:32:37,651 - transformer_training - INFO - Main loop iteration: 1132
2025-04-25 12:32:38,052 - transformer_training - INFO - Main loop iteration: 1133
2025-04-25 12:32:38,514 - transformer_training - INFO - Main loop iteration: 1134
2025-04-25 12:32:38,965 - transformer_training - INFO - Main loop iteration: 1135
2025-04-25 12:32:39,463 - transformer_training - INFO - Main loop iteration: 1136
2025-04-25 12:32:39,864 - transformer_training - INFO - Main loop iteration: 1137
2025-04-25 12:32:40,325 - transformer_training - INFO - Main loop iteration: 1138
2025-04-25 12:32:40,777 - transformer_training - INFO - Main loop iteration: 1139
2025-04-25 12:32:41,275 - transformer_training - INFO - Main loop iteration: 1140
Iter 1140: loss 5.6338, lr 0.000570, 92014.53 tokens/sec
2025-04-25 12:32:41,676 - transformer_training - INFO - Main loop iteration: 1141
2025-04-25 12:32:42,137 - transformer_training - INFO - Main loop iteration: 1142
2025-04-25 12:32:42,588 - transformer_training - INFO - Main loop iteration: 1143
2025-04-25 12:32:43,087 - transformer_training - INFO - Main loop iteration: 1144
2025-04-25 12:32:43,489 - transformer_training - INFO - Main loop iteration: 1145
2025-04-25 12:32:43,951 - transformer_training - INFO - Main loop iteration: 1146
2025-04-25 12:32:44,401 - transformer_training - INFO - Main loop iteration: 1147
2025-04-25 12:32:44,901 - transformer_training - INFO - Main loop iteration: 1148
2025-04-25 12:32:45,303 - transformer_training - INFO - Main loop iteration: 1149
2025-04-25 12:32:45,764 - transformer_training - INFO - Main loop iteration: 1150
Iter 1150: loss 5.6343, lr 0.000574, 81898.04 tokens/sec
2025-04-25 12:32:46,215 - transformer_training - INFO - Main loop iteration: 1151
2025-04-25 12:32:46,713 - transformer_training - INFO - Main loop iteration: 1152
2025-04-25 12:32:47,115 - transformer_training - INFO - Main loop iteration: 1153
2025-04-25 12:32:47,576 - transformer_training - INFO - Main loop iteration: 1154
2025-04-25 12:32:48,026 - transformer_training - INFO - Main loop iteration: 1155
2025-04-25 12:32:48,525 - transformer_training - INFO - Main loop iteration: 1156
2025-04-25 12:32:48,926 - transformer_training - INFO - Main loop iteration: 1157
2025-04-25 12:32:49,387 - transformer_training - INFO - Main loop iteration: 1158
2025-04-25 12:32:49,837 - transformer_training - INFO - Main loop iteration: 1159
2025-04-25 12:32:50,336 - transformer_training - INFO - Main loop iteration: 1160
Iter 1160: loss 5.5119, lr 0.000580, 91940.06 tokens/sec
2025-04-25 12:32:50,737 - transformer_training - INFO - Main loop iteration: 1161
2025-04-25 12:32:51,198 - transformer_training - INFO - Main loop iteration: 1162
2025-04-25 12:32:51,649 - transformer_training - INFO - Main loop iteration: 1163
2025-04-25 12:32:52,148 - transformer_training - INFO - Main loop iteration: 1164
2025-04-25 12:32:52,549 - transformer_training - INFO - Main loop iteration: 1165
2025-04-25 12:32:53,010 - transformer_training - INFO - Main loop iteration: 1166
2025-04-25 12:32:53,461 - transformer_training - INFO - Main loop iteration: 1167
2025-04-25 12:32:53,960 - transformer_training - INFO - Main loop iteration: 1168
2025-04-25 12:32:54,361 - transformer_training - INFO - Main loop iteration: 1169
2025-04-25 12:32:54,822 - transformer_training - INFO - Main loop iteration: 1170
Iter 1170: loss 5.6062, lr 0.000584, 81849.31 tokens/sec
2025-04-25 12:32:55,273 - transformer_training - INFO - Main loop iteration: 1171
2025-04-25 12:32:55,772 - transformer_training - INFO - Main loop iteration: 1172
2025-04-25 12:32:56,173 - transformer_training - INFO - Main loop iteration: 1173
2025-04-25 12:32:56,634 - transformer_training - INFO - Main loop iteration: 1174
2025-04-25 12:32:57,085 - transformer_training - INFO - Main loop iteration: 1175
2025-04-25 12:32:57,584 - transformer_training - INFO - Main loop iteration: 1176
2025-04-25 12:32:57,985 - transformer_training - INFO - Main loop iteration: 1177
2025-04-25 12:32:58,447 - transformer_training - INFO - Main loop iteration: 1178
2025-04-25 12:32:58,897 - transformer_training - INFO - Main loop iteration: 1179
2025-04-25 12:32:59,396 - transformer_training - INFO - Main loop iteration: 1180
Iter 1180: loss 5.5850, lr 0.000590, 91866.65 tokens/sec
2025-04-25 12:32:59,798 - transformer_training - INFO - Main loop iteration: 1181
2025-04-25 12:33:00,259 - transformer_training - INFO - Main loop iteration: 1182
2025-04-25 12:33:00,710 - transformer_training - INFO - Main loop iteration: 1183
2025-04-25 12:33:01,208 - transformer_training - INFO - Main loop iteration: 1184
2025-04-25 12:33:01,609 - transformer_training - INFO - Main loop iteration: 1185
2025-04-25 12:33:02,071 - transformer_training - INFO - Main loop iteration: 1186
2025-04-25 12:33:02,521 - transformer_training - INFO - Main loop iteration: 1187
2025-04-25 12:33:03,020 - transformer_training - INFO - Main loop iteration: 1188
2025-04-25 12:33:03,422 - transformer_training - INFO - Main loop iteration: 1189
2025-04-25 12:33:03,882 - transformer_training - INFO - Main loop iteration: 1190
Iter 1190: loss 5.4892, lr 0.000594, 81908.79 tokens/sec
2025-04-25 12:33:04,333 - transformer_training - INFO - Main loop iteration: 1191
2025-04-25 12:33:04,832 - transformer_training - INFO - Main loop iteration: 1192
2025-04-25 12:33:05,233 - transformer_training - INFO - Main loop iteration: 1193
2025-04-25 12:33:05,695 - transformer_training - INFO - Main loop iteration: 1194
2025-04-25 12:33:06,145 - transformer_training - INFO - Main loop iteration: 1195
2025-04-25 12:33:06,644 - transformer_training - INFO - Main loop iteration: 1196
2025-04-25 12:33:07,045 - transformer_training - INFO - Main loop iteration: 1197
2025-04-25 12:33:07,507 - transformer_training - INFO - Main loop iteration: 1198
2025-04-25 12:33:07,957 - transformer_training - INFO - Main loop iteration: 1199
2025-04-25 12:33:08,456 - transformer_training - INFO - Main loop iteration: 1200
Iter 1200: loss 5.4466, lr 0.000600, 91870.36 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1200: train loss 5.4779, val loss 5.4174
New best model saved with val loss: 5.4174
2025-04-25 12:33:25,996 - transformer_training - INFO - Main loop iteration: 1201
2025-04-25 12:33:26,405 - transformer_training - INFO - Main loop iteration: 1202
2025-04-25 12:33:26,855 - transformer_training - INFO - Main loop iteration: 1203
2025-04-25 12:33:27,353 - transformer_training - INFO - Main loop iteration: 1204
2025-04-25 12:33:27,754 - transformer_training - INFO - Main loop iteration: 1205
2025-04-25 12:33:28,217 - transformer_training - INFO - Main loop iteration: 1206
2025-04-25 12:33:28,667 - transformer_training - INFO - Main loop iteration: 1207
2025-04-25 12:33:29,166 - transformer_training - INFO - Main loop iteration: 1208
2025-04-25 12:33:29,566 - transformer_training - INFO - Main loop iteration: 1209
2025-04-25 12:33:30,028 - transformer_training - INFO - Main loop iteration: 1210
Iter 1210: loss 5.5377, lr 0.000604, 81972.37 tokens/sec
2025-04-25 12:33:30,478 - transformer_training - INFO - Main loop iteration: 1211
2025-04-25 12:33:30,977 - transformer_training - INFO - Main loop iteration: 1212
2025-04-25 12:33:31,377 - transformer_training - INFO - Main loop iteration: 1213
2025-04-25 12:33:31,841 - transformer_training - INFO - Main loop iteration: 1214
2025-04-25 12:33:32,291 - transformer_training - INFO - Main loop iteration: 1215
2025-04-25 12:33:32,790 - transformer_training - INFO - Main loop iteration: 1216
2025-04-25 12:33:33,191 - transformer_training - INFO - Main loop iteration: 1217
2025-04-25 12:33:33,652 - transformer_training - INFO - Main loop iteration: 1218
2025-04-25 12:33:34,102 - transformer_training - INFO - Main loop iteration: 1219
2025-04-25 12:33:34,601 - transformer_training - INFO - Main loop iteration: 1220
Iter 1220: loss 5.5523, lr 0.000610, 91993.73 tokens/sec
2025-04-25 12:33:35,002 - transformer_training - INFO - Main loop iteration: 1221
2025-04-25 12:33:35,463 - transformer_training - INFO - Main loop iteration: 1222
2025-04-25 12:33:35,914 - transformer_training - INFO - Main loop iteration: 1223
2025-04-25 12:33:36,413 - transformer_training - INFO - Main loop iteration: 1224
2025-04-25 12:33:36,814 - transformer_training - INFO - Main loop iteration: 1225
2025-04-25 12:33:37,276 - transformer_training - INFO - Main loop iteration: 1226
2025-04-25 12:33:37,726 - transformer_training - INFO - Main loop iteration: 1227
2025-04-25 12:33:38,227 - transformer_training - INFO - Main loop iteration: 1228
2025-04-25 12:33:38,628 - transformer_training - INFO - Main loop iteration: 1229
2025-04-25 12:33:39,089 - transformer_training - INFO - Main loop iteration: 1230
Iter 1230: loss 5.5575, lr 0.000614, 82089.13 tokens/sec
2025-04-25 12:33:39,539 - transformer_training - INFO - Main loop iteration: 1231
2025-04-25 12:33:40,038 - transformer_training - INFO - Main loop iteration: 1232
2025-04-25 12:33:40,439 - transformer_training - INFO - Main loop iteration: 1233
2025-04-25 12:33:40,900 - transformer_training - INFO - Main loop iteration: 1234
2025-04-25 12:33:41,351 - transformer_training - INFO - Main loop iteration: 1235
2025-04-25 12:33:41,850 - transformer_training - INFO - Main loop iteration: 1236
2025-04-25 12:33:42,253 - transformer_training - INFO - Main loop iteration: 1237
2025-04-25 12:33:42,714 - transformer_training - INFO - Main loop iteration: 1238
2025-04-25 12:33:43,164 - transformer_training - INFO - Main loop iteration: 1239
2025-04-25 12:33:43,663 - transformer_training - INFO - Main loop iteration: 1240
Iter 1240: loss 5.5365, lr 0.000620, 91832.16 tokens/sec
2025-04-25 12:33:44,064 - transformer_training - INFO - Main loop iteration: 1241
2025-04-25 12:33:44,525 - transformer_training - INFO - Main loop iteration: 1242
2025-04-25 12:33:44,976 - transformer_training - INFO - Main loop iteration: 1243
2025-04-25 12:33:45,475 - transformer_training - INFO - Main loop iteration: 1244
2025-04-25 12:33:45,876 - transformer_training - INFO - Main loop iteration: 1245
2025-04-25 12:33:46,338 - transformer_training - INFO - Main loop iteration: 1246
2025-04-25 12:33:46,789 - transformer_training - INFO - Main loop iteration: 1247
2025-04-25 12:33:47,287 - transformer_training - INFO - Main loop iteration: 1248
2025-04-25 12:33:47,689 - transformer_training - INFO - Main loop iteration: 1249
2025-04-25 12:33:48,150 - transformer_training - INFO - Main loop iteration: 1250
Iter 1250: loss 5.4079, lr 0.000624, 81838.13 tokens/sec
2025-04-25 12:33:48,601 - transformer_training - INFO - Main loop iteration: 1251
2025-04-25 12:33:49,099 - transformer_training - INFO - Main loop iteration: 1252
2025-04-25 12:33:49,501 - transformer_training - INFO - Main loop iteration: 1253
2025-04-25 12:33:49,962 - transformer_training - INFO - Main loop iteration: 1254
2025-04-25 12:33:50,412 - transformer_training - INFO - Main loop iteration: 1255
2025-04-25 12:33:50,911 - transformer_training - INFO - Main loop iteration: 1256
2025-04-25 12:33:51,314 - transformer_training - INFO - Main loop iteration: 1257
2025-04-25 12:33:51,775 - transformer_training - INFO - Main loop iteration: 1258
2025-04-25 12:33:52,226 - transformer_training - INFO - Main loop iteration: 1259
2025-04-25 12:33:52,725 - transformer_training - INFO - Main loop iteration: 1260
Iter 1260: loss 5.5280, lr 0.000630, 91852.95 tokens/sec
2025-04-25 12:33:53,126 - transformer_training - INFO - Main loop iteration: 1261
2025-04-25 12:33:53,587 - transformer_training - INFO - Main loop iteration: 1262
2025-04-25 12:33:54,038 - transformer_training - INFO - Main loop iteration: 1263
2025-04-25 12:33:54,537 - transformer_training - INFO - Main loop iteration: 1264
2025-04-25 12:33:54,938 - transformer_training - INFO - Main loop iteration: 1265
2025-04-25 12:33:55,399 - transformer_training - INFO - Main loop iteration: 1266
2025-04-25 12:33:55,850 - transformer_training - INFO - Main loop iteration: 1267
2025-04-25 12:33:56,349 - transformer_training - INFO - Main loop iteration: 1268
2025-04-25 12:33:56,750 - transformer_training - INFO - Main loop iteration: 1269
2025-04-25 12:33:57,211 - transformer_training - INFO - Main loop iteration: 1270
Iter 1270: loss 5.4433, lr 0.000634, 81907.28 tokens/sec
2025-04-25 12:33:57,662 - transformer_training - INFO - Main loop iteration: 1271
2025-04-25 12:33:58,161 - transformer_training - INFO - Main loop iteration: 1272
2025-04-25 12:33:58,563 - transformer_training - INFO - Main loop iteration: 1273
2025-04-25 12:33:59,025 - transformer_training - INFO - Main loop iteration: 1274
2025-04-25 12:33:59,475 - transformer_training - INFO - Main loop iteration: 1275
2025-04-25 12:33:59,974 - transformer_training - INFO - Main loop iteration: 1276
2025-04-25 12:34:00,375 - transformer_training - INFO - Main loop iteration: 1277
2025-04-25 12:34:00,837 - transformer_training - INFO - Main loop iteration: 1278
2025-04-25 12:34:01,288 - transformer_training - INFO - Main loop iteration: 1279
2025-04-25 12:34:01,788 - transformer_training - INFO - Main loop iteration: 1280
Iter 1280: loss 5.4158, lr 0.000640, 91953.30 tokens/sec
2025-04-25 12:34:02,190 - transformer_training - INFO - Main loop iteration: 1281
2025-04-25 12:34:02,650 - transformer_training - INFO - Main loop iteration: 1282
2025-04-25 12:34:03,101 - transformer_training - INFO - Main loop iteration: 1283
2025-04-25 12:34:03,600 - transformer_training - INFO - Main loop iteration: 1284
2025-04-25 12:34:04,001 - transformer_training - INFO - Main loop iteration: 1285
2025-04-25 12:34:04,462 - transformer_training - INFO - Main loop iteration: 1286
2025-04-25 12:34:04,913 - transformer_training - INFO - Main loop iteration: 1287
2025-04-25 12:34:05,412 - transformer_training - INFO - Main loop iteration: 1288
2025-04-25 12:34:05,813 - transformer_training - INFO - Main loop iteration: 1289
2025-04-25 12:34:06,274 - transformer_training - INFO - Main loop iteration: 1290
Iter 1290: loss 5.4107, lr 0.000644, 81858.49 tokens/sec
2025-04-25 12:34:06,725 - transformer_training - INFO - Main loop iteration: 1291
2025-04-25 12:34:07,224 - transformer_training - INFO - Main loop iteration: 1292
2025-04-25 12:34:07,625 - transformer_training - INFO - Main loop iteration: 1293
2025-04-25 12:34:08,087 - transformer_training - INFO - Main loop iteration: 1294
2025-04-25 12:34:08,537 - transformer_training - INFO - Main loop iteration: 1295
2025-04-25 12:34:09,036 - transformer_training - INFO - Main loop iteration: 1296
2025-04-25 12:34:09,437 - transformer_training - INFO - Main loop iteration: 1297
2025-04-25 12:34:09,898 - transformer_training - INFO - Main loop iteration: 1298
2025-04-25 12:34:10,349 - transformer_training - INFO - Main loop iteration: 1299
2025-04-25 12:34:10,849 - transformer_training - INFO - Main loop iteration: 1300
Iter 1300: loss 5.3562, lr 0.000650, 91985.30 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 1300: train loss 5.3305, val loss 5.2683
New best model saved with val loss: 5.2683
2025-04-25 12:34:29,582 - transformer_training - INFO - Main loop iteration: 1301
2025-04-25 12:34:30,068 - transformer_training - INFO - Main loop iteration: 1302
2025-04-25 12:34:30,479 - transformer_training - INFO - Main loop iteration: 1303
2025-04-25 12:34:30,977 - transformer_training - INFO - Main loop iteration: 1304
2025-04-25 12:34:31,377 - transformer_training - INFO - Main loop iteration: 1305
2025-04-25 12:34:31,838 - transformer_training - INFO - Main loop iteration: 1306
2025-04-25 12:34:32,288 - transformer_training - INFO - Main loop iteration: 1307
2025-04-25 12:34:32,787 - transformer_training - INFO - Main loop iteration: 1308
2025-04-25 12:34:33,188 - transformer_training - INFO - Main loop iteration: 1309
2025-04-25 12:34:33,648 - transformer_training - INFO - Main loop iteration: 1310
Iter 1310: loss 5.3731, lr 0.000654, 81920.16 tokens/sec
2025-04-25 12:34:34,099 - transformer_training - INFO - Main loop iteration: 1311
2025-04-25 12:34:34,597 - transformer_training - INFO - Main loop iteration: 1312
2025-04-25 12:34:34,997 - transformer_training - INFO - Main loop iteration: 1313
2025-04-25 12:34:35,458 - transformer_training - INFO - Main loop iteration: 1314
2025-04-25 12:34:35,908 - transformer_training - INFO - Main loop iteration: 1315
2025-04-25 12:34:36,407 - transformer_training - INFO - Main loop iteration: 1316
2025-04-25 12:34:36,807 - transformer_training - INFO - Main loop iteration: 1317
2025-04-25 12:34:37,268 - transformer_training - INFO - Main loop iteration: 1318
2025-04-25 12:34:37,719 - transformer_training - INFO - Main loop iteration: 1319
2025-04-25 12:34:38,219 - transformer_training - INFO - Main loop iteration: 1320
Iter 1320: loss 5.3691, lr 0.000660, 91919.46 tokens/sec
2025-04-25 12:34:38,620 - transformer_training - INFO - Main loop iteration: 1321
2025-04-25 12:34:39,081 - transformer_training - INFO - Main loop iteration: 1322
2025-04-25 12:34:39,531 - transformer_training - INFO - Main loop iteration: 1323
2025-04-25 12:34:40,030 - transformer_training - INFO - Main loop iteration: 1324
2025-04-25 12:34:40,431 - transformer_training - INFO - Main loop iteration: 1325
2025-04-25 12:34:40,892 - transformer_training - INFO - Main loop iteration: 1326
2025-04-25 12:34:41,342 - transformer_training - INFO - Main loop iteration: 1327
2025-04-25 12:34:41,842 - transformer_training - INFO - Main loop iteration: 1328
2025-04-25 12:34:42,243 - transformer_training - INFO - Main loop iteration: 1329
2025-04-25 12:34:42,703 - transformer_training - INFO - Main loop iteration: 1330
Iter 1330: loss 5.3086, lr 0.000664, 81936.62 tokens/sec
2025-04-25 12:34:43,154 - transformer_training - INFO - Main loop iteration: 1331
2025-04-25 12:34:43,652 - transformer_training - INFO - Main loop iteration: 1332
2025-04-25 12:34:44,053 - transformer_training - INFO - Main loop iteration: 1333
2025-04-25 12:34:44,514 - transformer_training - INFO - Main loop iteration: 1334
2025-04-25 12:34:44,964 - transformer_training - INFO - Main loop iteration: 1335
2025-04-25 12:34:45,463 - transformer_training - INFO - Main loop iteration: 1336
2025-04-25 12:34:45,864 - transformer_training - INFO - Main loop iteration: 1337
2025-04-25 12:34:46,325 - transformer_training - INFO - Main loop iteration: 1338
2025-04-25 12:34:46,775 - transformer_training - INFO - Main loop iteration: 1339
2025-04-25 12:34:47,274 - transformer_training - INFO - Main loop iteration: 1340
Iter 1340: loss 5.4189, lr 0.000670, 92016.66 tokens/sec
2025-04-25 12:34:47,675 - transformer_training - INFO - Main loop iteration: 1341
2025-04-25 12:34:48,135 - transformer_training - INFO - Main loop iteration: 1342
2025-04-25 12:34:48,587 - transformer_training - INFO - Main loop iteration: 1343
2025-04-25 12:34:49,086 - transformer_training - INFO - Main loop iteration: 1344
2025-04-25 12:34:49,486 - transformer_training - INFO - Main loop iteration: 1345
2025-04-25 12:34:49,947 - transformer_training - INFO - Main loop iteration: 1346
2025-04-25 12:34:50,397 - transformer_training - INFO - Main loop iteration: 1347
2025-04-25 12:34:50,896 - transformer_training - INFO - Main loop iteration: 1348
2025-04-25 12:34:51,297 - transformer_training - INFO - Main loop iteration: 1349
2025-04-25 12:34:51,758 - transformer_training - INFO - Main loop iteration: 1350
Iter 1350: loss 5.3863, lr 0.000674, 81830.59 tokens/sec
2025-04-25 12:34:52,209 - transformer_training - INFO - Main loop iteration: 1351
2025-04-25 12:34:52,707 - transformer_training - INFO - Main loop iteration: 1352
2025-04-25 12:34:53,108 - transformer_training - INFO - Main loop iteration: 1353
2025-04-25 12:34:53,569 - transformer_training - INFO - Main loop iteration: 1354
2025-04-25 12:34:54,019 - transformer_training - INFO - Main loop iteration: 1355
2025-04-25 12:34:54,518 - transformer_training - INFO - Main loop iteration: 1356
2025-04-25 12:34:54,919 - transformer_training - INFO - Main loop iteration: 1357
2025-04-25 12:34:55,380 - transformer_training - INFO - Main loop iteration: 1358
2025-04-25 12:34:55,830 - transformer_training - INFO - Main loop iteration: 1359
2025-04-25 12:34:56,329 - transformer_training - INFO - Main loop iteration: 1360
Iter 1360: loss 5.2492, lr 0.000680, 91962.21 tokens/sec
2025-04-25 12:34:56,730 - transformer_training - INFO - Main loop iteration: 1361
2025-04-25 12:34:57,191 - transformer_training - INFO - Main loop iteration: 1362
2025-04-25 12:34:57,641 - transformer_training - INFO - Main loop iteration: 1363
2025-04-25 12:34:58,140 - transformer_training - INFO - Main loop iteration: 1364
2025-04-25 12:34:58,541 - transformer_training - INFO - Main loop iteration: 1365
2025-04-25 12:34:59,001 - transformer_training - INFO - Main loop iteration: 1366
2025-04-25 12:34:59,452 - transformer_training - INFO - Main loop iteration: 1367
2025-04-25 12:34:59,950 - transformer_training - INFO - Main loop iteration: 1368
2025-04-25 12:35:00,351 - transformer_training - INFO - Main loop iteration: 1369
2025-04-25 12:35:00,812 - transformer_training - INFO - Main loop iteration: 1370
Iter 1370: loss 5.2762, lr 0.000684, 81861.35 tokens/sec
2025-04-25 12:35:01,263 - transformer_training - INFO - Main loop iteration: 1371
2025-04-25 12:35:01,762 - transformer_training - INFO - Main loop iteration: 1372
2025-04-25 12:35:02,163 - transformer_training - INFO - Main loop iteration: 1373
2025-04-25 12:35:02,623 - transformer_training - INFO - Main loop iteration: 1374
2025-04-25 12:35:03,074 - transformer_training - INFO - Main loop iteration: 1375
2025-04-25 12:35:03,572 - transformer_training - INFO - Main loop iteration: 1376
2025-04-25 12:35:03,973 - transformer_training - INFO - Main loop iteration: 1377
2025-04-25 12:35:04,434 - transformer_training - INFO - Main loop iteration: 1378
2025-04-25 12:35:04,884 - transformer_training - INFO - Main loop iteration: 1379
2025-04-25 12:35:05,384 - transformer_training - INFO - Main loop iteration: 1380
Iter 1380: loss 5.3030, lr 0.000690, 91965.87 tokens/sec
2025-04-25 12:35:05,785 - transformer_training - INFO - Main loop iteration: 1381
2025-04-25 12:35:06,246 - transformer_training - INFO - Main loop iteration: 1382
2025-04-25 12:35:06,696 - transformer_training - INFO - Main loop iteration: 1383
2025-04-25 12:35:07,195 - transformer_training - INFO - Main loop iteration: 1384
2025-04-25 12:35:07,595 - transformer_training - INFO - Main loop iteration: 1385
2025-04-25 12:35:08,056 - transformer_training - INFO - Main loop iteration: 1386
2025-04-25 12:35:08,507 - transformer_training - INFO - Main loop iteration: 1387
2025-04-25 12:35:09,006 - transformer_training - INFO - Main loop iteration: 1388
2025-04-25 12:35:09,407 - transformer_training - INFO - Main loop iteration: 1389
2025-04-25 12:35:09,868 - transformer_training - INFO - Main loop iteration: 1390
Iter 1390: loss 5.2869, lr 0.000694, 81971.63 tokens/sec
2025-04-25 12:35:10,318 - transformer_training - INFO - Main loop iteration: 1391
2025-04-25 12:35:10,816 - transformer_training - INFO - Main loop iteration: 1392
2025-04-25 12:35:11,217 - transformer_training - INFO - Main loop iteration: 1393
2025-04-25 12:35:11,677 - transformer_training - INFO - Main loop iteration: 1394
2025-04-25 12:35:12,128 - transformer_training - INFO - Main loop iteration: 1395
2025-04-25 12:35:12,627 - transformer_training - INFO - Main loop iteration: 1396
2025-04-25 12:35:13,028 - transformer_training - INFO - Main loop iteration: 1397
2025-04-25 12:35:13,489 - transformer_training - INFO - Main loop iteration: 1398
2025-04-25 12:35:13,940 - transformer_training - INFO - Main loop iteration: 1399
2025-04-25 12:35:14,438 - transformer_training - INFO - Main loop iteration: 1400
Iter 1400: loss 5.3107, lr 0.000700, 92038.52 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1400: train loss 5.2092, val loss 5.1440
New best model saved with val loss: 5.1440
2025-04-25 12:35:32,818 - transformer_training - INFO - Main loop iteration: 1401
2025-04-25 12:35:33,232 - transformer_training - INFO - Main loop iteration: 1402
2025-04-25 12:35:33,682 - transformer_training - INFO - Main loop iteration: 1403
2025-04-25 12:35:34,180 - transformer_training - INFO - Main loop iteration: 1404
2025-04-25 12:35:34,581 - transformer_training - INFO - Main loop iteration: 1405
2025-04-25 12:35:35,041 - transformer_training - INFO - Main loop iteration: 1406
2025-04-25 12:35:35,491 - transformer_training - INFO - Main loop iteration: 1407
2025-04-25 12:35:35,990 - transformer_training - INFO - Main loop iteration: 1408
2025-04-25 12:35:36,391 - transformer_training - INFO - Main loop iteration: 1409
2025-04-25 12:35:36,851 - transformer_training - INFO - Main loop iteration: 1410
Iter 1410: loss 5.1938, lr 0.000704, 81919.95 tokens/sec
2025-04-25 12:35:37,302 - transformer_training - INFO - Main loop iteration: 1411
2025-04-25 12:35:37,800 - transformer_training - INFO - Main loop iteration: 1412
2025-04-25 12:35:38,201 - transformer_training - INFO - Main loop iteration: 1413
2025-04-25 12:35:38,662 - transformer_training - INFO - Main loop iteration: 1414
2025-04-25 12:35:39,113 - transformer_training - INFO - Main loop iteration: 1415
2025-04-25 12:35:39,611 - transformer_training - INFO - Main loop iteration: 1416
2025-04-25 12:35:40,012 - transformer_training - INFO - Main loop iteration: 1417
2025-04-25 12:35:40,472 - transformer_training - INFO - Main loop iteration: 1418
2025-04-25 12:35:40,922 - transformer_training - INFO - Main loop iteration: 1419
2025-04-25 12:35:41,421 - transformer_training - INFO - Main loop iteration: 1420
Iter 1420: loss 5.2680, lr 0.000710, 92115.40 tokens/sec
2025-04-25 12:35:41,821 - transformer_training - INFO - Main loop iteration: 1421
2025-04-25 12:35:42,282 - transformer_training - INFO - Main loop iteration: 1422
2025-04-25 12:35:42,732 - transformer_training - INFO - Main loop iteration: 1423
2025-04-25 12:35:43,231 - transformer_training - INFO - Main loop iteration: 1424
2025-04-25 12:35:43,632 - transformer_training - INFO - Main loop iteration: 1425
2025-04-25 12:35:44,093 - transformer_training - INFO - Main loop iteration: 1426
2025-04-25 12:35:44,543 - transformer_training - INFO - Main loop iteration: 1427
2025-04-25 12:35:45,042 - transformer_training - INFO - Main loop iteration: 1428
2025-04-25 12:35:45,442 - transformer_training - INFO - Main loop iteration: 1429
2025-04-25 12:35:45,903 - transformer_training - INFO - Main loop iteration: 1430
Iter 1430: loss 5.2148, lr 0.000714, 81976.02 tokens/sec
2025-04-25 12:35:46,353 - transformer_training - INFO - Main loop iteration: 1431
2025-04-25 12:35:46,852 - transformer_training - INFO - Main loop iteration: 1432
2025-04-25 12:35:47,253 - transformer_training - INFO - Main loop iteration: 1433
2025-04-25 12:35:47,714 - transformer_training - INFO - Main loop iteration: 1434
2025-04-25 12:35:48,164 - transformer_training - INFO - Main loop iteration: 1435
2025-04-25 12:35:48,663 - transformer_training - INFO - Main loop iteration: 1436
2025-04-25 12:35:49,064 - transformer_training - INFO - Main loop iteration: 1437
2025-04-25 12:35:49,525 - transformer_training - INFO - Main loop iteration: 1438
2025-04-25 12:35:49,975 - transformer_training - INFO - Main loop iteration: 1439
2025-04-25 12:35:50,475 - transformer_training - INFO - Main loop iteration: 1440
Iter 1440: loss 5.1176, lr 0.000720, 92006.10 tokens/sec
2025-04-25 12:35:50,877 - transformer_training - INFO - Main loop iteration: 1441
2025-04-25 12:35:51,337 - transformer_training - INFO - Main loop iteration: 1442
2025-04-25 12:35:51,788 - transformer_training - INFO - Main loop iteration: 1443
2025-04-25 12:35:52,331 - transformer_training - INFO - Main loop iteration: 1444
2025-04-25 12:35:52,733 - transformer_training - INFO - Main loop iteration: 1445
2025-04-25 12:35:53,194 - transformer_training - INFO - Main loop iteration: 1446
2025-04-25 12:35:53,644 - transformer_training - INFO - Main loop iteration: 1447
2025-04-25 12:35:54,143 - transformer_training - INFO - Main loop iteration: 1448
2025-04-25 12:35:54,544 - transformer_training - INFO - Main loop iteration: 1449
2025-04-25 12:35:55,005 - transformer_training - INFO - Main loop iteration: 1450
Iter 1450: loss 5.1861, lr 0.000724, 81886.89 tokens/sec
2025-04-25 12:35:55,456 - transformer_training - INFO - Main loop iteration: 1451
2025-04-25 12:35:55,955 - transformer_training - INFO - Main loop iteration: 1452
2025-04-25 12:35:56,355 - transformer_training - INFO - Main loop iteration: 1453
2025-04-25 12:35:56,816 - transformer_training - INFO - Main loop iteration: 1454
2025-04-25 12:35:57,266 - transformer_training - INFO - Main loop iteration: 1455
2025-04-25 12:35:57,765 - transformer_training - INFO - Main loop iteration: 1456
2025-04-25 12:35:58,166 - transformer_training - INFO - Main loop iteration: 1457
2025-04-25 12:35:58,627 - transformer_training - INFO - Main loop iteration: 1458
2025-04-25 12:35:59,078 - transformer_training - INFO - Main loop iteration: 1459
2025-04-25 12:35:59,577 - transformer_training - INFO - Main loop iteration: 1460
Iter 1460: loss 5.2167, lr 0.000730, 92040.27 tokens/sec
2025-04-25 12:35:59,978 - transformer_training - INFO - Main loop iteration: 1461
2025-04-25 12:36:00,438 - transformer_training - INFO - Main loop iteration: 1462
2025-04-25 12:36:00,888 - transformer_training - INFO - Main loop iteration: 1463
2025-04-25 12:36:01,387 - transformer_training - INFO - Main loop iteration: 1464
2025-04-25 12:36:01,788 - transformer_training - INFO - Main loop iteration: 1465
2025-04-25 12:36:02,250 - transformer_training - INFO - Main loop iteration: 1466
2025-04-25 12:36:02,700 - transformer_training - INFO - Main loop iteration: 1467
2025-04-25 12:36:03,199 - transformer_training - INFO - Main loop iteration: 1468
2025-04-25 12:36:03,601 - transformer_training - INFO - Main loop iteration: 1469
2025-04-25 12:36:04,062 - transformer_training - INFO - Main loop iteration: 1470
Iter 1470: loss 5.1468, lr 0.000734, 81890.66 tokens/sec
2025-04-25 12:36:04,512 - transformer_training - INFO - Main loop iteration: 1471
2025-04-25 12:36:05,011 - transformer_training - INFO - Main loop iteration: 1472
2025-04-25 12:36:05,413 - transformer_training - INFO - Main loop iteration: 1473
2025-04-25 12:36:05,874 - transformer_training - INFO - Main loop iteration: 1474
2025-04-25 12:36:06,325 - transformer_training - INFO - Main loop iteration: 1475
2025-04-25 12:36:06,823 - transformer_training - INFO - Main loop iteration: 1476
2025-04-25 12:36:07,224 - transformer_training - INFO - Main loop iteration: 1477
2025-04-25 12:36:07,685 - transformer_training - INFO - Main loop iteration: 1478
2025-04-25 12:36:08,136 - transformer_training - INFO - Main loop iteration: 1479
2025-04-25 12:36:08,635 - transformer_training - INFO - Main loop iteration: 1480
Iter 1480: loss 5.1820, lr 0.000740, 91949.63 tokens/sec
2025-04-25 12:36:09,036 - transformer_training - INFO - Main loop iteration: 1481
2025-04-25 12:36:09,497 - transformer_training - INFO - Main loop iteration: 1482
2025-04-25 12:36:09,947 - transformer_training - INFO - Main loop iteration: 1483
2025-04-25 12:36:10,446 - transformer_training - INFO - Main loop iteration: 1484
2025-04-25 12:36:10,847 - transformer_training - INFO - Main loop iteration: 1485
2025-04-25 12:36:11,308 - transformer_training - INFO - Main loop iteration: 1486
2025-04-25 12:36:11,758 - transformer_training - INFO - Main loop iteration: 1487
2025-04-25 12:36:12,257 - transformer_training - INFO - Main loop iteration: 1488
2025-04-25 12:36:12,658 - transformer_training - INFO - Main loop iteration: 1489
2025-04-25 12:36:13,118 - transformer_training - INFO - Main loop iteration: 1490
Iter 1490: loss 5.1044, lr 0.000744, 81741.22 tokens/sec
2025-04-25 12:36:13,570 - transformer_training - INFO - Main loop iteration: 1491
2025-04-25 12:36:14,068 - transformer_training - INFO - Main loop iteration: 1492
2025-04-25 12:36:14,469 - transformer_training - INFO - Main loop iteration: 1493
2025-04-25 12:36:14,930 - transformer_training - INFO - Main loop iteration: 1494
2025-04-25 12:36:15,380 - transformer_training - INFO - Main loop iteration: 1495
2025-04-25 12:36:15,879 - transformer_training - INFO - Main loop iteration: 1496
2025-04-25 12:36:16,280 - transformer_training - INFO - Main loop iteration: 1497
2025-04-25 12:36:16,741 - transformer_training - INFO - Main loop iteration: 1498
2025-04-25 12:36:17,192 - transformer_training - INFO - Main loop iteration: 1499
2025-04-25 12:36:17,691 - transformer_training - INFO - Main loop iteration: 1500
Iter 1500: loss 5.1228, lr 0.000750, 92033.92 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 1500: train loss 5.0963, val loss 5.0082
New best model saved with val loss: 5.0082
2025-04-25 12:36:36,970 - transformer_training - INFO - Main loop iteration: 1501
2025-04-25 12:36:37,382 - transformer_training - INFO - Main loop iteration: 1502
2025-04-25 12:36:37,832 - transformer_training - INFO - Main loop iteration: 1503
2025-04-25 12:36:38,330 - transformer_training - INFO - Main loop iteration: 1504
2025-04-25 12:36:38,731 - transformer_training - INFO - Main loop iteration: 1505
2025-04-25 12:36:39,192 - transformer_training - INFO - Main loop iteration: 1506
2025-04-25 12:36:39,642 - transformer_training - INFO - Main loop iteration: 1507
2025-04-25 12:36:40,141 - transformer_training - INFO - Main loop iteration: 1508
2025-04-25 12:36:40,541 - transformer_training - INFO - Main loop iteration: 1509
2025-04-25 12:36:41,002 - transformer_training - INFO - Main loop iteration: 1510
Iter 1510: loss 5.1022, lr 0.000754, 81965.11 tokens/sec
2025-04-25 12:36:41,452 - transformer_training - INFO - Main loop iteration: 1511
2025-04-25 12:36:41,950 - transformer_training - INFO - Main loop iteration: 1512
2025-04-25 12:36:42,351 - transformer_training - INFO - Main loop iteration: 1513
2025-04-25 12:36:42,812 - transformer_training - INFO - Main loop iteration: 1514
2025-04-25 12:36:43,263 - transformer_training - INFO - Main loop iteration: 1515
2025-04-25 12:36:43,762 - transformer_training - INFO - Main loop iteration: 1516
2025-04-25 12:36:44,163 - transformer_training - INFO - Main loop iteration: 1517
2025-04-25 12:36:44,624 - transformer_training - INFO - Main loop iteration: 1518
2025-04-25 12:36:45,075 - transformer_training - INFO - Main loop iteration: 1519
2025-04-25 12:36:45,573 - transformer_training - INFO - Main loop iteration: 1520
Iter 1520: loss 5.1106, lr 0.000760, 92023.78 tokens/sec
2025-04-25 12:36:45,974 - transformer_training - INFO - Main loop iteration: 1521
2025-04-25 12:36:46,435 - transformer_training - INFO - Main loop iteration: 1522
2025-04-25 12:36:46,885 - transformer_training - INFO - Main loop iteration: 1523
2025-04-25 12:36:47,384 - transformer_training - INFO - Main loop iteration: 1524
2025-04-25 12:36:47,785 - transformer_training - INFO - Main loop iteration: 1525
2025-04-25 12:36:48,246 - transformer_training - INFO - Main loop iteration: 1526
2025-04-25 12:36:48,697 - transformer_training - INFO - Main loop iteration: 1527
2025-04-25 12:36:49,196 - transformer_training - INFO - Main loop iteration: 1528
2025-04-25 12:36:49,597 - transformer_training - INFO - Main loop iteration: 1529
2025-04-25 12:36:50,057 - transformer_training - INFO - Main loop iteration: 1530
Iter 1530: loss 5.0457, lr 0.000764, 81975.28 tokens/sec
2025-04-25 12:36:50,507 - transformer_training - INFO - Main loop iteration: 1531
2025-04-25 12:36:51,006 - transformer_training - INFO - Main loop iteration: 1532
2025-04-25 12:36:51,407 - transformer_training - INFO - Main loop iteration: 1533
2025-04-25 12:36:51,868 - transformer_training - INFO - Main loop iteration: 1534
2025-04-25 12:36:52,319 - transformer_training - INFO - Main loop iteration: 1535
2025-04-25 12:36:52,817 - transformer_training - INFO - Main loop iteration: 1536
2025-04-25 12:36:53,218 - transformer_training - INFO - Main loop iteration: 1537
2025-04-25 12:36:53,679 - transformer_training - INFO - Main loop iteration: 1538
2025-04-25 12:36:54,129 - transformer_training - INFO - Main loop iteration: 1539
2025-04-25 12:36:54,628 - transformer_training - INFO - Main loop iteration: 1540
Iter 1540: loss 5.0840, lr 0.000770, 91891.71 tokens/sec
2025-04-25 12:36:55,030 - transformer_training - INFO - Main loop iteration: 1541
2025-04-25 12:36:55,491 - transformer_training - INFO - Main loop iteration: 1542
2025-04-25 12:36:55,942 - transformer_training - INFO - Main loop iteration: 1543
2025-04-25 12:36:56,440 - transformer_training - INFO - Main loop iteration: 1544
2025-04-25 12:36:56,841 - transformer_training - INFO - Main loop iteration: 1545
2025-04-25 12:36:57,302 - transformer_training - INFO - Main loop iteration: 1546
2025-04-25 12:36:57,753 - transformer_training - INFO - Main loop iteration: 1547
2025-04-25 12:36:58,251 - transformer_training - INFO - Main loop iteration: 1548
2025-04-25 12:36:58,652 - transformer_training - INFO - Main loop iteration: 1549
2025-04-25 12:36:59,113 - transformer_training - INFO - Main loop iteration: 1550
Iter 1550: loss 5.1225, lr 0.000774, 81940.05 tokens/sec
2025-04-25 12:36:59,563 - transformer_training - INFO - Main loop iteration: 1551
2025-04-25 12:37:00,062 - transformer_training - INFO - Main loop iteration: 1552
2025-04-25 12:37:00,463 - transformer_training - INFO - Main loop iteration: 1553
2025-04-25 12:37:00,924 - transformer_training - INFO - Main loop iteration: 1554
2025-04-25 12:37:01,374 - transformer_training - INFO - Main loop iteration: 1555
2025-04-25 12:37:01,873 - transformer_training - INFO - Main loop iteration: 1556
2025-04-25 12:37:02,274 - transformer_training - INFO - Main loop iteration: 1557
2025-04-25 12:37:02,735 - transformer_training - INFO - Main loop iteration: 1558
2025-04-25 12:37:03,186 - transformer_training - INFO - Main loop iteration: 1559
2025-04-25 12:37:03,685 - transformer_training - INFO - Main loop iteration: 1560
Iter 1560: loss 5.0921, lr 0.000780, 91920.39 tokens/sec
2025-04-25 12:37:04,087 - transformer_training - INFO - Main loop iteration: 1561
2025-04-25 12:37:04,548 - transformer_training - INFO - Main loop iteration: 1562
2025-04-25 12:37:04,999 - transformer_training - INFO - Main loop iteration: 1563
2025-04-25 12:37:05,497 - transformer_training - INFO - Main loop iteration: 1564
2025-04-25 12:37:05,898 - transformer_training - INFO - Main loop iteration: 1565
2025-04-25 12:37:06,360 - transformer_training - INFO - Main loop iteration: 1566
2025-04-25 12:37:06,811 - transformer_training - INFO - Main loop iteration: 1567
2025-04-25 12:37:07,310 - transformer_training - INFO - Main loop iteration: 1568
2025-04-25 12:37:07,712 - transformer_training - INFO - Main loop iteration: 1569
2025-04-25 12:37:08,173 - transformer_training - INFO - Main loop iteration: 1570
Iter 1570: loss 5.0630, lr 0.000784, 81837.39 tokens/sec
2025-04-25 12:37:08,624 - transformer_training - INFO - Main loop iteration: 1571
2025-04-25 12:37:09,124 - transformer_training - INFO - Main loop iteration: 1572
2025-04-25 12:37:09,525 - transformer_training - INFO - Main loop iteration: 1573
2025-04-25 12:37:09,987 - transformer_training - INFO - Main loop iteration: 1574
2025-04-25 12:37:10,438 - transformer_training - INFO - Main loop iteration: 1575
2025-04-25 12:37:10,937 - transformer_training - INFO - Main loop iteration: 1576
2025-04-25 12:37:11,338 - transformer_training - INFO - Main loop iteration: 1577
2025-04-25 12:37:11,799 - transformer_training - INFO - Main loop iteration: 1578
2025-04-25 12:37:12,250 - transformer_training - INFO - Main loop iteration: 1579
2025-04-25 12:37:12,749 - transformer_training - INFO - Main loop iteration: 1580
Iter 1580: loss 5.0225, lr 0.000790, 91960.84 tokens/sec
2025-04-25 12:37:13,151 - transformer_training - INFO - Main loop iteration: 1581
2025-04-25 12:37:13,611 - transformer_training - INFO - Main loop iteration: 1582
2025-04-25 12:37:14,062 - transformer_training - INFO - Main loop iteration: 1583
2025-04-25 12:37:14,561 - transformer_training - INFO - Main loop iteration: 1584
2025-04-25 12:37:14,962 - transformer_training - INFO - Main loop iteration: 1585
2025-04-25 12:37:15,423 - transformer_training - INFO - Main loop iteration: 1586
2025-04-25 12:37:15,874 - transformer_training - INFO - Main loop iteration: 1587
2025-04-25 12:37:16,373 - transformer_training - INFO - Main loop iteration: 1588
2025-04-25 12:37:16,775 - transformer_training - INFO - Main loop iteration: 1589
2025-04-25 12:37:17,236 - transformer_training - INFO - Main loop iteration: 1590
Iter 1590: loss 5.0420, lr 0.000794, 81797.61 tokens/sec
2025-04-25 12:37:17,687 - transformer_training - INFO - Main loop iteration: 1591
2025-04-25 12:37:18,186 - transformer_training - INFO - Main loop iteration: 1592
2025-04-25 12:37:18,588 - transformer_training - INFO - Main loop iteration: 1593
2025-04-25 12:37:19,049 - transformer_training - INFO - Main loop iteration: 1594
2025-04-25 12:37:19,499 - transformer_training - INFO - Main loop iteration: 1595
2025-04-25 12:37:19,999 - transformer_training - INFO - Main loop iteration: 1596
2025-04-25 12:37:20,399 - transformer_training - INFO - Main loop iteration: 1597
2025-04-25 12:37:20,860 - transformer_training - INFO - Main loop iteration: 1598
2025-04-25 12:37:21,310 - transformer_training - INFO - Main loop iteration: 1599
2025-04-25 12:37:21,809 - transformer_training - INFO - Main loop iteration: 1600
Iter 1600: loss 4.9268, lr 0.000800, 91903.45 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 1600: train loss 4.9561, val loss 4.8551
New best model saved with val loss: 4.8551
2025-04-25 12:37:40,490 - transformer_training - INFO - Main loop iteration: 1601
2025-04-25 12:37:40,904 - transformer_training - INFO - Main loop iteration: 1602
2025-04-25 12:37:41,353 - transformer_training - INFO - Main loop iteration: 1603
2025-04-25 12:37:41,852 - transformer_training - INFO - Main loop iteration: 1604
2025-04-25 12:37:42,254 - transformer_training - INFO - Main loop iteration: 1605
2025-04-25 12:37:42,715 - transformer_training - INFO - Main loop iteration: 1606
2025-04-25 12:37:43,165 - transformer_training - INFO - Main loop iteration: 1607
2025-04-25 12:37:43,664 - transformer_training - INFO - Main loop iteration: 1608
2025-04-25 12:37:44,066 - transformer_training - INFO - Main loop iteration: 1609
2025-04-25 12:37:44,526 - transformer_training - INFO - Main loop iteration: 1610
Iter 1610: loss 5.0574, lr 0.000804, 81932.93 tokens/sec
2025-04-25 12:37:44,977 - transformer_training - INFO - Main loop iteration: 1611
2025-04-25 12:37:45,475 - transformer_training - INFO - Main loop iteration: 1612
2025-04-25 12:37:45,876 - transformer_training - INFO - Main loop iteration: 1613
2025-04-25 12:37:46,338 - transformer_training - INFO - Main loop iteration: 1614
2025-04-25 12:37:46,788 - transformer_training - INFO - Main loop iteration: 1615
2025-04-25 12:37:47,286 - transformer_training - INFO - Main loop iteration: 1616
2025-04-25 12:37:47,688 - transformer_training - INFO - Main loop iteration: 1617
2025-04-25 12:37:48,149 - transformer_training - INFO - Main loop iteration: 1618
2025-04-25 12:37:48,599 - transformer_training - INFO - Main loop iteration: 1619
2025-04-25 12:37:49,098 - transformer_training - INFO - Main loop iteration: 1620
Iter 1620: loss 4.9440, lr 0.000810, 91942.63 tokens/sec
2025-04-25 12:37:49,499 - transformer_training - INFO - Main loop iteration: 1621
2025-04-25 12:37:49,961 - transformer_training - INFO - Main loop iteration: 1622
2025-04-25 12:37:50,411 - transformer_training - INFO - Main loop iteration: 1623
2025-04-25 12:37:50,910 - transformer_training - INFO - Main loop iteration: 1624
2025-04-25 12:37:51,311 - transformer_training - INFO - Main loop iteration: 1625
2025-04-25 12:37:51,772 - transformer_training - INFO - Main loop iteration: 1626
2025-04-25 12:37:52,223 - transformer_training - INFO - Main loop iteration: 1627
2025-04-25 12:37:52,722 - transformer_training - INFO - Main loop iteration: 1628
2025-04-25 12:37:53,123 - transformer_training - INFO - Main loop iteration: 1629
2025-04-25 12:37:53,584 - transformer_training - INFO - Main loop iteration: 1630
Iter 1630: loss 5.0025, lr 0.000814, 81870.54 tokens/sec
2025-04-25 12:37:54,035 - transformer_training - INFO - Main loop iteration: 1631
2025-04-25 12:37:54,534 - transformer_training - INFO - Main loop iteration: 1632
2025-04-25 12:37:54,935 - transformer_training - INFO - Main loop iteration: 1633
2025-04-25 12:37:55,396 - transformer_training - INFO - Main loop iteration: 1634
2025-04-25 12:37:55,846 - transformer_training - INFO - Main loop iteration: 1635
2025-04-25 12:37:56,345 - transformer_training - INFO - Main loop iteration: 1636
2025-04-25 12:37:56,747 - transformer_training - INFO - Main loop iteration: 1637
2025-04-25 12:37:57,208 - transformer_training - INFO - Main loop iteration: 1638
2025-04-25 12:37:57,658 - transformer_training - INFO - Main loop iteration: 1639
2025-04-25 12:37:58,157 - transformer_training - INFO - Main loop iteration: 1640
Iter 1640: loss 4.8764, lr 0.000820, 91955.65 tokens/sec
2025-04-25 12:37:58,558 - transformer_training - INFO - Main loop iteration: 1641
2025-04-25 12:37:59,019 - transformer_training - INFO - Main loop iteration: 1642
2025-04-25 12:37:59,470 - transformer_training - INFO - Main loop iteration: 1643
2025-04-25 12:37:59,970 - transformer_training - INFO - Main loop iteration: 1644
2025-04-25 12:38:00,374 - transformer_training - INFO - Main loop iteration: 1645
2025-04-25 12:38:00,835 - transformer_training - INFO - Main loop iteration: 1646
2025-04-25 12:38:01,285 - transformer_training - INFO - Main loop iteration: 1647
2025-04-25 12:38:01,785 - transformer_training - INFO - Main loop iteration: 1648
2025-04-25 12:38:02,187 - transformer_training - INFO - Main loop iteration: 1649
2025-04-25 12:38:02,648 - transformer_training - INFO - Main loop iteration: 1650
Iter 1650: loss 4.9600, lr 0.000824, 81898.08 tokens/sec
2025-04-25 12:38:03,099 - transformer_training - INFO - Main loop iteration: 1651
2025-04-25 12:38:03,597 - transformer_training - INFO - Main loop iteration: 1652
2025-04-25 12:38:03,999 - transformer_training - INFO - Main loop iteration: 1653
2025-04-25 12:38:04,459 - transformer_training - INFO - Main loop iteration: 1654
2025-04-25 12:38:04,910 - transformer_training - INFO - Main loop iteration: 1655
2025-04-25 12:38:05,409 - transformer_training - INFO - Main loop iteration: 1656
2025-04-25 12:38:05,810 - transformer_training - INFO - Main loop iteration: 1657
2025-04-25 12:38:06,272 - transformer_training - INFO - Main loop iteration: 1658
2025-04-25 12:38:06,722 - transformer_training - INFO - Main loop iteration: 1659
2025-04-25 12:38:07,221 - transformer_training - INFO - Main loop iteration: 1660
Iter 1660: loss 5.0657, lr 0.000830, 91911.81 tokens/sec
2025-04-25 12:38:07,623 - transformer_training - INFO - Main loop iteration: 1661
2025-04-25 12:38:08,084 - transformer_training - INFO - Main loop iteration: 1662
2025-04-25 12:38:08,535 - transformer_training - INFO - Main loop iteration: 1663
2025-04-25 12:38:09,033 - transformer_training - INFO - Main loop iteration: 1664
2025-04-25 12:38:09,435 - transformer_training - INFO - Main loop iteration: 1665
2025-04-25 12:38:09,896 - transformer_training - INFO - Main loop iteration: 1666
2025-04-25 12:38:10,347 - transformer_training - INFO - Main loop iteration: 1667
2025-04-25 12:38:10,845 - transformer_training - INFO - Main loop iteration: 1668
2025-04-25 12:38:11,247 - transformer_training - INFO - Main loop iteration: 1669
2025-04-25 12:38:11,708 - transformer_training - INFO - Main loop iteration: 1670
Iter 1670: loss 4.8752, lr 0.000834, 81837.52 tokens/sec
2025-04-25 12:38:12,159 - transformer_training - INFO - Main loop iteration: 1671
2025-04-25 12:38:12,658 - transformer_training - INFO - Main loop iteration: 1672
2025-04-25 12:38:13,059 - transformer_training - INFO - Main loop iteration: 1673
2025-04-25 12:38:13,520 - transformer_training - INFO - Main loop iteration: 1674
2025-04-25 12:38:13,970 - transformer_training - INFO - Main loop iteration: 1675
2025-04-25 12:38:14,469 - transformer_training - INFO - Main loop iteration: 1676
2025-04-25 12:38:14,870 - transformer_training - INFO - Main loop iteration: 1677
2025-04-25 12:38:15,331 - transformer_training - INFO - Main loop iteration: 1678
2025-04-25 12:38:15,781 - transformer_training - INFO - Main loop iteration: 1679
2025-04-25 12:38:16,280 - transformer_training - INFO - Main loop iteration: 1680
Iter 1680: loss 4.9288, lr 0.000840, 92163.88 tokens/sec
2025-04-25 12:38:16,680 - transformer_training - INFO - Main loop iteration: 1681
2025-04-25 12:38:17,141 - transformer_training - INFO - Main loop iteration: 1682
2025-04-25 12:38:17,591 - transformer_training - INFO - Main loop iteration: 1683
2025-04-25 12:38:18,090 - transformer_training - INFO - Main loop iteration: 1684
2025-04-25 12:38:18,491 - transformer_training - INFO - Main loop iteration: 1685
2025-04-25 12:38:18,951 - transformer_training - INFO - Main loop iteration: 1686
2025-04-25 12:38:19,401 - transformer_training - INFO - Main loop iteration: 1687
2025-04-25 12:38:19,900 - transformer_training - INFO - Main loop iteration: 1688
2025-04-25 12:38:20,301 - transformer_training - INFO - Main loop iteration: 1689
2025-04-25 12:38:20,762 - transformer_training - INFO - Main loop iteration: 1690
Iter 1690: loss 4.9540, lr 0.000844, 81926.55 tokens/sec
2025-04-25 12:38:21,212 - transformer_training - INFO - Main loop iteration: 1691
2025-04-25 12:38:21,711 - transformer_training - INFO - Main loop iteration: 1692
2025-04-25 12:38:22,112 - transformer_training - INFO - Main loop iteration: 1693
2025-04-25 12:38:22,572 - transformer_training - INFO - Main loop iteration: 1694
2025-04-25 12:38:23,023 - transformer_training - INFO - Main loop iteration: 1695
2025-04-25 12:38:23,521 - transformer_training - INFO - Main loop iteration: 1696
2025-04-25 12:38:23,922 - transformer_training - INFO - Main loop iteration: 1697
2025-04-25 12:38:24,382 - transformer_training - INFO - Main loop iteration: 1698
2025-04-25 12:38:24,832 - transformer_training - INFO - Main loop iteration: 1699
2025-04-25 12:38:25,331 - transformer_training - INFO - Main loop iteration: 1700
Iter 1700: loss 4.8498, lr 0.000850, 92045.75 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1700: train loss 4.8480, val loss 4.7608
New best model saved with val loss: 4.7608
2025-04-25 12:38:43,512 - transformer_training - INFO - Main loop iteration: 1701
2025-04-25 12:38:43,995 - transformer_training - INFO - Main loop iteration: 1702
2025-04-25 12:38:44,406 - transformer_training - INFO - Main loop iteration: 1703
2025-04-25 12:38:44,905 - transformer_training - INFO - Main loop iteration: 1704
2025-04-25 12:38:45,306 - transformer_training - INFO - Main loop iteration: 1705
2025-04-25 12:38:45,766 - transformer_training - INFO - Main loop iteration: 1706
2025-04-25 12:38:46,217 - transformer_training - INFO - Main loop iteration: 1707
2025-04-25 12:38:46,716 - transformer_training - INFO - Main loop iteration: 1708
2025-04-25 12:38:47,117 - transformer_training - INFO - Main loop iteration: 1709
2025-04-25 12:38:47,578 - transformer_training - INFO - Main loop iteration: 1710
Iter 1710: loss 4.9428, lr 0.000854, 81833.67 tokens/sec
2025-04-25 12:38:48,029 - transformer_training - INFO - Main loop iteration: 1711
2025-04-25 12:38:48,527 - transformer_training - INFO - Main loop iteration: 1712
2025-04-25 12:38:48,929 - transformer_training - INFO - Main loop iteration: 1713
2025-04-25 12:38:49,390 - transformer_training - INFO - Main loop iteration: 1714
2025-04-25 12:38:49,840 - transformer_training - INFO - Main loop iteration: 1715
2025-04-25 12:38:50,339 - transformer_training - INFO - Main loop iteration: 1716
2025-04-25 12:38:50,740 - transformer_training - INFO - Main loop iteration: 1717
2025-04-25 12:38:51,201 - transformer_training - INFO - Main loop iteration: 1718
2025-04-25 12:38:51,652 - transformer_training - INFO - Main loop iteration: 1719
2025-04-25 12:38:52,151 - transformer_training - INFO - Main loop iteration: 1720
Iter 1720: loss 4.8637, lr 0.000860, 91833.69 tokens/sec
2025-04-25 12:38:52,552 - transformer_training - INFO - Main loop iteration: 1721
2025-04-25 12:38:53,013 - transformer_training - INFO - Main loop iteration: 1722
2025-04-25 12:38:53,463 - transformer_training - INFO - Main loop iteration: 1723
2025-04-25 12:38:53,962 - transformer_training - INFO - Main loop iteration: 1724
2025-04-25 12:38:54,363 - transformer_training - INFO - Main loop iteration: 1725
2025-04-25 12:38:54,824 - transformer_training - INFO - Main loop iteration: 1726
2025-04-25 12:38:55,274 - transformer_training - INFO - Main loop iteration: 1727
2025-04-25 12:38:55,773 - transformer_training - INFO - Main loop iteration: 1728
2025-04-25 12:38:56,175 - transformer_training - INFO - Main loop iteration: 1729
2025-04-25 12:38:56,636 - transformer_training - INFO - Main loop iteration: 1730
Iter 1730: loss 4.9261, lr 0.000864, 81933.71 tokens/sec
2025-04-25 12:38:57,086 - transformer_training - INFO - Main loop iteration: 1731
2025-04-25 12:38:57,585 - transformer_training - INFO - Main loop iteration: 1732
2025-04-25 12:38:57,986 - transformer_training - INFO - Main loop iteration: 1733
2025-04-25 12:38:58,447 - transformer_training - INFO - Main loop iteration: 1734
2025-04-25 12:38:58,897 - transformer_training - INFO - Main loop iteration: 1735
2025-04-25 12:38:59,396 - transformer_training - INFO - Main loop iteration: 1736
2025-04-25 12:38:59,797 - transformer_training - INFO - Main loop iteration: 1737
2025-04-25 12:39:00,259 - transformer_training - INFO - Main loop iteration: 1738
2025-04-25 12:39:00,709 - transformer_training - INFO - Main loop iteration: 1739
2025-04-25 12:39:01,208 - transformer_training - INFO - Main loop iteration: 1740
Iter 1740: loss 4.8382, lr 0.000870, 91857.42 tokens/sec
2025-04-25 12:39:01,609 - transformer_training - INFO - Main loop iteration: 1741
2025-04-25 12:39:02,071 - transformer_training - INFO - Main loop iteration: 1742
2025-04-25 12:39:02,522 - transformer_training - INFO - Main loop iteration: 1743
2025-04-25 12:39:03,021 - transformer_training - INFO - Main loop iteration: 1744
2025-04-25 12:39:03,423 - transformer_training - INFO - Main loop iteration: 1745
2025-04-25 12:39:03,884 - transformer_training - INFO - Main loop iteration: 1746
2025-04-25 12:39:04,335 - transformer_training - INFO - Main loop iteration: 1747
2025-04-25 12:39:04,834 - transformer_training - INFO - Main loop iteration: 1748
2025-04-25 12:39:05,235 - transformer_training - INFO - Main loop iteration: 1749
2025-04-25 12:39:05,696 - transformer_training - INFO - Main loop iteration: 1750
Iter 1750: loss 4.8518, lr 0.000874, 81841.59 tokens/sec
2025-04-25 12:39:06,147 - transformer_training - INFO - Main loop iteration: 1751
2025-04-25 12:39:06,646 - transformer_training - INFO - Main loop iteration: 1752
2025-04-25 12:39:07,048 - transformer_training - INFO - Main loop iteration: 1753
2025-04-25 12:39:07,509 - transformer_training - INFO - Main loop iteration: 1754
2025-04-25 12:39:08,030 - transformer_training - INFO - Main loop iteration: 1755
2025-04-25 12:39:08,531 - transformer_training - INFO - Main loop iteration: 1756
2025-04-25 12:39:08,932 - transformer_training - INFO - Main loop iteration: 1757
2025-04-25 12:39:09,393 - transformer_training - INFO - Main loop iteration: 1758
2025-04-25 12:39:09,844 - transformer_training - INFO - Main loop iteration: 1759
2025-04-25 12:39:10,343 - transformer_training - INFO - Main loop iteration: 1760
Iter 1760: loss 4.8435, lr 0.000880, 92011.41 tokens/sec
2025-04-25 12:39:10,744 - transformer_training - INFO - Main loop iteration: 1761
2025-04-25 12:39:11,205 - transformer_training - INFO - Main loop iteration: 1762
2025-04-25 12:39:11,655 - transformer_training - INFO - Main loop iteration: 1763
2025-04-25 12:39:12,154 - transformer_training - INFO - Main loop iteration: 1764
2025-04-25 12:39:12,556 - transformer_training - INFO - Main loop iteration: 1765
2025-04-25 12:39:13,017 - transformer_training - INFO - Main loop iteration: 1766
2025-04-25 12:39:13,467 - transformer_training - INFO - Main loop iteration: 1767
2025-04-25 12:39:13,966 - transformer_training - INFO - Main loop iteration: 1768
2025-04-25 12:39:14,367 - transformer_training - INFO - Main loop iteration: 1769
2025-04-25 12:39:14,828 - transformer_training - INFO - Main loop iteration: 1770
Iter 1770: loss 4.8415, lr 0.000884, 81948.86 tokens/sec
2025-04-25 12:39:15,279 - transformer_training - INFO - Main loop iteration: 1771
2025-04-25 12:39:15,777 - transformer_training - INFO - Main loop iteration: 1772
2025-04-25 12:39:16,178 - transformer_training - INFO - Main loop iteration: 1773
2025-04-25 12:39:16,639 - transformer_training - INFO - Main loop iteration: 1774
2025-04-25 12:39:17,090 - transformer_training - INFO - Main loop iteration: 1775
2025-04-25 12:39:17,588 - transformer_training - INFO - Main loop iteration: 1776
2025-04-25 12:39:17,990 - transformer_training - INFO - Main loop iteration: 1777
2025-04-25 12:39:18,451 - transformer_training - INFO - Main loop iteration: 1778
2025-04-25 12:39:18,901 - transformer_training - INFO - Main loop iteration: 1779
2025-04-25 12:39:19,400 - transformer_training - INFO - Main loop iteration: 1780
Iter 1780: loss 4.7668, lr 0.000890, 92011.30 tokens/sec
2025-04-25 12:39:19,801 - transformer_training - INFO - Main loop iteration: 1781
2025-04-25 12:39:20,262 - transformer_training - INFO - Main loop iteration: 1782
2025-04-25 12:39:20,713 - transformer_training - INFO - Main loop iteration: 1783
2025-04-25 12:39:21,212 - transformer_training - INFO - Main loop iteration: 1784
2025-04-25 12:39:21,612 - transformer_training - INFO - Main loop iteration: 1785
2025-04-25 12:39:22,073 - transformer_training - INFO - Main loop iteration: 1786
2025-04-25 12:39:22,524 - transformer_training - INFO - Main loop iteration: 1787
2025-04-25 12:39:23,023 - transformer_training - INFO - Main loop iteration: 1788
2025-04-25 12:39:23,423 - transformer_training - INFO - Main loop iteration: 1789
2025-04-25 12:39:23,884 - transformer_training - INFO - Main loop iteration: 1790
Iter 1790: loss 4.8223, lr 0.000894, 81890.70 tokens/sec
2025-04-25 12:39:24,335 - transformer_training - INFO - Main loop iteration: 1791
2025-04-25 12:39:24,833 - transformer_training - INFO - Main loop iteration: 1792
2025-04-25 12:39:25,233 - transformer_training - INFO - Main loop iteration: 1793
2025-04-25 12:39:25,694 - transformer_training - INFO - Main loop iteration: 1794
2025-04-25 12:39:26,145 - transformer_training - INFO - Main loop iteration: 1795
2025-04-25 12:39:26,643 - transformer_training - INFO - Main loop iteration: 1796
2025-04-25 12:39:27,044 - transformer_training - INFO - Main loop iteration: 1797
2025-04-25 12:39:27,505 - transformer_training - INFO - Main loop iteration: 1798
2025-04-25 12:39:27,955 - transformer_training - INFO - Main loop iteration: 1799
2025-04-25 12:39:28,454 - transformer_training - INFO - Main loop iteration: 1800
Iter 1800: loss 4.7889, lr 0.000900, 91962.10 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1800: train loss 4.7616, val loss 4.6608
New best model saved with val loss: 4.6608
2025-04-25 12:39:46,552 - transformer_training - INFO - Main loop iteration: 1801
2025-04-25 12:39:46,969 - transformer_training - INFO - Main loop iteration: 1802
2025-04-25 12:39:47,419 - transformer_training - INFO - Main loop iteration: 1803
2025-04-25 12:39:47,917 - transformer_training - INFO - Main loop iteration: 1804
2025-04-25 12:39:48,318 - transformer_training - INFO - Main loop iteration: 1805
2025-04-25 12:39:48,779 - transformer_training - INFO - Main loop iteration: 1806
2025-04-25 12:39:49,228 - transformer_training - INFO - Main loop iteration: 1807
2025-04-25 12:39:49,727 - transformer_training - INFO - Main loop iteration: 1808
2025-04-25 12:39:50,127 - transformer_training - INFO - Main loop iteration: 1809
2025-04-25 12:39:50,588 - transformer_training - INFO - Main loop iteration: 1810
Iter 1810: loss 4.9191, lr 0.000904, 81984.63 tokens/sec
2025-04-25 12:39:51,038 - transformer_training - INFO - Main loop iteration: 1811
2025-04-25 12:39:51,536 - transformer_training - INFO - Main loop iteration: 1812
2025-04-25 12:39:51,936 - transformer_training - INFO - Main loop iteration: 1813
2025-04-25 12:39:52,397 - transformer_training - INFO - Main loop iteration: 1814
2025-04-25 12:39:52,847 - transformer_training - INFO - Main loop iteration: 1815
2025-04-25 12:39:53,347 - transformer_training - INFO - Main loop iteration: 1816
2025-04-25 12:39:53,748 - transformer_training - INFO - Main loop iteration: 1817
2025-04-25 12:39:54,209 - transformer_training - INFO - Main loop iteration: 1818
2025-04-25 12:39:54,660 - transformer_training - INFO - Main loop iteration: 1819
2025-04-25 12:39:55,159 - transformer_training - INFO - Main loop iteration: 1820
Iter 1820: loss 4.8023, lr 0.000910, 92081.71 tokens/sec
2025-04-25 12:39:55,559 - transformer_training - INFO - Main loop iteration: 1821
2025-04-25 12:39:56,020 - transformer_training - INFO - Main loop iteration: 1822
2025-04-25 12:39:56,470 - transformer_training - INFO - Main loop iteration: 1823
2025-04-25 12:39:56,969 - transformer_training - INFO - Main loop iteration: 1824
2025-04-25 12:39:57,369 - transformer_training - INFO - Main loop iteration: 1825
2025-04-25 12:39:57,830 - transformer_training - INFO - Main loop iteration: 1826
2025-04-25 12:39:58,280 - transformer_training - INFO - Main loop iteration: 1827
2025-04-25 12:39:58,779 - transformer_training - INFO - Main loop iteration: 1828
2025-04-25 12:39:59,179 - transformer_training - INFO - Main loop iteration: 1829
2025-04-25 12:39:59,640 - transformer_training - INFO - Main loop iteration: 1830
Iter 1830: loss 4.8256, lr 0.000914, 81969.80 tokens/sec
2025-04-25 12:40:00,090 - transformer_training - INFO - Main loop iteration: 1831
2025-04-25 12:40:00,589 - transformer_training - INFO - Main loop iteration: 1832
2025-04-25 12:40:00,990 - transformer_training - INFO - Main loop iteration: 1833
2025-04-25 12:40:01,450 - transformer_training - INFO - Main loop iteration: 1834
2025-04-25 12:40:01,901 - transformer_training - INFO - Main loop iteration: 1835
2025-04-25 12:40:02,400 - transformer_training - INFO - Main loop iteration: 1836
2025-04-25 12:40:02,801 - transformer_training - INFO - Main loop iteration: 1837
2025-04-25 12:40:03,262 - transformer_training - INFO - Main loop iteration: 1838
2025-04-25 12:40:03,712 - transformer_training - INFO - Main loop iteration: 1839
2025-04-25 12:40:04,211 - transformer_training - INFO - Main loop iteration: 1840
Iter 1840: loss 4.8093, lr 0.000920, 91927.38 tokens/sec
2025-04-25 12:40:04,612 - transformer_training - INFO - Main loop iteration: 1841
2025-04-25 12:40:05,074 - transformer_training - INFO - Main loop iteration: 1842
2025-04-25 12:40:05,524 - transformer_training - INFO - Main loop iteration: 1843
2025-04-25 12:40:06,022 - transformer_training - INFO - Main loop iteration: 1844
2025-04-25 12:40:06,423 - transformer_training - INFO - Main loop iteration: 1845
2025-04-25 12:40:06,885 - transformer_training - INFO - Main loop iteration: 1846
2025-04-25 12:40:07,335 - transformer_training - INFO - Main loop iteration: 1847
2025-04-25 12:40:07,834 - transformer_training - INFO - Main loop iteration: 1848
2025-04-25 12:40:08,234 - transformer_training - INFO - Main loop iteration: 1849
2025-04-25 12:40:08,695 - transformer_training - INFO - Main loop iteration: 1850
Iter 1850: loss 4.7631, lr 0.000924, 81888.15 tokens/sec
2025-04-25 12:40:09,146 - transformer_training - INFO - Main loop iteration: 1851
2025-04-25 12:40:09,644 - transformer_training - INFO - Main loop iteration: 1852
2025-04-25 12:40:10,045 - transformer_training - INFO - Main loop iteration: 1853
2025-04-25 12:40:10,506 - transformer_training - INFO - Main loop iteration: 1854
2025-04-25 12:40:10,957 - transformer_training - INFO - Main loop iteration: 1855
2025-04-25 12:40:11,455 - transformer_training - INFO - Main loop iteration: 1856
2025-04-25 12:40:11,856 - transformer_training - INFO - Main loop iteration: 1857
2025-04-25 12:40:12,318 - transformer_training - INFO - Main loop iteration: 1858
2025-04-25 12:40:12,769 - transformer_training - INFO - Main loop iteration: 1859
2025-04-25 12:40:13,267 - transformer_training - INFO - Main loop iteration: 1860
Iter 1860: loss 4.7330, lr 0.000930, 91920.33 tokens/sec
2025-04-25 12:40:13,668 - transformer_training - INFO - Main loop iteration: 1861
2025-04-25 12:40:14,129 - transformer_training - INFO - Main loop iteration: 1862
2025-04-25 12:40:14,580 - transformer_training - INFO - Main loop iteration: 1863
2025-04-25 12:40:15,079 - transformer_training - INFO - Main loop iteration: 1864
2025-04-25 12:40:15,479 - transformer_training - INFO - Main loop iteration: 1865
2025-04-25 12:40:15,940 - transformer_training - INFO - Main loop iteration: 1866
2025-04-25 12:40:16,394 - transformer_training - INFO - Main loop iteration: 1867
2025-04-25 12:40:16,893 - transformer_training - INFO - Main loop iteration: 1868
2025-04-25 12:40:17,294 - transformer_training - INFO - Main loop iteration: 1869
2025-04-25 12:40:17,755 - transformer_training - INFO - Main loop iteration: 1870
Iter 1870: loss 4.7703, lr 0.000934, 81894.70 tokens/sec
2025-04-25 12:40:18,206 - transformer_training - INFO - Main loop iteration: 1871
2025-04-25 12:40:18,705 - transformer_training - INFO - Main loop iteration: 1872
2025-04-25 12:40:19,107 - transformer_training - INFO - Main loop iteration: 1873
2025-04-25 12:40:19,568 - transformer_training - INFO - Main loop iteration: 1874
2025-04-25 12:40:20,019 - transformer_training - INFO - Main loop iteration: 1875
2025-04-25 12:40:20,518 - transformer_training - INFO - Main loop iteration: 1876
2025-04-25 12:40:20,920 - transformer_training - INFO - Main loop iteration: 1877
2025-04-25 12:40:21,381 - transformer_training - INFO - Main loop iteration: 1878
2025-04-25 12:40:21,832 - transformer_training - INFO - Main loop iteration: 1879
2025-04-25 12:40:22,332 - transformer_training - INFO - Main loop iteration: 1880
Iter 1880: loss 4.6811, lr 0.000940, 91710.42 tokens/sec
2025-04-25 12:40:22,734 - transformer_training - INFO - Main loop iteration: 1881
2025-04-25 12:40:23,195 - transformer_training - INFO - Main loop iteration: 1882
2025-04-25 12:40:23,646 - transformer_training - INFO - Main loop iteration: 1883
2025-04-25 12:40:24,145 - transformer_training - INFO - Main loop iteration: 1884
2025-04-25 12:40:24,547 - transformer_training - INFO - Main loop iteration: 1885
2025-04-25 12:40:25,008 - transformer_training - INFO - Main loop iteration: 1886
2025-04-25 12:40:25,459 - transformer_training - INFO - Main loop iteration: 1887
2025-04-25 12:40:25,958 - transformer_training - INFO - Main loop iteration: 1888
2025-04-25 12:40:26,360 - transformer_training - INFO - Main loop iteration: 1889
2025-04-25 12:40:26,821 - transformer_training - INFO - Main loop iteration: 1890
Iter 1890: loss 4.7498, lr 0.000944, 81892.05 tokens/sec
2025-04-25 12:40:27,272 - transformer_training - INFO - Main loop iteration: 1891
2025-04-25 12:40:27,770 - transformer_training - INFO - Main loop iteration: 1892
2025-04-25 12:40:28,172 - transformer_training - INFO - Main loop iteration: 1893
2025-04-25 12:40:28,633 - transformer_training - INFO - Main loop iteration: 1894
2025-04-25 12:40:29,084 - transformer_training - INFO - Main loop iteration: 1895
2025-04-25 12:40:29,583 - transformer_training - INFO - Main loop iteration: 1896
2025-04-25 12:40:29,983 - transformer_training - INFO - Main loop iteration: 1897
2025-04-25 12:40:30,444 - transformer_training - INFO - Main loop iteration: 1898
2025-04-25 12:40:30,895 - transformer_training - INFO - Main loop iteration: 1899
2025-04-25 12:40:31,393 - transformer_training - INFO - Main loop iteration: 1900
Iter 1900: loss 4.7751, lr 0.000950, 92018.53 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 1900: train loss 4.6652, val loss 4.5709
New best model saved with val loss: 4.5709
2025-04-25 12:40:49,874 - transformer_training - INFO - Main loop iteration: 1901
2025-04-25 12:40:50,285 - transformer_training - INFO - Main loop iteration: 1902
2025-04-25 12:40:50,735 - transformer_training - INFO - Main loop iteration: 1903
2025-04-25 12:40:51,234 - transformer_training - INFO - Main loop iteration: 1904
2025-04-25 12:40:51,635 - transformer_training - INFO - Main loop iteration: 1905
2025-04-25 12:40:52,096 - transformer_training - INFO - Main loop iteration: 1906
2025-04-25 12:40:52,546 - transformer_training - INFO - Main loop iteration: 1907
2025-04-25 12:40:53,045 - transformer_training - INFO - Main loop iteration: 1908
2025-04-25 12:40:53,446 - transformer_training - INFO - Main loop iteration: 1909
2025-04-25 12:40:53,906 - transformer_training - INFO - Main loop iteration: 1910
Iter 1910: loss 4.6699, lr 0.000954, 81812.93 tokens/sec
2025-04-25 12:40:54,358 - transformer_training - INFO - Main loop iteration: 1911
2025-04-25 12:40:54,856 - transformer_training - INFO - Main loop iteration: 1912
2025-04-25 12:40:55,257 - transformer_training - INFO - Main loop iteration: 1913
2025-04-25 12:40:55,717 - transformer_training - INFO - Main loop iteration: 1914
2025-04-25 12:40:56,168 - transformer_training - INFO - Main loop iteration: 1915
2025-04-25 12:40:56,667 - transformer_training - INFO - Main loop iteration: 1916
2025-04-25 12:40:57,068 - transformer_training - INFO - Main loop iteration: 1917
2025-04-25 12:40:57,529 - transformer_training - INFO - Main loop iteration: 1918
2025-04-25 12:40:57,979 - transformer_training - INFO - Main loop iteration: 1919
2025-04-25 12:40:58,477 - transformer_training - INFO - Main loop iteration: 1920
Iter 1920: loss 4.7540, lr 0.000960, 91833.58 tokens/sec
2025-04-25 12:40:58,879 - transformer_training - INFO - Main loop iteration: 1921
2025-04-25 12:40:59,340 - transformer_training - INFO - Main loop iteration: 1922
2025-04-25 12:40:59,790 - transformer_training - INFO - Main loop iteration: 1923
2025-04-25 12:41:00,288 - transformer_training - INFO - Main loop iteration: 1924
2025-04-25 12:41:00,690 - transformer_training - INFO - Main loop iteration: 1925
2025-04-25 12:41:01,151 - transformer_training - INFO - Main loop iteration: 1926
2025-04-25 12:41:01,602 - transformer_training - INFO - Main loop iteration: 1927
2025-04-25 12:41:02,102 - transformer_training - INFO - Main loop iteration: 1928
2025-04-25 12:41:02,503 - transformer_training - INFO - Main loop iteration: 1929
2025-04-25 12:41:02,964 - transformer_training - INFO - Main loop iteration: 1930
Iter 1930: loss 4.7021, lr 0.000964, 81943.91 tokens/sec
2025-04-25 12:41:03,414 - transformer_training - INFO - Main loop iteration: 1931
2025-04-25 12:41:03,913 - transformer_training - INFO - Main loop iteration: 1932
2025-04-25 12:41:04,314 - transformer_training - INFO - Main loop iteration: 1933
2025-04-25 12:41:04,775 - transformer_training - INFO - Main loop iteration: 1934
2025-04-25 12:41:05,226 - transformer_training - INFO - Main loop iteration: 1935
2025-04-25 12:41:05,724 - transformer_training - INFO - Main loop iteration: 1936
2025-04-25 12:41:06,126 - transformer_training - INFO - Main loop iteration: 1937
2025-04-25 12:41:06,587 - transformer_training - INFO - Main loop iteration: 1938
2025-04-25 12:41:07,038 - transformer_training - INFO - Main loop iteration: 1939
2025-04-25 12:41:07,536 - transformer_training - INFO - Main loop iteration: 1940
Iter 1940: loss 4.7093, lr 0.000970, 91706.83 tokens/sec
2025-04-25 12:41:07,938 - transformer_training - INFO - Main loop iteration: 1941
2025-04-25 12:41:08,399 - transformer_training - INFO - Main loop iteration: 1942
2025-04-25 12:41:08,850 - transformer_training - INFO - Main loop iteration: 1943
2025-04-25 12:41:09,349 - transformer_training - INFO - Main loop iteration: 1944
2025-04-25 12:41:09,751 - transformer_training - INFO - Main loop iteration: 1945
2025-04-25 12:41:10,211 - transformer_training - INFO - Main loop iteration: 1946
2025-04-25 12:41:10,662 - transformer_training - INFO - Main loop iteration: 1947
2025-04-25 12:41:11,161 - transformer_training - INFO - Main loop iteration: 1948
2025-04-25 12:41:11,562 - transformer_training - INFO - Main loop iteration: 1949
2025-04-25 12:41:12,023 - transformer_training - INFO - Main loop iteration: 1950
Iter 1950: loss 4.6946, lr 0.000974, 81836.61 tokens/sec
2025-04-25 12:41:12,474 - transformer_training - INFO - Main loop iteration: 1951
2025-04-25 12:41:12,972 - transformer_training - INFO - Main loop iteration: 1952
2025-04-25 12:41:13,373 - transformer_training - INFO - Main loop iteration: 1953
2025-04-25 12:41:13,834 - transformer_training - INFO - Main loop iteration: 1954
2025-04-25 12:41:14,284 - transformer_training - INFO - Main loop iteration: 1955
2025-04-25 12:41:14,783 - transformer_training - INFO - Main loop iteration: 1956
2025-04-25 12:41:15,184 - transformer_training - INFO - Main loop iteration: 1957
2025-04-25 12:41:15,645 - transformer_training - INFO - Main loop iteration: 1958
2025-04-25 12:41:16,095 - transformer_training - INFO - Main loop iteration: 1959
2025-04-25 12:41:16,594 - transformer_training - INFO - Main loop iteration: 1960
Iter 1960: loss 4.7330, lr 0.000980, 91874.02 tokens/sec
2025-04-25 12:41:16,996 - transformer_training - INFO - Main loop iteration: 1961
2025-04-25 12:41:17,457 - transformer_training - INFO - Main loop iteration: 1962
2025-04-25 12:41:17,907 - transformer_training - INFO - Main loop iteration: 1963
2025-04-25 12:41:18,406 - transformer_training - INFO - Main loop iteration: 1964
2025-04-25 12:41:18,807 - transformer_training - INFO - Main loop iteration: 1965
2025-04-25 12:41:19,268 - transformer_training - INFO - Main loop iteration: 1966
2025-04-25 12:41:19,718 - transformer_training - INFO - Main loop iteration: 1967
2025-04-25 12:41:20,217 - transformer_training - INFO - Main loop iteration: 1968
2025-04-25 12:41:20,618 - transformer_training - INFO - Main loop iteration: 1969
2025-04-25 12:41:21,079 - transformer_training - INFO - Main loop iteration: 1970
Iter 1970: loss 4.7260, lr 0.000984, 81892.05 tokens/sec
2025-04-25 12:41:21,530 - transformer_training - INFO - Main loop iteration: 1971
2025-04-25 12:41:22,029 - transformer_training - INFO - Main loop iteration: 1972
2025-04-25 12:41:22,429 - transformer_training - INFO - Main loop iteration: 1973
2025-04-25 12:41:22,890 - transformer_training - INFO - Main loop iteration: 1974
2025-04-25 12:41:23,340 - transformer_training - INFO - Main loop iteration: 1975
2025-04-25 12:41:23,838 - transformer_training - INFO - Main loop iteration: 1976
2025-04-25 12:41:24,239 - transformer_training - INFO - Main loop iteration: 1977
2025-04-25 12:41:24,700 - transformer_training - INFO - Main loop iteration: 1978
2025-04-25 12:41:25,150 - transformer_training - INFO - Main loop iteration: 1979
2025-04-25 12:41:25,648 - transformer_training - INFO - Main loop iteration: 1980
Iter 1980: loss 4.6767, lr 0.000990, 92130.27 tokens/sec
2025-04-25 12:41:26,049 - transformer_training - INFO - Main loop iteration: 1981
2025-04-25 12:41:26,509 - transformer_training - INFO - Main loop iteration: 1982
2025-04-25 12:41:26,959 - transformer_training - INFO - Main loop iteration: 1983
2025-04-25 12:41:27,458 - transformer_training - INFO - Main loop iteration: 1984
2025-04-25 12:41:27,858 - transformer_training - INFO - Main loop iteration: 1985
2025-04-25 12:41:28,319 - transformer_training - INFO - Main loop iteration: 1986
2025-04-25 12:41:28,769 - transformer_training - INFO - Main loop iteration: 1987
2025-04-25 12:41:29,268 - transformer_training - INFO - Main loop iteration: 1988
2025-04-25 12:41:29,668 - transformer_training - INFO - Main loop iteration: 1989
2025-04-25 12:41:30,129 - transformer_training - INFO - Main loop iteration: 1990
Iter 1990: loss 4.6569, lr 0.000994, 81954.64 tokens/sec
2025-04-25 12:41:30,579 - transformer_training - INFO - Main loop iteration: 1991
2025-04-25 12:41:31,077 - transformer_training - INFO - Main loop iteration: 1992
2025-04-25 12:41:31,478 - transformer_training - INFO - Main loop iteration: 1993
2025-04-25 12:41:31,939 - transformer_training - INFO - Main loop iteration: 1994
2025-04-25 12:41:32,389 - transformer_training - INFO - Main loop iteration: 1995
2025-04-25 12:41:32,889 - transformer_training - INFO - Main loop iteration: 1996
2025-04-25 12:41:33,290 - transformer_training - INFO - Main loop iteration: 1997
2025-04-25 12:41:33,751 - transformer_training - INFO - Main loop iteration: 1998
2025-04-25 12:41:34,201 - transformer_training - INFO - Main loop iteration: 1999
2025-04-25 12:41:34,700 - transformer_training - INFO - Main loop iteration: 2000
Iter 2000: loss 4.6425, lr 0.001000, 91979.44 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!Flash Attention is available!

Flash Attention is available!
Flash Attention is available!
Flash Attention is available!Flash Attention is available!

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 2000: train loss 4.5967, val loss 4.4907
New best model saved with val loss: 4.4907
2025-04-25 12:41:55,476 - transformer_training - INFO - Main loop iteration: 2001
2025-04-25 12:41:55,972 - transformer_training - INFO - Main loop iteration: 2002
2025-04-25 12:41:56,422 - transformer_training - INFO - Main loop iteration: 2003
2025-04-25 12:41:56,921 - transformer_training - INFO - Main loop iteration: 2004
2025-04-25 12:41:57,321 - transformer_training - INFO - Main loop iteration: 2005
2025-04-25 12:41:57,782 - transformer_training - INFO - Main loop iteration: 2006
2025-04-25 12:41:58,232 - transformer_training - INFO - Main loop iteration: 2007
2025-04-25 12:41:58,731 - transformer_training - INFO - Main loop iteration: 2008
2025-04-25 12:41:59,131 - transformer_training - INFO - Main loop iteration: 2009
2025-04-25 12:41:59,592 - transformer_training - INFO - Main loop iteration: 2010
Iter 2010: loss 4.6713, lr 0.001000, 81959.51 tokens/sec
2025-04-25 12:42:00,043 - transformer_training - INFO - Main loop iteration: 2011
2025-04-25 12:42:00,540 - transformer_training - INFO - Main loop iteration: 2012
2025-04-25 12:42:00,942 - transformer_training - INFO - Main loop iteration: 2013
2025-04-25 12:42:01,403 - transformer_training - INFO - Main loop iteration: 2014
2025-04-25 12:42:01,853 - transformer_training - INFO - Main loop iteration: 2015
2025-04-25 12:42:02,352 - transformer_training - INFO - Main loop iteration: 2016
2025-04-25 12:42:02,753 - transformer_training - INFO - Main loop iteration: 2017
2025-04-25 12:42:03,214 - transformer_training - INFO - Main loop iteration: 2018
2025-04-25 12:42:03,664 - transformer_training - INFO - Main loop iteration: 2019
2025-04-25 12:42:04,163 - transformer_training - INFO - Main loop iteration: 2020
Iter 2020: loss 4.6387, lr 0.001000, 91890.40 tokens/sec
2025-04-25 12:42:04,564 - transformer_training - INFO - Main loop iteration: 2021
2025-04-25 12:42:05,025 - transformer_training - INFO - Main loop iteration: 2022
2025-04-25 12:42:05,475 - transformer_training - INFO - Main loop iteration: 2023
2025-04-25 12:42:05,974 - transformer_training - INFO - Main loop iteration: 2024
2025-04-25 12:42:06,375 - transformer_training - INFO - Main loop iteration: 2025
2025-04-25 12:42:06,837 - transformer_training - INFO - Main loop iteration: 2026
2025-04-25 12:42:07,288 - transformer_training - INFO - Main loop iteration: 2027
2025-04-25 12:42:07,786 - transformer_training - INFO - Main loop iteration: 2028
2025-04-25 12:42:08,188 - transformer_training - INFO - Main loop iteration: 2029
2025-04-25 12:42:08,649 - transformer_training - INFO - Main loop iteration: 2030
Iter 2030: loss 4.5665, lr 0.001000, 81900.59 tokens/sec
2025-04-25 12:42:09,099 - transformer_training - INFO - Main loop iteration: 2031
2025-04-25 12:42:09,598 - transformer_training - INFO - Main loop iteration: 2032
2025-04-25 12:42:09,999 - transformer_training - INFO - Main loop iteration: 2033
2025-04-25 12:42:10,461 - transformer_training - INFO - Main loop iteration: 2034
2025-04-25 12:42:10,911 - transformer_training - INFO - Main loop iteration: 2035
2025-04-25 12:42:11,410 - transformer_training - INFO - Main loop iteration: 2036
2025-04-25 12:42:11,812 - transformer_training - INFO - Main loop iteration: 2037
2025-04-25 12:42:12,273 - transformer_training - INFO - Main loop iteration: 2038
2025-04-25 12:42:12,724 - transformer_training - INFO - Main loop iteration: 2039
2025-04-25 12:42:13,223 - transformer_training - INFO - Main loop iteration: 2040
Iter 2040: loss 4.6624, lr 0.001000, 91911.59 tokens/sec
2025-04-25 12:42:13,624 - transformer_training - INFO - Main loop iteration: 2041
2025-04-25 12:42:14,085 - transformer_training - INFO - Main loop iteration: 2042
2025-04-25 12:42:14,535 - transformer_training - INFO - Main loop iteration: 2043
2025-04-25 12:42:15,034 - transformer_training - INFO - Main loop iteration: 2044
2025-04-25 12:42:15,436 - transformer_training - INFO - Main loop iteration: 2045
2025-04-25 12:42:15,896 - transformer_training - INFO - Main loop iteration: 2046
2025-04-25 12:42:16,348 - transformer_training - INFO - Main loop iteration: 2047
2025-04-25 12:42:16,848 - transformer_training - INFO - Main loop iteration: 2048
2025-04-25 12:42:17,249 - transformer_training - INFO - Main loop iteration: 2049
2025-04-25 12:42:17,711 - transformer_training - INFO - Main loop iteration: 2050
Iter 2050: loss 4.5625, lr 0.001000, 81974.98 tokens/sec
2025-04-25 12:42:18,161 - transformer_training - INFO - Main loop iteration: 2051
2025-04-25 12:42:18,660 - transformer_training - INFO - Main loop iteration: 2052
2025-04-25 12:42:19,062 - transformer_training - INFO - Main loop iteration: 2053
2025-04-25 12:42:19,523 - transformer_training - INFO - Main loop iteration: 2054
2025-04-25 12:42:19,974 - transformer_training - INFO - Main loop iteration: 2055
2025-04-25 12:42:20,473 - transformer_training - INFO - Main loop iteration: 2056
2025-04-25 12:42:20,874 - transformer_training - INFO - Main loop iteration: 2057
2025-04-25 12:42:21,335 - transformer_training - INFO - Main loop iteration: 2058
2025-04-25 12:42:21,786 - transformer_training - INFO - Main loop iteration: 2059
2025-04-25 12:42:22,286 - transformer_training - INFO - Main loop iteration: 2060
Iter 2060: loss 4.7309, lr 0.001000, 92026.52 tokens/sec
2025-04-25 12:42:22,687 - transformer_training - INFO - Main loop iteration: 2061
2025-04-25 12:42:23,148 - transformer_training - INFO - Main loop iteration: 2062
2025-04-25 12:42:23,598 - transformer_training - INFO - Main loop iteration: 2063
2025-04-25 12:42:24,097 - transformer_training - INFO - Main loop iteration: 2064
2025-04-25 12:42:24,498 - transformer_training - INFO - Main loop iteration: 2065
2025-04-25 12:42:24,959 - transformer_training - INFO - Main loop iteration: 2066
2025-04-25 12:42:25,409 - transformer_training - INFO - Main loop iteration: 2067
2025-04-25 12:42:25,908 - transformer_training - INFO - Main loop iteration: 2068
2025-04-25 12:42:26,309 - transformer_training - INFO - Main loop iteration: 2069
2025-04-25 12:42:26,770 - transformer_training - INFO - Main loop iteration: 2070
Iter 2070: loss 4.6261, lr 0.001000, 81965.29 tokens/sec
2025-04-25 12:42:27,221 - transformer_training - INFO - Main loop iteration: 2071
2025-04-25 12:42:27,719 - transformer_training - INFO - Main loop iteration: 2072
2025-04-25 12:42:28,120 - transformer_training - INFO - Main loop iteration: 2073
2025-04-25 12:42:28,582 - transformer_training - INFO - Main loop iteration: 2074
2025-04-25 12:42:29,032 - transformer_training - INFO - Main loop iteration: 2075
2025-04-25 12:42:29,531 - transformer_training - INFO - Main loop iteration: 2076
2025-04-25 12:42:29,932 - transformer_training - INFO - Main loop iteration: 2077
2025-04-25 12:42:30,393 - transformer_training - INFO - Main loop iteration: 2078
2025-04-25 12:42:30,844 - transformer_training - INFO - Main loop iteration: 2079
2025-04-25 12:42:31,343 - transformer_training - INFO - Main loop iteration: 2080
Iter 2080: loss 4.6551, lr 0.001000, 91931.43 tokens/sec
2025-04-25 12:42:31,744 - transformer_training - INFO - Main loop iteration: 2081
2025-04-25 12:42:32,205 - transformer_training - INFO - Main loop iteration: 2082
2025-04-25 12:42:32,656 - transformer_training - INFO - Main loop iteration: 2083
2025-04-25 12:42:33,155 - transformer_training - INFO - Main loop iteration: 2084
2025-04-25 12:42:33,556 - transformer_training - INFO - Main loop iteration: 2085
2025-04-25 12:42:34,018 - transformer_training - INFO - Main loop iteration: 2086
2025-04-25 12:42:34,468 - transformer_training - INFO - Main loop iteration: 2087
2025-04-25 12:42:34,967 - transformer_training - INFO - Main loop iteration: 2088
2025-04-25 12:42:35,368 - transformer_training - INFO - Main loop iteration: 2089
2025-04-25 12:42:35,828 - transformer_training - INFO - Main loop iteration: 2090
Iter 2090: loss 4.4941, lr 0.001000, 81890.57 tokens/sec
2025-04-25 12:42:36,279 - transformer_training - INFO - Main loop iteration: 2091
2025-04-25 12:42:36,778 - transformer_training - INFO - Main loop iteration: 2092
2025-04-25 12:42:37,179 - transformer_training - INFO - Main loop iteration: 2093
2025-04-25 12:42:37,640 - transformer_training - INFO - Main loop iteration: 2094
2025-04-25 12:42:38,091 - transformer_training - INFO - Main loop iteration: 2095
2025-04-25 12:42:38,590 - transformer_training - INFO - Main loop iteration: 2096
2025-04-25 12:42:38,992 - transformer_training - INFO - Main loop iteration: 2097
2025-04-25 12:42:39,453 - transformer_training - INFO - Main loop iteration: 2098
2025-04-25 12:42:39,904 - transformer_training - INFO - Main loop iteration: 2099
2025-04-25 12:42:40,403 - transformer_training - INFO - Main loop iteration: 2100
Iter 2100: loss 4.5492, lr 0.001000, 91971.40 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 2100: train loss 4.5088, val loss 4.4099
New best model saved with val loss: 4.4099
2025-04-25 12:42:59,087 - transformer_training - INFO - Main loop iteration: 2101
2025-04-25 12:42:59,506 - transformer_training - INFO - Main loop iteration: 2102
2025-04-25 12:42:59,954 - transformer_training - INFO - Main loop iteration: 2103
2025-04-25 12:43:00,452 - transformer_training - INFO - Main loop iteration: 2104
2025-04-25 12:43:00,853 - transformer_training - INFO - Main loop iteration: 2105
2025-04-25 12:43:01,313 - transformer_training - INFO - Main loop iteration: 2106
2025-04-25 12:43:01,763 - transformer_training - INFO - Main loop iteration: 2107
2025-04-25 12:43:02,262 - transformer_training - INFO - Main loop iteration: 2108
2025-04-25 12:43:02,662 - transformer_training - INFO - Main loop iteration: 2109
2025-04-25 12:43:03,123 - transformer_training - INFO - Main loop iteration: 2110
Iter 2110: loss 4.5589, lr 0.001000, 81979.41 tokens/sec
2025-04-25 12:43:03,573 - transformer_training - INFO - Main loop iteration: 2111
2025-04-25 12:43:04,071 - transformer_training - INFO - Main loop iteration: 2112
2025-04-25 12:43:04,471 - transformer_training - INFO - Main loop iteration: 2113
2025-04-25 12:43:04,932 - transformer_training - INFO - Main loop iteration: 2114
2025-04-25 12:43:05,382 - transformer_training - INFO - Main loop iteration: 2115
2025-04-25 12:43:05,881 - transformer_training - INFO - Main loop iteration: 2116
2025-04-25 12:43:06,281 - transformer_training - INFO - Main loop iteration: 2117
2025-04-25 12:43:06,742 - transformer_training - INFO - Main loop iteration: 2118
2025-04-25 12:43:07,193 - transformer_training - INFO - Main loop iteration: 2119
2025-04-25 12:43:07,691 - transformer_training - INFO - Main loop iteration: 2120
Iter 2120: loss 4.5888, lr 0.001000, 92103.43 tokens/sec
2025-04-25 12:43:08,092 - transformer_training - INFO - Main loop iteration: 2121
2025-04-25 12:43:08,553 - transformer_training - INFO - Main loop iteration: 2122
2025-04-25 12:43:09,003 - transformer_training - INFO - Main loop iteration: 2123
2025-04-25 12:43:09,501 - transformer_training - INFO - Main loop iteration: 2124
2025-04-25 12:43:09,902 - transformer_training - INFO - Main loop iteration: 2125
2025-04-25 12:43:10,363 - transformer_training - INFO - Main loop iteration: 2126
2025-04-25 12:43:10,813 - transformer_training - INFO - Main loop iteration: 2127
2025-04-25 12:43:11,312 - transformer_training - INFO - Main loop iteration: 2128
2025-04-25 12:43:11,713 - transformer_training - INFO - Main loop iteration: 2129
2025-04-25 12:43:12,174 - transformer_training - INFO - Main loop iteration: 2130
Iter 2130: loss 4.5868, lr 0.001000, 81886.11 tokens/sec
2025-04-25 12:43:12,624 - transformer_training - INFO - Main loop iteration: 2131
2025-04-25 12:43:13,123 - transformer_training - INFO - Main loop iteration: 2132
2025-04-25 12:43:13,524 - transformer_training - INFO - Main loop iteration: 2133
2025-04-25 12:43:13,984 - transformer_training - INFO - Main loop iteration: 2134
2025-04-25 12:43:14,435 - transformer_training - INFO - Main loop iteration: 2135
2025-04-25 12:43:14,934 - transformer_training - INFO - Main loop iteration: 2136
2025-04-25 12:43:15,335 - transformer_training - INFO - Main loop iteration: 2137
2025-04-25 12:43:15,796 - transformer_training - INFO - Main loop iteration: 2138
2025-04-25 12:43:16,246 - transformer_training - INFO - Main loop iteration: 2139
2025-04-25 12:43:16,745 - transformer_training - INFO - Main loop iteration: 2140
Iter 2140: loss 4.4619, lr 0.001000, 91934.27 tokens/sec
2025-04-25 12:43:17,146 - transformer_training - INFO - Main loop iteration: 2141
2025-04-25 12:43:17,606 - transformer_training - INFO - Main loop iteration: 2142
2025-04-25 12:43:18,056 - transformer_training - INFO - Main loop iteration: 2143
2025-04-25 12:43:18,556 - transformer_training - INFO - Main loop iteration: 2144
2025-04-25 12:43:18,957 - transformer_training - INFO - Main loop iteration: 2145
2025-04-25 12:43:19,417 - transformer_training - INFO - Main loop iteration: 2146
2025-04-25 12:43:19,868 - transformer_training - INFO - Main loop iteration: 2147
2025-04-25 12:43:20,366 - transformer_training - INFO - Main loop iteration: 2148
2025-04-25 12:43:20,768 - transformer_training - INFO - Main loop iteration: 2149
2025-04-25 12:43:21,229 - transformer_training - INFO - Main loop iteration: 2150
Iter 2150: loss 4.5224, lr 0.001000, 81637.33 tokens/sec
2025-04-25 12:43:21,681 - transformer_training - INFO - Main loop iteration: 2151
2025-04-25 12:43:22,180 - transformer_training - INFO - Main loop iteration: 2152
2025-04-25 12:43:22,581 - transformer_training - INFO - Main loop iteration: 2153
2025-04-25 12:43:23,042 - transformer_training - INFO - Main loop iteration: 2154
2025-04-25 12:43:23,493 - transformer_training - INFO - Main loop iteration: 2155
2025-04-25 12:43:23,991 - transformer_training - INFO - Main loop iteration: 2156
2025-04-25 12:43:24,392 - transformer_training - INFO - Main loop iteration: 2157
2025-04-25 12:43:24,853 - transformer_training - INFO - Main loop iteration: 2158
2025-04-25 12:43:25,304 - transformer_training - INFO - Main loop iteration: 2159
2025-04-25 12:43:25,802 - transformer_training - INFO - Main loop iteration: 2160
Iter 2160: loss 4.4519, lr 0.001000, 92081.82 tokens/sec
2025-04-25 12:43:26,203 - transformer_training - INFO - Main loop iteration: 2161
2025-04-25 12:43:26,663 - transformer_training - INFO - Main loop iteration: 2162
2025-04-25 12:43:27,114 - transformer_training - INFO - Main loop iteration: 2163
2025-04-25 12:43:27,612 - transformer_training - INFO - Main loop iteration: 2164
2025-04-25 12:43:28,014 - transformer_training - INFO - Main loop iteration: 2165
2025-04-25 12:43:28,475 - transformer_training - INFO - Main loop iteration: 2166
2025-04-25 12:43:28,925 - transformer_training - INFO - Main loop iteration: 2167
2025-04-25 12:43:29,425 - transformer_training - INFO - Main loop iteration: 2168
2025-04-25 12:43:29,826 - transformer_training - INFO - Main loop iteration: 2169
2025-04-25 12:43:30,286 - transformer_training - INFO - Main loop iteration: 2170
Iter 2170: loss 4.4964, lr 0.001000, 81966.46 tokens/sec
2025-04-25 12:43:30,737 - transformer_training - INFO - Main loop iteration: 2171
2025-04-25 12:43:31,235 - transformer_training - INFO - Main loop iteration: 2172
2025-04-25 12:43:31,636 - transformer_training - INFO - Main loop iteration: 2173
2025-04-25 12:43:32,098 - transformer_training - INFO - Main loop iteration: 2174
2025-04-25 12:43:32,549 - transformer_training - INFO - Main loop iteration: 2175
2025-04-25 12:43:33,047 - transformer_training - INFO - Main loop iteration: 2176
2025-04-25 12:43:33,448 - transformer_training - INFO - Main loop iteration: 2177
2025-04-25 12:43:33,910 - transformer_training - INFO - Main loop iteration: 2178
2025-04-25 12:43:34,360 - transformer_training - INFO - Main loop iteration: 2179
2025-04-25 12:43:34,859 - transformer_training - INFO - Main loop iteration: 2180
Iter 2180: loss 4.5714, lr 0.001000, 91945.53 tokens/sec
2025-04-25 12:43:35,260 - transformer_training - INFO - Main loop iteration: 2181
2025-04-25 12:43:35,721 - transformer_training - INFO - Main loop iteration: 2182
2025-04-25 12:43:36,171 - transformer_training - INFO - Main loop iteration: 2183
2025-04-25 12:43:36,670 - transformer_training - INFO - Main loop iteration: 2184
2025-04-25 12:43:37,072 - transformer_training - INFO - Main loop iteration: 2185
2025-04-25 12:43:37,533 - transformer_training - INFO - Main loop iteration: 2186
2025-04-25 12:43:37,983 - transformer_training - INFO - Main loop iteration: 2187
2025-04-25 12:43:38,482 - transformer_training - INFO - Main loop iteration: 2188
2025-04-25 12:43:38,884 - transformer_training - INFO - Main loop iteration: 2189
2025-04-25 12:43:39,345 - transformer_training - INFO - Main loop iteration: 2190
Iter 2190: loss 4.5538, lr 0.001000, 81854.98 tokens/sec
2025-04-25 12:43:39,796 - transformer_training - INFO - Main loop iteration: 2191
2025-04-25 12:43:40,294 - transformer_training - INFO - Main loop iteration: 2192
2025-04-25 12:43:40,695 - transformer_training - INFO - Main loop iteration: 2193
2025-04-25 12:43:41,156 - transformer_training - INFO - Main loop iteration: 2194
2025-04-25 12:43:41,607 - transformer_training - INFO - Main loop iteration: 2195
2025-04-25 12:43:42,107 - transformer_training - INFO - Main loop iteration: 2196
2025-04-25 12:43:42,508 - transformer_training - INFO - Main loop iteration: 2197
2025-04-25 12:43:42,969 - transformer_training - INFO - Main loop iteration: 2198
2025-04-25 12:43:43,419 - transformer_training - INFO - Main loop iteration: 2199
2025-04-25 12:43:43,918 - transformer_training - INFO - Main loop iteration: 2200
Iter 2200: loss 4.3827, lr 0.001000, 91972.17 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2200: train loss 4.4422, val loss 4.3294
New best model saved with val loss: 4.3294
2025-04-25 12:44:01,971 - transformer_training - INFO - Main loop iteration: 2201
2025-04-25 12:44:02,379 - transformer_training - INFO - Main loop iteration: 2202
2025-04-25 12:44:02,830 - transformer_training - INFO - Main loop iteration: 2203
2025-04-25 12:44:03,328 - transformer_training - INFO - Main loop iteration: 2204
2025-04-25 12:44:03,729 - transformer_training - INFO - Main loop iteration: 2205
2025-04-25 12:44:04,190 - transformer_training - INFO - Main loop iteration: 2206
2025-04-25 12:44:04,640 - transformer_training - INFO - Main loop iteration: 2207
2025-04-25 12:44:05,138 - transformer_training - INFO - Main loop iteration: 2208
2025-04-25 12:44:05,539 - transformer_training - INFO - Main loop iteration: 2209
2025-04-25 12:44:06,000 - transformer_training - INFO - Main loop iteration: 2210
Iter 2210: loss 4.5020, lr 0.001000, 81893.44 tokens/sec
2025-04-25 12:44:06,450 - transformer_training - INFO - Main loop iteration: 2211
2025-04-25 12:44:06,949 - transformer_training - INFO - Main loop iteration: 2212
2025-04-25 12:44:07,349 - transformer_training - INFO - Main loop iteration: 2213
2025-04-25 12:44:07,810 - transformer_training - INFO - Main loop iteration: 2214
2025-04-25 12:44:08,260 - transformer_training - INFO - Main loop iteration: 2215
2025-04-25 12:44:08,758 - transformer_training - INFO - Main loop iteration: 2216
2025-04-25 12:44:09,159 - transformer_training - INFO - Main loop iteration: 2217
2025-04-25 12:44:09,620 - transformer_training - INFO - Main loop iteration: 2218
2025-04-25 12:44:10,070 - transformer_training - INFO - Main loop iteration: 2219
2025-04-25 12:44:10,568 - transformer_training - INFO - Main loop iteration: 2220
Iter 2220: loss 4.4844, lr 0.001000, 92023.57 tokens/sec
2025-04-25 12:44:10,969 - transformer_training - INFO - Main loop iteration: 2221
2025-04-25 12:44:11,430 - transformer_training - INFO - Main loop iteration: 2222
2025-04-25 12:44:11,881 - transformer_training - INFO - Main loop iteration: 2223
2025-04-25 12:44:12,380 - transformer_training - INFO - Main loop iteration: 2224
2025-04-25 12:44:12,781 - transformer_training - INFO - Main loop iteration: 2225
2025-04-25 12:44:13,242 - transformer_training - INFO - Main loop iteration: 2226
2025-04-25 12:44:13,692 - transformer_training - INFO - Main loop iteration: 2227
2025-04-25 12:44:14,191 - transformer_training - INFO - Main loop iteration: 2228
2025-04-25 12:44:14,591 - transformer_training - INFO - Main loop iteration: 2229
2025-04-25 12:44:15,052 - transformer_training - INFO - Main loop iteration: 2230
Iter 2230: loss 4.4298, lr 0.001000, 81884.37 tokens/sec
2025-04-25 12:44:15,503 - transformer_training - INFO - Main loop iteration: 2231
2025-04-25 12:44:16,001 - transformer_training - INFO - Main loop iteration: 2232
2025-04-25 12:44:16,403 - transformer_training - INFO - Main loop iteration: 2233
2025-04-25 12:44:16,864 - transformer_training - INFO - Main loop iteration: 2234
2025-04-25 12:44:17,314 - transformer_training - INFO - Main loop iteration: 2235
2025-04-25 12:44:17,813 - transformer_training - INFO - Main loop iteration: 2236
2025-04-25 12:44:18,214 - transformer_training - INFO - Main loop iteration: 2237
2025-04-25 12:44:18,674 - transformer_training - INFO - Main loop iteration: 2238
2025-04-25 12:44:19,125 - transformer_training - INFO - Main loop iteration: 2239
2025-04-25 12:44:19,624 - transformer_training - INFO - Main loop iteration: 2240
Iter 2240: loss 4.4783, lr 0.001000, 91979.28 tokens/sec
2025-04-25 12:44:20,025 - transformer_training - INFO - Main loop iteration: 2241
2025-04-25 12:44:20,486 - transformer_training - INFO - Main loop iteration: 2242
2025-04-25 12:44:20,936 - transformer_training - INFO - Main loop iteration: 2243
2025-04-25 12:44:21,435 - transformer_training - INFO - Main loop iteration: 2244
2025-04-25 12:44:21,836 - transformer_training - INFO - Main loop iteration: 2245
2025-04-25 12:44:22,297 - transformer_training - INFO - Main loop iteration: 2246
2025-04-25 12:44:22,748 - transformer_training - INFO - Main loop iteration: 2247
2025-04-25 12:44:23,247 - transformer_training - INFO - Main loop iteration: 2248
2025-04-25 12:44:23,648 - transformer_training - INFO - Main loop iteration: 2249
2025-04-25 12:44:24,109 - transformer_training - INFO - Main loop iteration: 2250
Iter 2250: loss 4.4576, lr 0.001000, 81922.25 tokens/sec
2025-04-25 12:44:24,559 - transformer_training - INFO - Main loop iteration: 2251
2025-04-25 12:44:25,057 - transformer_training - INFO - Main loop iteration: 2252
2025-04-25 12:44:25,458 - transformer_training - INFO - Main loop iteration: 2253
2025-04-25 12:44:25,918 - transformer_training - INFO - Main loop iteration: 2254
2025-04-25 12:44:26,368 - transformer_training - INFO - Main loop iteration: 2255
2025-04-25 12:44:26,867 - transformer_training - INFO - Main loop iteration: 2256
2025-04-25 12:44:27,268 - transformer_training - INFO - Main loop iteration: 2257
2025-04-25 12:44:27,729 - transformer_training - INFO - Main loop iteration: 2258
2025-04-25 12:44:28,180 - transformer_training - INFO - Main loop iteration: 2259
2025-04-25 12:44:28,678 - transformer_training - INFO - Main loop iteration: 2260
Iter 2260: loss 4.3892, lr 0.001000, 92010.26 tokens/sec
2025-04-25 12:44:29,079 - transformer_training - INFO - Main loop iteration: 2261
2025-04-25 12:44:29,541 - transformer_training - INFO - Main loop iteration: 2262
2025-04-25 12:44:29,991 - transformer_training - INFO - Main loop iteration: 2263
2025-04-25 12:44:30,489 - transformer_training - INFO - Main loop iteration: 2264
2025-04-25 12:44:30,890 - transformer_training - INFO - Main loop iteration: 2265
2025-04-25 12:44:31,351 - transformer_training - INFO - Main loop iteration: 2266
2025-04-25 12:44:31,802 - transformer_training - INFO - Main loop iteration: 2267
2025-04-25 12:44:32,301 - transformer_training - INFO - Main loop iteration: 2268
2025-04-25 12:44:32,702 - transformer_training - INFO - Main loop iteration: 2269
2025-04-25 12:44:33,163 - transformer_training - INFO - Main loop iteration: 2270
Iter 2270: loss 4.3717, lr 0.001000, 81839.69 tokens/sec
2025-04-25 12:44:33,614 - transformer_training - INFO - Main loop iteration: 2271
2025-04-25 12:44:34,116 - transformer_training - INFO - Main loop iteration: 2272
2025-04-25 12:44:34,517 - transformer_training - INFO - Main loop iteration: 2273
2025-04-25 12:44:34,978 - transformer_training - INFO - Main loop iteration: 2274
2025-04-25 12:44:35,428 - transformer_training - INFO - Main loop iteration: 2275
2025-04-25 12:44:35,927 - transformer_training - INFO - Main loop iteration: 2276
2025-04-25 12:44:36,329 - transformer_training - INFO - Main loop iteration: 2277
2025-04-25 12:44:36,790 - transformer_training - INFO - Main loop iteration: 2278
2025-04-25 12:44:37,241 - transformer_training - INFO - Main loop iteration: 2279
2025-04-25 12:44:37,740 - transformer_training - INFO - Main loop iteration: 2280
Iter 2280: loss 4.5494, lr 0.001000, 92043.67 tokens/sec
2025-04-25 12:44:38,141 - transformer_training - INFO - Main loop iteration: 2281
2025-04-25 12:44:38,603 - transformer_training - INFO - Main loop iteration: 2282
2025-04-25 12:44:39,053 - transformer_training - INFO - Main loop iteration: 2283
2025-04-25 12:44:39,552 - transformer_training - INFO - Main loop iteration: 2284
2025-04-25 12:44:39,953 - transformer_training - INFO - Main loop iteration: 2285
2025-04-25 12:44:40,414 - transformer_training - INFO - Main loop iteration: 2286
2025-04-25 12:44:40,865 - transformer_training - INFO - Main loop iteration: 2287
2025-04-25 12:44:41,363 - transformer_training - INFO - Main loop iteration: 2288
2025-04-25 12:44:41,764 - transformer_training - INFO - Main loop iteration: 2289
2025-04-25 12:44:42,226 - transformer_training - INFO - Main loop iteration: 2290
Iter 2290: loss 4.4575, lr 0.001000, 81896.99 tokens/sec
2025-04-25 12:44:42,677 - transformer_training - INFO - Main loop iteration: 2291
2025-04-25 12:44:43,176 - transformer_training - INFO - Main loop iteration: 2292
2025-04-25 12:44:43,577 - transformer_training - INFO - Main loop iteration: 2293
2025-04-25 12:44:44,037 - transformer_training - INFO - Main loop iteration: 2294
2025-04-25 12:44:44,488 - transformer_training - INFO - Main loop iteration: 2295
2025-04-25 12:44:44,987 - transformer_training - INFO - Main loop iteration: 2296
2025-04-25 12:44:45,388 - transformer_training - INFO - Main loop iteration: 2297
2025-04-25 12:44:45,848 - transformer_training - INFO - Main loop iteration: 2298
2025-04-25 12:44:46,298 - transformer_training - INFO - Main loop iteration: 2299
2025-04-25 12:44:46,797 - transformer_training - INFO - Main loop iteration: 2300
Iter 2300: loss 4.4082, lr 0.001000, 91995.42 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2300: train loss 4.3810, val loss 4.2591
New best model saved with val loss: 4.2591
2025-04-25 12:45:04,767 - transformer_training - INFO - Main loop iteration: 2301
2025-04-25 12:45:05,216 - transformer_training - INFO - Main loop iteration: 2302
2025-04-25 12:45:05,664 - transformer_training - INFO - Main loop iteration: 2303
2025-04-25 12:45:06,163 - transformer_training - INFO - Main loop iteration: 2304
2025-04-25 12:45:06,564 - transformer_training - INFO - Main loop iteration: 2305
2025-04-25 12:45:07,025 - transformer_training - INFO - Main loop iteration: 2306
2025-04-25 12:45:07,475 - transformer_training - INFO - Main loop iteration: 2307
2025-04-25 12:45:07,974 - transformer_training - INFO - Main loop iteration: 2308
2025-04-25 12:45:08,376 - transformer_training - INFO - Main loop iteration: 2309
2025-04-25 12:45:08,836 - transformer_training - INFO - Main loop iteration: 2310
Iter 2310: loss 4.3961, lr 0.001000, 81819.55 tokens/sec
2025-04-25 12:45:09,287 - transformer_training - INFO - Main loop iteration: 2311
2025-04-25 12:45:09,785 - transformer_training - INFO - Main loop iteration: 2312
2025-04-25 12:45:10,187 - transformer_training - INFO - Main loop iteration: 2313
2025-04-25 12:45:10,648 - transformer_training - INFO - Main loop iteration: 2314
2025-04-25 12:45:11,099 - transformer_training - INFO - Main loop iteration: 2315
2025-04-25 12:45:11,597 - transformer_training - INFO - Main loop iteration: 2316
2025-04-25 12:45:11,999 - transformer_training - INFO - Main loop iteration: 2317
2025-04-25 12:45:12,460 - transformer_training - INFO - Main loop iteration: 2318
2025-04-25 12:45:12,911 - transformer_training - INFO - Main loop iteration: 2319
2025-04-25 12:45:13,409 - transformer_training - INFO - Main loop iteration: 2320
Iter 2320: loss 4.5044, lr 0.001000, 91895.37 tokens/sec
2025-04-25 12:45:13,811 - transformer_training - INFO - Main loop iteration: 2321
2025-04-25 12:45:14,271 - transformer_training - INFO - Main loop iteration: 2322
2025-04-25 12:45:14,722 - transformer_training - INFO - Main loop iteration: 2323
2025-04-25 12:45:15,220 - transformer_training - INFO - Main loop iteration: 2324
2025-04-25 12:45:15,621 - transformer_training - INFO - Main loop iteration: 2325
2025-04-25 12:45:16,082 - transformer_training - INFO - Main loop iteration: 2326
2025-04-25 12:45:16,533 - transformer_training - INFO - Main loop iteration: 2327
2025-04-25 12:45:17,032 - transformer_training - INFO - Main loop iteration: 2328
2025-04-25 12:45:17,433 - transformer_training - INFO - Main loop iteration: 2329
2025-04-25 12:45:17,894 - transformer_training - INFO - Main loop iteration: 2330
Iter 2330: loss 4.4186, lr 0.001000, 81774.68 tokens/sec
2025-04-25 12:45:18,346 - transformer_training - INFO - Main loop iteration: 2331
2025-04-25 12:45:18,845 - transformer_training - INFO - Main loop iteration: 2332
2025-04-25 12:45:19,246 - transformer_training - INFO - Main loop iteration: 2333
2025-04-25 12:45:19,707 - transformer_training - INFO - Main loop iteration: 2334
2025-04-25 12:45:20,158 - transformer_training - INFO - Main loop iteration: 2335
2025-04-25 12:45:20,657 - transformer_training - INFO - Main loop iteration: 2336
2025-04-25 12:45:21,058 - transformer_training - INFO - Main loop iteration: 2337
2025-04-25 12:45:21,519 - transformer_training - INFO - Main loop iteration: 2338
2025-04-25 12:45:21,969 - transformer_training - INFO - Main loop iteration: 2339
2025-04-25 12:45:22,468 - transformer_training - INFO - Main loop iteration: 2340
Iter 2340: loss 4.2597, lr 0.001000, 91930.33 tokens/sec
2025-04-25 12:45:22,870 - transformer_training - INFO - Main loop iteration: 2341
2025-04-25 12:45:23,331 - transformer_training - INFO - Main loop iteration: 2342
2025-04-25 12:45:23,781 - transformer_training - INFO - Main loop iteration: 2343
2025-04-25 12:45:24,280 - transformer_training - INFO - Main loop iteration: 2344
2025-04-25 12:45:24,681 - transformer_training - INFO - Main loop iteration: 2345
2025-04-25 12:45:25,142 - transformer_training - INFO - Main loop iteration: 2346
2025-04-25 12:45:25,593 - transformer_training - INFO - Main loop iteration: 2347
2025-04-25 12:45:26,093 - transformer_training - INFO - Main loop iteration: 2348
2025-04-25 12:45:26,494 - transformer_training - INFO - Main loop iteration: 2349
2025-04-25 12:45:26,955 - transformer_training - INFO - Main loop iteration: 2350
Iter 2350: loss 4.4405, lr 0.001000, 81765.85 tokens/sec
2025-04-25 12:45:27,406 - transformer_training - INFO - Main loop iteration: 2351
2025-04-25 12:45:27,906 - transformer_training - INFO - Main loop iteration: 2352
2025-04-25 12:45:28,307 - transformer_training - INFO - Main loop iteration: 2353
2025-04-25 12:45:28,768 - transformer_training - INFO - Main loop iteration: 2354
2025-04-25 12:45:29,218 - transformer_training - INFO - Main loop iteration: 2355
2025-04-25 12:45:29,717 - transformer_training - INFO - Main loop iteration: 2356
2025-04-25 12:45:30,118 - transformer_training - INFO - Main loop iteration: 2357
2025-04-25 12:45:30,579 - transformer_training - INFO - Main loop iteration: 2358
2025-04-25 12:45:31,030 - transformer_training - INFO - Main loop iteration: 2359
2025-04-25 12:45:31,528 - transformer_training - INFO - Main loop iteration: 2360
Iter 2360: loss 4.4107, lr 0.001000, 71883.33 tokens/sec
2025-04-25 12:45:32,041 - transformer_training - INFO - Main loop iteration: 2361
2025-04-25 12:45:32,502 - transformer_training - INFO - Main loop iteration: 2362
2025-04-25 12:45:32,953 - transformer_training - INFO - Main loop iteration: 2363
2025-04-25 12:45:33,451 - transformer_training - INFO - Main loop iteration: 2364
2025-04-25 12:45:33,853 - transformer_training - INFO - Main loop iteration: 2365
2025-04-25 12:45:34,313 - transformer_training - INFO - Main loop iteration: 2366
2025-04-25 12:45:34,764 - transformer_training - INFO - Main loop iteration: 2367
2025-04-25 12:45:35,262 - transformer_training - INFO - Main loop iteration: 2368
2025-04-25 12:45:35,663 - transformer_training - INFO - Main loop iteration: 2369
2025-04-25 12:45:36,124 - transformer_training - INFO - Main loop iteration: 2370
Iter 2370: loss 4.3837, lr 0.001000, 81990.67 tokens/sec
2025-04-25 12:45:36,574 - transformer_training - INFO - Main loop iteration: 2371
2025-04-25 12:45:37,072 - transformer_training - INFO - Main loop iteration: 2372
2025-04-25 12:45:37,473 - transformer_training - INFO - Main loop iteration: 2373
2025-04-25 12:45:37,934 - transformer_training - INFO - Main loop iteration: 2374
2025-04-25 12:45:38,384 - transformer_training - INFO - Main loop iteration: 2375
2025-04-25 12:45:38,890 - transformer_training - INFO - Main loop iteration: 2376
2025-04-25 12:45:39,290 - transformer_training - INFO - Main loop iteration: 2377
2025-04-25 12:45:39,750 - transformer_training - INFO - Main loop iteration: 2378
2025-04-25 12:45:40,201 - transformer_training - INFO - Main loop iteration: 2379
2025-04-25 12:45:40,700 - transformer_training - INFO - Main loop iteration: 2380
Iter 2380: loss 4.2803, lr 0.001000, 92004.07 tokens/sec
2025-04-25 12:45:41,101 - transformer_training - INFO - Main loop iteration: 2381
2025-04-25 12:45:41,561 - transformer_training - INFO - Main loop iteration: 2382
2025-04-25 12:45:42,012 - transformer_training - INFO - Main loop iteration: 2383
2025-04-25 12:45:42,512 - transformer_training - INFO - Main loop iteration: 2384
2025-04-25 12:45:42,913 - transformer_training - INFO - Main loop iteration: 2385
2025-04-25 12:45:43,374 - transformer_training - INFO - Main loop iteration: 2386
2025-04-25 12:45:43,825 - transformer_training - INFO - Main loop iteration: 2387
2025-04-25 12:45:44,324 - transformer_training - INFO - Main loop iteration: 2388
2025-04-25 12:45:44,724 - transformer_training - INFO - Main loop iteration: 2389
2025-04-25 12:45:45,185 - transformer_training - INFO - Main loop iteration: 2390
Iter 2390: loss 4.3466, lr 0.001000, 81949.43 tokens/sec
2025-04-25 12:45:45,635 - transformer_training - INFO - Main loop iteration: 2391
2025-04-25 12:45:46,134 - transformer_training - INFO - Main loop iteration: 2392
2025-04-25 12:45:46,535 - transformer_training - INFO - Main loop iteration: 2393
2025-04-25 12:45:46,996 - transformer_training - INFO - Main loop iteration: 2394
2025-04-25 12:45:47,446 - transformer_training - INFO - Main loop iteration: 2395
2025-04-25 12:45:47,945 - transformer_training - INFO - Main loop iteration: 2396
2025-04-25 12:45:48,347 - transformer_training - INFO - Main loop iteration: 2397
2025-04-25 12:45:48,808 - transformer_training - INFO - Main loop iteration: 2398
2025-04-25 12:45:49,258 - transformer_training - INFO - Main loop iteration: 2399
2025-04-25 12:45:49,757 - transformer_training - INFO - Main loop iteration: 2400
Iter 2400: loss 4.3517, lr 0.001000, 91931.54 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2400: train loss 4.2980, val loss 4.1832
New best model saved with val loss: 4.1832
2025-04-25 12:46:08,375 - transformer_training - INFO - Main loop iteration: 2401
2025-04-25 12:46:08,849 - transformer_training - INFO - Main loop iteration: 2402
2025-04-25 12:46:09,278 - transformer_training - INFO - Main loop iteration: 2403
2025-04-25 12:46:09,760 - transformer_training - INFO - Main loop iteration: 2404
2025-04-25 12:46:10,161 - transformer_training - INFO - Main loop iteration: 2405
2025-04-25 12:46:10,622 - transformer_training - INFO - Main loop iteration: 2406
2025-04-25 12:46:11,072 - transformer_training - INFO - Main loop iteration: 2407
2025-04-25 12:46:11,570 - transformer_training - INFO - Main loop iteration: 2408
2025-04-25 12:46:11,971 - transformer_training - INFO - Main loop iteration: 2409
2025-04-25 12:46:12,432 - transformer_training - INFO - Main loop iteration: 2410
Iter 2410: loss 4.3401, lr 0.001000, 81948.17 tokens/sec
2025-04-25 12:46:12,883 - transformer_training - INFO - Main loop iteration: 2411
2025-04-25 12:46:13,381 - transformer_training - INFO - Main loop iteration: 2412
2025-04-25 12:46:13,782 - transformer_training - INFO - Main loop iteration: 2413
2025-04-25 12:46:14,242 - transformer_training - INFO - Main loop iteration: 2414
2025-04-25 12:46:14,694 - transformer_training - INFO - Main loop iteration: 2415
2025-04-25 12:46:15,193 - transformer_training - INFO - Main loop iteration: 2416
2025-04-25 12:46:15,594 - transformer_training - INFO - Main loop iteration: 2417
2025-04-25 12:46:16,055 - transformer_training - INFO - Main loop iteration: 2418
2025-04-25 12:46:16,506 - transformer_training - INFO - Main loop iteration: 2419
2025-04-25 12:46:17,005 - transformer_training - INFO - Main loop iteration: 2420
Iter 2420: loss 4.2425, lr 0.001000, 92044.55 tokens/sec
2025-04-25 12:46:17,406 - transformer_training - INFO - Main loop iteration: 2421
2025-04-25 12:46:17,866 - transformer_training - INFO - Main loop iteration: 2422
2025-04-25 12:46:18,317 - transformer_training - INFO - Main loop iteration: 2423
2025-04-25 12:46:18,816 - transformer_training - INFO - Main loop iteration: 2424
2025-04-25 12:46:19,217 - transformer_training - INFO - Main loop iteration: 2425
2025-04-25 12:46:19,678 - transformer_training - INFO - Main loop iteration: 2426
2025-04-25 12:46:20,128 - transformer_training - INFO - Main loop iteration: 2427
2025-04-25 12:46:20,628 - transformer_training - INFO - Main loop iteration: 2428
2025-04-25 12:46:21,028 - transformer_training - INFO - Main loop iteration: 2429
2025-04-25 12:46:21,489 - transformer_training - INFO - Main loop iteration: 2430
Iter 2430: loss 4.3609, lr 0.001000, 81908.62 tokens/sec
2025-04-25 12:46:21,939 - transformer_training - INFO - Main loop iteration: 2431
2025-04-25 12:46:22,438 - transformer_training - INFO - Main loop iteration: 2432
2025-04-25 12:46:22,840 - transformer_training - INFO - Main loop iteration: 2433
2025-04-25 12:46:23,300 - transformer_training - INFO - Main loop iteration: 2434
2025-04-25 12:46:23,751 - transformer_training - INFO - Main loop iteration: 2435
2025-04-25 12:46:24,249 - transformer_training - INFO - Main loop iteration: 2436
2025-04-25 12:46:24,650 - transformer_training - INFO - Main loop iteration: 2437
2025-04-25 12:46:25,111 - transformer_training - INFO - Main loop iteration: 2438
2025-04-25 12:46:25,561 - transformer_training - INFO - Main loop iteration: 2439
2025-04-25 12:46:26,060 - transformer_training - INFO - Main loop iteration: 2440
Iter 2440: loss 4.3774, lr 0.001000, 91986.12 tokens/sec
2025-04-25 12:46:26,461 - transformer_training - INFO - Main loop iteration: 2441
2025-04-25 12:46:26,922 - transformer_training - INFO - Main loop iteration: 2442
2025-04-25 12:46:27,372 - transformer_training - INFO - Main loop iteration: 2443
2025-04-25 12:46:27,871 - transformer_training - INFO - Main loop iteration: 2444
2025-04-25 12:46:28,272 - transformer_training - INFO - Main loop iteration: 2445
2025-04-25 12:46:28,733 - transformer_training - INFO - Main loop iteration: 2446
2025-04-25 12:46:29,184 - transformer_training - INFO - Main loop iteration: 2447
2025-04-25 12:46:29,682 - transformer_training - INFO - Main loop iteration: 2448
2025-04-25 12:46:30,083 - transformer_training - INFO - Main loop iteration: 2449
2025-04-25 12:46:30,544 - transformer_training - INFO - Main loop iteration: 2450
Iter 2450: loss 4.4181, lr 0.001000, 81834.66 tokens/sec
2025-04-25 12:46:30,995 - transformer_training - INFO - Main loop iteration: 2451
2025-04-25 12:46:31,494 - transformer_training - INFO - Main loop iteration: 2452
2025-04-25 12:46:31,894 - transformer_training - INFO - Main loop iteration: 2453
2025-04-25 12:46:32,356 - transformer_training - INFO - Main loop iteration: 2454
2025-04-25 12:46:32,806 - transformer_training - INFO - Main loop iteration: 2455
2025-04-25 12:46:33,305 - transformer_training - INFO - Main loop iteration: 2456
2025-04-25 12:46:33,707 - transformer_training - INFO - Main loop iteration: 2457
2025-04-25 12:46:34,168 - transformer_training - INFO - Main loop iteration: 2458
2025-04-25 12:46:34,619 - transformer_training - INFO - Main loop iteration: 2459
2025-04-25 12:46:35,118 - transformer_training - INFO - Main loop iteration: 2460
Iter 2460: loss 4.2799, lr 0.001000, 91921.48 tokens/sec
2025-04-25 12:46:35,520 - transformer_training - INFO - Main loop iteration: 2461
2025-04-25 12:46:35,981 - transformer_training - INFO - Main loop iteration: 2462
2025-04-25 12:46:36,431 - transformer_training - INFO - Main loop iteration: 2463
2025-04-25 12:46:36,930 - transformer_training - INFO - Main loop iteration: 2464
2025-04-25 12:46:37,331 - transformer_training - INFO - Main loop iteration: 2465
2025-04-25 12:46:37,793 - transformer_training - INFO - Main loop iteration: 2466
2025-04-25 12:46:38,243 - transformer_training - INFO - Main loop iteration: 2467
2025-04-25 12:46:38,742 - transformer_training - INFO - Main loop iteration: 2468
2025-04-25 12:46:39,144 - transformer_training - INFO - Main loop iteration: 2469
2025-04-25 12:46:39,605 - transformer_training - INFO - Main loop iteration: 2470
Iter 2470: loss 4.3014, lr 0.001000, 81865.95 tokens/sec
2025-04-25 12:46:40,055 - transformer_training - INFO - Main loop iteration: 2471
2025-04-25 12:46:40,554 - transformer_training - INFO - Main loop iteration: 2472
2025-04-25 12:46:40,955 - transformer_training - INFO - Main loop iteration: 2473
2025-04-25 12:46:41,416 - transformer_training - INFO - Main loop iteration: 2474
2025-04-25 12:46:41,866 - transformer_training - INFO - Main loop iteration: 2475
2025-04-25 12:46:42,371 - transformer_training - INFO - Main loop iteration: 2476
2025-04-25 12:46:42,772 - transformer_training - INFO - Main loop iteration: 2477
2025-04-25 12:46:43,234 - transformer_training - INFO - Main loop iteration: 2478
2025-04-25 12:46:43,684 - transformer_training - INFO - Main loop iteration: 2479
2025-04-25 12:46:44,183 - transformer_training - INFO - Main loop iteration: 2480
Iter 2480: loss 4.2770, lr 0.001000, 91702.70 tokens/sec
2025-04-25 12:46:44,586 - transformer_training - INFO - Main loop iteration: 2481
2025-04-25 12:46:45,047 - transformer_training - INFO - Main loop iteration: 2482
2025-04-25 12:46:45,498 - transformer_training - INFO - Main loop iteration: 2483
2025-04-25 12:46:45,997 - transformer_training - INFO - Main loop iteration: 2484
2025-04-25 12:46:46,400 - transformer_training - INFO - Main loop iteration: 2485
2025-04-25 12:46:46,861 - transformer_training - INFO - Main loop iteration: 2486
2025-04-25 12:46:47,312 - transformer_training - INFO - Main loop iteration: 2487
2025-04-25 12:46:47,811 - transformer_training - INFO - Main loop iteration: 2488
2025-04-25 12:46:48,213 - transformer_training - INFO - Main loop iteration: 2489
2025-04-25 12:46:48,675 - transformer_training - INFO - Main loop iteration: 2490
Iter 2490: loss 4.3950, lr 0.001000, 81825.27 tokens/sec
2025-04-25 12:46:49,126 - transformer_training - INFO - Main loop iteration: 2491
2025-04-25 12:46:49,625 - transformer_training - INFO - Main loop iteration: 2492
2025-04-25 12:46:50,029 - transformer_training - INFO - Main loop iteration: 2493
2025-04-25 12:46:50,491 - transformer_training - INFO - Main loop iteration: 2494
2025-04-25 12:46:50,941 - transformer_training - INFO - Main loop iteration: 2495
2025-04-25 12:46:51,442 - transformer_training - INFO - Main loop iteration: 2496
2025-04-25 12:46:51,844 - transformer_training - INFO - Main loop iteration: 2497
2025-04-25 12:46:52,307 - transformer_training - INFO - Main loop iteration: 2498
2025-04-25 12:46:52,757 - transformer_training - INFO - Main loop iteration: 2499
2025-04-25 12:46:53,258 - transformer_training - INFO - Main loop iteration: 2500
Iter 2500: loss 4.3010, lr 0.001000, 91849.78 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2500: train loss 4.2387, val loss 4.1121
New best model saved with val loss: 4.1121
2025-04-25 12:47:12,811 - transformer_training - INFO - Main loop iteration: 2501
2025-04-25 12:47:13,229 - transformer_training - INFO - Main loop iteration: 2502
2025-04-25 12:47:13,680 - transformer_training - INFO - Main loop iteration: 2503
2025-04-25 12:47:14,178 - transformer_training - INFO - Main loop iteration: 2504
2025-04-25 12:47:14,578 - transformer_training - INFO - Main loop iteration: 2505
2025-04-25 12:47:15,040 - transformer_training - INFO - Main loop iteration: 2506
2025-04-25 12:47:15,491 - transformer_training - INFO - Main loop iteration: 2507
2025-04-25 12:47:15,989 - transformer_training - INFO - Main loop iteration: 2508
2025-04-25 12:47:16,390 - transformer_training - INFO - Main loop iteration: 2509
2025-04-25 12:47:16,851 - transformer_training - INFO - Main loop iteration: 2510
Iter 2510: loss 4.3612, lr 0.001000, 81944.56 tokens/sec
2025-04-25 12:47:17,301 - transformer_training - INFO - Main loop iteration: 2511
2025-04-25 12:47:17,799 - transformer_training - INFO - Main loop iteration: 2512
2025-04-25 12:47:18,200 - transformer_training - INFO - Main loop iteration: 2513
2025-04-25 12:47:18,661 - transformer_training - INFO - Main loop iteration: 2514
2025-04-25 12:47:19,111 - transformer_training - INFO - Main loop iteration: 2515
2025-04-25 12:47:19,610 - transformer_training - INFO - Main loop iteration: 2516
2025-04-25 12:47:20,010 - transformer_training - INFO - Main loop iteration: 2517
2025-04-25 12:47:20,471 - transformer_training - INFO - Main loop iteration: 2518
2025-04-25 12:47:20,921 - transformer_training - INFO - Main loop iteration: 2519
2025-04-25 12:47:21,420 - transformer_training - INFO - Main loop iteration: 2520
Iter 2520: loss 4.2853, lr 0.001000, 92077.49 tokens/sec
2025-04-25 12:47:21,821 - transformer_training - INFO - Main loop iteration: 2521
2025-04-25 12:47:22,282 - transformer_training - INFO - Main loop iteration: 2522
2025-04-25 12:47:22,732 - transformer_training - INFO - Main loop iteration: 2523
2025-04-25 12:47:23,231 - transformer_training - INFO - Main loop iteration: 2524
2025-04-25 12:47:23,631 - transformer_training - INFO - Main loop iteration: 2525
2025-04-25 12:47:24,092 - transformer_training - INFO - Main loop iteration: 2526
2025-04-25 12:47:24,542 - transformer_training - INFO - Main loop iteration: 2527
2025-04-25 12:47:25,041 - transformer_training - INFO - Main loop iteration: 2528
2025-04-25 12:47:25,443 - transformer_training - INFO - Main loop iteration: 2529
2025-04-25 12:47:25,903 - transformer_training - INFO - Main loop iteration: 2530
Iter 2530: loss 4.2412, lr 0.001000, 81810.03 tokens/sec
2025-04-25 12:47:26,355 - transformer_training - INFO - Main loop iteration: 2531
2025-04-25 12:47:26,853 - transformer_training - INFO - Main loop iteration: 2532
2025-04-25 12:47:27,254 - transformer_training - INFO - Main loop iteration: 2533
2025-04-25 12:47:27,715 - transformer_training - INFO - Main loop iteration: 2534
2025-04-25 12:47:28,165 - transformer_training - INFO - Main loop iteration: 2535
2025-04-25 12:47:28,664 - transformer_training - INFO - Main loop iteration: 2536
2025-04-25 12:47:29,065 - transformer_training - INFO - Main loop iteration: 2537
2025-04-25 12:47:29,526 - transformer_training - INFO - Main loop iteration: 2538
2025-04-25 12:47:29,976 - transformer_training - INFO - Main loop iteration: 2539
2025-04-25 12:47:30,475 - transformer_training - INFO - Main loop iteration: 2540
Iter 2540: loss 4.1726, lr 0.001000, 91983.11 tokens/sec
2025-04-25 12:47:30,876 - transformer_training - INFO - Main loop iteration: 2541
2025-04-25 12:47:31,337 - transformer_training - INFO - Main loop iteration: 2542
2025-04-25 12:47:31,788 - transformer_training - INFO - Main loop iteration: 2543
2025-04-25 12:47:32,288 - transformer_training - INFO - Main loop iteration: 2544
2025-04-25 12:47:32,689 - transformer_training - INFO - Main loop iteration: 2545
2025-04-25 12:47:33,150 - transformer_training - INFO - Main loop iteration: 2546
2025-04-25 12:47:33,603 - transformer_training - INFO - Main loop iteration: 2547
2025-04-25 12:47:34,100 - transformer_training - INFO - Main loop iteration: 2548
2025-04-25 12:47:34,502 - transformer_training - INFO - Main loop iteration: 2549
2025-04-25 12:47:34,963 - transformer_training - INFO - Main loop iteration: 2550
Iter 2550: loss 4.2834, lr 0.000999, 81938.22 tokens/sec
2025-04-25 12:47:35,413 - transformer_training - INFO - Main loop iteration: 2551
2025-04-25 12:47:35,913 - transformer_training - INFO - Main loop iteration: 2552
2025-04-25 12:47:36,314 - transformer_training - INFO - Main loop iteration: 2553
2025-04-25 12:47:36,776 - transformer_training - INFO - Main loop iteration: 2554
2025-04-25 12:47:37,226 - transformer_training - INFO - Main loop iteration: 2555
2025-04-25 12:47:37,725 - transformer_training - INFO - Main loop iteration: 2556
2025-04-25 12:47:38,127 - transformer_training - INFO - Main loop iteration: 2557
2025-04-25 12:47:38,589 - transformer_training - INFO - Main loop iteration: 2558
2025-04-25 12:47:39,040 - transformer_training - INFO - Main loop iteration: 2559
2025-04-25 12:47:39,539 - transformer_training - INFO - Main loop iteration: 2560
Iter 2560: loss 4.2175, lr 0.000999, 91801.79 tokens/sec
2025-04-25 12:47:39,941 - transformer_training - INFO - Main loop iteration: 2561
2025-04-25 12:47:40,402 - transformer_training - INFO - Main loop iteration: 2562
2025-04-25 12:47:40,854 - transformer_training - INFO - Main loop iteration: 2563
2025-04-25 12:47:41,353 - transformer_training - INFO - Main loop iteration: 2564
2025-04-25 12:47:41,755 - transformer_training - INFO - Main loop iteration: 2565
2025-04-25 12:47:42,216 - transformer_training - INFO - Main loop iteration: 2566
2025-04-25 12:47:42,667 - transformer_training - INFO - Main loop iteration: 2567
2025-04-25 12:47:43,165 - transformer_training - INFO - Main loop iteration: 2568
2025-04-25 12:47:43,567 - transformer_training - INFO - Main loop iteration: 2569
2025-04-25 12:47:44,029 - transformer_training - INFO - Main loop iteration: 2570
Iter 2570: loss 4.2200, lr 0.000999, 81870.11 tokens/sec
2025-04-25 12:47:44,480 - transformer_training - INFO - Main loop iteration: 2571
2025-04-25 12:47:44,979 - transformer_training - INFO - Main loop iteration: 2572
2025-04-25 12:47:45,381 - transformer_training - INFO - Main loop iteration: 2573
2025-04-25 12:47:45,843 - transformer_training - INFO - Main loop iteration: 2574
2025-04-25 12:47:46,293 - transformer_training - INFO - Main loop iteration: 2575
2025-04-25 12:47:46,791 - transformer_training - INFO - Main loop iteration: 2576
2025-04-25 12:47:47,193 - transformer_training - INFO - Main loop iteration: 2577
2025-04-25 12:47:47,654 - transformer_training - INFO - Main loop iteration: 2578
2025-04-25 12:47:48,105 - transformer_training - INFO - Main loop iteration: 2579
2025-04-25 12:47:48,604 - transformer_training - INFO - Main loop iteration: 2580
Iter 2580: loss 4.1827, lr 0.000999, 91738.01 tokens/sec
2025-04-25 12:47:49,006 - transformer_training - INFO - Main loop iteration: 2581
2025-04-25 12:47:49,468 - transformer_training - INFO - Main loop iteration: 2582
2025-04-25 12:47:49,919 - transformer_training - INFO - Main loop iteration: 2583
2025-04-25 12:47:50,418 - transformer_training - INFO - Main loop iteration: 2584
2025-04-25 12:47:50,820 - transformer_training - INFO - Main loop iteration: 2585
2025-04-25 12:47:51,281 - transformer_training - INFO - Main loop iteration: 2586
2025-04-25 12:47:51,732 - transformer_training - INFO - Main loop iteration: 2587
2025-04-25 12:47:52,231 - transformer_training - INFO - Main loop iteration: 2588
2025-04-25 12:47:52,633 - transformer_training - INFO - Main loop iteration: 2589
2025-04-25 12:47:53,094 - transformer_training - INFO - Main loop iteration: 2590
Iter 2590: loss 4.2576, lr 0.000999, 81787.74 tokens/sec
2025-04-25 12:47:53,545 - transformer_training - INFO - Main loop iteration: 2591
2025-04-25 12:47:54,044 - transformer_training - INFO - Main loop iteration: 2592
2025-04-25 12:47:54,446 - transformer_training - INFO - Main loop iteration: 2593
2025-04-25 12:47:54,908 - transformer_training - INFO - Main loop iteration: 2594
2025-04-25 12:47:55,359 - transformer_training - INFO - Main loop iteration: 2595
2025-04-25 12:47:55,857 - transformer_training - INFO - Main loop iteration: 2596
2025-04-25 12:47:56,259 - transformer_training - INFO - Main loop iteration: 2597
2025-04-25 12:47:56,721 - transformer_training - INFO - Main loop iteration: 2598
2025-04-25 12:47:57,172 - transformer_training - INFO - Main loop iteration: 2599
2025-04-25 12:47:57,671 - transformer_training - INFO - Main loop iteration: 2600
Iter 2600: loss 4.1743, lr 0.000999, 91779.67 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2600: train loss 4.1806, val loss 4.0451
New best model saved with val loss: 4.0451
2025-04-25 12:48:15,534 - transformer_training - INFO - Main loop iteration: 2601
2025-04-25 12:48:15,953 - transformer_training - INFO - Main loop iteration: 2602
2025-04-25 12:48:16,403 - transformer_training - INFO - Main loop iteration: 2603
2025-04-25 12:48:16,902 - transformer_training - INFO - Main loop iteration: 2604
2025-04-25 12:48:17,303 - transformer_training - INFO - Main loop iteration: 2605
2025-04-25 12:48:17,764 - transformer_training - INFO - Main loop iteration: 2606
2025-04-25 12:48:18,214 - transformer_training - INFO - Main loop iteration: 2607
2025-04-25 12:48:18,713 - transformer_training - INFO - Main loop iteration: 2608
2025-04-25 12:48:19,114 - transformer_training - INFO - Main loop iteration: 2609
2025-04-25 12:48:19,575 - transformer_training - INFO - Main loop iteration: 2610
Iter 2610: loss 4.2252, lr 0.000999, 81991.19 tokens/sec
2025-04-25 12:48:20,025 - transformer_training - INFO - Main loop iteration: 2611
2025-04-25 12:48:20,525 - transformer_training - INFO - Main loop iteration: 2612
2025-04-25 12:48:20,926 - transformer_training - INFO - Main loop iteration: 2613
2025-04-25 12:48:21,387 - transformer_training - INFO - Main loop iteration: 2614
2025-04-25 12:48:21,837 - transformer_training - INFO - Main loop iteration: 2615
2025-04-25 12:48:22,336 - transformer_training - INFO - Main loop iteration: 2616
2025-04-25 12:48:22,738 - transformer_training - INFO - Main loop iteration: 2617
2025-04-25 12:48:23,198 - transformer_training - INFO - Main loop iteration: 2618
2025-04-25 12:48:23,648 - transformer_training - INFO - Main loop iteration: 2619
2025-04-25 12:48:24,147 - transformer_training - INFO - Main loop iteration: 2620
Iter 2620: loss 4.1604, lr 0.000999, 91841.54 tokens/sec
2025-04-25 12:48:24,549 - transformer_training - INFO - Main loop iteration: 2621
2025-04-25 12:48:25,009 - transformer_training - INFO - Main loop iteration: 2622
2025-04-25 12:48:25,459 - transformer_training - INFO - Main loop iteration: 2623
2025-04-25 12:48:25,959 - transformer_training - INFO - Main loop iteration: 2624
2025-04-25 12:48:26,359 - transformer_training - INFO - Main loop iteration: 2625
2025-04-25 12:48:26,820 - transformer_training - INFO - Main loop iteration: 2626
2025-04-25 12:48:27,271 - transformer_training - INFO - Main loop iteration: 2627
2025-04-25 12:48:27,770 - transformer_training - INFO - Main loop iteration: 2628
2025-04-25 12:48:28,171 - transformer_training - INFO - Main loop iteration: 2629
2025-04-25 12:48:28,632 - transformer_training - INFO - Main loop iteration: 2630
Iter 2630: loss 4.1685, lr 0.000999, 81954.90 tokens/sec
2025-04-25 12:48:29,084 - transformer_training - INFO - Main loop iteration: 2631
2025-04-25 12:48:29,583 - transformer_training - INFO - Main loop iteration: 2632
2025-04-25 12:48:29,985 - transformer_training - INFO - Main loop iteration: 2633
2025-04-25 12:48:30,445 - transformer_training - INFO - Main loop iteration: 2634
2025-04-25 12:48:30,898 - transformer_training - INFO - Main loop iteration: 2635
2025-04-25 12:48:31,397 - transformer_training - INFO - Main loop iteration: 2636
2025-04-25 12:48:31,798 - transformer_training - INFO - Main loop iteration: 2637
2025-04-25 12:48:32,260 - transformer_training - INFO - Main loop iteration: 2638
2025-04-25 12:48:32,710 - transformer_training - INFO - Main loop iteration: 2639
2025-04-25 12:48:33,209 - transformer_training - INFO - Main loop iteration: 2640
Iter 2640: loss 4.3172, lr 0.000999, 91980.65 tokens/sec
2025-04-25 12:48:33,611 - transformer_training - INFO - Main loop iteration: 2641
2025-04-25 12:48:34,071 - transformer_training - INFO - Main loop iteration: 2642
2025-04-25 12:48:34,522 - transformer_training - INFO - Main loop iteration: 2643
2025-04-25 12:48:35,022 - transformer_training - INFO - Main loop iteration: 2644
2025-04-25 12:48:35,423 - transformer_training - INFO - Main loop iteration: 2645
2025-04-25 12:48:35,884 - transformer_training - INFO - Main loop iteration: 2646
2025-04-25 12:48:36,336 - transformer_training - INFO - Main loop iteration: 2647
2025-04-25 12:48:36,836 - transformer_training - INFO - Main loop iteration: 2648
2025-04-25 12:48:37,237 - transformer_training - INFO - Main loop iteration: 2649
2025-04-25 12:48:37,699 - transformer_training - INFO - Main loop iteration: 2650
Iter 2650: loss 4.2070, lr 0.000999, 81910.49 tokens/sec
2025-04-25 12:48:38,149 - transformer_training - INFO - Main loop iteration: 2651
2025-04-25 12:48:38,649 - transformer_training - INFO - Main loop iteration: 2652
2025-04-25 12:48:39,051 - transformer_training - INFO - Main loop iteration: 2653
2025-04-25 12:48:39,511 - transformer_training - INFO - Main loop iteration: 2654
2025-04-25 12:48:39,963 - transformer_training - INFO - Main loop iteration: 2655
2025-04-25 12:48:40,462 - transformer_training - INFO - Main loop iteration: 2656
2025-04-25 12:48:40,864 - transformer_training - INFO - Main loop iteration: 2657
2025-04-25 12:48:41,325 - transformer_training - INFO - Main loop iteration: 2658
2025-04-25 12:48:41,775 - transformer_training - INFO - Main loop iteration: 2659
2025-04-25 12:48:42,275 - transformer_training - INFO - Main loop iteration: 2660
Iter 2660: loss 4.2395, lr 0.000999, 91841.71 tokens/sec
2025-04-25 12:48:42,676 - transformer_training - INFO - Main loop iteration: 2661
2025-04-25 12:48:43,138 - transformer_training - INFO - Main loop iteration: 2662
2025-04-25 12:48:43,589 - transformer_training - INFO - Main loop iteration: 2663
2025-04-25 12:48:44,089 - transformer_training - INFO - Main loop iteration: 2664
2025-04-25 12:48:44,490 - transformer_training - INFO - Main loop iteration: 2665
2025-04-25 12:48:44,952 - transformer_training - INFO - Main loop iteration: 2666
2025-04-25 12:48:45,511 - transformer_training - INFO - Main loop iteration: 2667
2025-04-25 12:48:46,010 - transformer_training - INFO - Main loop iteration: 2668
2025-04-25 12:48:46,411 - transformer_training - INFO - Main loop iteration: 2669
2025-04-25 12:48:46,873 - transformer_training - INFO - Main loop iteration: 2670
Iter 2670: loss 4.2238, lr 0.000999, 81970.41 tokens/sec
2025-04-25 12:48:47,323 - transformer_training - INFO - Main loop iteration: 2671
2025-04-25 12:48:47,823 - transformer_training - INFO - Main loop iteration: 2672
2025-04-25 12:48:48,224 - transformer_training - INFO - Main loop iteration: 2673
2025-04-25 12:48:48,686 - transformer_training - INFO - Main loop iteration: 2674
2025-04-25 12:48:49,137 - transformer_training - INFO - Main loop iteration: 2675
2025-04-25 12:48:49,636 - transformer_training - INFO - Main loop iteration: 2676
2025-04-25 12:48:50,037 - transformer_training - INFO - Main loop iteration: 2677
2025-04-25 12:48:50,498 - transformer_training - INFO - Main loop iteration: 2678
2025-04-25 12:48:50,950 - transformer_training - INFO - Main loop iteration: 2679
2025-04-25 12:48:51,448 - transformer_training - INFO - Main loop iteration: 2680
Iter 2680: loss 4.1301, lr 0.000999, 91771.39 tokens/sec
2025-04-25 12:48:51,851 - transformer_training - INFO - Main loop iteration: 2681
2025-04-25 12:48:52,312 - transformer_training - INFO - Main loop iteration: 2682
2025-04-25 12:48:52,763 - transformer_training - INFO - Main loop iteration: 2683
2025-04-25 12:48:53,262 - transformer_training - INFO - Main loop iteration: 2684
2025-04-25 12:48:53,663 - transformer_training - INFO - Main loop iteration: 2685
2025-04-25 12:48:54,124 - transformer_training - INFO - Main loop iteration: 2686
2025-04-25 12:48:54,575 - transformer_training - INFO - Main loop iteration: 2687
2025-04-25 12:48:55,075 - transformer_training - INFO - Main loop iteration: 2688
2025-04-25 12:48:55,476 - transformer_training - INFO - Main loop iteration: 2689
2025-04-25 12:48:55,938 - transformer_training - INFO - Main loop iteration: 2690
Iter 2690: loss 4.1284, lr 0.000999, 81803.14 tokens/sec
2025-04-25 12:48:56,389 - transformer_training - INFO - Main loop iteration: 2691
2025-04-25 12:48:56,888 - transformer_training - INFO - Main loop iteration: 2692
2025-04-25 12:48:57,290 - transformer_training - INFO - Main loop iteration: 2693
2025-04-25 12:48:57,751 - transformer_training - INFO - Main loop iteration: 2694
2025-04-25 12:48:58,202 - transformer_training - INFO - Main loop iteration: 2695
2025-04-25 12:48:58,701 - transformer_training - INFO - Main loop iteration: 2696
2025-04-25 12:48:59,103 - transformer_training - INFO - Main loop iteration: 2697
2025-04-25 12:48:59,564 - transformer_training - INFO - Main loop iteration: 2698
2025-04-25 12:49:00,015 - transformer_training - INFO - Main loop iteration: 2699
2025-04-25 12:49:00,514 - transformer_training - INFO - Main loop iteration: 2700
Iter 2700: loss 4.0728, lr 0.000999, 91802.17 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2700: train loss 4.1312, val loss 3.9933
New best model saved with val loss: 3.9933
2025-04-25 12:49:18,261 - transformer_training - INFO - Main loop iteration: 2701
2025-04-25 12:49:18,675 - transformer_training - INFO - Main loop iteration: 2702
2025-04-25 12:49:19,124 - transformer_training - INFO - Main loop iteration: 2703
2025-04-25 12:49:19,623 - transformer_training - INFO - Main loop iteration: 2704
2025-04-25 12:49:20,023 - transformer_training - INFO - Main loop iteration: 2705
2025-04-25 12:49:20,483 - transformer_training - INFO - Main loop iteration: 2706
2025-04-25 12:49:20,934 - transformer_training - INFO - Main loop iteration: 2707
2025-04-25 12:49:21,432 - transformer_training - INFO - Main loop iteration: 2708
2025-04-25 12:49:21,832 - transformer_training - INFO - Main loop iteration: 2709
2025-04-25 12:49:22,293 - transformer_training - INFO - Main loop iteration: 2710
Iter 2710: loss 4.2302, lr 0.000999, 81945.87 tokens/sec
2025-04-25 12:49:22,743 - transformer_training - INFO - Main loop iteration: 2711
2025-04-25 12:49:23,242 - transformer_training - INFO - Main loop iteration: 2712
2025-04-25 12:49:23,642 - transformer_training - INFO - Main loop iteration: 2713
2025-04-25 12:49:24,103 - transformer_training - INFO - Main loop iteration: 2714
2025-04-25 12:49:24,553 - transformer_training - INFO - Main loop iteration: 2715
2025-04-25 12:49:25,051 - transformer_training - INFO - Main loop iteration: 2716
2025-04-25 12:49:25,452 - transformer_training - INFO - Main loop iteration: 2717
2025-04-25 12:49:25,913 - transformer_training - INFO - Main loop iteration: 2718
2025-04-25 12:49:26,362 - transformer_training - INFO - Main loop iteration: 2719
2025-04-25 12:49:26,861 - transformer_training - INFO - Main loop iteration: 2720
Iter 2720: loss 4.1058, lr 0.000999, 92022.42 tokens/sec
2025-04-25 12:49:27,262 - transformer_training - INFO - Main loop iteration: 2721
2025-04-25 12:49:27,722 - transformer_training - INFO - Main loop iteration: 2722
2025-04-25 12:49:28,175 - transformer_training - INFO - Main loop iteration: 2723
2025-04-25 12:49:28,674 - transformer_training - INFO - Main loop iteration: 2724
2025-04-25 12:49:29,075 - transformer_training - INFO - Main loop iteration: 2725
2025-04-25 12:49:29,536 - transformer_training - INFO - Main loop iteration: 2726
2025-04-25 12:49:29,987 - transformer_training - INFO - Main loop iteration: 2727
2025-04-25 12:49:30,485 - transformer_training - INFO - Main loop iteration: 2728
2025-04-25 12:49:30,887 - transformer_training - INFO - Main loop iteration: 2729
2025-04-25 12:49:31,348 - transformer_training - INFO - Main loop iteration: 2730
Iter 2730: loss 4.1387, lr 0.000999, 81825.27 tokens/sec
2025-04-25 12:49:31,799 - transformer_training - INFO - Main loop iteration: 2731
2025-04-25 12:49:32,298 - transformer_training - INFO - Main loop iteration: 2732
2025-04-25 12:49:32,699 - transformer_training - INFO - Main loop iteration: 2733
2025-04-25 12:49:33,162 - transformer_training - INFO - Main loop iteration: 2734
2025-04-25 12:49:33,612 - transformer_training - INFO - Main loop iteration: 2735
2025-04-25 12:49:34,111 - transformer_training - INFO - Main loop iteration: 2736
2025-04-25 12:49:34,512 - transformer_training - INFO - Main loop iteration: 2737
2025-04-25 12:49:34,973 - transformer_training - INFO - Main loop iteration: 2738
2025-04-25 12:49:35,424 - transformer_training - INFO - Main loop iteration: 2739
2025-04-25 12:49:35,923 - transformer_training - INFO - Main loop iteration: 2740
Iter 2740: loss 4.1481, lr 0.000999, 91943.02 tokens/sec
2025-04-25 12:49:36,324 - transformer_training - INFO - Main loop iteration: 2741
2025-04-25 12:49:36,786 - transformer_training - INFO - Main loop iteration: 2742
2025-04-25 12:49:37,236 - transformer_training - INFO - Main loop iteration: 2743
2025-04-25 12:49:37,735 - transformer_training - INFO - Main loop iteration: 2744
2025-04-25 12:49:38,136 - transformer_training - INFO - Main loop iteration: 2745
2025-04-25 12:49:38,597 - transformer_training - INFO - Main loop iteration: 2746
2025-04-25 12:49:39,048 - transformer_training - INFO - Main loop iteration: 2747
2025-04-25 12:49:39,546 - transformer_training - INFO - Main loop iteration: 2748
2025-04-25 12:49:39,948 - transformer_training - INFO - Main loop iteration: 2749
2025-04-25 12:49:40,410 - transformer_training - INFO - Main loop iteration: 2750
Iter 2750: loss 4.1247, lr 0.000999, 81847.27 tokens/sec
2025-04-25 12:49:40,861 - transformer_training - INFO - Main loop iteration: 2751
2025-04-25 12:49:41,359 - transformer_training - INFO - Main loop iteration: 2752
2025-04-25 12:49:41,761 - transformer_training - INFO - Main loop iteration: 2753
2025-04-25 12:49:42,223 - transformer_training - INFO - Main loop iteration: 2754
2025-04-25 12:49:42,673 - transformer_training - INFO - Main loop iteration: 2755
2025-04-25 12:49:43,173 - transformer_training - INFO - Main loop iteration: 2756
2025-04-25 12:49:43,575 - transformer_training - INFO - Main loop iteration: 2757
2025-04-25 12:49:44,036 - transformer_training - INFO - Main loop iteration: 2758
2025-04-25 12:49:44,489 - transformer_training - INFO - Main loop iteration: 2759
2025-04-25 12:49:44,989 - transformer_training - INFO - Main loop iteration: 2760
Iter 2760: loss 4.1264, lr 0.000999, 91802.67 tokens/sec
2025-04-25 12:49:45,390 - transformer_training - INFO - Main loop iteration: 2761
2025-04-25 12:49:45,851 - transformer_training - INFO - Main loop iteration: 2762
2025-04-25 12:49:46,302 - transformer_training - INFO - Main loop iteration: 2763
2025-04-25 12:49:46,801 - transformer_training - INFO - Main loop iteration: 2764
2025-04-25 12:49:47,203 - transformer_training - INFO - Main loop iteration: 2765
2025-04-25 12:49:47,664 - transformer_training - INFO - Main loop iteration: 2766
2025-04-25 12:49:48,116 - transformer_training - INFO - Main loop iteration: 2767
2025-04-25 12:49:48,615 - transformer_training - INFO - Main loop iteration: 2768
2025-04-25 12:49:49,017 - transformer_training - INFO - Main loop iteration: 2769
2025-04-25 12:49:49,479 - transformer_training - INFO - Main loop iteration: 2770
Iter 2770: loss 4.2157, lr 0.000999, 81873.06 tokens/sec
2025-04-25 12:49:49,930 - transformer_training - INFO - Main loop iteration: 2771
2025-04-25 12:49:50,428 - transformer_training - INFO - Main loop iteration: 2772
2025-04-25 12:49:50,830 - transformer_training - INFO - Main loop iteration: 2773
2025-04-25 12:49:51,291 - transformer_training - INFO - Main loop iteration: 2774
2025-04-25 12:49:51,742 - transformer_training - INFO - Main loop iteration: 2775
2025-04-25 12:49:52,241 - transformer_training - INFO - Main loop iteration: 2776
2025-04-25 12:49:52,643 - transformer_training - INFO - Main loop iteration: 2777
2025-04-25 12:49:53,104 - transformer_training - INFO - Main loop iteration: 2778
2025-04-25 12:49:53,555 - transformer_training - INFO - Main loop iteration: 2779
2025-04-25 12:49:54,053 - transformer_training - INFO - Main loop iteration: 2780
Iter 2780: loss 4.0854, lr 0.000999, 91957.73 tokens/sec
2025-04-25 12:49:54,455 - transformer_training - INFO - Main loop iteration: 2781
2025-04-25 12:49:54,915 - transformer_training - INFO - Main loop iteration: 2782
2025-04-25 12:49:55,367 - transformer_training - INFO - Main loop iteration: 2783
2025-04-25 12:49:55,866 - transformer_training - INFO - Main loop iteration: 2784
2025-04-25 12:49:56,267 - transformer_training - INFO - Main loop iteration: 2785
2025-04-25 12:49:56,728 - transformer_training - INFO - Main loop iteration: 2786
2025-04-25 12:49:57,179 - transformer_training - INFO - Main loop iteration: 2787
2025-04-25 12:49:57,677 - transformer_training - INFO - Main loop iteration: 2788
2025-04-25 12:49:58,080 - transformer_training - INFO - Main loop iteration: 2789
2025-04-25 12:49:58,541 - transformer_training - INFO - Main loop iteration: 2790
Iter 2790: loss 4.1333, lr 0.000999, 81811.54 tokens/sec
2025-04-25 12:49:58,992 - transformer_training - INFO - Main loop iteration: 2791
2025-04-25 12:49:59,491 - transformer_training - INFO - Main loop iteration: 2792
2025-04-25 12:49:59,893 - transformer_training - INFO - Main loop iteration: 2793
2025-04-25 12:50:00,355 - transformer_training - INFO - Main loop iteration: 2794
2025-04-25 12:50:00,805 - transformer_training - INFO - Main loop iteration: 2795
2025-04-25 12:50:01,305 - transformer_training - INFO - Main loop iteration: 2796
2025-04-25 12:50:01,707 - transformer_training - INFO - Main loop iteration: 2797
2025-04-25 12:50:02,168 - transformer_training - INFO - Main loop iteration: 2798
2025-04-25 12:50:02,619 - transformer_training - INFO - Main loop iteration: 2799
2025-04-25 12:50:03,118 - transformer_training - INFO - Main loop iteration: 2800
Iter 2800: loss 4.1163, lr 0.000999, 91778.14 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2800: train loss 4.0853, val loss 3.9376
New best model saved with val loss: 3.9376
2025-04-25 12:50:21,587 - transformer_training - INFO - Main loop iteration: 2801
2025-04-25 12:50:22,006 - transformer_training - INFO - Main loop iteration: 2802
2025-04-25 12:50:22,454 - transformer_training - INFO - Main loop iteration: 2803
2025-04-25 12:50:22,952 - transformer_training - INFO - Main loop iteration: 2804
2025-04-25 12:50:23,353 - transformer_training - INFO - Main loop iteration: 2805
2025-04-25 12:50:23,813 - transformer_training - INFO - Main loop iteration: 2806
2025-04-25 12:50:24,263 - transformer_training - INFO - Main loop iteration: 2807
2025-04-25 12:50:24,761 - transformer_training - INFO - Main loop iteration: 2808
2025-04-25 12:50:25,162 - transformer_training - INFO - Main loop iteration: 2809
2025-04-25 12:50:25,622 - transformer_training - INFO - Main loop iteration: 2810
Iter 2810: loss 4.0795, lr 0.000999, 81980.97 tokens/sec
2025-04-25 12:50:26,073 - transformer_training - INFO - Main loop iteration: 2811
2025-04-25 12:50:26,571 - transformer_training - INFO - Main loop iteration: 2812
2025-04-25 12:50:26,972 - transformer_training - INFO - Main loop iteration: 2813
2025-04-25 12:50:27,432 - transformer_training - INFO - Main loop iteration: 2814
2025-04-25 12:50:27,883 - transformer_training - INFO - Main loop iteration: 2815
2025-04-25 12:50:28,381 - transformer_training - INFO - Main loop iteration: 2816
2025-04-25 12:50:28,782 - transformer_training - INFO - Main loop iteration: 2817
2025-04-25 12:50:29,243 - transformer_training - INFO - Main loop iteration: 2818
2025-04-25 12:50:29,693 - transformer_training - INFO - Main loop iteration: 2819
2025-04-25 12:50:30,194 - transformer_training - INFO - Main loop iteration: 2820
Iter 2820: loss 4.1159, lr 0.000999, 91915.69 tokens/sec
2025-04-25 12:50:30,596 - transformer_training - INFO - Main loop iteration: 2821
2025-04-25 12:50:31,057 - transformer_training - INFO - Main loop iteration: 2822
2025-04-25 12:50:31,507 - transformer_training - INFO - Main loop iteration: 2823
2025-04-25 12:50:32,006 - transformer_training - INFO - Main loop iteration: 2824
2025-04-25 12:50:32,408 - transformer_training - INFO - Main loop iteration: 2825
2025-04-25 12:50:32,869 - transformer_training - INFO - Main loop iteration: 2826
2025-04-25 12:50:33,319 - transformer_training - INFO - Main loop iteration: 2827
2025-04-25 12:50:33,818 - transformer_training - INFO - Main loop iteration: 2828
2025-04-25 12:50:34,219 - transformer_training - INFO - Main loop iteration: 2829
2025-04-25 12:50:34,680 - transformer_training - INFO - Main loop iteration: 2830
Iter 2830: loss 4.1169, lr 0.000999, 81823.27 tokens/sec
2025-04-25 12:50:35,131 - transformer_training - INFO - Main loop iteration: 2831
2025-04-25 12:50:35,629 - transformer_training - INFO - Main loop iteration: 2832
2025-04-25 12:50:36,031 - transformer_training - INFO - Main loop iteration: 2833
2025-04-25 12:50:36,492 - transformer_training - INFO - Main loop iteration: 2834
2025-04-25 12:50:36,942 - transformer_training - INFO - Main loop iteration: 2835
2025-04-25 12:50:37,442 - transformer_training - INFO - Main loop iteration: 2836
2025-04-25 12:50:37,843 - transformer_training - INFO - Main loop iteration: 2837
2025-04-25 12:50:38,305 - transformer_training - INFO - Main loop iteration: 2838
2025-04-25 12:50:38,756 - transformer_training - INFO - Main loop iteration: 2839
2025-04-25 12:50:39,255 - transformer_training - INFO - Main loop iteration: 2840
Iter 2840: loss 3.9801, lr 0.000999, 91891.49 tokens/sec
2025-04-25 12:50:39,657 - transformer_training - INFO - Main loop iteration: 2841
2025-04-25 12:50:40,117 - transformer_training - INFO - Main loop iteration: 2842
2025-04-25 12:50:40,567 - transformer_training - INFO - Main loop iteration: 2843
2025-04-25 12:50:41,067 - transformer_training - INFO - Main loop iteration: 2844
2025-04-25 12:50:41,467 - transformer_training - INFO - Main loop iteration: 2845
2025-04-25 12:50:41,928 - transformer_training - INFO - Main loop iteration: 2846
2025-04-25 12:50:42,378 - transformer_training - INFO - Main loop iteration: 2847
2025-04-25 12:50:42,877 - transformer_training - INFO - Main loop iteration: 2848
2025-04-25 12:50:43,278 - transformer_training - INFO - Main loop iteration: 2849
2025-04-25 12:50:43,739 - transformer_training - INFO - Main loop iteration: 2850
Iter 2850: loss 3.9422, lr 0.000999, 81906.71 tokens/sec
2025-04-25 12:50:44,190 - transformer_training - INFO - Main loop iteration: 2851
2025-04-25 12:50:44,689 - transformer_training - INFO - Main loop iteration: 2852
2025-04-25 12:50:45,090 - transformer_training - INFO - Main loop iteration: 2853
2025-04-25 12:50:45,552 - transformer_training - INFO - Main loop iteration: 2854
2025-04-25 12:50:46,003 - transformer_training - INFO - Main loop iteration: 2855
2025-04-25 12:50:46,501 - transformer_training - INFO - Main loop iteration: 2856
2025-04-25 12:50:46,902 - transformer_training - INFO - Main loop iteration: 2857
2025-04-25 12:50:47,363 - transformer_training - INFO - Main loop iteration: 2858
2025-04-25 12:50:47,814 - transformer_training - INFO - Main loop iteration: 2859
2025-04-25 12:50:48,313 - transformer_training - INFO - Main loop iteration: 2860
Iter 2860: loss 4.0362, lr 0.000999, 91972.71 tokens/sec
2025-04-25 12:50:48,714 - transformer_training - INFO - Main loop iteration: 2861
2025-04-25 12:50:49,176 - transformer_training - INFO - Main loop iteration: 2862
2025-04-25 12:50:49,627 - transformer_training - INFO - Main loop iteration: 2863
2025-04-25 12:50:50,125 - transformer_training - INFO - Main loop iteration: 2864
2025-04-25 12:50:50,526 - transformer_training - INFO - Main loop iteration: 2865
2025-04-25 12:50:50,987 - transformer_training - INFO - Main loop iteration: 2866
2025-04-25 12:50:51,438 - transformer_training - INFO - Main loop iteration: 2867
2025-04-25 12:50:51,952 - transformer_training - INFO - Main loop iteration: 2868
2025-04-25 12:50:52,353 - transformer_training - INFO - Main loop iteration: 2869
2025-04-25 12:50:52,813 - transformer_training - INFO - Main loop iteration: 2870
Iter 2870: loss 4.1164, lr 0.000999, 81922.20 tokens/sec
2025-04-25 12:50:53,264 - transformer_training - INFO - Main loop iteration: 2871
2025-04-25 12:50:53,762 - transformer_training - INFO - Main loop iteration: 2872
2025-04-25 12:50:54,163 - transformer_training - INFO - Main loop iteration: 2873
2025-04-25 12:50:54,624 - transformer_training - INFO - Main loop iteration: 2874
2025-04-25 12:50:55,074 - transformer_training - INFO - Main loop iteration: 2875
2025-04-25 12:50:55,574 - transformer_training - INFO - Main loop iteration: 2876
2025-04-25 12:50:55,975 - transformer_training - INFO - Main loop iteration: 2877
2025-04-25 12:50:56,436 - transformer_training - INFO - Main loop iteration: 2878
2025-04-25 12:50:56,886 - transformer_training - INFO - Main loop iteration: 2879
2025-04-25 12:50:57,386 - transformer_training - INFO - Main loop iteration: 2880
Iter 2880: loss 4.0885, lr 0.000999, 92018.20 tokens/sec
2025-04-25 12:50:57,787 - transformer_training - INFO - Main loop iteration: 2881
2025-04-25 12:50:58,248 - transformer_training - INFO - Main loop iteration: 2882
2025-04-25 12:50:58,699 - transformer_training - INFO - Main loop iteration: 2883
2025-04-25 12:50:59,198 - transformer_training - INFO - Main loop iteration: 2884
2025-04-25 12:50:59,599 - transformer_training - INFO - Main loop iteration: 2885
2025-04-25 12:51:00,060 - transformer_training - INFO - Main loop iteration: 2886
2025-04-25 12:51:00,510 - transformer_training - INFO - Main loop iteration: 2887
2025-04-25 12:51:01,009 - transformer_training - INFO - Main loop iteration: 2888
2025-04-25 12:51:01,410 - transformer_training - INFO - Main loop iteration: 2889
2025-04-25 12:51:01,871 - transformer_training - INFO - Main loop iteration: 2890
Iter 2890: loss 4.0546, lr 0.000999, 81721.47 tokens/sec
2025-04-25 12:51:02,323 - transformer_training - INFO - Main loop iteration: 2891
2025-04-25 12:51:02,822 - transformer_training - INFO - Main loop iteration: 2892
2025-04-25 12:51:03,223 - transformer_training - INFO - Main loop iteration: 2893
2025-04-25 12:51:03,684 - transformer_training - INFO - Main loop iteration: 2894
2025-04-25 12:51:04,135 - transformer_training - INFO - Main loop iteration: 2895
2025-04-25 12:51:04,634 - transformer_training - INFO - Main loop iteration: 2896
2025-04-25 12:51:05,035 - transformer_training - INFO - Main loop iteration: 2897
2025-04-25 12:51:05,497 - transformer_training - INFO - Main loop iteration: 2898
2025-04-25 12:51:05,947 - transformer_training - INFO - Main loop iteration: 2899
2025-04-25 12:51:06,446 - transformer_training - INFO - Main loop iteration: 2900
Iter 2900: loss 4.0617, lr 0.000999, 91991.43 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 2900: train loss 4.0460, val loss 3.9015
New best model saved with val loss: 3.9015
2025-04-25 12:51:24,630 - transformer_training - INFO - Main loop iteration: 2901
2025-04-25 12:51:25,040 - transformer_training - INFO - Main loop iteration: 2902
2025-04-25 12:51:25,490 - transformer_training - INFO - Main loop iteration: 2903
2025-04-25 12:51:25,991 - transformer_training - INFO - Main loop iteration: 2904
2025-04-25 12:51:26,392 - transformer_training - INFO - Main loop iteration: 2905
2025-04-25 12:51:26,852 - transformer_training - INFO - Main loop iteration: 2906
2025-04-25 12:51:27,303 - transformer_training - INFO - Main loop iteration: 2907
2025-04-25 12:51:27,804 - transformer_training - INFO - Main loop iteration: 2908
2025-04-25 12:51:28,204 - transformer_training - INFO - Main loop iteration: 2909
2025-04-25 12:51:28,665 - transformer_training - INFO - Main loop iteration: 2910
Iter 2910: loss 4.0707, lr 0.000999, 82052.19 tokens/sec
2025-04-25 12:51:29,115 - transformer_training - INFO - Main loop iteration: 2911
2025-04-25 12:51:29,614 - transformer_training - INFO - Main loop iteration: 2912
2025-04-25 12:51:30,015 - transformer_training - INFO - Main loop iteration: 2913
2025-04-25 12:51:30,475 - transformer_training - INFO - Main loop iteration: 2914
2025-04-25 12:51:30,926 - transformer_training - INFO - Main loop iteration: 2915
2025-04-25 12:51:31,424 - transformer_training - INFO - Main loop iteration: 2916
2025-04-25 12:51:31,825 - transformer_training - INFO - Main loop iteration: 2917
2025-04-25 12:51:32,285 - transformer_training - INFO - Main loop iteration: 2918
2025-04-25 12:51:32,735 - transformer_training - INFO - Main loop iteration: 2919
2025-04-25 12:51:33,234 - transformer_training - INFO - Main loop iteration: 2920
Iter 2920: loss 4.0409, lr 0.000999, 92148.00 tokens/sec
2025-04-25 12:51:33,635 - transformer_training - INFO - Main loop iteration: 2921
2025-04-25 12:51:34,095 - transformer_training - INFO - Main loop iteration: 2922
2025-04-25 12:51:34,545 - transformer_training - INFO - Main loop iteration: 2923
2025-04-25 12:51:35,044 - transformer_training - INFO - Main loop iteration: 2924
2025-04-25 12:51:35,445 - transformer_training - INFO - Main loop iteration: 2925
2025-04-25 12:51:35,906 - transformer_training - INFO - Main loop iteration: 2926
2025-04-25 12:51:36,356 - transformer_training - INFO - Main loop iteration: 2927
2025-04-25 12:51:36,855 - transformer_training - INFO - Main loop iteration: 2928
2025-04-25 12:51:37,256 - transformer_training - INFO - Main loop iteration: 2929
2025-04-25 12:51:37,717 - transformer_training - INFO - Main loop iteration: 2930
Iter 2930: loss 4.0343, lr 0.000999, 81887.93 tokens/sec
2025-04-25 12:51:38,168 - transformer_training - INFO - Main loop iteration: 2931
2025-04-25 12:51:38,666 - transformer_training - INFO - Main loop iteration: 2932
2025-04-25 12:51:39,068 - transformer_training - INFO - Main loop iteration: 2933
2025-04-25 12:51:39,530 - transformer_training - INFO - Main loop iteration: 2934
2025-04-25 12:51:39,980 - transformer_training - INFO - Main loop iteration: 2935
2025-04-25 12:51:40,478 - transformer_training - INFO - Main loop iteration: 2936
2025-04-25 12:51:40,879 - transformer_training - INFO - Main loop iteration: 2937
2025-04-25 12:51:41,340 - transformer_training - INFO - Main loop iteration: 2938
2025-04-25 12:51:41,790 - transformer_training - INFO - Main loop iteration: 2939
2025-04-25 12:51:42,289 - transformer_training - INFO - Main loop iteration: 2940
Iter 2940: loss 4.1196, lr 0.000999, 92084.67 tokens/sec
2025-04-25 12:51:42,690 - transformer_training - INFO - Main loop iteration: 2941
2025-04-25 12:51:43,151 - transformer_training - INFO - Main loop iteration: 2942
2025-04-25 12:51:43,601 - transformer_training - INFO - Main loop iteration: 2943
2025-04-25 12:51:44,100 - transformer_training - INFO - Main loop iteration: 2944
2025-04-25 12:51:44,501 - transformer_training - INFO - Main loop iteration: 2945
2025-04-25 12:51:44,962 - transformer_training - INFO - Main loop iteration: 2946
2025-04-25 12:51:45,412 - transformer_training - INFO - Main loop iteration: 2947
2025-04-25 12:51:45,912 - transformer_training - INFO - Main loop iteration: 2948
2025-04-25 12:51:46,312 - transformer_training - INFO - Main loop iteration: 2949
2025-04-25 12:51:46,774 - transformer_training - INFO - Main loop iteration: 2950
Iter 2950: loss 4.0557, lr 0.000998, 81970.72 tokens/sec
2025-04-25 12:51:47,224 - transformer_training - INFO - Main loop iteration: 2951
2025-04-25 12:51:47,723 - transformer_training - INFO - Main loop iteration: 2952
2025-04-25 12:51:48,123 - transformer_training - INFO - Main loop iteration: 2953
2025-04-25 12:51:48,585 - transformer_training - INFO - Main loop iteration: 2954
2025-04-25 12:51:49,035 - transformer_training - INFO - Main loop iteration: 2955
2025-04-25 12:51:49,534 - transformer_training - INFO - Main loop iteration: 2956
2025-04-25 12:51:49,934 - transformer_training - INFO - Main loop iteration: 2957
2025-04-25 12:51:50,395 - transformer_training - INFO - Main loop iteration: 2958
2025-04-25 12:51:50,845 - transformer_training - INFO - Main loop iteration: 2959
2025-04-25 12:51:51,344 - transformer_training - INFO - Main loop iteration: 2960
Iter 2960: loss 4.0288, lr 0.000998, 92099.98 tokens/sec
2025-04-25 12:51:51,744 - transformer_training - INFO - Main loop iteration: 2961
2025-04-25 12:51:52,205 - transformer_training - INFO - Main loop iteration: 2962
2025-04-25 12:51:52,655 - transformer_training - INFO - Main loop iteration: 2963
2025-04-25 12:51:53,154 - transformer_training - INFO - Main loop iteration: 2964
2025-04-25 12:51:53,556 - transformer_training - INFO - Main loop iteration: 2965
2025-04-25 12:51:54,016 - transformer_training - INFO - Main loop iteration: 2966
2025-04-25 12:51:54,466 - transformer_training - INFO - Main loop iteration: 2967
2025-04-25 12:51:54,965 - transformer_training - INFO - Main loop iteration: 2968
2025-04-25 12:51:55,365 - transformer_training - INFO - Main loop iteration: 2969
2025-04-25 12:51:55,826 - transformer_training - INFO - Main loop iteration: 2970
Iter 2970: loss 3.9978, lr 0.000998, 81916.17 tokens/sec
2025-04-25 12:51:56,277 - transformer_training - INFO - Main loop iteration: 2971
2025-04-25 12:51:56,775 - transformer_training - INFO - Main loop iteration: 2972
2025-04-25 12:51:57,176 - transformer_training - INFO - Main loop iteration: 2973
2025-04-25 12:51:57,637 - transformer_training - INFO - Main loop iteration: 2974
2025-04-25 12:51:58,088 - transformer_training - INFO - Main loop iteration: 2975
2025-04-25 12:51:58,587 - transformer_training - INFO - Main loop iteration: 2976
2025-04-25 12:51:58,987 - transformer_training - INFO - Main loop iteration: 2977
2025-04-25 12:51:59,449 - transformer_training - INFO - Main loop iteration: 2978
2025-04-25 12:51:59,899 - transformer_training - INFO - Main loop iteration: 2979
2025-04-25 12:52:00,397 - transformer_training - INFO - Main loop iteration: 2980
Iter 2980: loss 4.1717, lr 0.000998, 92027.07 tokens/sec
2025-04-25 12:52:00,798 - transformer_training - INFO - Main loop iteration: 2981
2025-04-25 12:52:01,259 - transformer_training - INFO - Main loop iteration: 2982
2025-04-25 12:52:01,709 - transformer_training - INFO - Main loop iteration: 2983
2025-04-25 12:52:02,208 - transformer_training - INFO - Main loop iteration: 2984
2025-04-25 12:52:02,608 - transformer_training - INFO - Main loop iteration: 2985
2025-04-25 12:52:03,069 - transformer_training - INFO - Main loop iteration: 2986
2025-04-25 12:52:03,519 - transformer_training - INFO - Main loop iteration: 2987
2025-04-25 12:52:04,019 - transformer_training - INFO - Main loop iteration: 2988
2025-04-25 12:52:04,420 - transformer_training - INFO - Main loop iteration: 2989
2025-04-25 12:52:04,881 - transformer_training - INFO - Main loop iteration: 2990
Iter 2990: loss 3.9265, lr 0.000998, 81940.87 tokens/sec
2025-04-25 12:52:05,331 - transformer_training - INFO - Main loop iteration: 2991
2025-04-25 12:52:05,830 - transformer_training - INFO - Main loop iteration: 2992
2025-04-25 12:52:06,231 - transformer_training - INFO - Main loop iteration: 2993
2025-04-25 12:52:06,691 - transformer_training - INFO - Main loop iteration: 2994
2025-04-25 12:52:07,142 - transformer_training - INFO - Main loop iteration: 2995
2025-04-25 12:52:07,641 - transformer_training - INFO - Main loop iteration: 2996
2025-04-25 12:52:08,042 - transformer_training - INFO - Main loop iteration: 2997
2025-04-25 12:52:08,504 - transformer_training - INFO - Main loop iteration: 2998
2025-04-25 12:52:08,955 - transformer_training - INFO - Main loop iteration: 2999
2025-04-25 12:52:09,453 - transformer_training - INFO - Main loop iteration: 3000
Iter 3000: loss 4.1020, lr 0.000998, 91918.26 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 3000: train loss 4.0063, val loss 3.8715
New best model saved with val loss: 3.8715
2025-04-25 12:52:30,212 - transformer_training - INFO - Main loop iteration: 3001
2025-04-25 12:52:30,659 - transformer_training - INFO - Main loop iteration: 3002
2025-04-25 12:52:31,109 - transformer_training - INFO - Main loop iteration: 3003
2025-04-25 12:52:31,607 - transformer_training - INFO - Main loop iteration: 3004
2025-04-25 12:52:32,007 - transformer_training - INFO - Main loop iteration: 3005
2025-04-25 12:52:32,468 - transformer_training - INFO - Main loop iteration: 3006
2025-04-25 12:52:32,918 - transformer_training - INFO - Main loop iteration: 3007
2025-04-25 12:52:33,422 - transformer_training - INFO - Main loop iteration: 3008
2025-04-25 12:52:33,824 - transformer_training - INFO - Main loop iteration: 3009
2025-04-25 12:52:34,286 - transformer_training - INFO - Main loop iteration: 3010
Iter 3010: loss 4.0949, lr 0.000998, 82049.23 tokens/sec
2025-04-25 12:52:34,737 - transformer_training - INFO - Main loop iteration: 3011
2025-04-25 12:52:35,237 - transformer_training - INFO - Main loop iteration: 3012
2025-04-25 12:52:35,638 - transformer_training - INFO - Main loop iteration: 3013
2025-04-25 12:52:36,100 - transformer_training - INFO - Main loop iteration: 3014
2025-04-25 12:52:36,551 - transformer_training - INFO - Main loop iteration: 3015
2025-04-25 12:52:37,051 - transformer_training - INFO - Main loop iteration: 3016
2025-04-25 12:52:37,453 - transformer_training - INFO - Main loop iteration: 3017
2025-04-25 12:52:37,916 - transformer_training - INFO - Main loop iteration: 3018
2025-04-25 12:52:38,366 - transformer_training - INFO - Main loop iteration: 3019
2025-04-25 12:52:38,867 - transformer_training - INFO - Main loop iteration: 3020
Iter 3020: loss 4.1017, lr 0.000998, 91830.74 tokens/sec
2025-04-25 12:52:39,269 - transformer_training - INFO - Main loop iteration: 3021
2025-04-25 12:52:39,731 - transformer_training - INFO - Main loop iteration: 3022
2025-04-25 12:52:40,182 - transformer_training - INFO - Main loop iteration: 3023
2025-04-25 12:52:40,682 - transformer_training - INFO - Main loop iteration: 3024
2025-04-25 12:52:41,084 - transformer_training - INFO - Main loop iteration: 3025
2025-04-25 12:52:41,545 - transformer_training - INFO - Main loop iteration: 3026
2025-04-25 12:52:41,997 - transformer_training - INFO - Main loop iteration: 3027
2025-04-25 12:52:42,497 - transformer_training - INFO - Main loop iteration: 3028
2025-04-25 12:52:42,899 - transformer_training - INFO - Main loop iteration: 3029
2025-04-25 12:52:43,359 - transformer_training - INFO - Main loop iteration: 3030
Iter 3030: loss 4.0466, lr 0.000998, 81915.65 tokens/sec
2025-04-25 12:52:43,810 - transformer_training - INFO - Main loop iteration: 3031
2025-04-25 12:52:44,310 - transformer_training - INFO - Main loop iteration: 3032
2025-04-25 12:52:44,710 - transformer_training - INFO - Main loop iteration: 3033
2025-04-25 12:52:45,171 - transformer_training - INFO - Main loop iteration: 3034
2025-04-25 12:52:45,621 - transformer_training - INFO - Main loop iteration: 3035
2025-04-25 12:52:46,121 - transformer_training - INFO - Main loop iteration: 3036
2025-04-25 12:52:46,523 - transformer_training - INFO - Main loop iteration: 3037
2025-04-25 12:52:46,986 - transformer_training - INFO - Main loop iteration: 3038
2025-04-25 12:52:47,436 - transformer_training - INFO - Main loop iteration: 3039
2025-04-25 12:52:47,936 - transformer_training - INFO - Main loop iteration: 3040
Iter 3040: loss 3.9619, lr 0.000998, 92005.93 tokens/sec
2025-04-25 12:52:48,337 - transformer_training - INFO - Main loop iteration: 3041
2025-04-25 12:52:48,798 - transformer_training - INFO - Main loop iteration: 3042
2025-04-25 12:52:49,248 - transformer_training - INFO - Main loop iteration: 3043
2025-04-25 12:52:49,746 - transformer_training - INFO - Main loop iteration: 3044
2025-04-25 12:52:50,147 - transformer_training - INFO - Main loop iteration: 3045
2025-04-25 12:52:50,607 - transformer_training - INFO - Main loop iteration: 3046
2025-04-25 12:52:51,058 - transformer_training - INFO - Main loop iteration: 3047
2025-04-25 12:52:51,557 - transformer_training - INFO - Main loop iteration: 3048
2025-04-25 12:52:51,958 - transformer_training - INFO - Main loop iteration: 3049
2025-04-25 12:52:52,423 - transformer_training - INFO - Main loop iteration: 3050
Iter 3050: loss 4.0330, lr 0.000998, 81069.71 tokens/sec
2025-04-25 12:52:52,879 - transformer_training - INFO - Main loop iteration: 3051
2025-04-25 12:52:53,378 - transformer_training - INFO - Main loop iteration: 3052
2025-04-25 12:52:53,779 - transformer_training - INFO - Main loop iteration: 3053
2025-04-25 12:52:54,241 - transformer_training - INFO - Main loop iteration: 3054
2025-04-25 12:52:54,639 - transformer_training - INFO - Main loop iteration: 3055
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
2025-04-25 12:52:57,887 - transformer_training - INFO - Main loop iteration: 3056
2025-04-25 12:52:58,288 - transformer_training - INFO - Main loop iteration: 3057
2025-04-25 12:52:58,749 - transformer_training - INFO - Main loop iteration: 3058
2025-04-25 12:52:59,199 - transformer_training - INFO - Main loop iteration: 3059
2025-04-25 12:52:59,697 - transformer_training - INFO - Main loop iteration: 3060
Iter 3060: loss 3.9193, lr 0.000998, 92023.35 tokens/sec
2025-04-25 12:53:00,098 - transformer_training - INFO - Main loop iteration: 3061
2025-04-25 12:53:00,559 - transformer_training - INFO - Main loop iteration: 3062
2025-04-25 12:53:01,009 - transformer_training - INFO - Main loop iteration: 3063
2025-04-25 12:53:01,507 - transformer_training - INFO - Main loop iteration: 3064
2025-04-25 12:53:01,908 - transformer_training - INFO - Main loop iteration: 3065
2025-04-25 12:53:02,370 - transformer_training - INFO - Main loop iteration: 3066
2025-04-25 12:53:02,820 - transformer_training - INFO - Main loop iteration: 3067
2025-04-25 12:53:03,319 - transformer_training - INFO - Main loop iteration: 3068
2025-04-25 12:53:03,720 - transformer_training - INFO - Main loop iteration: 3069
2025-04-25 12:53:04,181 - transformer_training - INFO - Main loop iteration: 3070
Iter 3070: loss 3.9537, lr 0.000998, 82003.71 tokens/sec
2025-04-25 12:53:04,631 - transformer_training - INFO - Main loop iteration: 3071
2025-04-25 12:53:05,129 - transformer_training - INFO - Main loop iteration: 3072
2025-04-25 12:53:05,530 - transformer_training - INFO - Main loop iteration: 3073
2025-04-25 12:53:05,990 - transformer_training - INFO - Main loop iteration: 3074
2025-04-25 12:53:06,441 - transformer_training - INFO - Main loop iteration: 3075
2025-04-25 12:53:06,940 - transformer_training - INFO - Main loop iteration: 3076
2025-04-25 12:53:07,340 - transformer_training - INFO - Main loop iteration: 3077
2025-04-25 12:53:07,801 - transformer_training - INFO - Main loop iteration: 3078
2025-04-25 12:53:08,252 - transformer_training - INFO - Main loop iteration: 3079
2025-04-25 12:53:08,750 - transformer_training - INFO - Main loop iteration: 3080
Iter 3080: loss 3.9241, lr 0.000998, 92099.10 tokens/sec
2025-04-25 12:53:09,151 - transformer_training - INFO - Main loop iteration: 3081
2025-04-25 12:53:09,611 - transformer_training - INFO - Main loop iteration: 3082
2025-04-25 12:53:10,061 - transformer_training - INFO - Main loop iteration: 3083
2025-04-25 12:53:10,560 - transformer_training - INFO - Main loop iteration: 3084
2025-04-25 12:53:10,961 - transformer_training - INFO - Main loop iteration: 3085
2025-04-25 12:53:11,421 - transformer_training - INFO - Main loop iteration: 3086
2025-04-25 12:53:11,871 - transformer_training - INFO - Main loop iteration: 3087
2025-04-25 12:53:12,370 - transformer_training - INFO - Main loop iteration: 3088
2025-04-25 12:53:12,771 - transformer_training - INFO - Main loop iteration: 3089
2025-04-25 12:53:13,233 - transformer_training - INFO - Main loop iteration: 3090
Iter 3090: loss 4.0051, lr 0.000998, 81937.27 tokens/sec
2025-04-25 12:53:13,683 - transformer_training - INFO - Main loop iteration: 3091
2025-04-25 12:53:14,182 - transformer_training - INFO - Main loop iteration: 3092
2025-04-25 12:53:14,583 - transformer_training - INFO - Main loop iteration: 3093
2025-04-25 12:53:15,044 - transformer_training - INFO - Main loop iteration: 3094
2025-04-25 12:53:15,494 - transformer_training - INFO - Main loop iteration: 3095
2025-04-25 12:53:15,993 - transformer_training - INFO - Main loop iteration: 3096
2025-04-25 12:53:16,394 - transformer_training - INFO - Main loop iteration: 3097
2025-04-25 12:53:16,854 - transformer_training - INFO - Main loop iteration: 3098
2025-04-25 12:53:17,305 - transformer_training - INFO - Main loop iteration: 3099
2025-04-25 12:53:17,804 - transformer_training - INFO - Main loop iteration: 3100
Iter 3100: loss 3.9485, lr 0.000998, 92038.25 tokens/sec
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 3100: train loss 3.5416, val loss 3.8261
New best model saved with val loss: 3.8261
2025-04-25 12:53:36,974 - transformer_training - INFO - Main loop iteration: 3101
2025-04-25 12:53:37,390 - transformer_training - INFO - Main loop iteration: 3102
2025-04-25 12:53:37,840 - transformer_training - INFO - Main loop iteration: 3103
2025-04-25 12:53:38,339 - transformer_training - INFO - Main loop iteration: 3104
2025-04-25 12:53:38,741 - transformer_training - INFO - Main loop iteration: 3105
2025-04-25 12:53:39,201 - transformer_training - INFO - Main loop iteration: 3106
2025-04-25 12:53:39,652 - transformer_training - INFO - Main loop iteration: 3107
2025-04-25 12:53:40,150 - transformer_training - INFO - Main loop iteration: 3108
2025-04-25 12:53:40,551 - transformer_training - INFO - Main loop iteration: 3109
2025-04-25 12:53:41,012 - transformer_training - INFO - Main loop iteration: 3110
Iter 3110: loss 3.9534, lr 0.000998, 81936.23 tokens/sec
2025-04-25 12:53:41,463 - transformer_training - INFO - Main loop iteration: 3111
2025-04-25 12:53:41,963 - transformer_training - INFO - Main loop iteration: 3112
2025-04-25 12:53:42,363 - transformer_training - INFO - Main loop iteration: 3113
2025-04-25 12:53:42,823 - transformer_training - INFO - Main loop iteration: 3114
2025-04-25 12:53:43,273 - transformer_training - INFO - Main loop iteration: 3115
2025-04-25 12:53:43,773 - transformer_training - INFO - Main loop iteration: 3116
2025-04-25 12:53:44,173 - transformer_training - INFO - Main loop iteration: 3117
2025-04-25 12:53:44,634 - transformer_training - INFO - Main loop iteration: 3118
2025-04-25 12:53:45,084 - transformer_training - INFO - Main loop iteration: 3119
2025-04-25 12:53:45,583 - transformer_training - INFO - Main loop iteration: 3120
Iter 3120: loss 3.9427, lr 0.000998, 92051.18 tokens/sec
2025-04-25 12:53:45,984 - transformer_training - INFO - Main loop iteration: 3121
2025-04-25 12:53:46,445 - transformer_training - INFO - Main loop iteration: 3122
2025-04-25 12:53:46,895 - transformer_training - INFO - Main loop iteration: 3123
2025-04-25 12:53:47,394 - transformer_training - INFO - Main loop iteration: 3124
2025-04-25 12:53:47,794 - transformer_training - INFO - Main loop iteration: 3125
2025-04-25 12:53:48,256 - transformer_training - INFO - Main loop iteration: 3126
2025-04-25 12:53:48,706 - transformer_training - INFO - Main loop iteration: 3127
2025-04-25 12:53:49,206 - transformer_training - INFO - Main loop iteration: 3128
2025-04-25 12:53:49,606 - transformer_training - INFO - Main loop iteration: 3129
2025-04-25 12:53:50,067 - transformer_training - INFO - Main loop iteration: 3130
Iter 3130: loss 3.9216, lr 0.000998, 81997.36 tokens/sec
2025-04-25 12:53:50,518 - transformer_training - INFO - Main loop iteration: 3131
2025-04-25 12:53:51,016 - transformer_training - INFO - Main loop iteration: 3132
2025-04-25 12:53:51,417 - transformer_training - INFO - Main loop iteration: 3133
2025-04-25 12:53:51,877 - transformer_training - INFO - Main loop iteration: 3134
2025-04-25 12:53:52,328 - transformer_training - INFO - Main loop iteration: 3135
2025-04-25 12:53:52,828 - transformer_training - INFO - Main loop iteration: 3136
2025-04-25 12:53:53,228 - transformer_training - INFO - Main loop iteration: 3137
2025-04-25 12:53:53,689 - transformer_training - INFO - Main loop iteration: 3138
2025-04-25 12:53:54,140 - transformer_training - INFO - Main loop iteration: 3139
2025-04-25 12:53:54,639 - transformer_training - INFO - Main loop iteration: 3140
Iter 3140: loss 3.8535, lr 0.000998, 91987.32 tokens/sec
2025-04-25 12:53:55,040 - transformer_training - INFO - Main loop iteration: 3141
2025-04-25 12:53:55,500 - transformer_training - INFO - Main loop iteration: 3142
2025-04-25 12:53:55,950 - transformer_training - INFO - Main loop iteration: 3143
2025-04-25 12:53:56,450 - transformer_training - INFO - Main loop iteration: 3144
2025-04-25 12:53:56,850 - transformer_training - INFO - Main loop iteration: 3145
2025-04-25 12:53:57,311 - transformer_training - INFO - Main loop iteration: 3146
2025-04-25 12:53:57,761 - transformer_training - INFO - Main loop iteration: 3147
2025-04-25 12:53:58,260 - transformer_training - INFO - Main loop iteration: 3148
2025-04-25 12:53:58,662 - transformer_training - INFO - Main loop iteration: 3149
2025-04-25 12:53:59,123 - transformer_training - INFO - Main loop iteration: 3150
Iter 3150: loss 3.8910, lr 0.000998, 82003.89 tokens/sec
2025-04-25 12:53:59,573 - transformer_training - INFO - Main loop iteration: 3151
2025-04-25 12:54:00,072 - transformer_training - INFO - Main loop iteration: 3152
2025-04-25 12:54:00,473 - transformer_training - INFO - Main loop iteration: 3153
2025-04-25 12:54:00,934 - transformer_training - INFO - Main loop iteration: 3154
2025-04-25 12:54:01,385 - transformer_training - INFO - Main loop iteration: 3155
2025-04-25 12:54:01,884 - transformer_training - INFO - Main loop iteration: 3156
2025-04-25 12:54:02,285 - transformer_training - INFO - Main loop iteration: 3157
2025-04-25 12:54:02,745 - transformer_training - INFO - Main loop iteration: 3158
2025-04-25 12:54:03,195 - transformer_training - INFO - Main loop iteration: 3159
2025-04-25 12:54:03,694 - transformer_training - INFO - Main loop iteration: 3160
Iter 3160: loss 3.9292, lr 0.000998, 92047.23 tokens/sec
2025-04-25 12:54:04,095 - transformer_training - INFO - Main loop iteration: 3161
2025-04-25 12:54:04,555 - transformer_training - INFO - Main loop iteration: 3162
2025-04-25 12:54:05,006 - transformer_training - INFO - Main loop iteration: 3163
2025-04-25 12:54:05,505 - transformer_training - INFO - Main loop iteration: 3164
2025-04-25 12:54:05,905 - transformer_training - INFO - Main loop iteration: 3165
2025-04-25 12:54:06,366 - transformer_training - INFO - Main loop iteration: 3166
2025-04-25 12:54:06,816 - transformer_training - INFO - Main loop iteration: 3167
2025-04-25 12:54:07,316 - transformer_training - INFO - Main loop iteration: 3168
2025-04-25 12:54:07,717 - transformer_training - INFO - Main loop iteration: 3169
2025-04-25 12:54:08,178 - transformer_training - INFO - Main loop iteration: 3170
Iter 3170: loss 3.8472, lr 0.000998, 81955.81 tokens/sec
2025-04-25 12:54:08,629 - transformer_training - INFO - Main loop iteration: 3171
2025-04-25 12:54:09,128 - transformer_training - INFO - Main loop iteration: 3172
2025-04-25 12:54:09,528 - transformer_training - INFO - Main loop iteration: 3173
2025-04-25 12:54:09,989 - transformer_training - INFO - Main loop iteration: 3174
2025-04-25 12:54:10,440 - transformer_training - INFO - Main loop iteration: 3175
2025-04-25 12:54:10,939 - transformer_training - INFO - Main loop iteration: 3176
2025-04-25 12:54:11,339 - transformer_training - INFO - Main loop iteration: 3177
2025-04-25 12:54:11,801 - transformer_training - INFO - Main loop iteration: 3178
2025-04-25 12:54:12,252 - transformer_training - INFO - Main loop iteration: 3179
2025-04-25 12:54:12,751 - transformer_training - INFO - Main loop iteration: 3180
Iter 3180: loss 3.9800, lr 0.000998, 92068.00 tokens/sec
2025-04-25 12:54:13,152 - transformer_training - INFO - Main loop iteration: 3181
2025-04-25 12:54:13,612 - transformer_training - INFO - Main loop iteration: 3182
2025-04-25 12:54:14,062 - transformer_training - INFO - Main loop iteration: 3183
2025-04-25 12:54:14,561 - transformer_training - INFO - Main loop iteration: 3184
2025-04-25 12:54:14,962 - transformer_training - INFO - Main loop iteration: 3185
2025-04-25 12:54:15,423 - transformer_training - INFO - Main loop iteration: 3186
2025-04-25 12:54:15,873 - transformer_training - INFO - Main loop iteration: 3187
2025-04-25 12:54:16,373 - transformer_training - INFO - Main loop iteration: 3188
2025-04-25 12:54:16,774 - transformer_training - INFO - Main loop iteration: 3189
2025-04-25 12:54:17,234 - transformer_training - INFO - Main loop iteration: 3190
Iter 3190: loss 3.9367, lr 0.000998, 81897.82 tokens/sec
2025-04-25 12:54:17,685 - transformer_training - INFO - Main loop iteration: 3191
2025-04-25 12:54:18,184 - transformer_training - INFO - Main loop iteration: 3192
2025-04-25 12:54:18,585 - transformer_training - INFO - Main loop iteration: 3193
2025-04-25 12:54:19,047 - transformer_training - INFO - Main loop iteration: 3194
2025-04-25 12:54:19,499 - transformer_training - INFO - Main loop iteration: 3195
2025-04-25 12:54:19,998 - transformer_training - INFO - Main loop iteration: 3196
2025-04-25 12:54:20,399 - transformer_training - INFO - Main loop iteration: 3197
2025-04-25 12:54:20,860 - transformer_training - INFO - Main loop iteration: 3198
2025-04-25 12:54:21,310 - transformer_training - INFO - Main loop iteration: 3199
2025-04-25 12:54:21,809 - transformer_training - INFO - Main loop iteration: 3200
Iter 3200: loss 3.8795, lr 0.000998, 91952.04 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 3200: train loss 3.6214, val loss 3.8009
New best model saved with val loss: 3.8009
2025-04-25 12:54:39,967 - transformer_training - INFO - Main loop iteration: 3201
2025-04-25 12:54:40,389 - transformer_training - INFO - Main loop iteration: 3202
2025-04-25 12:54:40,839 - transformer_training - INFO - Main loop iteration: 3203
2025-04-25 12:54:41,338 - transformer_training - INFO - Main loop iteration: 3204
2025-04-25 12:54:41,738 - transformer_training - INFO - Main loop iteration: 3205
2025-04-25 12:54:42,199 - transformer_training - INFO - Main loop iteration: 3206
2025-04-25 12:54:42,649 - transformer_training - INFO - Main loop iteration: 3207
2025-04-25 12:54:43,147 - transformer_training - INFO - Main loop iteration: 3208
2025-04-25 12:54:43,548 - transformer_training - INFO - Main loop iteration: 3209
2025-04-25 12:54:44,009 - transformer_training - INFO - Main loop iteration: 3210
Iter 3210: loss 3.9269, lr 0.000998, 81998.80 tokens/sec
2025-04-25 12:54:44,459 - transformer_training - INFO - Main loop iteration: 3211
2025-04-25 12:54:44,957 - transformer_training - INFO - Main loop iteration: 3212
2025-04-25 12:54:45,359 - transformer_training - INFO - Main loop iteration: 3213
2025-04-25 12:54:45,819 - transformer_training - INFO - Main loop iteration: 3214
2025-04-25 12:54:46,269 - transformer_training - INFO - Main loop iteration: 3215
2025-04-25 12:54:46,769 - transformer_training - INFO - Main loop iteration: 3216
2025-04-25 12:54:47,169 - transformer_training - INFO - Main loop iteration: 3217
2025-04-25 12:54:47,630 - transformer_training - INFO - Main loop iteration: 3218
2025-04-25 12:54:48,081 - transformer_training - INFO - Main loop iteration: 3219
2025-04-25 12:54:48,581 - transformer_training - INFO - Main loop iteration: 3220
Iter 3220: loss 3.9582, lr 0.000997, 92148.50 tokens/sec
2025-04-25 12:54:48,981 - transformer_training - INFO - Main loop iteration: 3221
2025-04-25 12:54:49,442 - transformer_training - INFO - Main loop iteration: 3222
2025-04-25 12:54:49,892 - transformer_training - INFO - Main loop iteration: 3223
2025-04-25 12:54:50,391 - transformer_training - INFO - Main loop iteration: 3224
2025-04-25 12:54:50,792 - transformer_training - INFO - Main loop iteration: 3225
2025-04-25 12:54:51,253 - transformer_training - INFO - Main loop iteration: 3226
2025-04-25 12:54:51,703 - transformer_training - INFO - Main loop iteration: 3227
2025-04-25 12:54:52,203 - transformer_training - INFO - Main loop iteration: 3228
2025-04-25 12:54:52,604 - transformer_training - INFO - Main loop iteration: 3229
2025-04-25 12:54:53,064 - transformer_training - INFO - Main loop iteration: 3230
Iter 3230: loss 3.9446, lr 0.000997, 81863.39 tokens/sec
2025-04-25 12:54:53,515 - transformer_training - INFO - Main loop iteration: 3231
2025-04-25 12:54:54,014 - transformer_training - INFO - Main loop iteration: 3232
2025-04-25 12:54:54,415 - transformer_training - INFO - Main loop iteration: 3233
2025-04-25 12:54:54,876 - transformer_training - INFO - Main loop iteration: 3234
2025-04-25 12:54:55,326 - transformer_training - INFO - Main loop iteration: 3235
2025-04-25 12:54:55,825 - transformer_training - INFO - Main loop iteration: 3236
2025-04-25 12:54:56,225 - transformer_training - INFO - Main loop iteration: 3237
2025-04-25 12:54:56,686 - transformer_training - INFO - Main loop iteration: 3238
2025-04-25 12:54:57,137 - transformer_training - INFO - Main loop iteration: 3239
2025-04-25 12:54:57,636 - transformer_training - INFO - Main loop iteration: 3240
Iter 3240: loss 3.9407, lr 0.000997, 92047.07 tokens/sec
2025-04-25 12:54:58,037 - transformer_training - INFO - Main loop iteration: 3241
2025-04-25 12:54:58,498 - transformer_training - INFO - Main loop iteration: 3242
2025-04-25 12:54:58,949 - transformer_training - INFO - Main loop iteration: 3243
2025-04-25 12:54:59,448 - transformer_training - INFO - Main loop iteration: 3244
2025-04-25 12:54:59,849 - transformer_training - INFO - Main loop iteration: 3245
2025-04-25 12:55:00,310 - transformer_training - INFO - Main loop iteration: 3246
2025-04-25 12:55:00,760 - transformer_training - INFO - Main loop iteration: 3247
2025-04-25 12:55:01,259 - transformer_training - INFO - Main loop iteration: 3248
2025-04-25 12:55:01,660 - transformer_training - INFO - Main loop iteration: 3249
2025-04-25 12:55:02,122 - transformer_training - INFO - Main loop iteration: 3250
Iter 3250: loss 3.7968, lr 0.000997, 81810.37 tokens/sec
2025-04-25 12:55:02,573 - transformer_training - INFO - Main loop iteration: 3251
2025-04-25 12:55:03,072 - transformer_training - INFO - Main loop iteration: 3252
2025-04-25 12:55:03,473 - transformer_training - INFO - Main loop iteration: 3253
2025-04-25 12:55:03,934 - transformer_training - INFO - Main loop iteration: 3254
2025-04-25 12:55:04,384 - transformer_training - INFO - Main loop iteration: 3255
2025-04-25 12:55:04,883 - transformer_training - INFO - Main loop iteration: 3256
2025-04-25 12:55:05,284 - transformer_training - INFO - Main loop iteration: 3257
2025-04-25 12:55:05,745 - transformer_training - INFO - Main loop iteration: 3258
2025-04-25 12:55:06,195 - transformer_training - INFO - Main loop iteration: 3259
2025-04-25 12:55:06,695 - transformer_training - INFO - Main loop iteration: 3260
Iter 3260: loss 3.9222, lr 0.000997, 92093.28 tokens/sec
2025-04-25 12:55:07,095 - transformer_training - INFO - Main loop iteration: 3261
2025-04-25 12:55:07,556 - transformer_training - INFO - Main loop iteration: 3262
2025-04-25 12:55:08,007 - transformer_training - INFO - Main loop iteration: 3263
2025-04-25 12:55:08,506 - transformer_training - INFO - Main loop iteration: 3264
2025-04-25 12:55:08,907 - transformer_training - INFO - Main loop iteration: 3265
2025-04-25 12:55:09,368 - transformer_training - INFO - Main loop iteration: 3266
2025-04-25 12:55:09,819 - transformer_training - INFO - Main loop iteration: 3267
2025-04-25 12:55:10,318 - transformer_training - INFO - Main loop iteration: 3268
2025-04-25 12:55:10,719 - transformer_training - INFO - Main loop iteration: 3269
2025-04-25 12:55:11,180 - transformer_training - INFO - Main loop iteration: 3270
Iter 3270: loss 3.9260, lr 0.000997, 81936.92 tokens/sec
2025-04-25 12:55:11,631 - transformer_training - INFO - Main loop iteration: 3271
2025-04-25 12:55:12,130 - transformer_training - INFO - Main loop iteration: 3272
2025-04-25 12:55:12,531 - transformer_training - INFO - Main loop iteration: 3273
2025-04-25 12:55:12,992 - transformer_training - INFO - Main loop iteration: 3274
2025-04-25 12:55:13,443 - transformer_training - INFO - Main loop iteration: 3275
2025-04-25 12:55:13,942 - transformer_training - INFO - Main loop iteration: 3276
2025-04-25 12:55:14,343 - transformer_training - INFO - Main loop iteration: 3277
2025-04-25 12:55:14,804 - transformer_training - INFO - Main loop iteration: 3278
2025-04-25 12:55:15,255 - transformer_training - INFO - Main loop iteration: 3279
2025-04-25 12:55:15,754 - transformer_training - INFO - Main loop iteration: 3280
Iter 3280: loss 3.9214, lr 0.000997, 91963.80 tokens/sec
2025-04-25 12:55:16,155 - transformer_training - INFO - Main loop iteration: 3281
2025-04-25 12:55:16,617 - transformer_training - INFO - Main loop iteration: 3282
2025-04-25 12:55:17,067 - transformer_training - INFO - Main loop iteration: 3283
2025-04-25 12:55:17,567 - transformer_training - INFO - Main loop iteration: 3284
2025-04-25 12:55:17,968 - transformer_training - INFO - Main loop iteration: 3285
2025-04-25 12:55:18,429 - transformer_training - INFO - Main loop iteration: 3286
2025-04-25 12:55:18,880 - transformer_training - INFO - Main loop iteration: 3287
2025-04-25 12:55:19,379 - transformer_training - INFO - Main loop iteration: 3288
2025-04-25 12:55:19,780 - transformer_training - INFO - Main loop iteration: 3289
2025-04-25 12:55:20,241 - transformer_training - INFO - Main loop iteration: 3290
Iter 3290: loss 3.9568, lr 0.000997, 81848.57 tokens/sec
2025-04-25 12:55:20,692 - transformer_training - INFO - Main loop iteration: 3291
2025-04-25 12:55:21,191 - transformer_training - INFO - Main loop iteration: 3292
2025-04-25 12:55:21,591 - transformer_training - INFO - Main loop iteration: 3293
2025-04-25 12:55:22,053 - transformer_training - INFO - Main loop iteration: 3294
2025-04-25 12:55:22,504 - transformer_training - INFO - Main loop iteration: 3295
2025-04-25 12:55:23,003 - transformer_training - INFO - Main loop iteration: 3296
2025-04-25 12:55:23,404 - transformer_training - INFO - Main loop iteration: 3297
2025-04-25 12:55:23,865 - transformer_training - INFO - Main loop iteration: 3298
2025-04-25 12:55:24,315 - transformer_training - INFO - Main loop iteration: 3299
2025-04-25 12:55:24,814 - transformer_training - INFO - Main loop iteration: 3300
Iter 3300: loss 3.9681, lr 0.000997, 92018.03 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 3300: train loss 3.6730, val loss 3.7758
New best model saved with val loss: 3.7758
2025-04-25 12:55:43,267 - transformer_training - INFO - Main loop iteration: 3301
2025-04-25 12:55:43,687 - transformer_training - INFO - Main loop iteration: 3302
2025-04-25 12:55:44,136 - transformer_training - INFO - Main loop iteration: 3303
2025-04-25 12:55:44,635 - transformer_training - INFO - Main loop iteration: 3304
2025-04-25 12:55:45,035 - transformer_training - INFO - Main loop iteration: 3305
2025-04-25 12:55:45,496 - transformer_training - INFO - Main loop iteration: 3306
2025-04-25 12:55:45,947 - transformer_training - INFO - Main loop iteration: 3307
2025-04-25 12:55:46,447 - transformer_training - INFO - Main loop iteration: 3308
2025-04-25 12:55:46,848 - transformer_training - INFO - Main loop iteration: 3309
2025-04-25 12:55:47,309 - transformer_training - INFO - Main loop iteration: 3310
Iter 3310: loss 3.8430, lr 0.000997, 82006.71 tokens/sec
2025-04-25 12:55:47,759 - transformer_training - INFO - Main loop iteration: 3311
2025-04-25 12:55:48,258 - transformer_training - INFO - Main loop iteration: 3312
2025-04-25 12:55:48,659 - transformer_training - INFO - Main loop iteration: 3313
2025-04-25 12:55:49,120 - transformer_training - INFO - Main loop iteration: 3314
2025-04-25 12:55:49,570 - transformer_training - INFO - Main loop iteration: 3315
2025-04-25 12:55:50,070 - transformer_training - INFO - Main loop iteration: 3316
2025-04-25 12:55:50,471 - transformer_training - INFO - Main loop iteration: 3317
2025-04-25 12:55:50,932 - transformer_training - INFO - Main loop iteration: 3318
2025-04-25 12:55:51,382 - transformer_training - INFO - Main loop iteration: 3319
2025-04-25 12:55:51,882 - transformer_training - INFO - Main loop iteration: 3320
Iter 3320: loss 3.8340, lr 0.000997, 92000.08 tokens/sec
2025-04-25 12:55:52,283 - transformer_training - INFO - Main loop iteration: 3321
2025-04-25 12:55:52,744 - transformer_training - INFO - Main loop iteration: 3322
2025-04-25 12:55:53,195 - transformer_training - INFO - Main loop iteration: 3323
2025-04-25 12:55:53,695 - transformer_training - INFO - Main loop iteration: 3324
2025-04-25 12:55:54,096 - transformer_training - INFO - Main loop iteration: 3325
2025-04-25 12:55:54,557 - transformer_training - INFO - Main loop iteration: 3326
2025-04-25 12:55:55,007 - transformer_training - INFO - Main loop iteration: 3327
2025-04-25 12:55:55,507 - transformer_training - INFO - Main loop iteration: 3328
2025-04-25 12:55:55,907 - transformer_training - INFO - Main loop iteration: 3329
2025-04-25 12:55:56,368 - transformer_training - INFO - Main loop iteration: 3330
Iter 3330: loss 3.8915, lr 0.000997, 81891.75 tokens/sec
2025-04-25 12:55:56,819 - transformer_training - INFO - Main loop iteration: 3331
2025-04-25 12:55:57,318 - transformer_training - INFO - Main loop iteration: 3332
2025-04-25 12:55:57,719 - transformer_training - INFO - Main loop iteration: 3333
2025-04-25 12:55:58,180 - transformer_training - INFO - Main loop iteration: 3334
2025-04-25 12:55:58,631 - transformer_training - INFO - Main loop iteration: 3335
2025-04-25 12:55:59,130 - transformer_training - INFO - Main loop iteration: 3336
2025-04-25 12:55:59,530 - transformer_training - INFO - Main loop iteration: 3337
2025-04-25 12:55:59,991 - transformer_training - INFO - Main loop iteration: 3338
2025-04-25 12:56:00,442 - transformer_training - INFO - Main loop iteration: 3339
2025-04-25 12:56:00,942 - transformer_training - INFO - Main loop iteration: 3340
Iter 3340: loss 3.8987, lr 0.000997, 92048.22 tokens/sec
2025-04-25 12:56:01,343 - transformer_training - INFO - Main loop iteration: 3341
2025-04-25 12:56:01,804 - transformer_training - INFO - Main loop iteration: 3342
2025-04-25 12:56:02,255 - transformer_training - INFO - Main loop iteration: 3343
2025-04-25 12:56:02,755 - transformer_training - INFO - Main loop iteration: 3344
2025-04-25 12:56:03,157 - transformer_training - INFO - Main loop iteration: 3345
2025-04-25 12:56:03,617 - transformer_training - INFO - Main loop iteration: 3346
2025-04-25 12:56:04,068 - transformer_training - INFO - Main loop iteration: 3347
2025-04-25 12:56:04,567 - transformer_training - INFO - Main loop iteration: 3348
2025-04-25 12:56:04,968 - transformer_training - INFO - Main loop iteration: 3349
2025-04-25 12:56:05,428 - transformer_training - INFO - Main loop iteration: 3350
Iter 3350: loss 3.8636, lr 0.000997, 81951.60 tokens/sec
2025-04-25 12:56:05,879 - transformer_training - INFO - Main loop iteration: 3351
2025-04-25 12:56:06,378 - transformer_training - INFO - Main loop iteration: 3352
2025-04-25 12:56:06,779 - transformer_training - INFO - Main loop iteration: 3353
2025-04-25 12:56:07,240 - transformer_training - INFO - Main loop iteration: 3354
2025-04-25 12:56:07,690 - transformer_training - INFO - Main loop iteration: 3355
2025-04-25 12:56:08,190 - transformer_training - INFO - Main loop iteration: 3356
2025-04-25 12:56:08,591 - transformer_training - INFO - Main loop iteration: 3357
2025-04-25 12:56:09,052 - transformer_training - INFO - Main loop iteration: 3358
2025-04-25 12:56:09,502 - transformer_training - INFO - Main loop iteration: 3359
2025-04-25 12:56:10,089 - transformer_training - INFO - Main loop iteration: 3360
Iter 3360: loss 3.8320, lr 0.000997, 92070.20 tokens/sec
2025-04-25 12:56:10,490 - transformer_training - INFO - Main loop iteration: 3361
2025-04-25 12:56:10,950 - transformer_training - INFO - Main loop iteration: 3362
2025-04-25 12:56:11,401 - transformer_training - INFO - Main loop iteration: 3363
2025-04-25 12:56:11,900 - transformer_training - INFO - Main loop iteration: 3364
2025-04-25 12:56:12,301 - transformer_training - INFO - Main loop iteration: 3365
2025-04-25 12:56:12,762 - transformer_training - INFO - Main loop iteration: 3366
2025-04-25 12:56:13,213 - transformer_training - INFO - Main loop iteration: 3367
2025-04-25 12:56:13,712 - transformer_training - INFO - Main loop iteration: 3368
2025-04-25 12:56:14,113 - transformer_training - INFO - Main loop iteration: 3369
2025-04-25 12:56:14,574 - transformer_training - INFO - Main loop iteration: 3370
Iter 3370: loss 3.9442, lr 0.000997, 81930.24 tokens/sec
2025-04-25 12:56:15,024 - transformer_training - INFO - Main loop iteration: 3371
2025-04-25 12:56:15,523 - transformer_training - INFO - Main loop iteration: 3372
2025-04-25 12:56:15,925 - transformer_training - INFO - Main loop iteration: 3373
2025-04-25 12:56:16,386 - transformer_training - INFO - Main loop iteration: 3374
2025-04-25 12:56:16,837 - transformer_training - INFO - Main loop iteration: 3375
2025-04-25 12:56:17,336 - transformer_training - INFO - Main loop iteration: 3376
2025-04-25 12:56:17,737 - transformer_training - INFO - Main loop iteration: 3377
2025-04-25 12:56:18,198 - transformer_training - INFO - Main loop iteration: 3378
2025-04-25 12:56:18,649 - transformer_training - INFO - Main loop iteration: 3379
2025-04-25 12:56:19,148 - transformer_training - INFO - Main loop iteration: 3380
Iter 3380: loss 3.9463, lr 0.000997, 92006.10 tokens/sec
2025-04-25 12:56:19,549 - transformer_training - INFO - Main loop iteration: 3381
2025-04-25 12:56:20,010 - transformer_training - INFO - Main loop iteration: 3382
2025-04-25 12:56:20,461 - transformer_training - INFO - Main loop iteration: 3383
2025-04-25 12:56:20,960 - transformer_training - INFO - Main loop iteration: 3384
2025-04-25 12:56:21,361 - transformer_training - INFO - Main loop iteration: 3385
2025-04-25 12:56:21,822 - transformer_training - INFO - Main loop iteration: 3386
2025-04-25 12:56:22,273 - transformer_training - INFO - Main loop iteration: 3387
2025-04-25 12:56:22,772 - transformer_training - INFO - Main loop iteration: 3388
2025-04-25 12:56:23,173 - transformer_training - INFO - Main loop iteration: 3389
2025-04-25 12:56:23,634 - transformer_training - INFO - Main loop iteration: 3390
Iter 3390: loss 3.9934, lr 0.000997, 81838.61 tokens/sec
2025-04-25 12:56:24,085 - transformer_training - INFO - Main loop iteration: 3391
2025-04-25 12:56:24,584 - transformer_training - INFO - Main loop iteration: 3392
2025-04-25 12:56:24,985 - transformer_training - INFO - Main loop iteration: 3393
2025-04-25 12:56:25,446 - transformer_training - INFO - Main loop iteration: 3394
2025-04-25 12:56:25,897 - transformer_training - INFO - Main loop iteration: 3395
2025-04-25 12:56:26,396 - transformer_training - INFO - Main loop iteration: 3396
2025-04-25 12:56:26,797 - transformer_training - INFO - Main loop iteration: 3397
2025-04-25 12:56:27,259 - transformer_training - INFO - Main loop iteration: 3398
2025-04-25 12:56:27,709 - transformer_training - INFO - Main loop iteration: 3399
2025-04-25 12:56:28,208 - transformer_training - INFO - Main loop iteration: 3400
Iter 3400: loss 3.8826, lr 0.000997, 91852.62 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 3400: train loss 3.6923, val loss 3.7494
New best model saved with val loss: 3.7494
2025-04-25 12:56:46,729 - transformer_training - INFO - Main loop iteration: 3401
2025-04-25 12:56:47,142 - transformer_training - INFO - Main loop iteration: 3402
2025-04-25 12:56:47,592 - transformer_training - INFO - Main loop iteration: 3403
2025-04-25 12:56:48,091 - transformer_training - INFO - Main loop iteration: 3404
2025-04-25 12:56:48,492 - transformer_training - INFO - Main loop iteration: 3405
2025-04-25 12:56:48,953 - transformer_training - INFO - Main loop iteration: 3406
2025-04-25 12:56:49,403 - transformer_training - INFO - Main loop iteration: 3407
2025-04-25 12:56:49,902 - transformer_training - INFO - Main loop iteration: 3408
2025-04-25 12:56:50,303 - transformer_training - INFO - Main loop iteration: 3409
2025-04-25 12:56:50,764 - transformer_training - INFO - Main loop iteration: 3410
Iter 3410: loss 3.8501, lr 0.000997, 81942.87 tokens/sec
2025-04-25 12:56:51,214 - transformer_training - INFO - Main loop iteration: 3411
2025-04-25 12:56:51,713 - transformer_training - INFO - Main loop iteration: 3412
2025-04-25 12:56:52,114 - transformer_training - INFO - Main loop iteration: 3413
2025-04-25 12:56:52,576 - transformer_training - INFO - Main loop iteration: 3414
2025-04-25 12:56:53,027 - transformer_training - INFO - Main loop iteration: 3415
2025-04-25 12:56:53,525 - transformer_training - INFO - Main loop iteration: 3416
2025-04-25 12:56:53,926 - transformer_training - INFO - Main loop iteration: 3417
2025-04-25 12:56:54,387 - transformer_training - INFO - Main loop iteration: 3418
2025-04-25 12:56:54,838 - transformer_training - INFO - Main loop iteration: 3419
2025-04-25 12:56:55,337 - transformer_training - INFO - Main loop iteration: 3420
Iter 3420: loss 3.8440, lr 0.000997, 92090.21 tokens/sec
2025-04-25 12:56:55,737 - transformer_training - INFO - Main loop iteration: 3421
2025-04-25 12:56:56,198 - transformer_training - INFO - Main loop iteration: 3422
2025-04-25 12:56:56,649 - transformer_training - INFO - Main loop iteration: 3423
2025-04-25 12:56:57,148 - transformer_training - INFO - Main loop iteration: 3424
2025-04-25 12:56:57,549 - transformer_training - INFO - Main loop iteration: 3425
2025-04-25 12:56:58,010 - transformer_training - INFO - Main loop iteration: 3426
2025-04-25 12:56:58,461 - transformer_training - INFO - Main loop iteration: 3427
2025-04-25 12:56:58,960 - transformer_training - INFO - Main loop iteration: 3428
2025-04-25 12:56:59,360 - transformer_training - INFO - Main loop iteration: 3429
2025-04-25 12:56:59,821 - transformer_training - INFO - Main loop iteration: 3430
Iter 3430: loss 3.8598, lr 0.000997, 81869.81 tokens/sec
2025-04-25 12:57:00,272 - transformer_training - INFO - Main loop iteration: 3431
2025-04-25 12:57:00,770 - transformer_training - INFO - Main loop iteration: 3432
2025-04-25 12:57:01,171 - transformer_training - INFO - Main loop iteration: 3433
2025-04-25 12:57:01,632 - transformer_training - INFO - Main loop iteration: 3434
2025-04-25 12:57:02,083 - transformer_training - INFO - Main loop iteration: 3435
2025-04-25 12:57:02,582 - transformer_training - INFO - Main loop iteration: 3436
2025-04-25 12:57:02,983 - transformer_training - INFO - Main loop iteration: 3437
2025-04-25 12:57:03,444 - transformer_training - INFO - Main loop iteration: 3438
2025-04-25 12:57:03,894 - transformer_training - INFO - Main loop iteration: 3439
2025-04-25 12:57:04,392 - transformer_training - INFO - Main loop iteration: 3440
Iter 3440: loss 3.9248, lr 0.000996, 92048.77 tokens/sec
2025-04-25 12:57:04,793 - transformer_training - INFO - Main loop iteration: 3441
2025-04-25 12:57:05,254 - transformer_training - INFO - Main loop iteration: 3442
2025-04-25 12:57:05,704 - transformer_training - INFO - Main loop iteration: 3443
2025-04-25 12:57:06,202 - transformer_training - INFO - Main loop iteration: 3444
2025-04-25 12:57:06,603 - transformer_training - INFO - Main loop iteration: 3445
2025-04-25 12:57:07,064 - transformer_training - INFO - Main loop iteration: 3446
2025-04-25 12:57:07,514 - transformer_training - INFO - Main loop iteration: 3447
2025-04-25 12:57:08,013 - transformer_training - INFO - Main loop iteration: 3448
2025-04-25 12:57:08,414 - transformer_training - INFO - Main loop iteration: 3449
2025-04-25 12:57:08,875 - transformer_training - INFO - Main loop iteration: 3450
Iter 3450: loss 3.8769, lr 0.000996, 81458.20 tokens/sec
2025-04-25 12:57:09,328 - transformer_training - INFO - Main loop iteration: 3451
2025-04-25 12:57:09,826 - transformer_training - INFO - Main loop iteration: 3452
2025-04-25 12:57:10,227 - transformer_training - INFO - Main loop iteration: 3453
2025-04-25 12:57:10,688 - transformer_training - INFO - Main loop iteration: 3454
2025-04-25 12:57:11,138 - transformer_training - INFO - Main loop iteration: 3455
2025-04-25 12:57:11,637 - transformer_training - INFO - Main loop iteration: 3456
2025-04-25 12:57:12,037 - transformer_training - INFO - Main loop iteration: 3457
2025-04-25 12:57:12,499 - transformer_training - INFO - Main loop iteration: 3458
2025-04-25 12:57:12,949 - transformer_training - INFO - Main loop iteration: 3459
2025-04-25 12:57:13,447 - transformer_training - INFO - Main loop iteration: 3460
Iter 3460: loss 3.8662, lr 0.000996, 92049.92 tokens/sec
2025-04-25 12:57:13,848 - transformer_training - INFO - Main loop iteration: 3461
2025-04-25 12:57:14,309 - transformer_training - INFO - Main loop iteration: 3462
2025-04-25 12:57:14,759 - transformer_training - INFO - Main loop iteration: 3463
2025-04-25 12:57:15,259 - transformer_training - INFO - Main loop iteration: 3464
2025-04-25 12:57:15,660 - transformer_training - INFO - Main loop iteration: 3465
2025-04-25 12:57:16,121 - transformer_training - INFO - Main loop iteration: 3466
2025-04-25 12:57:16,571 - transformer_training - INFO - Main loop iteration: 3467
2025-04-25 12:57:17,070 - transformer_training - INFO - Main loop iteration: 3468
2025-04-25 12:57:17,471 - transformer_training - INFO - Main loop iteration: 3469
2025-04-25 12:57:17,932 - transformer_training - INFO - Main loop iteration: 3470
Iter 3470: loss 3.8374, lr 0.000996, 81857.63 tokens/sec
2025-04-25 12:57:18,383 - transformer_training - INFO - Main loop iteration: 3471
2025-04-25 12:57:18,883 - transformer_training - INFO - Main loop iteration: 3472
2025-04-25 12:57:19,284 - transformer_training - INFO - Main loop iteration: 3473
2025-04-25 12:57:19,744 - transformer_training - INFO - Main loop iteration: 3474
2025-04-25 12:57:20,195 - transformer_training - INFO - Main loop iteration: 3475
2025-04-25 12:57:20,694 - transformer_training - INFO - Main loop iteration: 3476
2025-04-25 12:57:21,095 - transformer_training - INFO - Main loop iteration: 3477
2025-04-25 12:57:21,556 - transformer_training - INFO - Main loop iteration: 3478
2025-04-25 12:57:22,007 - transformer_training - INFO - Main loop iteration: 3479
2025-04-25 12:57:22,506 - transformer_training - INFO - Main loop iteration: 3480
Iter 3480: loss 3.9292, lr 0.000996, 91965.38 tokens/sec
2025-04-25 12:57:22,907 - transformer_training - INFO - Main loop iteration: 3481
2025-04-25 12:57:23,368 - transformer_training - INFO - Main loop iteration: 3482
2025-04-25 12:57:23,818 - transformer_training - INFO - Main loop iteration: 3483
2025-04-25 12:57:24,317 - transformer_training - INFO - Main loop iteration: 3484
2025-04-25 12:57:24,718 - transformer_training - INFO - Main loop iteration: 3485
2025-04-25 12:57:25,179 - transformer_training - INFO - Main loop iteration: 3486
2025-04-25 12:57:25,629 - transformer_training - INFO - Main loop iteration: 3487
2025-04-25 12:57:26,128 - transformer_training - INFO - Main loop iteration: 3488
2025-04-25 12:57:26,528 - transformer_training - INFO - Main loop iteration: 3489
2025-04-25 12:57:26,989 - transformer_training - INFO - Main loop iteration: 3490
Iter 3490: loss 3.8635, lr 0.000996, 81964.55 tokens/sec
2025-04-25 12:57:27,439 - transformer_training - INFO - Main loop iteration: 3491
2025-04-25 12:57:27,938 - transformer_training - INFO - Main loop iteration: 3492
2025-04-25 12:57:28,339 - transformer_training - INFO - Main loop iteration: 3493
2025-04-25 12:57:28,800 - transformer_training - INFO - Main loop iteration: 3494
2025-04-25 12:57:29,251 - transformer_training - INFO - Main loop iteration: 3495
2025-04-25 12:57:29,750 - transformer_training - INFO - Main loop iteration: 3496
2025-04-25 12:57:30,150 - transformer_training - INFO - Main loop iteration: 3497
2025-04-25 12:57:30,611 - transformer_training - INFO - Main loop iteration: 3498
2025-04-25 12:57:31,062 - transformer_training - INFO - Main loop iteration: 3499
2025-04-25 12:57:31,560 - transformer_training - INFO - Main loop iteration: 3500
Iter 3500: loss 3.9175, lr 0.000996, 91952.37 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!Flash Attention is available!

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 3500: train loss 3.7048, val loss 3.7323
New best model saved with val loss: 3.7323
2025-04-25 12:57:51,879 - transformer_training - INFO - Main loop iteration: 3501
2025-04-25 12:57:52,351 - transformer_training - INFO - Main loop iteration: 3502
2025-04-25 12:57:52,763 - transformer_training - INFO - Main loop iteration: 3503
2025-04-25 12:57:53,262 - transformer_training - INFO - Main loop iteration: 3504
2025-04-25 12:57:53,663 - transformer_training - INFO - Main loop iteration: 3505
2025-04-25 12:57:54,124 - transformer_training - INFO - Main loop iteration: 3506
2025-04-25 12:57:54,573 - transformer_training - INFO - Main loop iteration: 3507
2025-04-25 12:57:55,072 - transformer_training - INFO - Main loop iteration: 3508
2025-04-25 12:57:55,473 - transformer_training - INFO - Main loop iteration: 3509
2025-04-25 12:57:55,934 - transformer_training - INFO - Main loop iteration: 3510
Iter 3510: loss 3.9334, lr 0.000996, 81925.94 tokens/sec
2025-04-25 12:57:56,385 - transformer_training - INFO - Main loop iteration: 3511
2025-04-25 12:57:56,884 - transformer_training - INFO - Main loop iteration: 3512
2025-04-25 12:57:57,284 - transformer_training - INFO - Main loop iteration: 3513
2025-04-25 12:57:57,745 - transformer_training - INFO - Main loop iteration: 3514
2025-04-25 12:57:58,195 - transformer_training - INFO - Main loop iteration: 3515
2025-04-25 12:57:58,694 - transformer_training - INFO - Main loop iteration: 3516
2025-04-25 12:57:59,095 - transformer_training - INFO - Main loop iteration: 3517
2025-04-25 12:57:59,555 - transformer_training - INFO - Main loop iteration: 3518
2025-04-25 12:58:00,006 - transformer_training - INFO - Main loop iteration: 3519
2025-04-25 12:58:00,505 - transformer_training - INFO - Main loop iteration: 3520
Iter 3520: loss 3.8586, lr 0.000996, 92049.20 tokens/sec
2025-04-25 12:58:00,905 - transformer_training - INFO - Main loop iteration: 3521
2025-04-25 12:58:01,366 - transformer_training - INFO - Main loop iteration: 3522
2025-04-25 12:58:01,816 - transformer_training - INFO - Main loop iteration: 3523
2025-04-25 12:58:02,316 - transformer_training - INFO - Main loop iteration: 3524
2025-04-25 12:58:02,716 - transformer_training - INFO - Main loop iteration: 3525
2025-04-25 12:58:03,177 - transformer_training - INFO - Main loop iteration: 3526
2025-04-25 12:58:03,627 - transformer_training - INFO - Main loop iteration: 3527
2025-04-25 12:58:04,126 - transformer_training - INFO - Main loop iteration: 3528
2025-04-25 12:58:04,527 - transformer_training - INFO - Main loop iteration: 3529
2025-04-25 12:58:04,988 - transformer_training - INFO - Main loop iteration: 3530
Iter 3530: loss 3.8931, lr 0.000996, 81978.37 tokens/sec
2025-04-25 12:58:05,438 - transformer_training - INFO - Main loop iteration: 3531
2025-04-25 12:58:05,937 - transformer_training - INFO - Main loop iteration: 3532
2025-04-25 12:58:06,338 - transformer_training - INFO - Main loop iteration: 3533
2025-04-25 12:58:06,799 - transformer_training - INFO - Main loop iteration: 3534
2025-04-25 12:58:07,250 - transformer_training - INFO - Main loop iteration: 3535
2025-04-25 12:58:07,749 - transformer_training - INFO - Main loop iteration: 3536
2025-04-25 12:58:08,149 - transformer_training - INFO - Main loop iteration: 3537
2025-04-25 12:58:08,610 - transformer_training - INFO - Main loop iteration: 3538
2025-04-25 12:58:09,061 - transformer_training - INFO - Main loop iteration: 3539
2025-04-25 12:58:09,560 - transformer_training - INFO - Main loop iteration: 3540
Iter 3540: loss 3.9274, lr 0.000996, 92091.04 tokens/sec
2025-04-25 12:58:09,961 - transformer_training - INFO - Main loop iteration: 3541
2025-04-25 12:58:10,421 - transformer_training - INFO - Main loop iteration: 3542
2025-04-25 12:58:10,872 - transformer_training - INFO - Main loop iteration: 3543
2025-04-25 12:58:11,371 - transformer_training - INFO - Main loop iteration: 3544
2025-04-25 12:58:11,772 - transformer_training - INFO - Main loop iteration: 3545
2025-04-25 12:58:12,233 - transformer_training - INFO - Main loop iteration: 3546
2025-04-25 12:58:12,683 - transformer_training - INFO - Main loop iteration: 3547
2025-04-25 12:58:13,182 - transformer_training - INFO - Main loop iteration: 3548
2025-04-25 12:58:13,583 - transformer_training - INFO - Main loop iteration: 3549
2025-04-25 12:58:14,044 - transformer_training - INFO - Main loop iteration: 3550
Iter 3550: loss 3.8812, lr 0.000996, 81927.07 tokens/sec
2025-04-25 12:58:14,494 - transformer_training - INFO - Main loop iteration: 3551
2025-04-25 12:58:14,993 - transformer_training - INFO - Main loop iteration: 3552
2025-04-25 12:58:15,394 - transformer_training - INFO - Main loop iteration: 3553
2025-04-25 12:58:15,855 - transformer_training - INFO - Main loop iteration: 3554
2025-04-25 12:58:16,305 - transformer_training - INFO - Main loop iteration: 3555
2025-04-25 12:58:16,805 - transformer_training - INFO - Main loop iteration: 3556
2025-04-25 12:58:17,206 - transformer_training - INFO - Main loop iteration: 3557
2025-04-25 12:58:17,667 - transformer_training - INFO - Main loop iteration: 3558
2025-04-25 12:58:18,117 - transformer_training - INFO - Main loop iteration: 3559
2025-04-25 12:58:18,617 - transformer_training - INFO - Main loop iteration: 3560
Iter 3560: loss 3.9557, lr 0.000996, 91899.57 tokens/sec
2025-04-25 12:58:19,019 - transformer_training - INFO - Main loop iteration: 3561
2025-04-25 12:58:19,480 - transformer_training - INFO - Main loop iteration: 3562
2025-04-25 12:58:19,930 - transformer_training - INFO - Main loop iteration: 3563
2025-04-25 12:58:20,430 - transformer_training - INFO - Main loop iteration: 3564
2025-04-25 12:58:20,831 - transformer_training - INFO - Main loop iteration: 3565
2025-04-25 12:58:21,293 - transformer_training - INFO - Main loop iteration: 3566
2025-04-25 12:58:21,743 - transformer_training - INFO - Main loop iteration: 3567
2025-04-25 12:58:22,244 - transformer_training - INFO - Main loop iteration: 3568
2025-04-25 12:58:22,646 - transformer_training - INFO - Main loop iteration: 3569
2025-04-25 12:58:23,107 - transformer_training - INFO - Main loop iteration: 3570
Iter 3570: loss 3.8621, lr 0.000996, 81989.97 tokens/sec
2025-04-25 12:58:23,558 - transformer_training - INFO - Main loop iteration: 3571
2025-04-25 12:58:24,057 - transformer_training - INFO - Main loop iteration: 3572
2025-04-25 12:58:24,458 - transformer_training - INFO - Main loop iteration: 3573
2025-04-25 12:58:24,919 - transformer_training - INFO - Main loop iteration: 3574
2025-04-25 12:58:25,370 - transformer_training - INFO - Main loop iteration: 3575
2025-04-25 12:58:25,870 - transformer_training - INFO - Main loop iteration: 3576
2025-04-25 12:58:26,271 - transformer_training - INFO - Main loop iteration: 3577
2025-04-25 12:58:26,732 - transformer_training - INFO - Main loop iteration: 3578
2025-04-25 12:58:27,183 - transformer_training - INFO - Main loop iteration: 3579
2025-04-25 12:58:27,683 - transformer_training - INFO - Main loop iteration: 3580
Iter 3580: loss 3.9263, lr 0.000996, 91859.44 tokens/sec
2025-04-25 12:58:28,084 - transformer_training - INFO - Main loop iteration: 3581
2025-04-25 12:58:28,545 - transformer_training - INFO - Main loop iteration: 3582
2025-04-25 12:58:28,996 - transformer_training - INFO - Main loop iteration: 3583
2025-04-25 12:58:29,496 - transformer_training - INFO - Main loop iteration: 3584
2025-04-25 12:58:29,897 - transformer_training - INFO - Main loop iteration: 3585
2025-04-25 12:58:30,358 - transformer_training - INFO - Main loop iteration: 3586
2025-04-25 12:58:30,809 - transformer_training - INFO - Main loop iteration: 3587
2025-04-25 12:58:31,309 - transformer_training - INFO - Main loop iteration: 3588
2025-04-25 12:58:31,710 - transformer_training - INFO - Main loop iteration: 3589
2025-04-25 12:58:32,172 - transformer_training - INFO - Main loop iteration: 3590
Iter 3590: loss 3.8446, lr 0.000996, 82005.32 tokens/sec
2025-04-25 12:58:32,623 - transformer_training - INFO - Main loop iteration: 3591
2025-04-25 12:58:33,122 - transformer_training - INFO - Main loop iteration: 3592
2025-04-25 12:58:33,523 - transformer_training - INFO - Main loop iteration: 3593
2025-04-25 12:58:33,985 - transformer_training - INFO - Main loop iteration: 3594
2025-04-25 12:58:34,436 - transformer_training - INFO - Main loop iteration: 3595
2025-04-25 12:58:34,936 - transformer_training - INFO - Main loop iteration: 3596
2025-04-25 12:58:35,337 - transformer_training - INFO - Main loop iteration: 3597
2025-04-25 12:58:35,798 - transformer_training - INFO - Main loop iteration: 3598
2025-04-25 12:58:36,249 - transformer_training - INFO - Main loop iteration: 3599
2025-04-25 12:58:36,748 - transformer_training - INFO - Main loop iteration: 3600
Iter 3600: loss 3.9193, lr 0.000996, 91961.72 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 3600: train loss 3.6935, val loss 3.7033
New best model saved with val loss: 3.7033
2025-04-25 12:58:54,704 - transformer_training - INFO - Main loop iteration: 3601
2025-04-25 12:58:55,119 - transformer_training - INFO - Main loop iteration: 3602
2025-04-25 12:58:55,570 - transformer_training - INFO - Main loop iteration: 3603
2025-04-25 12:58:56,069 - transformer_training - INFO - Main loop iteration: 3604
2025-04-25 12:58:56,469 - transformer_training - INFO - Main loop iteration: 3605
2025-04-25 12:58:56,930 - transformer_training - INFO - Main loop iteration: 3606
2025-04-25 12:58:57,381 - transformer_training - INFO - Main loop iteration: 3607
2025-04-25 12:58:57,880 - transformer_training - INFO - Main loop iteration: 3608
2025-04-25 12:58:58,281 - transformer_training - INFO - Main loop iteration: 3609
2025-04-25 12:58:58,742 - transformer_training - INFO - Main loop iteration: 3610
Iter 3610: loss 3.7826, lr 0.000996, 81948.17 tokens/sec
2025-04-25 12:58:59,193 - transformer_training - INFO - Main loop iteration: 3611
2025-04-25 12:58:59,694 - transformer_training - INFO - Main loop iteration: 3612
2025-04-25 12:59:00,094 - transformer_training - INFO - Main loop iteration: 3613
2025-04-25 12:59:00,555 - transformer_training - INFO - Main loop iteration: 3614
2025-04-25 12:59:01,005 - transformer_training - INFO - Main loop iteration: 3615
2025-04-25 12:59:01,505 - transformer_training - INFO - Main loop iteration: 3616
2025-04-25 12:59:01,906 - transformer_training - INFO - Main loop iteration: 3617
2025-04-25 12:59:02,367 - transformer_training - INFO - Main loop iteration: 3618
2025-04-25 12:59:02,817 - transformer_training - INFO - Main loop iteration: 3619
2025-04-25 12:59:03,316 - transformer_training - INFO - Main loop iteration: 3620
Iter 3620: loss 3.7180, lr 0.000996, 91968.88 tokens/sec
2025-04-25 12:59:03,717 - transformer_training - INFO - Main loop iteration: 3621
2025-04-25 12:59:04,178 - transformer_training - INFO - Main loop iteration: 3622
2025-04-25 12:59:04,628 - transformer_training - INFO - Main loop iteration: 3623
2025-04-25 12:59:05,127 - transformer_training - INFO - Main loop iteration: 3624
2025-04-25 12:59:05,528 - transformer_training - INFO - Main loop iteration: 3625
2025-04-25 12:59:05,989 - transformer_training - INFO - Main loop iteration: 3626
2025-04-25 12:59:06,439 - transformer_training - INFO - Main loop iteration: 3627
2025-04-25 12:59:06,939 - transformer_training - INFO - Main loop iteration: 3628
2025-04-25 12:59:07,339 - transformer_training - INFO - Main loop iteration: 3629
2025-04-25 12:59:07,800 - transformer_training - INFO - Main loop iteration: 3630
Iter 3630: loss 3.8144, lr 0.000996, 81997.80 tokens/sec
2025-04-25 12:59:08,251 - transformer_training - INFO - Main loop iteration: 3631
2025-04-25 12:59:08,751 - transformer_training - INFO - Main loop iteration: 3632
2025-04-25 12:59:09,151 - transformer_training - INFO - Main loop iteration: 3633
2025-04-25 12:59:09,613 - transformer_training - INFO - Main loop iteration: 3634
2025-04-25 12:59:10,064 - transformer_training - INFO - Main loop iteration: 3635
2025-04-25 12:59:10,563 - transformer_training - INFO - Main loop iteration: 3636
2025-04-25 12:59:10,964 - transformer_training - INFO - Main loop iteration: 3637
2025-04-25 12:59:11,426 - transformer_training - INFO - Main loop iteration: 3638
2025-04-25 12:59:11,876 - transformer_training - INFO - Main loop iteration: 3639
2025-04-25 12:59:12,376 - transformer_training - INFO - Main loop iteration: 3640
Iter 3640: loss 3.9337, lr 0.000995, 92071.24 tokens/sec
2025-04-25 12:59:12,777 - transformer_training - INFO - Main loop iteration: 3641
2025-04-25 12:59:13,237 - transformer_training - INFO - Main loop iteration: 3642
2025-04-25 12:59:13,688 - transformer_training - INFO - Main loop iteration: 3643
2025-04-25 12:59:14,188 - transformer_training - INFO - Main loop iteration: 3644
2025-04-25 12:59:14,589 - transformer_training - INFO - Main loop iteration: 3645
2025-04-25 12:59:15,050 - transformer_training - INFO - Main loop iteration: 3646
2025-04-25 12:59:15,501 - transformer_training - INFO - Main loop iteration: 3647
2025-04-25 12:59:16,001 - transformer_training - INFO - Main loop iteration: 3648
2025-04-25 12:59:16,401 - transformer_training - INFO - Main loop iteration: 3649
2025-04-25 12:59:16,863 - transformer_training - INFO - Main loop iteration: 3650
Iter 3650: loss 3.9310, lr 0.000995, 82086.26 tokens/sec
2025-04-25 12:59:17,313 - transformer_training - INFO - Main loop iteration: 3651
2025-04-25 12:59:17,812 - transformer_training - INFO - Main loop iteration: 3652
2025-04-25 12:59:18,213 - transformer_training - INFO - Main loop iteration: 3653
2025-04-25 12:59:18,675 - transformer_training - INFO - Main loop iteration: 3654
2025-04-25 12:59:19,125 - transformer_training - INFO - Main loop iteration: 3655
2025-04-25 12:59:19,624 - transformer_training - INFO - Main loop iteration: 3656
2025-04-25 12:59:20,025 - transformer_training - INFO - Main loop iteration: 3657
2025-04-25 12:59:20,485 - transformer_training - INFO - Main loop iteration: 3658
2025-04-25 12:59:20,936 - transformer_training - INFO - Main loop iteration: 3659
2025-04-25 12:59:21,435 - transformer_training - INFO - Main loop iteration: 3660
Iter 3660: loss 3.9335, lr 0.000995, 92053.97 tokens/sec
2025-04-25 12:59:21,836 - transformer_training - INFO - Main loop iteration: 3661
2025-04-25 12:59:22,297 - transformer_training - INFO - Main loop iteration: 3662
2025-04-25 12:59:22,748 - transformer_training - INFO - Main loop iteration: 3663
2025-04-25 12:59:23,248 - transformer_training - INFO - Main loop iteration: 3664
2025-04-25 12:59:23,648 - transformer_training - INFO - Main loop iteration: 3665
2025-04-25 12:59:24,109 - transformer_training - INFO - Main loop iteration: 3666
2025-04-25 12:59:24,560 - transformer_training - INFO - Main loop iteration: 3667
2025-04-25 12:59:25,060 - transformer_training - INFO - Main loop iteration: 3668
2025-04-25 12:59:25,461 - transformer_training - INFO - Main loop iteration: 3669
2025-04-25 12:59:25,922 - transformer_training - INFO - Main loop iteration: 3670
Iter 3670: loss 3.8045, lr 0.000995, 82111.76 tokens/sec
2025-04-25 12:59:26,372 - transformer_training - INFO - Main loop iteration: 3671
2025-04-25 12:59:26,873 - transformer_training - INFO - Main loop iteration: 3672
2025-04-25 12:59:27,274 - transformer_training - INFO - Main loop iteration: 3673
2025-04-25 12:59:27,735 - transformer_training - INFO - Main loop iteration: 3674
2025-04-25 12:59:28,185 - transformer_training - INFO - Main loop iteration: 3675
2025-04-25 12:59:28,773 - transformer_training - INFO - Main loop iteration: 3676
2025-04-25 12:59:29,174 - transformer_training - INFO - Main loop iteration: 3677
2025-04-25 12:59:29,635 - transformer_training - INFO - Main loop iteration: 3678
2025-04-25 12:59:30,087 - transformer_training - INFO - Main loop iteration: 3679
2025-04-25 12:59:30,585 - transformer_training - INFO - Main loop iteration: 3680
Iter 3680: loss 3.8753, lr 0.000995, 92034.03 tokens/sec
2025-04-25 12:59:30,986 - transformer_training - INFO - Main loop iteration: 3681
2025-04-25 12:59:31,447 - transformer_training - INFO - Main loop iteration: 3682
2025-04-25 12:59:31,898 - transformer_training - INFO - Main loop iteration: 3683
2025-04-25 12:59:32,397 - transformer_training - INFO - Main loop iteration: 3684
2025-04-25 12:59:32,798 - transformer_training - INFO - Main loop iteration: 3685
2025-04-25 12:59:33,259 - transformer_training - INFO - Main loop iteration: 3686
2025-04-25 12:59:33,710 - transformer_training - INFO - Main loop iteration: 3687
2025-04-25 12:59:34,208 - transformer_training - INFO - Main loop iteration: 3688
2025-04-25 12:59:34,610 - transformer_training - INFO - Main loop iteration: 3689
2025-04-25 12:59:35,070 - transformer_training - INFO - Main loop iteration: 3690
Iter 3690: loss 3.8405, lr 0.000995, 81916.04 tokens/sec
2025-04-25 12:59:35,521 - transformer_training - INFO - Main loop iteration: 3691
2025-04-25 12:59:36,020 - transformer_training - INFO - Main loop iteration: 3692
2025-04-25 12:59:36,422 - transformer_training - INFO - Main loop iteration: 3693
2025-04-25 12:59:36,883 - transformer_training - INFO - Main loop iteration: 3694
2025-04-25 12:59:37,333 - transformer_training - INFO - Main loop iteration: 3695
2025-04-25 12:59:37,833 - transformer_training - INFO - Main loop iteration: 3696
2025-04-25 12:59:38,233 - transformer_training - INFO - Main loop iteration: 3697
2025-04-25 12:59:38,695 - transformer_training - INFO - Main loop iteration: 3698
2025-04-25 12:59:39,145 - transformer_training - INFO - Main loop iteration: 3699
2025-04-25 12:59:39,644 - transformer_training - INFO - Main loop iteration: 3700
Iter 3700: loss 3.7333, lr 0.000995, 91717.88 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 3700: train loss 3.6907, val loss 3.6886
New best model saved with val loss: 3.6886
2025-04-25 12:59:57,059 - transformer_training - INFO - Main loop iteration: 3701
2025-04-25 12:59:57,472 - transformer_training - INFO - Main loop iteration: 3702
2025-04-25 12:59:57,923 - transformer_training - INFO - Main loop iteration: 3703
2025-04-25 12:59:58,421 - transformer_training - INFO - Main loop iteration: 3704
2025-04-25 12:59:58,821 - transformer_training - INFO - Main loop iteration: 3705
2025-04-25 12:59:59,282 - transformer_training - INFO - Main loop iteration: 3706
2025-04-25 12:59:59,732 - transformer_training - INFO - Main loop iteration: 3707
2025-04-25 13:00:00,231 - transformer_training - INFO - Main loop iteration: 3708
2025-04-25 13:00:00,632 - transformer_training - INFO - Main loop iteration: 3709
2025-04-25 13:00:01,093 - transformer_training - INFO - Main loop iteration: 3710
Iter 3710: loss 3.8225, lr 0.000995, 82007.24 tokens/sec
2025-04-25 13:00:01,543 - transformer_training - INFO - Main loop iteration: 3711
2025-04-25 13:00:02,044 - transformer_training - INFO - Main loop iteration: 3712
2025-04-25 13:00:02,445 - transformer_training - INFO - Main loop iteration: 3713
2025-04-25 13:00:02,907 - transformer_training - INFO - Main loop iteration: 3714
2025-04-25 13:00:03,361 - transformer_training - INFO - Main loop iteration: 3715
2025-04-25 13:00:03,861 - transformer_training - INFO - Main loop iteration: 3716
2025-04-25 13:00:04,262 - transformer_training - INFO - Main loop iteration: 3717
2025-04-25 13:00:04,723 - transformer_training - INFO - Main loop iteration: 3718
2025-04-25 13:00:05,174 - transformer_training - INFO - Main loop iteration: 3719
2025-04-25 13:00:05,673 - transformer_training - INFO - Main loop iteration: 3720
Iter 3720: loss 3.7989, lr 0.000995, 91817.71 tokens/sec
2025-04-25 13:00:06,075 - transformer_training - INFO - Main loop iteration: 3721
2025-04-25 13:00:06,536 - transformer_training - INFO - Main loop iteration: 3722
2025-04-25 13:00:06,986 - transformer_training - INFO - Main loop iteration: 3723
2025-04-25 13:00:07,485 - transformer_training - INFO - Main loop iteration: 3724
2025-04-25 13:00:07,887 - transformer_training - INFO - Main loop iteration: 3725
2025-04-25 13:00:08,348 - transformer_training - INFO - Main loop iteration: 3726
2025-04-25 13:00:08,798 - transformer_training - INFO - Main loop iteration: 3727
2025-04-25 13:00:09,297 - transformer_training - INFO - Main loop iteration: 3728
2025-04-25 13:00:09,698 - transformer_training - INFO - Main loop iteration: 3729
2025-04-25 13:00:10,160 - transformer_training - INFO - Main loop iteration: 3730
Iter 3730: loss 3.8455, lr 0.000995, 81871.02 tokens/sec
2025-04-25 13:00:10,611 - transformer_training - INFO - Main loop iteration: 3731
2025-04-25 13:00:11,109 - transformer_training - INFO - Main loop iteration: 3732
2025-04-25 13:00:11,510 - transformer_training - INFO - Main loop iteration: 3733
2025-04-25 13:00:11,971 - transformer_training - INFO - Main loop iteration: 3734
2025-04-25 13:00:12,421 - transformer_training - INFO - Main loop iteration: 3735
2025-04-25 13:00:12,920 - transformer_training - INFO - Main loop iteration: 3736
2025-04-25 13:00:13,322 - transformer_training - INFO - Main loop iteration: 3737
2025-04-25 13:00:13,783 - transformer_training - INFO - Main loop iteration: 3738
2025-04-25 13:00:14,234 - transformer_training - INFO - Main loop iteration: 3739
2025-04-25 13:00:14,732 - transformer_training - INFO - Main loop iteration: 3740
Iter 3740: loss 3.8472, lr 0.000995, 91867.08 tokens/sec
2025-04-25 13:00:15,134 - transformer_training - INFO - Main loop iteration: 3741
2025-04-25 13:00:15,594 - transformer_training - INFO - Main loop iteration: 3742
2025-04-25 13:00:16,044 - transformer_training - INFO - Main loop iteration: 3743
2025-04-25 13:00:16,543 - transformer_training - INFO - Main loop iteration: 3744
2025-04-25 13:00:16,945 - transformer_training - INFO - Main loop iteration: 3745
2025-04-25 13:00:17,406 - transformer_training - INFO - Main loop iteration: 3746
2025-04-25 13:00:17,857 - transformer_training - INFO - Main loop iteration: 3747
2025-04-25 13:00:18,356 - transformer_training - INFO - Main loop iteration: 3748
2025-04-25 13:00:18,758 - transformer_training - INFO - Main loop iteration: 3749
2025-04-25 13:00:19,219 - transformer_training - INFO - Main loop iteration: 3750
Iter 3750: loss 3.8218, lr 0.000995, 81906.97 tokens/sec
2025-04-25 13:00:19,669 - transformer_training - INFO - Main loop iteration: 3751
2025-04-25 13:00:20,168 - transformer_training - INFO - Main loop iteration: 3752
2025-04-25 13:00:20,570 - transformer_training - INFO - Main loop iteration: 3753
2025-04-25 13:00:21,031 - transformer_training - INFO - Main loop iteration: 3754
2025-04-25 13:00:21,481 - transformer_training - INFO - Main loop iteration: 3755
2025-04-25 13:00:21,980 - transformer_training - INFO - Main loop iteration: 3756
2025-04-25 13:00:22,382 - transformer_training - INFO - Main loop iteration: 3757
2025-04-25 13:00:22,843 - transformer_training - INFO - Main loop iteration: 3758
2025-04-25 13:00:23,293 - transformer_training - INFO - Main loop iteration: 3759
2025-04-25 13:00:23,792 - transformer_training - INFO - Main loop iteration: 3760
Iter 3760: loss 3.8526, lr 0.000995, 91911.48 tokens/sec
2025-04-25 13:00:24,194 - transformer_training - INFO - Main loop iteration: 3761
2025-04-25 13:00:24,655 - transformer_training - INFO - Main loop iteration: 3762
2025-04-25 13:00:25,105 - transformer_training - INFO - Main loop iteration: 3763
2025-04-25 13:00:25,604 - transformer_training - INFO - Main loop iteration: 3764
2025-04-25 13:00:26,006 - transformer_training - INFO - Main loop iteration: 3765
2025-04-25 13:00:26,467 - transformer_training - INFO - Main loop iteration: 3766
2025-04-25 13:00:26,917 - transformer_training - INFO - Main loop iteration: 3767
2025-04-25 13:00:27,415 - transformer_training - INFO - Main loop iteration: 3768
2025-04-25 13:00:27,817 - transformer_training - INFO - Main loop iteration: 3769
2025-04-25 13:00:28,278 - transformer_training - INFO - Main loop iteration: 3770
Iter 3770: loss 3.9123, lr 0.000995, 81797.56 tokens/sec
2025-04-25 13:00:28,729 - transformer_training - INFO - Main loop iteration: 3771
2025-04-25 13:00:29,228 - transformer_training - INFO - Main loop iteration: 3772
2025-04-25 13:00:29,630 - transformer_training - INFO - Main loop iteration: 3773
2025-04-25 13:00:30,091 - transformer_training - INFO - Main loop iteration: 3774
2025-04-25 13:00:30,542 - transformer_training - INFO - Main loop iteration: 3775
2025-04-25 13:00:31,041 - transformer_training - INFO - Main loop iteration: 3776
2025-04-25 13:00:31,442 - transformer_training - INFO - Main loop iteration: 3777
2025-04-25 13:00:31,904 - transformer_training - INFO - Main loop iteration: 3778
2025-04-25 13:00:32,355 - transformer_training - INFO - Main loop iteration: 3779
2025-04-25 13:00:32,854 - transformer_training - INFO - Main loop iteration: 3780
Iter 3780: loss 3.8844, lr 0.000995, 91801.58 tokens/sec
2025-04-25 13:00:33,256 - transformer_training - INFO - Main loop iteration: 3781
2025-04-25 13:00:33,717 - transformer_training - INFO - Main loop iteration: 3782
2025-04-25 13:00:34,168 - transformer_training - INFO - Main loop iteration: 3783
2025-04-25 13:00:34,667 - transformer_training - INFO - Main loop iteration: 3784
2025-04-25 13:00:35,069 - transformer_training - INFO - Main loop iteration: 3785
2025-04-25 13:00:35,530 - transformer_training - INFO - Main loop iteration: 3786
2025-04-25 13:00:35,981 - transformer_training - INFO - Main loop iteration: 3787
2025-04-25 13:00:36,479 - transformer_training - INFO - Main loop iteration: 3788
2025-04-25 13:00:36,881 - transformer_training - INFO - Main loop iteration: 3789
2025-04-25 13:00:37,342 - transformer_training - INFO - Main loop iteration: 3790
Iter 3790: loss 3.8328, lr 0.000995, 81769.88 tokens/sec
2025-04-25 13:00:37,793 - transformer_training - INFO - Main loop iteration: 3791
2025-04-25 13:00:38,292 - transformer_training - INFO - Main loop iteration: 3792
2025-04-25 13:00:38,693 - transformer_training - INFO - Main loop iteration: 3793
2025-04-25 13:00:39,154 - transformer_training - INFO - Main loop iteration: 3794
2025-04-25 13:00:39,605 - transformer_training - INFO - Main loop iteration: 3795
2025-04-25 13:00:40,104 - transformer_training - INFO - Main loop iteration: 3796
2025-04-25 13:00:40,505 - transformer_training - INFO - Main loop iteration: 3797
2025-04-25 13:00:40,967 - transformer_training - INFO - Main loop iteration: 3798
2025-04-25 13:00:41,418 - transformer_training - INFO - Main loop iteration: 3799
2025-04-25 13:00:41,918 - transformer_training - INFO - Main loop iteration: 3800
Iter 3800: loss 3.7767, lr 0.000994, 91931.21 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 3800: train loss 3.6812, val loss 3.6664
New best model saved with val loss: 3.6664
2025-04-25 13:01:00,721 - transformer_training - INFO - Main loop iteration: 3801
2025-04-25 13:01:01,129 - transformer_training - INFO - Main loop iteration: 3802
2025-04-25 13:01:01,579 - transformer_training - INFO - Main loop iteration: 3803
2025-04-25 13:01:02,079 - transformer_training - INFO - Main loop iteration: 3804
2025-04-25 13:01:02,479 - transformer_training - INFO - Main loop iteration: 3805
2025-04-25 13:01:02,939 - transformer_training - INFO - Main loop iteration: 3806
2025-04-25 13:01:03,389 - transformer_training - INFO - Main loop iteration: 3807
2025-04-25 13:01:03,887 - transformer_training - INFO - Main loop iteration: 3808
2025-04-25 13:01:04,288 - transformer_training - INFO - Main loop iteration: 3809
2025-04-25 13:01:04,748 - transformer_training - INFO - Main loop iteration: 3810
Iter 3810: loss 3.8688, lr 0.000994, 82031.60 tokens/sec
2025-04-25 13:01:05,198 - transformer_training - INFO - Main loop iteration: 3811
2025-04-25 13:01:05,696 - transformer_training - INFO - Main loop iteration: 3812
2025-04-25 13:01:06,097 - transformer_training - INFO - Main loop iteration: 3813
2025-04-25 13:01:06,560 - transformer_training - INFO - Main loop iteration: 3814
2025-04-25 13:01:07,011 - transformer_training - INFO - Main loop iteration: 3815
2025-04-25 13:01:07,509 - transformer_training - INFO - Main loop iteration: 3816
2025-04-25 13:01:07,911 - transformer_training - INFO - Main loop iteration: 3817
2025-04-25 13:01:08,372 - transformer_training - INFO - Main loop iteration: 3818
2025-04-25 13:01:08,822 - transformer_training - INFO - Main loop iteration: 3819
2025-04-25 13:01:09,320 - transformer_training - INFO - Main loop iteration: 3820
Iter 3820: loss 3.7843, lr 0.000994, 92117.54 tokens/sec
2025-04-25 13:01:09,721 - transformer_training - INFO - Main loop iteration: 3821
2025-04-25 13:01:10,182 - transformer_training - INFO - Main loop iteration: 3822
2025-04-25 13:01:10,632 - transformer_training - INFO - Main loop iteration: 3823
2025-04-25 13:01:11,130 - transformer_training - INFO - Main loop iteration: 3824
2025-04-25 13:01:11,531 - transformer_training - INFO - Main loop iteration: 3825
2025-04-25 13:01:11,992 - transformer_training - INFO - Main loop iteration: 3826
2025-04-25 13:01:12,442 - transformer_training - INFO - Main loop iteration: 3827
2025-04-25 13:01:12,941 - transformer_training - INFO - Main loop iteration: 3828
2025-04-25 13:01:13,341 - transformer_training - INFO - Main loop iteration: 3829
2025-04-25 13:01:13,802 - transformer_training - INFO - Main loop iteration: 3830
Iter 3830: loss 3.7778, lr 0.000994, 81974.58 tokens/sec
2025-04-25 13:01:14,252 - transformer_training - INFO - Main loop iteration: 3831
2025-04-25 13:01:14,751 - transformer_training - INFO - Main loop iteration: 3832
2025-04-25 13:01:15,151 - transformer_training - INFO - Main loop iteration: 3833
2025-04-25 13:01:15,612 - transformer_training - INFO - Main loop iteration: 3834
2025-04-25 13:01:16,063 - transformer_training - INFO - Main loop iteration: 3835
2025-04-25 13:01:16,561 - transformer_training - INFO - Main loop iteration: 3836
2025-04-25 13:01:16,962 - transformer_training - INFO - Main loop iteration: 3837
2025-04-25 13:01:17,422 - transformer_training - INFO - Main loop iteration: 3838
2025-04-25 13:01:17,872 - transformer_training - INFO - Main loop iteration: 3839
2025-04-25 13:01:18,372 - transformer_training - INFO - Main loop iteration: 3840
Iter 3840: loss 3.8119, lr 0.000994, 92049.92 tokens/sec
2025-04-25 13:01:18,773 - transformer_training - INFO - Main loop iteration: 3841
2025-04-25 13:01:19,234 - transformer_training - INFO - Main loop iteration: 3842
2025-04-25 13:01:19,683 - transformer_training - INFO - Main loop iteration: 3843
2025-04-25 13:01:20,182 - transformer_training - INFO - Main loop iteration: 3844
2025-04-25 13:01:20,583 - transformer_training - INFO - Main loop iteration: 3845
2025-04-25 13:01:21,044 - transformer_training - INFO - Main loop iteration: 3846
2025-04-25 13:01:21,495 - transformer_training - INFO - Main loop iteration: 3847
2025-04-25 13:01:21,995 - transformer_training - INFO - Main loop iteration: 3848
2025-04-25 13:01:22,394 - transformer_training - INFO - Main loop iteration: 3849
2025-04-25 13:01:22,855 - transformer_training - INFO - Main loop iteration: 3850
Iter 3850: loss 3.8281, lr 0.000994, 82023.25 tokens/sec
2025-04-25 13:01:23,306 - transformer_training - INFO - Main loop iteration: 3851
2025-04-25 13:01:23,804 - transformer_training - INFO - Main loop iteration: 3852
2025-04-25 13:01:24,205 - transformer_training - INFO - Main loop iteration: 3853
2025-04-25 13:01:24,665 - transformer_training - INFO - Main loop iteration: 3854
2025-04-25 13:01:25,115 - transformer_training - INFO - Main loop iteration: 3855
2025-04-25 13:01:25,614 - transformer_training - INFO - Main loop iteration: 3856
2025-04-25 13:01:26,015 - transformer_training - INFO - Main loop iteration: 3857
2025-04-25 13:01:26,475 - transformer_training - INFO - Main loop iteration: 3858
2025-04-25 13:01:26,926 - transformer_training - INFO - Main loop iteration: 3859
2025-04-25 13:01:27,424 - transformer_training - INFO - Main loop iteration: 3860
Iter 3860: loss 3.8990, lr 0.000994, 92044.22 tokens/sec
2025-04-25 13:01:27,825 - transformer_training - INFO - Main loop iteration: 3861
2025-04-25 13:01:28,286 - transformer_training - INFO - Main loop iteration: 3862
2025-04-25 13:01:28,737 - transformer_training - INFO - Main loop iteration: 3863
2025-04-25 13:01:29,236 - transformer_training - INFO - Main loop iteration: 3864
2025-04-25 13:01:29,637 - transformer_training - INFO - Main loop iteration: 3865
2025-04-25 13:01:30,097 - transformer_training - INFO - Main loop iteration: 3866
2025-04-25 13:01:30,547 - transformer_training - INFO - Main loop iteration: 3867
2025-04-25 13:01:31,046 - transformer_training - INFO - Main loop iteration: 3868
2025-04-25 13:01:31,447 - transformer_training - INFO - Main loop iteration: 3869
2025-04-25 13:01:31,907 - transformer_training - INFO - Main loop iteration: 3870
Iter 3870: loss 3.8369, lr 0.000994, 81902.42 tokens/sec
2025-04-25 13:01:32,358 - transformer_training - INFO - Main loop iteration: 3871
2025-04-25 13:01:32,857 - transformer_training - INFO - Main loop iteration: 3872
2025-04-25 13:01:33,258 - transformer_training - INFO - Main loop iteration: 3873
2025-04-25 13:01:33,719 - transformer_training - INFO - Main loop iteration: 3874
2025-04-25 13:01:34,170 - transformer_training - INFO - Main loop iteration: 3875
2025-04-25 13:01:34,668 - transformer_training - INFO - Main loop iteration: 3876
2025-04-25 13:01:35,069 - transformer_training - INFO - Main loop iteration: 3877
2025-04-25 13:01:35,530 - transformer_training - INFO - Main loop iteration: 3878
2025-04-25 13:01:35,980 - transformer_training - INFO - Main loop iteration: 3879
2025-04-25 13:01:36,479 - transformer_training - INFO - Main loop iteration: 3880
Iter 3880: loss 3.7768, lr 0.000994, 92037.42 tokens/sec
2025-04-25 13:01:36,880 - transformer_training - INFO - Main loop iteration: 3881
2025-04-25 13:01:37,341 - transformer_training - INFO - Main loop iteration: 3882
2025-04-25 13:01:37,791 - transformer_training - INFO - Main loop iteration: 3883
2025-04-25 13:01:38,290 - transformer_training - INFO - Main loop iteration: 3884
2025-04-25 13:01:38,691 - transformer_training - INFO - Main loop iteration: 3885
2025-04-25 13:01:39,152 - transformer_training - INFO - Main loop iteration: 3886
2025-04-25 13:01:39,602 - transformer_training - INFO - Main loop iteration: 3887
2025-04-25 13:01:40,102 - transformer_training - INFO - Main loop iteration: 3888
2025-04-25 13:01:40,503 - transformer_training - INFO - Main loop iteration: 3889
2025-04-25 13:01:40,964 - transformer_training - INFO - Main loop iteration: 3890
Iter 3890: loss 3.7544, lr 0.000994, 81913.39 tokens/sec
2025-04-25 13:01:41,415 - transformer_training - INFO - Main loop iteration: 3891
2025-04-25 13:01:41,914 - transformer_training - INFO - Main loop iteration: 3892
2025-04-25 13:01:42,315 - transformer_training - INFO - Main loop iteration: 3893
2025-04-25 13:01:42,776 - transformer_training - INFO - Main loop iteration: 3894
2025-04-25 13:01:43,226 - transformer_training - INFO - Main loop iteration: 3895
2025-04-25 13:01:43,725 - transformer_training - INFO - Main loop iteration: 3896
2025-04-25 13:01:44,126 - transformer_training - INFO - Main loop iteration: 3897
2025-04-25 13:01:44,587 - transformer_training - INFO - Main loop iteration: 3898
2025-04-25 13:01:45,037 - transformer_training - INFO - Main loop iteration: 3899
2025-04-25 13:01:45,536 - transformer_training - INFO - Main loop iteration: 3900
Iter 3900: loss 3.7385, lr 0.000994, 92109.96 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 3900: train loss 3.6738, val loss 3.6668
2025-04-25 13:02:01,423 - transformer_training - INFO - Main loop iteration: 3901
2025-04-25 13:02:01,833 - transformer_training - INFO - Main loop iteration: 3902
2025-04-25 13:02:02,284 - transformer_training - INFO - Main loop iteration: 3903
2025-04-25 13:02:02,782 - transformer_training - INFO - Main loop iteration: 3904
2025-04-25 13:02:03,183 - transformer_training - INFO - Main loop iteration: 3905
2025-04-25 13:02:03,643 - transformer_training - INFO - Main loop iteration: 3906
2025-04-25 13:02:04,093 - transformer_training - INFO - Main loop iteration: 3907
2025-04-25 13:02:04,592 - transformer_training - INFO - Main loop iteration: 3908
2025-04-25 13:02:04,993 - transformer_training - INFO - Main loop iteration: 3909
2025-04-25 13:02:05,454 - transformer_training - INFO - Main loop iteration: 3910
Iter 3910: loss 3.7967, lr 0.000994, 81920.86 tokens/sec
2025-04-25 13:02:05,904 - transformer_training - INFO - Main loop iteration: 3911
2025-04-25 13:02:06,403 - transformer_training - INFO - Main loop iteration: 3912
2025-04-25 13:02:06,805 - transformer_training - INFO - Main loop iteration: 3913
2025-04-25 13:02:07,266 - transformer_training - INFO - Main loop iteration: 3914
2025-04-25 13:02:07,716 - transformer_training - INFO - Main loop iteration: 3915
2025-04-25 13:02:08,214 - transformer_training - INFO - Main loop iteration: 3916
2025-04-25 13:02:08,615 - transformer_training - INFO - Main loop iteration: 3917
2025-04-25 13:02:09,077 - transformer_training - INFO - Main loop iteration: 3918
2025-04-25 13:02:09,527 - transformer_training - INFO - Main loop iteration: 3919
2025-04-25 13:02:10,025 - transformer_training - INFO - Main loop iteration: 3920
Iter 3920: loss 3.8523, lr 0.000994, 91713.74 tokens/sec
2025-04-25 13:02:10,427 - transformer_training - INFO - Main loop iteration: 3921
2025-04-25 13:02:10,888 - transformer_training - INFO - Main loop iteration: 3922
2025-04-25 13:02:11,339 - transformer_training - INFO - Main loop iteration: 3923
2025-04-25 13:02:11,838 - transformer_training - INFO - Main loop iteration: 3924
2025-04-25 13:02:12,239 - transformer_training - INFO - Main loop iteration: 3925
2025-04-25 13:02:12,700 - transformer_training - INFO - Main loop iteration: 3926
2025-04-25 13:02:13,151 - transformer_training - INFO - Main loop iteration: 3927
2025-04-25 13:02:13,650 - transformer_training - INFO - Main loop iteration: 3928
2025-04-25 13:02:14,050 - transformer_training - INFO - Main loop iteration: 3929
2025-04-25 13:02:14,511 - transformer_training - INFO - Main loop iteration: 3930
Iter 3930: loss 3.7087, lr 0.000994, 81830.33 tokens/sec
2025-04-25 13:02:14,963 - transformer_training - INFO - Main loop iteration: 3931
2025-04-25 13:02:15,461 - transformer_training - INFO - Main loop iteration: 3932
2025-04-25 13:02:15,862 - transformer_training - INFO - Main loop iteration: 3933
2025-04-25 13:02:16,323 - transformer_training - INFO - Main loop iteration: 3934
2025-04-25 13:02:16,774 - transformer_training - INFO - Main loop iteration: 3935
2025-04-25 13:02:17,274 - transformer_training - INFO - Main loop iteration: 3936
2025-04-25 13:02:17,674 - transformer_training - INFO - Main loop iteration: 3937
2025-04-25 13:02:18,136 - transformer_training - INFO - Main loop iteration: 3938
2025-04-25 13:02:18,586 - transformer_training - INFO - Main loop iteration: 3939
2025-04-25 13:02:19,086 - transformer_training - INFO - Main loop iteration: 3940
Iter 3940: loss 3.8207, lr 0.000994, 92033.15 tokens/sec
2025-04-25 13:02:19,487 - transformer_training - INFO - Main loop iteration: 3941
2025-04-25 13:02:19,948 - transformer_training - INFO - Main loop iteration: 3942
2025-04-25 13:02:20,400 - transformer_training - INFO - Main loop iteration: 3943
2025-04-25 13:02:20,899 - transformer_training - INFO - Main loop iteration: 3944
2025-04-25 13:02:21,299 - transformer_training - INFO - Main loop iteration: 3945
2025-04-25 13:02:21,761 - transformer_training - INFO - Main loop iteration: 3946
2025-04-25 13:02:22,212 - transformer_training - INFO - Main loop iteration: 3947
2025-04-25 13:02:22,712 - transformer_training - INFO - Main loop iteration: 3948
2025-04-25 13:02:23,112 - transformer_training - INFO - Main loop iteration: 3949
2025-04-25 13:02:23,573 - transformer_training - INFO - Main loop iteration: 3950
Iter 3950: loss 3.7595, lr 0.000994, 81988.41 tokens/sec
2025-04-25 13:02:24,024 - transformer_training - INFO - Main loop iteration: 3951
2025-04-25 13:02:24,523 - transformer_training - INFO - Main loop iteration: 3952
2025-04-25 13:02:24,924 - transformer_training - INFO - Main loop iteration: 3953
2025-04-25 13:02:25,385 - transformer_training - INFO - Main loop iteration: 3954
2025-04-25 13:02:25,835 - transformer_training - INFO - Main loop iteration: 3955
2025-04-25 13:02:26,335 - transformer_training - INFO - Main loop iteration: 3956
2025-04-25 13:02:26,736 - transformer_training - INFO - Main loop iteration: 3957
2025-04-25 13:02:27,197 - transformer_training - INFO - Main loop iteration: 3958
2025-04-25 13:02:27,648 - transformer_training - INFO - Main loop iteration: 3959
2025-04-25 13:02:28,147 - transformer_training - INFO - Main loop iteration: 3960
Iter 3960: loss 3.8043, lr 0.000993, 91854.26 tokens/sec
2025-04-25 13:02:28,549 - transformer_training - INFO - Main loop iteration: 3961
2025-04-25 13:02:29,011 - transformer_training - INFO - Main loop iteration: 3962
2025-04-25 13:02:29,461 - transformer_training - INFO - Main loop iteration: 3963
2025-04-25 13:02:29,961 - transformer_training - INFO - Main loop iteration: 3964
2025-04-25 13:02:30,362 - transformer_training - INFO - Main loop iteration: 3965
2025-04-25 13:02:30,823 - transformer_training - INFO - Main loop iteration: 3966
2025-04-25 13:02:31,273 - transformer_training - INFO - Main loop iteration: 3967
2025-04-25 13:02:31,773 - transformer_training - INFO - Main loop iteration: 3968
2025-04-25 13:02:32,174 - transformer_training - INFO - Main loop iteration: 3969
2025-04-25 13:02:32,635 - transformer_training - INFO - Main loop iteration: 3970
Iter 3970: loss 3.7903, lr 0.000993, 82000.32 tokens/sec
2025-04-25 13:02:33,086 - transformer_training - INFO - Main loop iteration: 3971
2025-04-25 13:02:33,585 - transformer_training - INFO - Main loop iteration: 3972
2025-04-25 13:02:33,985 - transformer_training - INFO - Main loop iteration: 3973
2025-04-25 13:02:34,446 - transformer_training - INFO - Main loop iteration: 3974
2025-04-25 13:02:34,898 - transformer_training - INFO - Main loop iteration: 3975
2025-04-25 13:02:35,396 - transformer_training - INFO - Main loop iteration: 3976
2025-04-25 13:02:35,797 - transformer_training - INFO - Main loop iteration: 3977
2025-04-25 13:02:36,258 - transformer_training - INFO - Main loop iteration: 3978
2025-04-25 13:02:36,709 - transformer_training - INFO - Main loop iteration: 3979
2025-04-25 13:02:37,208 - transformer_training - INFO - Main loop iteration: 3980
Iter 3980: loss 3.7228, lr 0.000993, 92073.38 tokens/sec
2025-04-25 13:02:37,608 - transformer_training - INFO - Main loop iteration: 3981
2025-04-25 13:02:38,070 - transformer_training - INFO - Main loop iteration: 3982
2025-04-25 13:02:38,521 - transformer_training - INFO - Main loop iteration: 3983
2025-04-25 13:02:39,020 - transformer_training - INFO - Main loop iteration: 3984
2025-04-25 13:02:39,421 - transformer_training - INFO - Main loop iteration: 3985
2025-04-25 13:02:39,883 - transformer_training - INFO - Main loop iteration: 3986
2025-04-25 13:02:40,334 - transformer_training - INFO - Main loop iteration: 3987
2025-04-25 13:02:40,833 - transformer_training - INFO - Main loop iteration: 3988
2025-04-25 13:02:41,234 - transformer_training - INFO - Main loop iteration: 3989
2025-04-25 13:02:41,695 - transformer_training - INFO - Main loop iteration: 3990
Iter 3990: loss 3.7421, lr 0.000993, 81898.69 tokens/sec
2025-04-25 13:02:42,147 - transformer_training - INFO - Main loop iteration: 3991
2025-04-25 13:02:42,646 - transformer_training - INFO - Main loop iteration: 3992
2025-04-25 13:02:43,047 - transformer_training - INFO - Main loop iteration: 3993
2025-04-25 13:02:43,509 - transformer_training - INFO - Main loop iteration: 3994
2025-04-25 13:02:43,960 - transformer_training - INFO - Main loop iteration: 3995
2025-04-25 13:02:44,460 - transformer_training - INFO - Main loop iteration: 3996
2025-04-25 13:02:44,860 - transformer_training - INFO - Main loop iteration: 3997
2025-04-25 13:02:45,322 - transformer_training - INFO - Main loop iteration: 3998
2025-04-25 13:02:45,773 - transformer_training - INFO - Main loop iteration: 3999
2025-04-25 13:02:46,272 - transformer_training - INFO - Main loop iteration: 4000
Iter 4000: loss 3.8093, lr 0.000993, 91993.45 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 4000: train loss 3.6731, val loss 3.6401
New best model saved with val loss: 3.6401
2025-04-25 13:03:06,560 - transformer_training - INFO - Main loop iteration: 4001
2025-04-25 13:03:06,975 - transformer_training - INFO - Main loop iteration: 4002
2025-04-25 13:03:07,425 - transformer_training - INFO - Main loop iteration: 4003
2025-04-25 13:03:07,923 - transformer_training - INFO - Main loop iteration: 4004
2025-04-25 13:03:08,324 - transformer_training - INFO - Main loop iteration: 4005
2025-04-25 13:03:08,785 - transformer_training - INFO - Main loop iteration: 4006
2025-04-25 13:03:09,235 - transformer_training - INFO - Main loop iteration: 4007
2025-04-25 13:03:09,734 - transformer_training - INFO - Main loop iteration: 4008
2025-04-25 13:03:10,134 - transformer_training - INFO - Main loop iteration: 4009
2025-04-25 13:03:10,595 - transformer_training - INFO - Main loop iteration: 4010
Iter 4010: loss 3.8303, lr 0.000993, 81887.63 tokens/sec
2025-04-25 13:03:11,046 - transformer_training - INFO - Main loop iteration: 4011
2025-04-25 13:03:11,545 - transformer_training - INFO - Main loop iteration: 4012
2025-04-25 13:03:11,946 - transformer_training - INFO - Main loop iteration: 4013
2025-04-25 13:03:12,408 - transformer_training - INFO - Main loop iteration: 4014
2025-04-25 13:03:12,858 - transformer_training - INFO - Main loop iteration: 4015
2025-04-25 13:03:13,356 - transformer_training - INFO - Main loop iteration: 4016
2025-04-25 13:03:13,757 - transformer_training - INFO - Main loop iteration: 4017
2025-04-25 13:03:14,217 - transformer_training - INFO - Main loop iteration: 4018
2025-04-25 13:03:14,668 - transformer_training - INFO - Main loop iteration: 4019
2025-04-25 13:03:15,166 - transformer_training - INFO - Main loop iteration: 4020
Iter 4020: loss 3.7069, lr 0.000993, 91796.78 tokens/sec
2025-04-25 13:03:15,568 - transformer_training - INFO - Main loop iteration: 4021
2025-04-25 13:03:16,029 - transformer_training - INFO - Main loop iteration: 4022
2025-04-25 13:03:16,480 - transformer_training - INFO - Main loop iteration: 4023
2025-04-25 13:03:16,979 - transformer_training - INFO - Main loop iteration: 4024
2025-04-25 13:03:17,380 - transformer_training - INFO - Main loop iteration: 4025
2025-04-25 13:03:17,841 - transformer_training - INFO - Main loop iteration: 4026
2025-04-25 13:03:18,292 - transformer_training - INFO - Main loop iteration: 4027
2025-04-25 13:03:18,791 - transformer_training - INFO - Main loop iteration: 4028
2025-04-25 13:03:19,192 - transformer_training - INFO - Main loop iteration: 4029
2025-04-25 13:03:19,653 - transformer_training - INFO - Main loop iteration: 4030
Iter 4030: loss 3.6689, lr 0.000993, 81925.63 tokens/sec
2025-04-25 13:03:20,104 - transformer_training - INFO - Main loop iteration: 4031
2025-04-25 13:03:20,602 - transformer_training - INFO - Main loop iteration: 4032
2025-04-25 13:03:21,004 - transformer_training - INFO - Main loop iteration: 4033
2025-04-25 13:03:21,465 - transformer_training - INFO - Main loop iteration: 4034
2025-04-25 13:03:21,916 - transformer_training - INFO - Main loop iteration: 4035
2025-04-25 13:03:22,415 - transformer_training - INFO - Main loop iteration: 4036
2025-04-25 13:03:22,817 - transformer_training - INFO - Main loop iteration: 4037
2025-04-25 13:03:23,278 - transformer_training - INFO - Main loop iteration: 4038
2025-04-25 13:03:23,729 - transformer_training - INFO - Main loop iteration: 4039
2025-04-25 13:03:24,227 - transformer_training - INFO - Main loop iteration: 4040
Iter 4040: loss 3.7830, lr 0.000993, 91827.36 tokens/sec
2025-04-25 13:03:24,629 - transformer_training - INFO - Main loop iteration: 4041
2025-04-25 13:03:25,090 - transformer_training - INFO - Main loop iteration: 4042
2025-04-25 13:03:25,541 - transformer_training - INFO - Main loop iteration: 4043
2025-04-25 13:03:26,039 - transformer_training - INFO - Main loop iteration: 4044
2025-04-25 13:03:26,441 - transformer_training - INFO - Main loop iteration: 4045
2025-04-25 13:03:26,902 - transformer_training - INFO - Main loop iteration: 4046
2025-04-25 13:03:27,353 - transformer_training - INFO - Main loop iteration: 4047
2025-04-25 13:03:27,851 - transformer_training - INFO - Main loop iteration: 4048
2025-04-25 13:03:28,253 - transformer_training - INFO - Main loop iteration: 4049
2025-04-25 13:03:28,715 - transformer_training - INFO - Main loop iteration: 4050
Iter 4050: loss 3.6963, lr 0.000993, 81842.37 tokens/sec
2025-04-25 13:03:29,166 - transformer_training - INFO - Main loop iteration: 4051
2025-04-25 13:03:29,664 - transformer_training - INFO - Main loop iteration: 4052
2025-04-25 13:03:30,066 - transformer_training - INFO - Main loop iteration: 4053
2025-04-25 13:03:30,527 - transformer_training - INFO - Main loop iteration: 4054
2025-04-25 13:03:30,978 - transformer_training - INFO - Main loop iteration: 4055
2025-04-25 13:03:31,571 - transformer_training - INFO - Main loop iteration: 4056
2025-04-25 13:03:31,972 - transformer_training - INFO - Main loop iteration: 4057
2025-04-25 13:03:32,434 - transformer_training - INFO - Main loop iteration: 4058
2025-04-25 13:03:32,885 - transformer_training - INFO - Main loop iteration: 4059
2025-04-25 13:03:33,384 - transformer_training - INFO - Main loop iteration: 4060
Iter 4060: loss 3.7914, lr 0.000993, 91845.20 tokens/sec
2025-04-25 13:03:33,785 - transformer_training - INFO - Main loop iteration: 4061
2025-04-25 13:03:34,246 - transformer_training - INFO - Main loop iteration: 4062
2025-04-25 13:03:34,697 - transformer_training - INFO - Main loop iteration: 4063
2025-04-25 13:03:35,196 - transformer_training - INFO - Main loop iteration: 4064
2025-04-25 13:03:35,597 - transformer_training - INFO - Main loop iteration: 4065
2025-04-25 13:03:36,058 - transformer_training - INFO - Main loop iteration: 4066
2025-04-25 13:03:36,508 - transformer_training - INFO - Main loop iteration: 4067
2025-04-25 13:03:37,007 - transformer_training - INFO - Main loop iteration: 4068
2025-04-25 13:03:37,408 - transformer_training - INFO - Main loop iteration: 4069
2025-04-25 13:03:37,869 - transformer_training - INFO - Main loop iteration: 4070
Iter 4070: loss 3.7696, lr 0.000993, 81960.98 tokens/sec
2025-04-25 13:03:38,320 - transformer_training - INFO - Main loop iteration: 4071
2025-04-25 13:03:38,819 - transformer_training - INFO - Main loop iteration: 4072
2025-04-25 13:03:39,220 - transformer_training - INFO - Main loop iteration: 4073
2025-04-25 13:03:39,682 - transformer_training - INFO - Main loop iteration: 4074
2025-04-25 13:03:40,133 - transformer_training - INFO - Main loop iteration: 4075
2025-04-25 13:03:40,631 - transformer_training - INFO - Main loop iteration: 4076
2025-04-25 13:03:41,033 - transformer_training - INFO - Main loop iteration: 4077
2025-04-25 13:03:41,494 - transformer_training - INFO - Main loop iteration: 4078
2025-04-25 13:03:41,944 - transformer_training - INFO - Main loop iteration: 4079
2025-04-25 13:03:42,445 - transformer_training - INFO - Main loop iteration: 4080
Iter 4080: loss 3.8026, lr 0.000993, 91817.71 tokens/sec
2025-04-25 13:03:42,847 - transformer_training - INFO - Main loop iteration: 4081
2025-04-25 13:03:43,308 - transformer_training - INFO - Main loop iteration: 4082
2025-04-25 13:03:43,759 - transformer_training - INFO - Main loop iteration: 4083
2025-04-25 13:03:44,259 - transformer_training - INFO - Main loop iteration: 4084
2025-04-25 13:03:44,660 - transformer_training - INFO - Main loop iteration: 4085
2025-04-25 13:03:45,122 - transformer_training - INFO - Main loop iteration: 4086
2025-04-25 13:03:45,573 - transformer_training - INFO - Main loop iteration: 4087
2025-04-25 13:03:46,072 - transformer_training - INFO - Main loop iteration: 4088
2025-04-25 13:03:46,474 - transformer_training - INFO - Main loop iteration: 4089
2025-04-25 13:03:46,936 - transformer_training - INFO - Main loop iteration: 4090
Iter 4090: loss 3.7437, lr 0.000993, 81848.61 tokens/sec
2025-04-25 13:03:47,386 - transformer_training - INFO - Main loop iteration: 4091
2025-04-25 13:03:47,886 - transformer_training - INFO - Main loop iteration: 4092
2025-04-25 13:03:48,288 - transformer_training - INFO - Main loop iteration: 4093
2025-04-25 13:03:48,751 - transformer_training - INFO - Main loop iteration: 4094
2025-04-25 13:03:49,201 - transformer_training - INFO - Main loop iteration: 4095
2025-04-25 13:03:49,700 - transformer_training - INFO - Main loop iteration: 4096
2025-04-25 13:03:50,102 - transformer_training - INFO - Main loop iteration: 4097
2025-04-25 13:03:50,566 - transformer_training - INFO - Main loop iteration: 4098
2025-04-25 13:03:51,017 - transformer_training - INFO - Main loop iteration: 4099
2025-04-25 13:03:51,516 - transformer_training - INFO - Main loop iteration: 4100
Iter 4100: loss 3.7794, lr 0.000993, 91772.26 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 4100: train loss 3.6689, val loss 3.6225
New best model saved with val loss: 3.6225
2025-04-25 13:04:10,036 - transformer_training - INFO - Main loop iteration: 4101
2025-04-25 13:04:10,451 - transformer_training - INFO - Main loop iteration: 4102
2025-04-25 13:04:10,900 - transformer_training - INFO - Main loop iteration: 4103
2025-04-25 13:04:11,399 - transformer_training - INFO - Main loop iteration: 4104
2025-04-25 13:04:11,801 - transformer_training - INFO - Main loop iteration: 4105
2025-04-25 13:04:12,262 - transformer_training - INFO - Main loop iteration: 4106
2025-04-25 13:04:12,712 - transformer_training - INFO - Main loop iteration: 4107
2025-04-25 13:04:13,211 - transformer_training - INFO - Main loop iteration: 4108
2025-04-25 13:04:13,612 - transformer_training - INFO - Main loop iteration: 4109
2025-04-25 13:04:14,072 - transformer_training - INFO - Main loop iteration: 4110
Iter 4110: loss 3.7133, lr 0.000992, 81916.30 tokens/sec
2025-04-25 13:04:14,523 - transformer_training - INFO - Main loop iteration: 4111
2025-04-25 13:04:15,021 - transformer_training - INFO - Main loop iteration: 4112
2025-04-25 13:04:15,422 - transformer_training - INFO - Main loop iteration: 4113
2025-04-25 13:04:15,883 - transformer_training - INFO - Main loop iteration: 4114
2025-04-25 13:04:16,333 - transformer_training - INFO - Main loop iteration: 4115
2025-04-25 13:04:16,833 - transformer_training - INFO - Main loop iteration: 4116
2025-04-25 13:04:17,234 - transformer_training - INFO - Main loop iteration: 4117
2025-04-25 13:04:17,694 - transformer_training - INFO - Main loop iteration: 4118
2025-04-25 13:04:18,145 - transformer_training - INFO - Main loop iteration: 4119
2025-04-25 13:04:18,643 - transformer_training - INFO - Main loop iteration: 4120
Iter 4120: loss 3.7713, lr 0.000992, 92016.17 tokens/sec
2025-04-25 13:04:19,044 - transformer_training - INFO - Main loop iteration: 4121
2025-04-25 13:04:19,505 - transformer_training - INFO - Main loop iteration: 4122
2025-04-25 13:04:19,955 - transformer_training - INFO - Main loop iteration: 4123
2025-04-25 13:04:20,454 - transformer_training - INFO - Main loop iteration: 4124
2025-04-25 13:04:20,855 - transformer_training - INFO - Main loop iteration: 4125
2025-04-25 13:04:21,316 - transformer_training - INFO - Main loop iteration: 4126
2025-04-25 13:04:21,766 - transformer_training - INFO - Main loop iteration: 4127
2025-04-25 13:04:22,265 - transformer_training - INFO - Main loop iteration: 4128
2025-04-25 13:04:22,666 - transformer_training - INFO - Main loop iteration: 4129
2025-04-25 13:04:23,127 - transformer_training - INFO - Main loop iteration: 4130
Iter 4130: loss 3.7553, lr 0.000992, 81961.90 tokens/sec
2025-04-25 13:04:23,578 - transformer_training - INFO - Main loop iteration: 4131
2025-04-25 13:04:24,076 - transformer_training - INFO - Main loop iteration: 4132
2025-04-25 13:04:24,477 - transformer_training - INFO - Main loop iteration: 4133
2025-04-25 13:04:24,938 - transformer_training - INFO - Main loop iteration: 4134
2025-04-25 13:04:25,388 - transformer_training - INFO - Main loop iteration: 4135
2025-04-25 13:04:25,887 - transformer_training - INFO - Main loop iteration: 4136
2025-04-25 13:04:26,288 - transformer_training - INFO - Main loop iteration: 4137
2025-04-25 13:04:26,749 - transformer_training - INFO - Main loop iteration: 4138
2025-04-25 13:04:27,200 - transformer_training - INFO - Main loop iteration: 4139
2025-04-25 13:04:27,699 - transformer_training - INFO - Main loop iteration: 4140
Iter 4140: loss 3.8338, lr 0.000992, 92019.40 tokens/sec
2025-04-25 13:04:28,100 - transformer_training - INFO - Main loop iteration: 4141
2025-04-25 13:04:28,561 - transformer_training - INFO - Main loop iteration: 4142
2025-04-25 13:04:29,015 - transformer_training - INFO - Main loop iteration: 4143
2025-04-25 13:04:29,514 - transformer_training - INFO - Main loop iteration: 4144
2025-04-25 13:04:29,915 - transformer_training - INFO - Main loop iteration: 4145
2025-04-25 13:04:30,376 - transformer_training - INFO - Main loop iteration: 4146
2025-04-25 13:04:30,827 - transformer_training - INFO - Main loop iteration: 4147
2025-04-25 13:04:31,326 - transformer_training - INFO - Main loop iteration: 4148
2025-04-25 13:04:31,727 - transformer_training - INFO - Main loop iteration: 4149
2025-04-25 13:04:32,188 - transformer_training - INFO - Main loop iteration: 4150
Iter 4150: loss 3.8011, lr 0.000992, 81723.50 tokens/sec
2025-04-25 13:04:32,640 - transformer_training - INFO - Main loop iteration: 4151
2025-04-25 13:04:33,139 - transformer_training - INFO - Main loop iteration: 4152
2025-04-25 13:04:33,540 - transformer_training - INFO - Main loop iteration: 4153
2025-04-25 13:04:34,001 - transformer_training - INFO - Main loop iteration: 4154
2025-04-25 13:04:34,451 - transformer_training - INFO - Main loop iteration: 4155
2025-04-25 13:04:34,951 - transformer_training - INFO - Main loop iteration: 4156
2025-04-25 13:04:35,351 - transformer_training - INFO - Main loop iteration: 4157
2025-04-25 13:04:35,812 - transformer_training - INFO - Main loop iteration: 4158
2025-04-25 13:04:36,263 - transformer_training - INFO - Main loop iteration: 4159
2025-04-25 13:04:36,762 - transformer_training - INFO - Main loop iteration: 4160
Iter 4160: loss 3.7459, lr 0.000992, 91973.21 tokens/sec
2025-04-25 13:04:37,163 - transformer_training - INFO - Main loop iteration: 4161
2025-04-25 13:04:37,624 - transformer_training - INFO - Main loop iteration: 4162
2025-04-25 13:04:38,074 - transformer_training - INFO - Main loop iteration: 4163
2025-04-25 13:04:38,573 - transformer_training - INFO - Main loop iteration: 4164
2025-04-25 13:04:38,974 - transformer_training - INFO - Main loop iteration: 4165
2025-04-25 13:04:39,435 - transformer_training - INFO - Main loop iteration: 4166
2025-04-25 13:04:39,886 - transformer_training - INFO - Main loop iteration: 4167
2025-04-25 13:04:40,384 - transformer_training - INFO - Main loop iteration: 4168
2025-04-25 13:04:40,785 - transformer_training - INFO - Main loop iteration: 4169
2025-04-25 13:04:41,247 - transformer_training - INFO - Main loop iteration: 4170
Iter 4170: loss 3.8748, lr 0.000992, 81873.23 tokens/sec
2025-04-25 13:04:41,697 - transformer_training - INFO - Main loop iteration: 4171
2025-04-25 13:04:42,197 - transformer_training - INFO - Main loop iteration: 4172
2025-04-25 13:04:42,598 - transformer_training - INFO - Main loop iteration: 4173
2025-04-25 13:04:43,059 - transformer_training - INFO - Main loop iteration: 4174
2025-04-25 13:04:43,510 - transformer_training - INFO - Main loop iteration: 4175
2025-04-25 13:04:44,010 - transformer_training - INFO - Main loop iteration: 4176
2025-04-25 13:04:44,411 - transformer_training - INFO - Main loop iteration: 4177
2025-04-25 13:04:44,872 - transformer_training - INFO - Main loop iteration: 4178
2025-04-25 13:04:45,322 - transformer_training - INFO - Main loop iteration: 4179
2025-04-25 13:04:45,822 - transformer_training - INFO - Main loop iteration: 4180
Iter 4180: loss 3.7164, lr 0.000992, 92032.71 tokens/sec
2025-04-25 13:04:46,223 - transformer_training - INFO - Main loop iteration: 4181
2025-04-25 13:04:46,684 - transformer_training - INFO - Main loop iteration: 4182
2025-04-25 13:04:47,134 - transformer_training - INFO - Main loop iteration: 4183
2025-04-25 13:04:47,634 - transformer_training - INFO - Main loop iteration: 4184
2025-04-25 13:04:48,035 - transformer_training - INFO - Main loop iteration: 4185
2025-04-25 13:04:48,497 - transformer_training - INFO - Main loop iteration: 4186
2025-04-25 13:04:48,947 - transformer_training - INFO - Main loop iteration: 4187
2025-04-25 13:04:49,446 - transformer_training - INFO - Main loop iteration: 4188
2025-04-25 13:04:49,847 - transformer_training - INFO - Main loop iteration: 4189
2025-04-25 13:04:50,308 - transformer_training - INFO - Main loop iteration: 4190
Iter 4190: loss 3.8772, lr 0.000992, 81793.23 tokens/sec
2025-04-25 13:04:50,759 - transformer_training - INFO - Main loop iteration: 4191
2025-04-25 13:04:51,259 - transformer_training - INFO - Main loop iteration: 4192
2025-04-25 13:04:51,660 - transformer_training - INFO - Main loop iteration: 4193
2025-04-25 13:04:52,121 - transformer_training - INFO - Main loop iteration: 4194
2025-04-25 13:04:52,572 - transformer_training - INFO - Main loop iteration: 4195
2025-04-25 13:04:53,071 - transformer_training - INFO - Main loop iteration: 4196
2025-04-25 13:04:53,472 - transformer_training - INFO - Main loop iteration: 4197
2025-04-25 13:04:53,934 - transformer_training - INFO - Main loop iteration: 4198
2025-04-25 13:04:54,384 - transformer_training - INFO - Main loop iteration: 4199
2025-04-25 13:04:54,884 - transformer_training - INFO - Main loop iteration: 4200
Iter 4200: loss 3.6949, lr 0.000992, 91957.23 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 4200: train loss 3.6590, val loss 3.6126
New best model saved with val loss: 3.6126
2025-04-25 13:05:13,255 - transformer_training - INFO - Main loop iteration: 4201
2025-04-25 13:05:13,673 - transformer_training - INFO - Main loop iteration: 4202
2025-04-25 13:05:14,124 - transformer_training - INFO - Main loop iteration: 4203
2025-04-25 13:05:14,623 - transformer_training - INFO - Main loop iteration: 4204
2025-04-25 13:05:15,023 - transformer_training - INFO - Main loop iteration: 4205
2025-04-25 13:05:15,484 - transformer_training - INFO - Main loop iteration: 4206
2025-04-25 13:05:15,934 - transformer_training - INFO - Main loop iteration: 4207
2025-04-25 13:05:16,432 - transformer_training - INFO - Main loop iteration: 4208
2025-04-25 13:05:16,833 - transformer_training - INFO - Main loop iteration: 4209
2025-04-25 13:05:17,295 - transformer_training - INFO - Main loop iteration: 4210
Iter 4210: loss 3.8572, lr 0.000992, 82090.05 tokens/sec
2025-04-25 13:05:17,745 - transformer_training - INFO - Main loop iteration: 4211
2025-04-25 13:05:18,244 - transformer_training - INFO - Main loop iteration: 4212
2025-04-25 13:05:18,645 - transformer_training - INFO - Main loop iteration: 4213
2025-04-25 13:05:19,106 - transformer_training - INFO - Main loop iteration: 4214
2025-04-25 13:05:19,556 - transformer_training - INFO - Main loop iteration: 4215
2025-04-25 13:05:20,056 - transformer_training - INFO - Main loop iteration: 4216
2025-04-25 13:05:20,456 - transformer_training - INFO - Main loop iteration: 4217
2025-04-25 13:05:20,918 - transformer_training - INFO - Main loop iteration: 4218
2025-04-25 13:05:21,368 - transformer_training - INFO - Main loop iteration: 4219
2025-04-25 13:05:21,867 - transformer_training - INFO - Main loop iteration: 4220
Iter 4220: loss 3.8152, lr 0.000992, 91991.59 tokens/sec
2025-04-25 13:05:22,268 - transformer_training - INFO - Main loop iteration: 4221
2025-04-25 13:05:22,729 - transformer_training - INFO - Main loop iteration: 4222
2025-04-25 13:05:23,180 - transformer_training - INFO - Main loop iteration: 4223
2025-04-25 13:05:23,679 - transformer_training - INFO - Main loop iteration: 4224
2025-04-25 13:05:24,081 - transformer_training - INFO - Main loop iteration: 4225
2025-04-25 13:05:24,542 - transformer_training - INFO - Main loop iteration: 4226
2025-04-25 13:05:24,993 - transformer_training - INFO - Main loop iteration: 4227
2025-04-25 13:05:25,493 - transformer_training - INFO - Main loop iteration: 4228
2025-04-25 13:05:25,893 - transformer_training - INFO - Main loop iteration: 4229
2025-04-25 13:05:26,354 - transformer_training - INFO - Main loop iteration: 4230
Iter 4230: loss 3.8706, lr 0.000992, 81977.41 tokens/sec
2025-04-25 13:05:26,805 - transformer_training - INFO - Main loop iteration: 4231
2025-04-25 13:05:27,304 - transformer_training - INFO - Main loop iteration: 4232
2025-04-25 13:05:27,705 - transformer_training - INFO - Main loop iteration: 4233
2025-04-25 13:05:28,166 - transformer_training - INFO - Main loop iteration: 4234
2025-04-25 13:05:28,617 - transformer_training - INFO - Main loop iteration: 4235
2025-04-25 13:05:29,117 - transformer_training - INFO - Main loop iteration: 4236
2025-04-25 13:05:29,517 - transformer_training - INFO - Main loop iteration: 4237
2025-04-25 13:05:29,978 - transformer_training - INFO - Main loop iteration: 4238
2025-04-25 13:05:30,429 - transformer_training - INFO - Main loop iteration: 4239
2025-04-25 13:05:30,928 - transformer_training - INFO - Main loop iteration: 4240
Iter 4240: loss 3.7252, lr 0.000991, 92065.59 tokens/sec
2025-04-25 13:05:31,329 - transformer_training - INFO - Main loop iteration: 4241
2025-04-25 13:05:31,789 - transformer_training - INFO - Main loop iteration: 4242
2025-04-25 13:05:32,240 - transformer_training - INFO - Main loop iteration: 4243
2025-04-25 13:05:32,739 - transformer_training - INFO - Main loop iteration: 4244
2025-04-25 13:05:33,140 - transformer_training - INFO - Main loop iteration: 4245
2025-04-25 13:05:33,601 - transformer_training - INFO - Main loop iteration: 4246
2025-04-25 13:05:34,051 - transformer_training - INFO - Main loop iteration: 4247
2025-04-25 13:05:34,550 - transformer_training - INFO - Main loop iteration: 4248
2025-04-25 13:05:34,950 - transformer_training - INFO - Main loop iteration: 4249
2025-04-25 13:05:35,411 - transformer_training - INFO - Main loop iteration: 4250
Iter 4250: loss 3.7362, lr 0.000991, 82012.80 tokens/sec
2025-04-25 13:05:35,861 - transformer_training - INFO - Main loop iteration: 4251
2025-04-25 13:05:36,360 - transformer_training - INFO - Main loop iteration: 4252
2025-04-25 13:05:36,761 - transformer_training - INFO - Main loop iteration: 4253
2025-04-25 13:05:37,222 - transformer_training - INFO - Main loop iteration: 4254
2025-04-25 13:05:37,672 - transformer_training - INFO - Main loop iteration: 4255
2025-04-25 13:05:38,171 - transformer_training - INFO - Main loop iteration: 4256
2025-04-25 13:05:38,572 - transformer_training - INFO - Main loop iteration: 4257
2025-04-25 13:05:39,033 - transformer_training - INFO - Main loop iteration: 4258
2025-04-25 13:05:39,483 - transformer_training - INFO - Main loop iteration: 4259
2025-04-25 13:05:39,982 - transformer_training - INFO - Main loop iteration: 4260
Iter 4260: loss 3.6988, lr 0.000991, 92094.98 tokens/sec
2025-04-25 13:05:40,383 - transformer_training - INFO - Main loop iteration: 4261
2025-04-25 13:05:40,844 - transformer_training - INFO - Main loop iteration: 4262
2025-04-25 13:05:41,294 - transformer_training - INFO - Main loop iteration: 4263
2025-04-25 13:05:41,793 - transformer_training - INFO - Main loop iteration: 4264
2025-04-25 13:05:42,194 - transformer_training - INFO - Main loop iteration: 4265
2025-04-25 13:05:42,655 - transformer_training - INFO - Main loop iteration: 4266
2025-04-25 13:05:43,105 - transformer_training - INFO - Main loop iteration: 4267
2025-04-25 13:05:43,604 - transformer_training - INFO - Main loop iteration: 4268
2025-04-25 13:05:44,005 - transformer_training - INFO - Main loop iteration: 4269
2025-04-25 13:05:44,466 - transformer_training - INFO - Main loop iteration: 4270
Iter 4270: loss 3.6852, lr 0.000991, 81940.09 tokens/sec
2025-04-25 13:05:44,916 - transformer_training - INFO - Main loop iteration: 4271
2025-04-25 13:05:45,416 - transformer_training - INFO - Main loop iteration: 4272
2025-04-25 13:05:45,816 - transformer_training - INFO - Main loop iteration: 4273
2025-04-25 13:05:46,277 - transformer_training - INFO - Main loop iteration: 4274
2025-04-25 13:05:46,727 - transformer_training - INFO - Main loop iteration: 4275
2025-04-25 13:05:47,226 - transformer_training - INFO - Main loop iteration: 4276
2025-04-25 13:05:47,626 - transformer_training - INFO - Main loop iteration: 4277
2025-04-25 13:05:48,088 - transformer_training - INFO - Main loop iteration: 4278
2025-04-25 13:05:48,538 - transformer_training - INFO - Main loop iteration: 4279
2025-04-25 13:05:49,038 - transformer_training - INFO - Main loop iteration: 4280
Iter 4280: loss 3.7592, lr 0.000991, 92030.80 tokens/sec
2025-04-25 13:05:49,439 - transformer_training - INFO - Main loop iteration: 4281
2025-04-25 13:05:49,899 - transformer_training - INFO - Main loop iteration: 4282
2025-04-25 13:05:50,350 - transformer_training - INFO - Main loop iteration: 4283
2025-04-25 13:05:50,848 - transformer_training - INFO - Main loop iteration: 4284
2025-04-25 13:05:51,250 - transformer_training - INFO - Main loop iteration: 4285
2025-04-25 13:05:51,711 - transformer_training - INFO - Main loop iteration: 4286
2025-04-25 13:05:52,162 - transformer_training - INFO - Main loop iteration: 4287
2025-04-25 13:05:52,664 - transformer_training - INFO - Main loop iteration: 4288
2025-04-25 13:05:53,065 - transformer_training - INFO - Main loop iteration: 4289
2025-04-25 13:05:53,528 - transformer_training - INFO - Main loop iteration: 4290
Iter 4290: loss 3.7364, lr 0.000991, 81583.32 tokens/sec
2025-04-25 13:05:53,982 - transformer_training - INFO - Main loop iteration: 4291
2025-04-25 13:05:54,484 - transformer_training - INFO - Main loop iteration: 4292
2025-04-25 13:05:54,887 - transformer_training - INFO - Main loop iteration: 4293
2025-04-25 13:05:55,349 - transformer_training - INFO - Main loop iteration: 4294
2025-04-25 13:05:55,801 - transformer_training - INFO - Main loop iteration: 4295
2025-04-25 13:05:56,313 - transformer_training - INFO - Main loop iteration: 4296
2025-04-25 13:05:56,716 - transformer_training - INFO - Main loop iteration: 4297
2025-04-25 13:05:57,182 - transformer_training - INFO - Main loop iteration: 4298
2025-04-25 13:05:57,634 - transformer_training - INFO - Main loop iteration: 4299
2025-04-25 13:05:58,139 - transformer_training - INFO - Main loop iteration: 4300
Iter 4300: loss 3.7288, lr 0.000991, 91656.55 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!Flash Attention is available!

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!Flash Attention is available!

Flash Attention is available!Flash Attention is available!

Iter 4300: train loss 3.6402, val loss 3.5895
New best model saved with val loss: 3.5895
2025-04-25 13:06:25,052 - transformer_training - INFO - Main loop iteration: 4301
2025-04-25 13:06:25,472 - transformer_training - INFO - Main loop iteration: 4302
2025-04-25 13:06:25,931 - transformer_training - INFO - Main loop iteration: 4303
2025-04-25 13:06:26,435 - transformer_training - INFO - Main loop iteration: 4304
2025-04-25 13:06:26,843 - transformer_training - INFO - Main loop iteration: 4305
2025-04-25 13:06:27,307 - transformer_training - INFO - Main loop iteration: 4306
2025-04-25 13:06:27,760 - transformer_training - INFO - Main loop iteration: 4307
2025-04-25 13:06:28,263 - transformer_training - INFO - Main loop iteration: 4308
2025-04-25 13:06:28,666 - transformer_training - INFO - Main loop iteration: 4309
2025-04-25 13:06:29,130 - transformer_training - INFO - Main loop iteration: 4310
Iter 4310: loss 3.8229, lr 0.000991, 81610.53 tokens/sec
2025-04-25 13:06:29,583 - transformer_training - INFO - Main loop iteration: 4311
2025-04-25 13:06:30,083 - transformer_training - INFO - Main loop iteration: 4312
2025-04-25 13:06:30,487 - transformer_training - INFO - Main loop iteration: 4313
2025-04-25 13:06:30,950 - transformer_training - INFO - Main loop iteration: 4314
2025-04-25 13:06:31,404 - transformer_training - INFO - Main loop iteration: 4315
2025-04-25 13:06:31,906 - transformer_training - INFO - Main loop iteration: 4316
2025-04-25 13:06:32,308 - transformer_training - INFO - Main loop iteration: 4317
2025-04-25 13:06:32,775 - transformer_training - INFO - Main loop iteration: 4318
2025-04-25 13:06:33,228 - transformer_training - INFO - Main loop iteration: 4319
2025-04-25 13:06:33,733 - transformer_training - INFO - Main loop iteration: 4320
Iter 4320: loss 3.8433, lr 0.000991, 91476.68 tokens/sec
2025-04-25 13:06:34,137 - transformer_training - INFO - Main loop iteration: 4321
2025-04-25 13:06:34,600 - transformer_training - INFO - Main loop iteration: 4322
2025-04-25 13:06:35,057 - transformer_training - INFO - Main loop iteration: 4323
2025-04-25 13:06:35,558 - transformer_training - INFO - Main loop iteration: 4324
2025-04-25 13:06:35,961 - transformer_training - INFO - Main loop iteration: 4325
2025-04-25 13:06:36,425 - transformer_training - INFO - Main loop iteration: 4326
2025-04-25 13:06:36,877 - transformer_training - INFO - Main loop iteration: 4327
2025-04-25 13:06:37,379 - transformer_training - INFO - Main loop iteration: 4328
2025-04-25 13:06:37,783 - transformer_training - INFO - Main loop iteration: 4329
2025-04-25 13:06:38,248 - transformer_training - INFO - Main loop iteration: 4330
Iter 4330: loss 3.7480, lr 0.000991, 81161.58 tokens/sec
2025-04-25 13:06:38,703 - transformer_training - INFO - Main loop iteration: 4331
2025-04-25 13:06:39,208 - transformer_training - INFO - Main loop iteration: 4332
2025-04-25 13:06:39,611 - transformer_training - INFO - Main loop iteration: 4333
2025-04-25 13:06:40,076 - transformer_training - INFO - Main loop iteration: 4334
2025-04-25 13:06:40,530 - transformer_training - INFO - Main loop iteration: 4335
2025-04-25 13:06:41,031 - transformer_training - INFO - Main loop iteration: 4336
2025-04-25 13:06:41,441 - transformer_training - INFO - Main loop iteration: 4337
2025-04-25 13:06:41,910 - transformer_training - INFO - Main loop iteration: 4338
2025-04-25 13:06:42,364 - transformer_training - INFO - Main loop iteration: 4339
2025-04-25 13:06:42,869 - transformer_training - INFO - Main loop iteration: 4340
Iter 4340: loss 3.8051, lr 0.000991, 91655.14 tokens/sec
2025-04-25 13:06:43,271 - transformer_training - INFO - Main loop iteration: 4341
2025-04-25 13:06:43,746 - transformer_training - INFO - Main loop iteration: 4342
2025-04-25 13:06:44,205 - transformer_training - INFO - Main loop iteration: 4343
2025-04-25 13:06:44,710 - transformer_training - INFO - Main loop iteration: 4344
2025-04-25 13:06:45,114 - transformer_training - INFO - Main loop iteration: 4345
2025-04-25 13:06:45,578 - transformer_training - INFO - Main loop iteration: 4346
2025-04-25 13:06:46,031 - transformer_training - INFO - Main loop iteration: 4347
2025-04-25 13:06:46,535 - transformer_training - INFO - Main loop iteration: 4348
2025-04-25 13:06:46,943 - transformer_training - INFO - Main loop iteration: 4349
2025-04-25 13:06:47,404 - transformer_training - INFO - Main loop iteration: 4350
Iter 4350: loss 3.7360, lr 0.000991, 81465.41 tokens/sec
2025-04-25 13:06:47,857 - transformer_training - INFO - Main loop iteration: 4351
2025-04-25 13:06:48,361 - transformer_training - INFO - Main loop iteration: 4352
2025-04-25 13:06:48,763 - transformer_training - INFO - Main loop iteration: 4353
2025-04-25 13:06:49,225 - transformer_training - INFO - Main loop iteration: 4354
2025-04-25 13:06:49,678 - transformer_training - INFO - Main loop iteration: 4355
2025-04-25 13:06:50,189 - transformer_training - INFO - Main loop iteration: 4356
2025-04-25 13:06:50,597 - transformer_training - INFO - Main loop iteration: 4357
2025-04-25 13:06:51,061 - transformer_training - INFO - Main loop iteration: 4358
2025-04-25 13:06:51,515 - transformer_training - INFO - Main loop iteration: 4359
2025-04-25 13:06:52,022 - transformer_training - INFO - Main loop iteration: 4360
Iter 4360: loss 3.8162, lr 0.000991, 91902.47 tokens/sec
2025-04-25 13:06:52,424 - transformer_training - INFO - Main loop iteration: 4361
2025-04-25 13:06:52,889 - transformer_training - INFO - Main loop iteration: 4362
2025-04-25 13:06:53,345 - transformer_training - INFO - Main loop iteration: 4363
2025-04-25 13:06:53,851 - transformer_training - INFO - Main loop iteration: 4364
2025-04-25 13:06:54,254 - transformer_training - INFO - Main loop iteration: 4365
2025-04-25 13:06:54,720 - transformer_training - INFO - Main loop iteration: 4366
2025-04-25 13:06:55,173 - transformer_training - INFO - Main loop iteration: 4367
2025-04-25 13:06:55,676 - transformer_training - INFO - Main loop iteration: 4368
2025-04-25 13:06:56,079 - transformer_training - INFO - Main loop iteration: 4369
2025-04-25 13:06:56,547 - transformer_training - INFO - Main loop iteration: 4370
Iter 4370: loss 3.7063, lr 0.000990, 81610.96 tokens/sec
2025-04-25 13:06:57,000 - transformer_training - INFO - Main loop iteration: 4371
2025-04-25 13:06:57,511 - transformer_training - INFO - Main loop iteration: 4372
2025-04-25 13:06:57,914 - transformer_training - INFO - Main loop iteration: 4373
2025-04-25 13:06:58,377 - transformer_training - INFO - Main loop iteration: 4374
2025-04-25 13:06:58,832 - transformer_training - INFO - Main loop iteration: 4375
2025-04-25 13:06:59,339 - transformer_training - INFO - Main loop iteration: 4376
2025-04-25 13:06:59,742 - transformer_training - INFO - Main loop iteration: 4377
2025-04-25 13:07:00,209 - transformer_training - INFO - Main loop iteration: 4378
2025-04-25 13:07:00,663 - transformer_training - INFO - Main loop iteration: 4379
2025-04-25 13:07:01,168 - transformer_training - INFO - Main loop iteration: 4380
Iter 4380: loss 3.7811, lr 0.000990, 91344.17 tokens/sec
2025-04-25 13:07:01,572 - transformer_training - INFO - Main loop iteration: 4381
2025-04-25 13:07:02,037 - transformer_training - INFO - Main loop iteration: 4382
2025-04-25 13:07:02,490 - transformer_training - INFO - Main loop iteration: 4383
2025-04-25 13:07:03,007 - transformer_training - INFO - Main loop iteration: 4384
2025-04-25 13:07:03,416 - transformer_training - INFO - Main loop iteration: 4385
2025-04-25 13:07:03,876 - transformer_training - INFO - Main loop iteration: 4386
2025-04-25 13:07:04,330 - transformer_training - INFO - Main loop iteration: 4387
2025-04-25 13:07:04,838 - transformer_training - INFO - Main loop iteration: 4388
2025-04-25 13:07:05,240 - transformer_training - INFO - Main loop iteration: 4389
2025-04-25 13:07:05,705 - transformer_training - INFO - Main loop iteration: 4390
Iter 4390: loss 3.7257, lr 0.000990, 81670.62 tokens/sec
2025-04-25 13:07:06,158 - transformer_training - INFO - Main loop iteration: 4391
2025-04-25 13:07:06,660 - transformer_training - INFO - Main loop iteration: 4392
2025-04-25 13:07:07,063 - transformer_training - INFO - Main loop iteration: 4393
2025-04-25 13:07:07,529 - transformer_training - INFO - Main loop iteration: 4394
2025-04-25 13:07:07,983 - transformer_training - INFO - Main loop iteration: 4395
2025-04-25 13:07:08,487 - transformer_training - INFO - Main loop iteration: 4396
2025-04-25 13:07:08,891 - transformer_training - INFO - Main loop iteration: 4397
2025-04-25 13:07:09,360 - transformer_training - INFO - Main loop iteration: 4398
2025-04-25 13:07:09,821 - transformer_training - INFO - Main loop iteration: 4399
2025-04-25 13:07:10,322 - transformer_training - INFO - Main loop iteration: 4400
Iter 4400: loss 3.7654, lr 0.000990, 91736.27 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.jsonTokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json

Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 4400: train loss 3.6373, val loss 3.5841
New best model saved with val loss: 3.5841
2025-04-25 13:07:30,755 - transformer_training - INFO - Main loop iteration: 4401
2025-04-25 13:07:31,173 - transformer_training - INFO - Main loop iteration: 4402
2025-04-25 13:07:31,624 - transformer_training - INFO - Main loop iteration: 4403
2025-04-25 13:07:32,258 - transformer_training - INFO - Main loop iteration: 4404
2025-04-25 13:07:32,659 - transformer_training - INFO - Main loop iteration: 4405
2025-04-25 13:07:33,120 - transformer_training - INFO - Main loop iteration: 4406
2025-04-25 13:07:33,570 - transformer_training - INFO - Main loop iteration: 4407
2025-04-25 13:07:34,069 - transformer_training - INFO - Main loop iteration: 4408
2025-04-25 13:07:34,469 - transformer_training - INFO - Main loop iteration: 4409
2025-04-25 13:07:34,930 - transformer_training - INFO - Main loop iteration: 4410
Iter 4410: loss 3.8005, lr 0.000990, 82107.09 tokens/sec
2025-04-25 13:07:35,379 - transformer_training - INFO - Main loop iteration: 4411
2025-04-25 13:07:35,878 - transformer_training - INFO - Main loop iteration: 4412
2025-04-25 13:07:36,278 - transformer_training - INFO - Main loop iteration: 4413
2025-04-25 13:07:36,740 - transformer_training - INFO - Main loop iteration: 4414
2025-04-25 13:07:37,191 - transformer_training - INFO - Main loop iteration: 4415
2025-04-25 13:07:37,690 - transformer_training - INFO - Main loop iteration: 4416
2025-04-25 13:07:38,091 - transformer_training - INFO - Main loop iteration: 4417
2025-04-25 13:07:38,552 - transformer_training - INFO - Main loop iteration: 4418
2025-04-25 13:07:39,002 - transformer_training - INFO - Main loop iteration: 4419
2025-04-25 13:07:39,500 - transformer_training - INFO - Main loop iteration: 4420
Iter 4420: loss 3.7952, lr 0.000990, 91967.52 tokens/sec
2025-04-25 13:07:39,901 - transformer_training - INFO - Main loop iteration: 4421
2025-04-25 13:07:40,362 - transformer_training - INFO - Main loop iteration: 4422
2025-04-25 13:07:40,813 - transformer_training - INFO - Main loop iteration: 4423
2025-04-25 13:07:41,310 - transformer_training - INFO - Main loop iteration: 4424
2025-04-25 13:07:41,712 - transformer_training - INFO - Main loop iteration: 4425
2025-04-25 13:07:42,175 - transformer_training - INFO - Main loop iteration: 4426
2025-04-25 13:07:42,630 - transformer_training - INFO - Main loop iteration: 4427
2025-04-25 13:07:43,133 - transformer_training - INFO - Main loop iteration: 4428
2025-04-25 13:07:43,536 - transformer_training - INFO - Main loop iteration: 4429
2025-04-25 13:07:43,998 - transformer_training - INFO - Main loop iteration: 4430
Iter 4430: loss 3.6646, lr 0.000990, 81454.59 tokens/sec
2025-04-25 13:07:44,452 - transformer_training - INFO - Main loop iteration: 4431
2025-04-25 13:07:44,952 - transformer_training - INFO - Main loop iteration: 4432
2025-04-25 13:07:45,354 - transformer_training - INFO - Main loop iteration: 4433
2025-04-25 13:07:45,816 - transformer_training - INFO - Main loop iteration: 4434
2025-04-25 13:07:46,268 - transformer_training - INFO - Main loop iteration: 4435
2025-04-25 13:07:46,767 - transformer_training - INFO - Main loop iteration: 4436
2025-04-25 13:07:47,168 - transformer_training - INFO - Main loop iteration: 4437
2025-04-25 13:07:47,630 - transformer_training - INFO - Main loop iteration: 4438
2025-04-25 13:07:48,082 - transformer_training - INFO - Main loop iteration: 4439
2025-04-25 13:07:48,588 - transformer_training - INFO - Main loop iteration: 4440
Iter 4440: loss 3.7117, lr 0.000990, 91594.00 tokens/sec
2025-04-25 13:07:48,991 - transformer_training - INFO - Main loop iteration: 4441
2025-04-25 13:07:49,456 - transformer_training - INFO - Main loop iteration: 4442
2025-04-25 13:07:49,910 - transformer_training - INFO - Main loop iteration: 4443
2025-04-25 13:07:50,413 - transformer_training - INFO - Main loop iteration: 4444
2025-04-25 13:07:50,816 - transformer_training - INFO - Main loop iteration: 4445
2025-04-25 13:07:51,280 - transformer_training - INFO - Main loop iteration: 4446
2025-04-25 13:07:51,732 - transformer_training - INFO - Main loop iteration: 4447
2025-04-25 13:07:52,232 - transformer_training - INFO - Main loop iteration: 4448
2025-04-25 13:07:52,633 - transformer_training - INFO - Main loop iteration: 4449
2025-04-25 13:07:53,095 - transformer_training - INFO - Main loop iteration: 4450
Iter 4450: loss 3.8322, lr 0.000990, 81827.91 tokens/sec
2025-04-25 13:07:53,546 - transformer_training - INFO - Main loop iteration: 4451
2025-04-25 13:07:54,044 - transformer_training - INFO - Main loop iteration: 4452
2025-04-25 13:07:54,446 - transformer_training - INFO - Main loop iteration: 4453
2025-04-25 13:07:54,908 - transformer_training - INFO - Main loop iteration: 4454
2025-04-25 13:07:55,358 - transformer_training - INFO - Main loop iteration: 4455
2025-04-25 13:07:55,858 - transformer_training - INFO - Main loop iteration: 4456
2025-04-25 13:07:56,260 - transformer_training - INFO - Main loop iteration: 4457
2025-04-25 13:07:56,720 - transformer_training - INFO - Main loop iteration: 4458
2025-04-25 13:07:57,171 - transformer_training - INFO - Main loop iteration: 4459
2025-04-25 13:07:57,670 - transformer_training - INFO - Main loop iteration: 4460
Iter 4460: loss 3.7569, lr 0.000990, 91882.53 tokens/sec
2025-04-25 13:07:58,071 - transformer_training - INFO - Main loop iteration: 4461
2025-04-25 13:07:58,532 - transformer_training - INFO - Main loop iteration: 4462
2025-04-25 13:07:58,983 - transformer_training - INFO - Main loop iteration: 4463
2025-04-25 13:07:59,481 - transformer_training - INFO - Main loop iteration: 4464
2025-04-25 13:07:59,883 - transformer_training - INFO - Main loop iteration: 4465
2025-04-25 13:08:00,344 - transformer_training - INFO - Main loop iteration: 4466
2025-04-25 13:08:00,794 - transformer_training - INFO - Main loop iteration: 4467
2025-04-25 13:08:01,294 - transformer_training - INFO - Main loop iteration: 4468
2025-04-25 13:08:01,696 - transformer_training - INFO - Main loop iteration: 4469
2025-04-25 13:08:02,157 - transformer_training - INFO - Main loop iteration: 4470
Iter 4470: loss 3.8325, lr 0.000990, 81846.92 tokens/sec
2025-04-25 13:08:02,608 - transformer_training - INFO - Main loop iteration: 4471
2025-04-25 13:08:03,106 - transformer_training - INFO - Main loop iteration: 4472
2025-04-25 13:08:03,508 - transformer_training - INFO - Main loop iteration: 4473
2025-04-25 13:08:03,969 - transformer_training - INFO - Main loop iteration: 4474
2025-04-25 13:08:04,420 - transformer_training - INFO - Main loop iteration: 4475
2025-04-25 13:08:04,918 - transformer_training - INFO - Main loop iteration: 4476
2025-04-25 13:08:05,319 - transformer_training - INFO - Main loop iteration: 4477
2025-04-25 13:08:05,781 - transformer_training - INFO - Main loop iteration: 4478
2025-04-25 13:08:06,231 - transformer_training - INFO - Main loop iteration: 4479
2025-04-25 13:08:06,730 - transformer_training - INFO - Main loop iteration: 4480
Iter 4480: loss 3.6449, lr 0.000990, 91860.15 tokens/sec
2025-04-25 13:08:07,131 - transformer_training - INFO - Main loop iteration: 4481
2025-04-25 13:08:07,592 - transformer_training - INFO - Main loop iteration: 4482
2025-04-25 13:08:08,043 - transformer_training - INFO - Main loop iteration: 4483
2025-04-25 13:08:08,542 - transformer_training - INFO - Main loop iteration: 4484
2025-04-25 13:08:08,944 - transformer_training - INFO - Main loop iteration: 4485
2025-04-25 13:08:09,405 - transformer_training - INFO - Main loop iteration: 4486
2025-04-25 13:08:09,855 - transformer_training - INFO - Main loop iteration: 4487
2025-04-25 13:08:10,354 - transformer_training - INFO - Main loop iteration: 4488
2025-04-25 13:08:10,756 - transformer_training - INFO - Main loop iteration: 4489
2025-04-25 13:08:11,217 - transformer_training - INFO - Main loop iteration: 4490
Iter 4490: loss 3.7279, lr 0.000989, 81943.09 tokens/sec
2025-04-25 13:08:11,668 - transformer_training - INFO - Main loop iteration: 4491
2025-04-25 13:08:12,167 - transformer_training - INFO - Main loop iteration: 4492
2025-04-25 13:08:12,569 - transformer_training - INFO - Main loop iteration: 4493
2025-04-25 13:08:13,029 - transformer_training - INFO - Main loop iteration: 4494
2025-04-25 13:08:13,480 - transformer_training - INFO - Main loop iteration: 4495
2025-04-25 13:08:13,979 - transformer_training - INFO - Main loop iteration: 4496
2025-04-25 13:08:14,381 - transformer_training - INFO - Main loop iteration: 4497
2025-04-25 13:08:14,843 - transformer_training - INFO - Main loop iteration: 4498
2025-04-25 13:08:15,293 - transformer_training - INFO - Main loop iteration: 4499
2025-04-25 13:08:15,792 - transformer_training - INFO - Main loop iteration: 4500
Iter 4500: loss 3.6294, lr 0.000989, 91752.76 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 4500: train loss 3.6262, val loss 3.5694
New best model saved with val loss: 3.5694
2025-04-25 13:08:34,825 - transformer_training - INFO - Main loop iteration: 4501
2025-04-25 13:08:35,238 - transformer_training - INFO - Main loop iteration: 4502
2025-04-25 13:08:35,687 - transformer_training - INFO - Main loop iteration: 4503
2025-04-25 13:08:36,185 - transformer_training - INFO - Main loop iteration: 4504
2025-04-25 13:08:36,586 - transformer_training - INFO - Main loop iteration: 4505
2025-04-25 13:08:37,047 - transformer_training - INFO - Main loop iteration: 4506
2025-04-25 13:08:37,497 - transformer_training - INFO - Main loop iteration: 4507
2025-04-25 13:08:37,996 - transformer_training - INFO - Main loop iteration: 4508
2025-04-25 13:08:38,397 - transformer_training - INFO - Main loop iteration: 4509
2025-04-25 13:08:38,858 - transformer_training - INFO - Main loop iteration: 4510
Iter 4510: loss 3.8697, lr 0.000989, 81910.62 tokens/sec
2025-04-25 13:08:39,308 - transformer_training - INFO - Main loop iteration: 4511
2025-04-25 13:08:39,807 - transformer_training - INFO - Main loop iteration: 4512
2025-04-25 13:08:40,209 - transformer_training - INFO - Main loop iteration: 4513
2025-04-25 13:08:40,670 - transformer_training - INFO - Main loop iteration: 4514
2025-04-25 13:08:41,121 - transformer_training - INFO - Main loop iteration: 4515
2025-04-25 13:08:41,619 - transformer_training - INFO - Main loop iteration: 4516
2025-04-25 13:08:42,020 - transformer_training - INFO - Main loop iteration: 4517
2025-04-25 13:08:42,482 - transformer_training - INFO - Main loop iteration: 4518
2025-04-25 13:08:42,932 - transformer_training - INFO - Main loop iteration: 4519
2025-04-25 13:08:43,430 - transformer_training - INFO - Main loop iteration: 4520
Iter 4520: loss 3.6960, lr 0.000989, 91926.29 tokens/sec
2025-04-25 13:08:43,832 - transformer_training - INFO - Main loop iteration: 4521
2025-04-25 13:08:44,293 - transformer_training - INFO - Main loop iteration: 4522
2025-04-25 13:08:44,743 - transformer_training - INFO - Main loop iteration: 4523
2025-04-25 13:08:45,241 - transformer_training - INFO - Main loop iteration: 4524
2025-04-25 13:08:45,643 - transformer_training - INFO - Main loop iteration: 4525
2025-04-25 13:08:46,105 - transformer_training - INFO - Main loop iteration: 4526
2025-04-25 13:08:46,556 - transformer_training - INFO - Main loop iteration: 4527
2025-04-25 13:08:47,054 - transformer_training - INFO - Main loop iteration: 4528
2025-04-25 13:08:47,455 - transformer_training - INFO - Main loop iteration: 4529
2025-04-25 13:08:47,916 - transformer_training - INFO - Main loop iteration: 4530
Iter 4530: loss 3.7286, lr 0.000989, 81877.91 tokens/sec
2025-04-25 13:08:48,367 - transformer_training - INFO - Main loop iteration: 4531
2025-04-25 13:08:48,866 - transformer_training - INFO - Main loop iteration: 4532
2025-04-25 13:08:49,268 - transformer_training - INFO - Main loop iteration: 4533
2025-04-25 13:08:49,728 - transformer_training - INFO - Main loop iteration: 4534
2025-04-25 13:08:50,179 - transformer_training - INFO - Main loop iteration: 4535
2025-04-25 13:08:50,678 - transformer_training - INFO - Main loop iteration: 4536
2025-04-25 13:08:51,079 - transformer_training - INFO - Main loop iteration: 4537
2025-04-25 13:08:51,541 - transformer_training - INFO - Main loop iteration: 4538
2025-04-25 13:08:51,991 - transformer_training - INFO - Main loop iteration: 4539
2025-04-25 13:08:52,491 - transformer_training - INFO - Main loop iteration: 4540
Iter 4540: loss 3.7139, lr 0.000989, 91776.78 tokens/sec
2025-04-25 13:08:52,893 - transformer_training - INFO - Main loop iteration: 4541
2025-04-25 13:08:53,354 - transformer_training - INFO - Main loop iteration: 4542
2025-04-25 13:08:53,805 - transformer_training - INFO - Main loop iteration: 4543
2025-04-25 13:08:54,304 - transformer_training - INFO - Main loop iteration: 4544
2025-04-25 13:08:54,706 - transformer_training - INFO - Main loop iteration: 4545
2025-04-25 13:08:55,166 - transformer_training - INFO - Main loop iteration: 4546
2025-04-25 13:08:55,617 - transformer_training - INFO - Main loop iteration: 4547
2025-04-25 13:08:56,115 - transformer_training - INFO - Main loop iteration: 4548
2025-04-25 13:08:56,517 - transformer_training - INFO - Main loop iteration: 4549
2025-04-25 13:08:56,977 - transformer_training - INFO - Main loop iteration: 4550
Iter 4550: loss 3.6328, lr 0.000989, 81902.63 tokens/sec
2025-04-25 13:08:57,428 - transformer_training - INFO - Main loop iteration: 4551
2025-04-25 13:08:57,927 - transformer_training - INFO - Main loop iteration: 4552
2025-04-25 13:08:58,329 - transformer_training - INFO - Main loop iteration: 4553
2025-04-25 13:08:58,790 - transformer_training - INFO - Main loop iteration: 4554
2025-04-25 13:08:59,241 - transformer_training - INFO - Main loop iteration: 4555
2025-04-25 13:08:59,739 - transformer_training - INFO - Main loop iteration: 4556
2025-04-25 13:09:00,141 - transformer_training - INFO - Main loop iteration: 4557
2025-04-25 13:09:00,602 - transformer_training - INFO - Main loop iteration: 4558
2025-04-25 13:09:01,052 - transformer_training - INFO - Main loop iteration: 4559
2025-04-25 13:09:01,551 - transformer_training - INFO - Main loop iteration: 4560
Iter 4560: loss 3.5859, lr 0.000989, 91784.79 tokens/sec
2025-04-25 13:09:01,954 - transformer_training - INFO - Main loop iteration: 4561
2025-04-25 13:09:02,414 - transformer_training - INFO - Main loop iteration: 4562
2025-04-25 13:09:02,865 - transformer_training - INFO - Main loop iteration: 4563
2025-04-25 13:09:03,364 - transformer_training - INFO - Main loop iteration: 4564
2025-04-25 13:09:03,765 - transformer_training - INFO - Main loop iteration: 4565
2025-04-25 13:09:04,226 - transformer_training - INFO - Main loop iteration: 4566
2025-04-25 13:09:04,676 - transformer_training - INFO - Main loop iteration: 4567
2025-04-25 13:09:05,175 - transformer_training - INFO - Main loop iteration: 4568
2025-04-25 13:09:05,577 - transformer_training - INFO - Main loop iteration: 4569
2025-04-25 13:09:06,037 - transformer_training - INFO - Main loop iteration: 4570
Iter 4570: loss 3.7858, lr 0.000989, 81904.46 tokens/sec
2025-04-25 13:09:06,488 - transformer_training - INFO - Main loop iteration: 4571
2025-04-25 13:09:06,986 - transformer_training - INFO - Main loop iteration: 4572
2025-04-25 13:09:07,388 - transformer_training - INFO - Main loop iteration: 4573
2025-04-25 13:09:07,848 - transformer_training - INFO - Main loop iteration: 4574
2025-04-25 13:09:08,298 - transformer_training - INFO - Main loop iteration: 4575
2025-04-25 13:09:08,797 - transformer_training - INFO - Main loop iteration: 4576
2025-04-25 13:09:09,199 - transformer_training - INFO - Main loop iteration: 4577
2025-04-25 13:09:09,660 - transformer_training - INFO - Main loop iteration: 4578
2025-04-25 13:09:10,110 - transformer_training - INFO - Main loop iteration: 4579
2025-04-25 13:09:10,609 - transformer_training - INFO - Main loop iteration: 4580
Iter 4580: loss 3.7008, lr 0.000989, 91897.00 tokens/sec
2025-04-25 13:09:11,011 - transformer_training - INFO - Main loop iteration: 4581
2025-04-25 13:09:11,472 - transformer_training - INFO - Main loop iteration: 4582
2025-04-25 13:09:11,922 - transformer_training - INFO - Main loop iteration: 4583
2025-04-25 13:09:12,421 - transformer_training - INFO - Main loop iteration: 4584
2025-04-25 13:09:12,822 - transformer_training - INFO - Main loop iteration: 4585
2025-04-25 13:09:13,283 - transformer_training - INFO - Main loop iteration: 4586
2025-04-25 13:09:13,733 - transformer_training - INFO - Main loop iteration: 4587
2025-04-25 13:09:14,232 - transformer_training - INFO - Main loop iteration: 4588
2025-04-25 13:09:14,633 - transformer_training - INFO - Main loop iteration: 4589
2025-04-25 13:09:15,094 - transformer_training - INFO - Main loop iteration: 4590
Iter 4590: loss 3.7357, lr 0.000989, 81799.77 tokens/sec
2025-04-25 13:09:15,545 - transformer_training - INFO - Main loop iteration: 4591
2025-04-25 13:09:16,044 - transformer_training - INFO - Main loop iteration: 4592
2025-04-25 13:09:16,445 - transformer_training - INFO - Main loop iteration: 4593
2025-04-25 13:09:16,906 - transformer_training - INFO - Main loop iteration: 4594
2025-04-25 13:09:17,357 - transformer_training - INFO - Main loop iteration: 4595
2025-04-25 13:09:17,855 - transformer_training - INFO - Main loop iteration: 4596
2025-04-25 13:09:18,257 - transformer_training - INFO - Main loop iteration: 4597
2025-04-25 13:09:18,717 - transformer_training - INFO - Main loop iteration: 4598
2025-04-25 13:09:19,168 - transformer_training - INFO - Main loop iteration: 4599
2025-04-25 13:09:19,666 - transformer_training - INFO - Main loop iteration: 4600
Iter 4600: loss 3.7867, lr 0.000989, 91864.79 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 4600: train loss 3.6267, val loss 3.5541
New best model saved with val loss: 3.5541
2025-04-25 13:09:37,842 - transformer_training - INFO - Main loop iteration: 4601
2025-04-25 13:09:38,260 - transformer_training - INFO - Main loop iteration: 4602
2025-04-25 13:09:38,710 - transformer_training - INFO - Main loop iteration: 4603
2025-04-25 13:09:39,209 - transformer_training - INFO - Main loop iteration: 4604
2025-04-25 13:09:39,610 - transformer_training - INFO - Main loop iteration: 4605
2025-04-25 13:09:40,071 - transformer_training - INFO - Main loop iteration: 4606
2025-04-25 13:09:40,521 - transformer_training - INFO - Main loop iteration: 4607
2025-04-25 13:09:41,020 - transformer_training - INFO - Main loop iteration: 4608
2025-04-25 13:09:41,421 - transformer_training - INFO - Main loop iteration: 4609
2025-04-25 13:09:41,882 - transformer_training - INFO - Main loop iteration: 4610
Iter 4610: loss 3.7701, lr 0.000988, 81934.71 tokens/sec
2025-04-25 13:09:42,332 - transformer_training - INFO - Main loop iteration: 4611
2025-04-25 13:09:42,831 - transformer_training - INFO - Main loop iteration: 4612
2025-04-25 13:09:43,233 - transformer_training - INFO - Main loop iteration: 4613
2025-04-25 13:09:43,694 - transformer_training - INFO - Main loop iteration: 4614
2025-04-25 13:09:44,144 - transformer_training - INFO - Main loop iteration: 4615
2025-04-25 13:09:44,643 - transformer_training - INFO - Main loop iteration: 4616
2025-04-25 13:09:45,045 - transformer_training - INFO - Main loop iteration: 4617
2025-04-25 13:09:45,506 - transformer_training - INFO - Main loop iteration: 4618
2025-04-25 13:09:45,957 - transformer_training - INFO - Main loop iteration: 4619
2025-04-25 13:09:46,456 - transformer_training - INFO - Main loop iteration: 4620
Iter 4620: loss 3.6734, lr 0.000988, 91872.05 tokens/sec
2025-04-25 13:09:46,858 - transformer_training - INFO - Main loop iteration: 4621
2025-04-25 13:09:47,318 - transformer_training - INFO - Main loop iteration: 4622
2025-04-25 13:09:47,769 - transformer_training - INFO - Main loop iteration: 4623
2025-04-25 13:09:48,268 - transformer_training - INFO - Main loop iteration: 4624
2025-04-25 13:09:48,669 - transformer_training - INFO - Main loop iteration: 4625
2025-04-25 13:09:49,130 - transformer_training - INFO - Main loop iteration: 4626
2025-04-25 13:09:49,581 - transformer_training - INFO - Main loop iteration: 4627
2025-04-25 13:09:50,080 - transformer_training - INFO - Main loop iteration: 4628
2025-04-25 13:09:50,482 - transformer_training - INFO - Main loop iteration: 4629
2025-04-25 13:09:50,943 - transformer_training - INFO - Main loop iteration: 4630
Iter 4630: loss 3.6580, lr 0.000988, 81796.48 tokens/sec
2025-04-25 13:09:51,394 - transformer_training - INFO - Main loop iteration: 4631
2025-04-25 13:09:51,892 - transformer_training - INFO - Main loop iteration: 4632
2025-04-25 13:09:52,295 - transformer_training - INFO - Main loop iteration: 4633
2025-04-25 13:09:52,756 - transformer_training - INFO - Main loop iteration: 4634
2025-04-25 13:09:53,206 - transformer_training - INFO - Main loop iteration: 4635
2025-04-25 13:09:53,706 - transformer_training - INFO - Main loop iteration: 4636
2025-04-25 13:09:54,108 - transformer_training - INFO - Main loop iteration: 4637
2025-04-25 13:09:54,569 - transformer_training - INFO - Main loop iteration: 4638
2025-04-25 13:09:55,019 - transformer_training - INFO - Main loop iteration: 4639
2025-04-25 13:09:55,518 - transformer_training - INFO - Main loop iteration: 4640
Iter 4640: loss 3.6490, lr 0.000988, 91881.39 tokens/sec
2025-04-25 13:09:55,921 - transformer_training - INFO - Main loop iteration: 4641
2025-04-25 13:09:56,381 - transformer_training - INFO - Main loop iteration: 4642
2025-04-25 13:09:56,832 - transformer_training - INFO - Main loop iteration: 4643
2025-04-25 13:09:57,330 - transformer_training - INFO - Main loop iteration: 4644
2025-04-25 13:09:57,732 - transformer_training - INFO - Main loop iteration: 4645
2025-04-25 13:09:58,193 - transformer_training - INFO - Main loop iteration: 4646
2025-04-25 13:09:58,645 - transformer_training - INFO - Main loop iteration: 4647
2025-04-25 13:09:59,143 - transformer_training - INFO - Main loop iteration: 4648
2025-04-25 13:09:59,545 - transformer_training - INFO - Main loop iteration: 4649
2025-04-25 13:10:00,005 - transformer_training - INFO - Main loop iteration: 4650
Iter 4650: loss 3.6220, lr 0.000988, 81857.41 tokens/sec
2025-04-25 13:10:00,456 - transformer_training - INFO - Main loop iteration: 4651
2025-04-25 13:10:00,955 - transformer_training - INFO - Main loop iteration: 4652
2025-04-25 13:10:01,357 - transformer_training - INFO - Main loop iteration: 4653
2025-04-25 13:10:01,819 - transformer_training - INFO - Main loop iteration: 4654
2025-04-25 13:10:02,270 - transformer_training - INFO - Main loop iteration: 4655
2025-04-25 13:10:02,769 - transformer_training - INFO - Main loop iteration: 4656
2025-04-25 13:10:03,170 - transformer_training - INFO - Main loop iteration: 4657
2025-04-25 13:10:03,631 - transformer_training - INFO - Main loop iteration: 4658
2025-04-25 13:10:04,082 - transformer_training - INFO - Main loop iteration: 4659
2025-04-25 13:10:04,581 - transformer_training - INFO - Main loop iteration: 4660
Iter 4660: loss 3.6794, lr 0.000988, 91871.29 tokens/sec
2025-04-25 13:10:04,983 - transformer_training - INFO - Main loop iteration: 4661
2025-04-25 13:10:05,443 - transformer_training - INFO - Main loop iteration: 4662
2025-04-25 13:10:05,894 - transformer_training - INFO - Main loop iteration: 4663
2025-04-25 13:10:06,393 - transformer_training - INFO - Main loop iteration: 4664
2025-04-25 13:10:06,794 - transformer_training - INFO - Main loop iteration: 4665
2025-04-25 13:10:07,255 - transformer_training - INFO - Main loop iteration: 4666
2025-04-25 13:10:07,706 - transformer_training - INFO - Main loop iteration: 4667
2025-04-25 13:10:08,204 - transformer_training - INFO - Main loop iteration: 4668
2025-04-25 13:10:08,605 - transformer_training - INFO - Main loop iteration: 4669
2025-04-25 13:10:09,067 - transformer_training - INFO - Main loop iteration: 4670
Iter 4670: loss 3.7563, lr 0.000988, 81955.38 tokens/sec
2025-04-25 13:10:09,517 - transformer_training - INFO - Main loop iteration: 4671
2025-04-25 13:10:10,015 - transformer_training - INFO - Main loop iteration: 4672
2025-04-25 13:10:10,416 - transformer_training - INFO - Main loop iteration: 4673
2025-04-25 13:10:10,877 - transformer_training - INFO - Main loop iteration: 4674
2025-04-25 13:10:11,328 - transformer_training - INFO - Main loop iteration: 4675
2025-04-25 13:10:11,826 - transformer_training - INFO - Main loop iteration: 4676
2025-04-25 13:10:12,228 - transformer_training - INFO - Main loop iteration: 4677
2025-04-25 13:10:12,689 - transformer_training - INFO - Main loop iteration: 4678
2025-04-25 13:10:13,139 - transformer_training - INFO - Main loop iteration: 4679
2025-04-25 13:10:13,638 - transformer_training - INFO - Main loop iteration: 4680
Iter 4680: loss 3.7647, lr 0.000988, 91963.74 tokens/sec
2025-04-25 13:10:14,039 - transformer_training - INFO - Main loop iteration: 4681
2025-04-25 13:10:14,500 - transformer_training - INFO - Main loop iteration: 4682
2025-04-25 13:10:14,951 - transformer_training - INFO - Main loop iteration: 4683
2025-04-25 13:10:15,450 - transformer_training - INFO - Main loop iteration: 4684
2025-04-25 13:10:15,852 - transformer_training - INFO - Main loop iteration: 4685
2025-04-25 13:10:16,313 - transformer_training - INFO - Main loop iteration: 4686
2025-04-25 13:10:16,764 - transformer_training - INFO - Main loop iteration: 4687
2025-04-25 13:10:17,263 - transformer_training - INFO - Main loop iteration: 4688
2025-04-25 13:10:17,664 - transformer_training - INFO - Main loop iteration: 4689
2025-04-25 13:10:18,126 - transformer_training - INFO - Main loop iteration: 4690
Iter 4690: loss 3.7124, lr 0.000988, 81865.51 tokens/sec
2025-04-25 13:10:18,577 - transformer_training - INFO - Main loop iteration: 4691
2025-04-25 13:10:19,075 - transformer_training - INFO - Main loop iteration: 4692
2025-04-25 13:10:19,477 - transformer_training - INFO - Main loop iteration: 4693
2025-04-25 13:10:19,938 - transformer_training - INFO - Main loop iteration: 4694
2025-04-25 13:10:20,389 - transformer_training - INFO - Main loop iteration: 4695
2025-04-25 13:10:20,888 - transformer_training - INFO - Main loop iteration: 4696
2025-04-25 13:10:21,290 - transformer_training - INFO - Main loop iteration: 4697
2025-04-25 13:10:21,751 - transformer_training - INFO - Main loop iteration: 4698
2025-04-25 13:10:22,202 - transformer_training - INFO - Main loop iteration: 4699
2025-04-25 13:10:22,701 - transformer_training - INFO - Main loop iteration: 4700
Iter 4700: loss 3.7630, lr 0.000988, 91926.45 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 4700: train loss 3.6098, val loss 3.5371
New best model saved with val loss: 3.5371
2025-04-25 13:10:40,332 - transformer_training - INFO - Main loop iteration: 4701
2025-04-25 13:10:40,751 - transformer_training - INFO - Main loop iteration: 4702
2025-04-25 13:10:41,199 - transformer_training - INFO - Main loop iteration: 4703
2025-04-25 13:10:41,697 - transformer_training - INFO - Main loop iteration: 4704
2025-04-25 13:10:42,099 - transformer_training - INFO - Main loop iteration: 4705
2025-04-25 13:10:42,560 - transformer_training - INFO - Main loop iteration: 4706
2025-04-25 13:10:43,010 - transformer_training - INFO - Main loop iteration: 4707
2025-04-25 13:10:43,508 - transformer_training - INFO - Main loop iteration: 4708
2025-04-25 13:10:43,910 - transformer_training - INFO - Main loop iteration: 4709
2025-04-25 13:10:44,370 - transformer_training - INFO - Main loop iteration: 4710
Iter 4710: loss 3.6100, lr 0.000988, 81984.84 tokens/sec
2025-04-25 13:10:44,821 - transformer_training - INFO - Main loop iteration: 4711
2025-04-25 13:10:45,319 - transformer_training - INFO - Main loop iteration: 4712
2025-04-25 13:10:45,721 - transformer_training - INFO - Main loop iteration: 4713
2025-04-25 13:10:46,181 - transformer_training - INFO - Main loop iteration: 4714
2025-04-25 13:10:46,632 - transformer_training - INFO - Main loop iteration: 4715
2025-04-25 13:10:47,131 - transformer_training - INFO - Main loop iteration: 4716
2025-04-25 13:10:47,531 - transformer_training - INFO - Main loop iteration: 4717
2025-04-25 13:10:47,992 - transformer_training - INFO - Main loop iteration: 4718
2025-04-25 13:10:48,443 - transformer_training - INFO - Main loop iteration: 4719
2025-04-25 13:10:48,941 - transformer_training - INFO - Main loop iteration: 4720
Iter 4720: loss 3.6636, lr 0.000987, 91981.69 tokens/sec
2025-04-25 13:10:49,342 - transformer_training - INFO - Main loop iteration: 4721
2025-04-25 13:10:49,803 - transformer_training - INFO - Main loop iteration: 4722
2025-04-25 13:10:50,255 - transformer_training - INFO - Main loop iteration: 4723
2025-04-25 13:10:50,755 - transformer_training - INFO - Main loop iteration: 4724
2025-04-25 13:10:51,157 - transformer_training - INFO - Main loop iteration: 4725
2025-04-25 13:10:51,621 - transformer_training - INFO - Main loop iteration: 4726
2025-04-25 13:10:52,072 - transformer_training - INFO - Main loop iteration: 4727
2025-04-25 13:10:52,571 - transformer_training - INFO - Main loop iteration: 4728
2025-04-25 13:10:52,973 - transformer_training - INFO - Main loop iteration: 4729
2025-04-25 13:10:53,434 - transformer_training - INFO - Main loop iteration: 4730
Iter 4730: loss 3.6942, lr 0.000987, 81574.11 tokens/sec
2025-04-25 13:10:53,886 - transformer_training - INFO - Main loop iteration: 4731
2025-04-25 13:10:54,386 - transformer_training - INFO - Main loop iteration: 4732
2025-04-25 13:10:54,787 - transformer_training - INFO - Main loop iteration: 4733
2025-04-25 13:10:55,248 - transformer_training - INFO - Main loop iteration: 4734
2025-04-25 13:10:55,699 - transformer_training - INFO - Main loop iteration: 4735
2025-04-25 13:10:56,198 - transformer_training - INFO - Main loop iteration: 4736
2025-04-25 13:10:56,599 - transformer_training - INFO - Main loop iteration: 4737
2025-04-25 13:10:57,060 - transformer_training - INFO - Main loop iteration: 4738
2025-04-25 13:10:57,511 - transformer_training - INFO - Main loop iteration: 4739
2025-04-25 13:10:58,009 - transformer_training - INFO - Main loop iteration: 4740
Iter 4740: loss 3.8563, lr 0.000987, 74426.64 tokens/sec
2025-04-25 13:10:58,505 - transformer_training - INFO - Main loop iteration: 4741
2025-04-25 13:10:58,967 - transformer_training - INFO - Main loop iteration: 4742
2025-04-25 13:10:59,416 - transformer_training - INFO - Main loop iteration: 4743
2025-04-25 13:10:59,916 - transformer_training - INFO - Main loop iteration: 4744
2025-04-25 13:11:00,318 - transformer_training - INFO - Main loop iteration: 4745
2025-04-25 13:11:00,779 - transformer_training - INFO - Main loop iteration: 4746
2025-04-25 13:11:01,230 - transformer_training - INFO - Main loop iteration: 4747
2025-04-25 13:11:01,729 - transformer_training - INFO - Main loop iteration: 4748
2025-04-25 13:11:02,131 - transformer_training - INFO - Main loop iteration: 4749
2025-04-25 13:11:02,592 - transformer_training - INFO - Main loop iteration: 4750
Iter 4750: loss 3.7461, lr 0.000987, 81824.79 tokens/sec
2025-04-25 13:11:03,043 - transformer_training - INFO - Main loop iteration: 4751
2025-04-25 13:11:03,542 - transformer_training - INFO - Main loop iteration: 4752
2025-04-25 13:11:03,943 - transformer_training - INFO - Main loop iteration: 4753
2025-04-25 13:11:04,405 - transformer_training - INFO - Main loop iteration: 4754
2025-04-25 13:11:04,855 - transformer_training - INFO - Main loop iteration: 4755
2025-04-25 13:11:05,354 - transformer_training - INFO - Main loop iteration: 4756
2025-04-25 13:11:05,755 - transformer_training - INFO - Main loop iteration: 4757
2025-04-25 13:11:06,217 - transformer_training - INFO - Main loop iteration: 4758
2025-04-25 13:11:06,667 - transformer_training - INFO - Main loop iteration: 4759
2025-04-25 13:11:07,166 - transformer_training - INFO - Main loop iteration: 4760
Iter 4760: loss 3.7399, lr 0.000987, 91875.43 tokens/sec
2025-04-25 13:11:07,568 - transformer_training - INFO - Main loop iteration: 4761
2025-04-25 13:11:08,029 - transformer_training - INFO - Main loop iteration: 4762
2025-04-25 13:11:08,480 - transformer_training - INFO - Main loop iteration: 4763
2025-04-25 13:11:08,979 - transformer_training - INFO - Main loop iteration: 4764
2025-04-25 13:11:09,381 - transformer_training - INFO - Main loop iteration: 4765
2025-04-25 13:11:09,842 - transformer_training - INFO - Main loop iteration: 4766
2025-04-25 13:11:10,293 - transformer_training - INFO - Main loop iteration: 4767
2025-04-25 13:11:10,792 - transformer_training - INFO - Main loop iteration: 4768
2025-04-25 13:11:11,194 - transformer_training - INFO - Main loop iteration: 4769
2025-04-25 13:11:11,655 - transformer_training - INFO - Main loop iteration: 4770
Iter 4770: loss 3.5992, lr 0.000987, 81797.78 tokens/sec
2025-04-25 13:11:12,106 - transformer_training - INFO - Main loop iteration: 4771
2025-04-25 13:11:12,605 - transformer_training - INFO - Main loop iteration: 4772
2025-04-25 13:11:13,007 - transformer_training - INFO - Main loop iteration: 4773
2025-04-25 13:11:13,467 - transformer_training - INFO - Main loop iteration: 4774
2025-04-25 13:11:13,918 - transformer_training - INFO - Main loop iteration: 4775
2025-04-25 13:11:14,417 - transformer_training - INFO - Main loop iteration: 4776
2025-04-25 13:11:14,819 - transformer_training - INFO - Main loop iteration: 4777
2025-04-25 13:11:15,280 - transformer_training - INFO - Main loop iteration: 4778
2025-04-25 13:11:15,731 - transformer_training - INFO - Main loop iteration: 4779
2025-04-25 13:11:16,230 - transformer_training - INFO - Main loop iteration: 4780
Iter 4780: loss 3.6502, lr 0.000987, 91901.65 tokens/sec
2025-04-25 13:11:16,632 - transformer_training - INFO - Main loop iteration: 4781
2025-04-25 13:11:17,093 - transformer_training - INFO - Main loop iteration: 4782
2025-04-25 13:11:17,543 - transformer_training - INFO - Main loop iteration: 4783
2025-04-25 13:11:18,042 - transformer_training - INFO - Main loop iteration: 4784
2025-04-25 13:11:18,444 - transformer_training - INFO - Main loop iteration: 4785
2025-04-25 13:11:18,906 - transformer_training - INFO - Main loop iteration: 4786
2025-04-25 13:11:19,356 - transformer_training - INFO - Main loop iteration: 4787
2025-04-25 13:11:19,855 - transformer_training - INFO - Main loop iteration: 4788
2025-04-25 13:11:20,257 - transformer_training - INFO - Main loop iteration: 4789
2025-04-25 13:11:20,719 - transformer_training - INFO - Main loop iteration: 4790
Iter 4790: loss 3.6531, lr 0.000987, 81956.99 tokens/sec
2025-04-25 13:11:21,169 - transformer_training - INFO - Main loop iteration: 4791
2025-04-25 13:11:21,668 - transformer_training - INFO - Main loop iteration: 4792
2025-04-25 13:11:22,070 - transformer_training - INFO - Main loop iteration: 4793
2025-04-25 13:11:22,532 - transformer_training - INFO - Main loop iteration: 4794
2025-04-25 13:11:22,983 - transformer_training - INFO - Main loop iteration: 4795
2025-04-25 13:11:23,481 - transformer_training - INFO - Main loop iteration: 4796
2025-04-25 13:11:23,883 - transformer_training - INFO - Main loop iteration: 4797
2025-04-25 13:11:24,344 - transformer_training - INFO - Main loop iteration: 4798
2025-04-25 13:11:24,795 - transformer_training - INFO - Main loop iteration: 4799
2025-04-25 13:11:25,294 - transformer_training - INFO - Main loop iteration: 4800
Iter 4800: loss 3.6763, lr 0.000987, 91787.46 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 4800: train loss 3.6039, val loss 3.5250
New best model saved with val loss: 3.5250
2025-04-25 13:11:42,396 - transformer_training - INFO - Main loop iteration: 4801
2025-04-25 13:11:42,816 - transformer_training - INFO - Main loop iteration: 4802
2025-04-25 13:11:43,265 - transformer_training - INFO - Main loop iteration: 4803
2025-04-25 13:11:43,764 - transformer_training - INFO - Main loop iteration: 4804
2025-04-25 13:11:44,164 - transformer_training - INFO - Main loop iteration: 4805
2025-04-25 13:11:44,624 - transformer_training - INFO - Main loop iteration: 4806
2025-04-25 13:11:45,075 - transformer_training - INFO - Main loop iteration: 4807
2025-04-25 13:11:45,573 - transformer_training - INFO - Main loop iteration: 4808
2025-04-25 13:11:45,974 - transformer_training - INFO - Main loop iteration: 4809
2025-04-25 13:11:46,434 - transformer_training - INFO - Main loop iteration: 4810
Iter 4810: loss 3.6671, lr 0.000987, 81993.28 tokens/sec
2025-04-25 13:11:46,884 - transformer_training - INFO - Main loop iteration: 4811
2025-04-25 13:11:47,383 - transformer_training - INFO - Main loop iteration: 4812
2025-04-25 13:11:47,783 - transformer_training - INFO - Main loop iteration: 4813
2025-04-25 13:11:48,245 - transformer_training - INFO - Main loop iteration: 4814
2025-04-25 13:11:48,696 - transformer_training - INFO - Main loop iteration: 4815
2025-04-25 13:11:49,195 - transformer_training - INFO - Main loop iteration: 4816
2025-04-25 13:11:49,597 - transformer_training - INFO - Main loop iteration: 4817
2025-04-25 13:11:50,058 - transformer_training - INFO - Main loop iteration: 4818
2025-04-25 13:11:50,508 - transformer_training - INFO - Main loop iteration: 4819
2025-04-25 13:11:51,007 - transformer_training - INFO - Main loop iteration: 4820
Iter 4820: loss 3.7505, lr 0.000987, 91828.84 tokens/sec
2025-04-25 13:11:51,409 - transformer_training - INFO - Main loop iteration: 4821
2025-04-25 13:11:51,869 - transformer_training - INFO - Main loop iteration: 4822
2025-04-25 13:11:52,320 - transformer_training - INFO - Main loop iteration: 4823
2025-04-25 13:11:52,818 - transformer_training - INFO - Main loop iteration: 4824
2025-04-25 13:11:53,220 - transformer_training - INFO - Main loop iteration: 4825
2025-04-25 13:11:53,681 - transformer_training - INFO - Main loop iteration: 4826
2025-04-25 13:11:54,132 - transformer_training - INFO - Main loop iteration: 4827
2025-04-25 13:11:54,631 - transformer_training - INFO - Main loop iteration: 4828
2025-04-25 13:11:55,032 - transformer_training - INFO - Main loop iteration: 4829
2025-04-25 13:11:55,493 - transformer_training - INFO - Main loop iteration: 4830
Iter 4830: loss 3.6532, lr 0.000986, 81815.96 tokens/sec
2025-04-25 13:11:55,944 - transformer_training - INFO - Main loop iteration: 4831
2025-04-25 13:11:56,442 - transformer_training - INFO - Main loop iteration: 4832
2025-04-25 13:11:56,844 - transformer_training - INFO - Main loop iteration: 4833
2025-04-25 13:11:57,305 - transformer_training - INFO - Main loop iteration: 4834
2025-04-25 13:11:57,755 - transformer_training - INFO - Main loop iteration: 4835
2025-04-25 13:11:58,254 - transformer_training - INFO - Main loop iteration: 4836
2025-04-25 13:11:58,656 - transformer_training - INFO - Main loop iteration: 4837
2025-04-25 13:11:59,117 - transformer_training - INFO - Main loop iteration: 4838
2025-04-25 13:11:59,568 - transformer_training - INFO - Main loop iteration: 4839
2025-04-25 13:12:00,066 - transformer_training - INFO - Main loop iteration: 4840
Iter 4840: loss 3.6617, lr 0.000986, 91971.95 tokens/sec
2025-04-25 13:12:00,468 - transformer_training - INFO - Main loop iteration: 4841
2025-04-25 13:12:00,928 - transformer_training - INFO - Main loop iteration: 4842
2025-04-25 13:12:01,379 - transformer_training - INFO - Main loop iteration: 4843
2025-04-25 13:12:01,878 - transformer_training - INFO - Main loop iteration: 4844
2025-04-25 13:12:02,280 - transformer_training - INFO - Main loop iteration: 4845
2025-04-25 13:12:02,740 - transformer_training - INFO - Main loop iteration: 4846
2025-04-25 13:12:03,191 - transformer_training - INFO - Main loop iteration: 4847
2025-04-25 13:12:03,689 - transformer_training - INFO - Main loop iteration: 4848
2025-04-25 13:12:04,091 - transformer_training - INFO - Main loop iteration: 4849
2025-04-25 13:12:04,553 - transformer_training - INFO - Main loop iteration: 4850
Iter 4850: loss 3.6266, lr 0.000986, 81911.01 tokens/sec
2025-04-25 13:12:05,003 - transformer_training - INFO - Main loop iteration: 4851
2025-04-25 13:12:05,503 - transformer_training - INFO - Main loop iteration: 4852
2025-04-25 13:12:05,904 - transformer_training - INFO - Main loop iteration: 4853
2025-04-25 13:12:06,365 - transformer_training - INFO - Main loop iteration: 4854
2025-04-25 13:12:06,816 - transformer_training - INFO - Main loop iteration: 4855
2025-04-25 13:12:07,316 - transformer_training - INFO - Main loop iteration: 4856
2025-04-25 13:12:07,717 - transformer_training - INFO - Main loop iteration: 4857
2025-04-25 13:12:08,178 - transformer_training - INFO - Main loop iteration: 4858
2025-04-25 13:12:08,628 - transformer_training - INFO - Main loop iteration: 4859
2025-04-25 13:12:09,127 - transformer_training - INFO - Main loop iteration: 4860
Iter 4860: loss 3.6583, lr 0.000986, 91924.81 tokens/sec
2025-04-25 13:12:09,528 - transformer_training - INFO - Main loop iteration: 4861
2025-04-25 13:12:09,989 - transformer_training - INFO - Main loop iteration: 4862
2025-04-25 13:12:10,440 - transformer_training - INFO - Main loop iteration: 4863
2025-04-25 13:12:10,938 - transformer_training - INFO - Main loop iteration: 4864
2025-04-25 13:12:11,340 - transformer_training - INFO - Main loop iteration: 4865
2025-04-25 13:12:11,801 - transformer_training - INFO - Main loop iteration: 4866
2025-04-25 13:12:12,252 - transformer_training - INFO - Main loop iteration: 4867
2025-04-25 13:12:12,751 - transformer_training - INFO - Main loop iteration: 4868
2025-04-25 13:12:13,153 - transformer_training - INFO - Main loop iteration: 4869
2025-04-25 13:12:13,614 - transformer_training - INFO - Main loop iteration: 4870
Iter 4870: loss 3.6281, lr 0.000986, 81922.38 tokens/sec
2025-04-25 13:12:14,065 - transformer_training - INFO - Main loop iteration: 4871
2025-04-25 13:12:14,564 - transformer_training - INFO - Main loop iteration: 4872
2025-04-25 13:12:14,966 - transformer_training - INFO - Main loop iteration: 4873
2025-04-25 13:12:15,427 - transformer_training - INFO - Main loop iteration: 4874
2025-04-25 13:12:15,878 - transformer_training - INFO - Main loop iteration: 4875
2025-04-25 13:12:16,377 - transformer_training - INFO - Main loop iteration: 4876
2025-04-25 13:12:16,778 - transformer_training - INFO - Main loop iteration: 4877
2025-04-25 13:12:17,239 - transformer_training - INFO - Main loop iteration: 4878
2025-04-25 13:12:17,689 - transformer_training - INFO - Main loop iteration: 4879
2025-04-25 13:12:18,192 - transformer_training - INFO - Main loop iteration: 4880
Iter 4880: loss 3.6974, lr 0.000986, 92063.62 tokens/sec
2025-04-25 13:12:18,593 - transformer_training - INFO - Main loop iteration: 4881
2025-04-25 13:12:19,054 - transformer_training - INFO - Main loop iteration: 4882
2025-04-25 13:12:19,504 - transformer_training - INFO - Main loop iteration: 4883
2025-04-25 13:12:20,003 - transformer_training - INFO - Main loop iteration: 4884
2025-04-25 13:12:20,404 - transformer_training - INFO - Main loop iteration: 4885
2025-04-25 13:12:20,865 - transformer_training - INFO - Main loop iteration: 4886
2025-04-25 13:12:21,317 - transformer_training - INFO - Main loop iteration: 4887
2025-04-25 13:12:21,815 - transformer_training - INFO - Main loop iteration: 4888
2025-04-25 13:12:22,218 - transformer_training - INFO - Main loop iteration: 4889
2025-04-25 13:12:22,680 - transformer_training - INFO - Main loop iteration: 4890
Iter 4890: loss 3.6630, lr 0.000986, 81642.38 tokens/sec
2025-04-25 13:12:23,132 - transformer_training - INFO - Main loop iteration: 4891
2025-04-25 13:12:23,631 - transformer_training - INFO - Main loop iteration: 4892
2025-04-25 13:12:24,033 - transformer_training - INFO - Main loop iteration: 4893
2025-04-25 13:12:24,494 - transformer_training - INFO - Main loop iteration: 4894
2025-04-25 13:12:24,944 - transformer_training - INFO - Main loop iteration: 4895
2025-04-25 13:12:25,443 - transformer_training - INFO - Main loop iteration: 4896
2025-04-25 13:12:25,844 - transformer_training - INFO - Main loop iteration: 4897
2025-04-25 13:12:26,306 - transformer_training - INFO - Main loop iteration: 4898
2025-04-25 13:12:26,757 - transformer_training - INFO - Main loop iteration: 4899
2025-04-25 13:12:27,255 - transformer_training - INFO - Main loop iteration: 4900
Iter 4900: loss 3.7262, lr 0.000986, 91836.58 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
terminate called without an active exception
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 4900: train loss 3.5951, val loss 3.5176
New best model saved with val loss: 3.5176
2025-04-25 13:12:45,238 - transformer_training - INFO - Main loop iteration: 4901
2025-04-25 13:12:45,658 - transformer_training - INFO - Main loop iteration: 4902
2025-04-25 13:12:46,105 - transformer_training - INFO - Main loop iteration: 4903
2025-04-25 13:12:46,604 - transformer_training - INFO - Main loop iteration: 4904
2025-04-25 13:12:47,005 - transformer_training - INFO - Main loop iteration: 4905
2025-04-25 13:12:47,465 - transformer_training - INFO - Main loop iteration: 4906
2025-04-25 13:12:47,916 - transformer_training - INFO - Main loop iteration: 4907
2025-04-25 13:12:48,416 - transformer_training - INFO - Main loop iteration: 4908
2025-04-25 13:12:48,816 - transformer_training - INFO - Main loop iteration: 4909
2025-04-25 13:12:49,276 - transformer_training - INFO - Main loop iteration: 4910
Iter 4910: loss 3.6237, lr 0.000986, 82007.67 tokens/sec
2025-04-25 13:12:49,727 - transformer_training - INFO - Main loop iteration: 4911
2025-04-25 13:12:50,225 - transformer_training - INFO - Main loop iteration: 4912
2025-04-25 13:12:50,625 - transformer_training - INFO - Main loop iteration: 4913
2025-04-25 13:12:51,086 - transformer_training - INFO - Main loop iteration: 4914
2025-04-25 13:12:51,536 - transformer_training - INFO - Main loop iteration: 4915
2025-04-25 13:12:52,035 - transformer_training - INFO - Main loop iteration: 4916
2025-04-25 13:12:52,436 - transformer_training - INFO - Main loop iteration: 4917
2025-04-25 13:12:52,896 - transformer_training - INFO - Main loop iteration: 4918
2025-04-25 13:12:53,347 - transformer_training - INFO - Main loop iteration: 4919
2025-04-25 13:12:53,846 - transformer_training - INFO - Main loop iteration: 4920
Iter 4920: loss 3.6225, lr 0.000986, 91993.84 tokens/sec
2025-04-25 13:12:54,247 - transformer_training - INFO - Main loop iteration: 4921
2025-04-25 13:12:54,708 - transformer_training - INFO - Main loop iteration: 4922
2025-04-25 13:12:55,159 - transformer_training - INFO - Main loop iteration: 4923
2025-04-25 13:12:55,657 - transformer_training - INFO - Main loop iteration: 4924
2025-04-25 13:12:56,058 - transformer_training - INFO - Main loop iteration: 4925
2025-04-25 13:12:56,519 - transformer_training - INFO - Main loop iteration: 4926
2025-04-25 13:12:56,970 - transformer_training - INFO - Main loop iteration: 4927
2025-04-25 13:12:57,468 - transformer_training - INFO - Main loop iteration: 4928
2025-04-25 13:12:57,869 - transformer_training - INFO - Main loop iteration: 4929
2025-04-25 13:12:58,330 - transformer_training - INFO - Main loop iteration: 4930
Iter 4930: loss 3.7551, lr 0.000985, 81988.06 tokens/sec
2025-04-25 13:12:58,780 - transformer_training - INFO - Main loop iteration: 4931
2025-04-25 13:12:59,278 - transformer_training - INFO - Main loop iteration: 4932
2025-04-25 13:12:59,679 - transformer_training - INFO - Main loop iteration: 4933
2025-04-25 13:13:00,140 - transformer_training - INFO - Main loop iteration: 4934
2025-04-25 13:13:00,590 - transformer_training - INFO - Main loop iteration: 4935
2025-04-25 13:13:01,088 - transformer_training - INFO - Main loop iteration: 4936
2025-04-25 13:13:01,489 - transformer_training - INFO - Main loop iteration: 4937
2025-04-25 13:13:01,950 - transformer_training - INFO - Main loop iteration: 4938
2025-04-25 13:13:02,401 - transformer_training - INFO - Main loop iteration: 4939
2025-04-25 13:13:02,899 - transformer_training - INFO - Main loop iteration: 4940
Iter 4940: loss 3.7325, lr 0.000985, 91989.35 tokens/sec
2025-04-25 13:13:03,300 - transformer_training - INFO - Main loop iteration: 4941
2025-04-25 13:13:03,761 - transformer_training - INFO - Main loop iteration: 4942
2025-04-25 13:13:04,211 - transformer_training - INFO - Main loop iteration: 4943
2025-04-25 13:13:04,710 - transformer_training - INFO - Main loop iteration: 4944
2025-04-25 13:13:05,110 - transformer_training - INFO - Main loop iteration: 4945
2025-04-25 13:13:05,571 - transformer_training - INFO - Main loop iteration: 4946
2025-04-25 13:13:06,021 - transformer_training - INFO - Main loop iteration: 4947
2025-04-25 13:13:06,520 - transformer_training - INFO - Main loop iteration: 4948
2025-04-25 13:13:06,920 - transformer_training - INFO - Main loop iteration: 4949
2025-04-25 13:13:07,381 - transformer_training - INFO - Main loop iteration: 4950
Iter 4950: loss 3.6742, lr 0.000985, 81989.28 tokens/sec
2025-04-25 13:13:07,832 - transformer_training - INFO - Main loop iteration: 4951
2025-04-25 13:13:08,331 - transformer_training - INFO - Main loop iteration: 4952
2025-04-25 13:13:08,731 - transformer_training - INFO - Main loop iteration: 4953
2025-04-25 13:13:09,192 - transformer_training - INFO - Main loop iteration: 4954
2025-04-25 13:13:09,642 - transformer_training - INFO - Main loop iteration: 4955
2025-04-25 13:13:10,141 - transformer_training - INFO - Main loop iteration: 4956
2025-04-25 13:13:10,542 - transformer_training - INFO - Main loop iteration: 4957
2025-04-25 13:13:11,002 - transformer_training - INFO - Main loop iteration: 4958
2025-04-25 13:13:11,452 - transformer_training - INFO - Main loop iteration: 4959
2025-04-25 13:13:11,952 - transformer_training - INFO - Main loop iteration: 4960
Iter 4960: loss 3.6305, lr 0.000985, 92090.60 tokens/sec
2025-04-25 13:13:12,352 - transformer_training - INFO - Main loop iteration: 4961
2025-04-25 13:13:12,813 - transformer_training - INFO - Main loop iteration: 4962
2025-04-25 13:13:13,263 - transformer_training - INFO - Main loop iteration: 4963
2025-04-25 13:13:13,763 - transformer_training - INFO - Main loop iteration: 4964
2025-04-25 13:13:14,163 - transformer_training - INFO - Main loop iteration: 4965
2025-04-25 13:13:14,624 - transformer_training - INFO - Main loop iteration: 4966
2025-04-25 13:13:15,074 - transformer_training - INFO - Main loop iteration: 4967
2025-04-25 13:13:15,574 - transformer_training - INFO - Main loop iteration: 4968
2025-04-25 13:13:15,974 - transformer_training - INFO - Main loop iteration: 4969
2025-04-25 13:13:16,435 - transformer_training - INFO - Main loop iteration: 4970
Iter 4970: loss 3.6470, lr 0.000985, 81941.31 tokens/sec
2025-04-25 13:13:16,886 - transformer_training - INFO - Main loop iteration: 4971
2025-04-25 13:13:17,386 - transformer_training - INFO - Main loop iteration: 4972
2025-04-25 13:13:17,786 - transformer_training - INFO - Main loop iteration: 4973
2025-04-25 13:13:18,247 - transformer_training - INFO - Main loop iteration: 4974
2025-04-25 13:13:18,698 - transformer_training - INFO - Main loop iteration: 4975
2025-04-25 13:13:19,197 - transformer_training - INFO - Main loop iteration: 4976
2025-04-25 13:13:19,598 - transformer_training - INFO - Main loop iteration: 4977
2025-04-25 13:13:20,059 - transformer_training - INFO - Main loop iteration: 4978
2025-04-25 13:13:20,509 - transformer_training - INFO - Main loop iteration: 4979
2025-04-25 13:13:21,008 - transformer_training - INFO - Main loop iteration: 4980
Iter 4980: loss 3.6835, lr 0.000985, 91996.57 tokens/sec
2025-04-25 13:13:21,409 - transformer_training - INFO - Main loop iteration: 4981
2025-04-25 13:13:21,870 - transformer_training - INFO - Main loop iteration: 4982
2025-04-25 13:13:22,321 - transformer_training - INFO - Main loop iteration: 4983
2025-04-25 13:13:22,820 - transformer_training - INFO - Main loop iteration: 4984
2025-04-25 13:13:23,220 - transformer_training - INFO - Main loop iteration: 4985
2025-04-25 13:13:23,681 - transformer_training - INFO - Main loop iteration: 4986
2025-04-25 13:13:24,131 - transformer_training - INFO - Main loop iteration: 4987
2025-04-25 13:13:24,630 - transformer_training - INFO - Main loop iteration: 4988
2025-04-25 13:13:25,031 - transformer_training - INFO - Main loop iteration: 4989
2025-04-25 13:13:25,492 - transformer_training - INFO - Main loop iteration: 4990
Iter 4990: loss 3.6517, lr 0.000985, 81978.06 tokens/sec
2025-04-25 13:13:25,942 - transformer_training - INFO - Main loop iteration: 4991
2025-04-25 13:13:26,441 - transformer_training - INFO - Main loop iteration: 4992
2025-04-25 13:13:26,841 - transformer_training - INFO - Main loop iteration: 4993
2025-04-25 13:13:27,302 - transformer_training - INFO - Main loop iteration: 4994
2025-04-25 13:13:27,752 - transformer_training - INFO - Main loop iteration: 4995
2025-04-25 13:13:28,252 - transformer_training - INFO - Main loop iteration: 4996
2025-04-25 13:13:28,653 - transformer_training - INFO - Main loop iteration: 4997
2025-04-25 13:13:29,113 - transformer_training - INFO - Main loop iteration: 4998
2025-04-25 13:13:29,564 - transformer_training - INFO - Main loop iteration: 4999
2025-04-25 13:13:30,062 - transformer_training - INFO - Main loop iteration: 5000
Iter 5000: loss 3.6313, lr 0.000985, 92093.61 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 5000: train loss 3.5943, val loss 3.4976
New best model saved with val loss: 3.4976
2025-04-25 13:13:49,914 - transformer_training - INFO - Main loop iteration: 5001
2025-04-25 13:13:50,326 - transformer_training - INFO - Main loop iteration: 5002
2025-04-25 13:13:50,776 - transformer_training - INFO - Main loop iteration: 5003
2025-04-25 13:13:51,276 - transformer_training - INFO - Main loop iteration: 5004
2025-04-25 13:13:51,677 - transformer_training - INFO - Main loop iteration: 5005
2025-04-25 13:13:52,139 - transformer_training - INFO - Main loop iteration: 5006
2025-04-25 13:13:52,589 - transformer_training - INFO - Main loop iteration: 5007
2025-04-25 13:13:53,088 - transformer_training - INFO - Main loop iteration: 5008
2025-04-25 13:13:53,490 - transformer_training - INFO - Main loop iteration: 5009
2025-04-25 13:13:53,951 - transformer_training - INFO - Main loop iteration: 5010
Iter 5010: loss 3.6681, lr 0.000985, 82113.90 tokens/sec
2025-04-25 13:13:54,401 - transformer_training - INFO - Main loop iteration: 5011
2025-04-25 13:13:54,901 - transformer_training - INFO - Main loop iteration: 5012
2025-04-25 13:13:55,302 - transformer_training - INFO - Main loop iteration: 5013
2025-04-25 13:13:55,763 - transformer_training - INFO - Main loop iteration: 5014
2025-04-25 13:13:56,213 - transformer_training - INFO - Main loop iteration: 5015
2025-04-25 13:13:56,712 - transformer_training - INFO - Main loop iteration: 5016
2025-04-25 13:13:57,112 - transformer_training - INFO - Main loop iteration: 5017
2025-04-25 13:13:57,573 - transformer_training - INFO - Main loop iteration: 5018
2025-04-25 13:13:58,024 - transformer_training - INFO - Main loop iteration: 5019
2025-04-25 13:13:58,524 - transformer_training - INFO - Main loop iteration: 5020
Iter 5020: loss 3.7394, lr 0.000985, 92147.18 tokens/sec
2025-04-25 13:13:58,924 - transformer_training - INFO - Main loop iteration: 5021
2025-04-25 13:13:59,385 - transformer_training - INFO - Main loop iteration: 5022
2025-04-25 13:13:59,835 - transformer_training - INFO - Main loop iteration: 5023
2025-04-25 13:14:00,334 - transformer_training - INFO - Main loop iteration: 5024
2025-04-25 13:14:00,736 - transformer_training - INFO - Main loop iteration: 5025
2025-04-25 13:14:01,197 - transformer_training - INFO - Main loop iteration: 5026
2025-04-25 13:14:01,648 - transformer_training - INFO - Main loop iteration: 5027
2025-04-25 13:14:02,150 - transformer_training - INFO - Main loop iteration: 5028
2025-04-25 13:14:02,551 - transformer_training - INFO - Main loop iteration: 5029
2025-04-25 13:14:03,012 - transformer_training - INFO - Main loop iteration: 5030
Iter 5030: loss 3.5440, lr 0.000984, 82123.93 tokens/sec
2025-04-25 13:14:03,462 - transformer_training - INFO - Main loop iteration: 5031
2025-04-25 13:14:03,961 - transformer_training - INFO - Main loop iteration: 5032
2025-04-25 13:14:04,362 - transformer_training - INFO - Main loop iteration: 5033
2025-04-25 13:14:04,823 - transformer_training - INFO - Main loop iteration: 5034
2025-04-25 13:14:05,273 - transformer_training - INFO - Main loop iteration: 5035
2025-04-25 13:14:05,772 - transformer_training - INFO - Main loop iteration: 5036
2025-04-25 13:14:06,173 - transformer_training - INFO - Main loop iteration: 5037
2025-04-25 13:14:06,633 - transformer_training - INFO - Main loop iteration: 5038
2025-04-25 13:14:07,083 - transformer_training - INFO - Main loop iteration: 5039
2025-04-25 13:14:07,583 - transformer_training - INFO - Main loop iteration: 5040
Iter 5040: loss 3.6316, lr 0.000984, 92031.23 tokens/sec
2025-04-25 13:14:07,984 - transformer_training - INFO - Main loop iteration: 5041
2025-04-25 13:14:08,445 - transformer_training - INFO - Main loop iteration: 5042
2025-04-25 13:14:08,895 - transformer_training - INFO - Main loop iteration: 5043
2025-04-25 13:14:09,395 - transformer_training - INFO - Main loop iteration: 5044
2025-04-25 13:14:09,795 - transformer_training - INFO - Main loop iteration: 5045
2025-04-25 13:14:10,257 - transformer_training - INFO - Main loop iteration: 5046
2025-04-25 13:14:10,707 - transformer_training - INFO - Main loop iteration: 5047
2025-04-25 13:14:11,206 - transformer_training - INFO - Main loop iteration: 5048
2025-04-25 13:14:11,607 - transformer_training - INFO - Main loop iteration: 5049
2025-04-25 13:14:12,069 - transformer_training - INFO - Main loop iteration: 5050
Iter 5050: loss 3.7302, lr 0.000984, 82232.38 tokens/sec
2025-04-25 13:14:12,519 - transformer_training - INFO - Main loop iteration: 5051
2025-04-25 13:14:13,018 - transformer_training - INFO - Main loop iteration: 5052
2025-04-25 13:14:13,419 - transformer_training - INFO - Main loop iteration: 5053
2025-04-25 13:14:13,880 - transformer_training - INFO - Main loop iteration: 5054
2025-04-25 13:14:14,331 - transformer_training - INFO - Main loop iteration: 5055
2025-04-25 13:14:14,830 - transformer_training - INFO - Main loop iteration: 5056
2025-04-25 13:14:15,231 - transformer_training - INFO - Main loop iteration: 5057
2025-04-25 13:14:15,692 - transformer_training - INFO - Main loop iteration: 5058
2025-04-25 13:14:16,142 - transformer_training - INFO - Main loop iteration: 5059
2025-04-25 13:14:16,644 - transformer_training - INFO - Main loop iteration: 5060
Iter 5060: loss 3.5950, lr 0.000984, 91954.06 tokens/sec
2025-04-25 13:14:17,045 - transformer_training - INFO - Main loop iteration: 5061
2025-04-25 13:14:17,507 - transformer_training - INFO - Main loop iteration: 5062
2025-04-25 13:14:17,957 - transformer_training - INFO - Main loop iteration: 5063
2025-04-25 13:14:18,457 - transformer_training - INFO - Main loop iteration: 5064
2025-04-25 13:14:18,858 - transformer_training - INFO - Main loop iteration: 5065
2025-04-25 13:14:19,318 - transformer_training - INFO - Main loop iteration: 5066
2025-04-25 13:14:19,768 - transformer_training - INFO - Main loop iteration: 5067
2025-04-25 13:14:20,268 - transformer_training - INFO - Main loop iteration: 5068
2025-04-25 13:14:20,668 - transformer_training - INFO - Main loop iteration: 5069
2025-04-25 13:14:21,129 - transformer_training - INFO - Main loop iteration: 5070
Iter 5070: loss 3.6358, lr 0.000984, 81850.95 tokens/sec
2025-04-25 13:14:21,580 - transformer_training - INFO - Main loop iteration: 5071
2025-04-25 13:14:22,080 - transformer_training - INFO - Main loop iteration: 5072
2025-04-25 13:14:22,480 - transformer_training - INFO - Main loop iteration: 5073
2025-04-25 13:14:22,941 - transformer_training - INFO - Main loop iteration: 5074
2025-04-25 13:14:23,391 - transformer_training - INFO - Main loop iteration: 5075
2025-04-25 13:14:23,890 - transformer_training - INFO - Main loop iteration: 5076
2025-04-25 13:14:24,291 - transformer_training - INFO - Main loop iteration: 5077
2025-04-25 13:14:24,752 - transformer_training - INFO - Main loop iteration: 5078
2025-04-25 13:14:25,202 - transformer_training - INFO - Main loop iteration: 5079
2025-04-25 13:14:25,702 - transformer_training - INFO - Main loop iteration: 5080
Iter 5080: loss 3.6879, lr 0.000984, 92111.11 tokens/sec
2025-04-25 13:14:26,103 - transformer_training - INFO - Main loop iteration: 5081
2025-04-25 13:14:26,563 - transformer_training - INFO - Main loop iteration: 5082
2025-04-25 13:14:27,014 - transformer_training - INFO - Main loop iteration: 5083
2025-04-25 13:14:27,513 - transformer_training - INFO - Main loop iteration: 5084
2025-04-25 13:14:27,914 - transformer_training - INFO - Main loop iteration: 5085
2025-04-25 13:14:28,376 - transformer_training - INFO - Main loop iteration: 5086
2025-04-25 13:14:28,826 - transformer_training - INFO - Main loop iteration: 5087
2025-04-25 13:14:29,325 - transformer_training - INFO - Main loop iteration: 5088
2025-04-25 13:14:29,726 - transformer_training - INFO - Main loop iteration: 5089
2025-04-25 13:14:30,187 - transformer_training - INFO - Main loop iteration: 5090
Iter 5090: loss 3.5852, lr 0.000984, 81980.76 tokens/sec
2025-04-25 13:14:30,638 - transformer_training - INFO - Main loop iteration: 5091
2025-04-25 13:14:31,137 - transformer_training - INFO - Main loop iteration: 5092
2025-04-25 13:14:31,538 - transformer_training - INFO - Main loop iteration: 5093
2025-04-25 13:14:31,999 - transformer_training - INFO - Main loop iteration: 5094
2025-04-25 13:14:32,450 - transformer_training - INFO - Main loop iteration: 5095
2025-04-25 13:14:32,951 - transformer_training - INFO - Main loop iteration: 5096
2025-04-25 13:14:33,351 - transformer_training - INFO - Main loop iteration: 5097
2025-04-25 13:14:33,812 - transformer_training - INFO - Main loop iteration: 5098
2025-04-25 13:14:34,263 - transformer_training - INFO - Main loop iteration: 5099
2025-04-25 13:14:34,762 - transformer_training - INFO - Main loop iteration: 5100
Iter 5100: loss 3.7197, lr 0.000984, 92071.35 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 5100: train loss 3.5848, val loss 3.4930
New best model saved with val loss: 3.4930
2025-04-25 13:14:53,174 - transformer_training - INFO - Main loop iteration: 5101
2025-04-25 13:14:53,592 - transformer_training - INFO - Main loop iteration: 5102
2025-04-25 13:14:54,042 - transformer_training - INFO - Main loop iteration: 5103
2025-04-25 13:14:54,540 - transformer_training - INFO - Main loop iteration: 5104
2025-04-25 13:14:54,940 - transformer_training - INFO - Main loop iteration: 5105
2025-04-25 13:14:55,401 - transformer_training - INFO - Main loop iteration: 5106
2025-04-25 13:14:55,851 - transformer_training - INFO - Main loop iteration: 5107
2025-04-25 13:14:56,350 - transformer_training - INFO - Main loop iteration: 5108
2025-04-25 13:14:56,750 - transformer_training - INFO - Main loop iteration: 5109
2025-04-25 13:14:57,211 - transformer_training - INFO - Main loop iteration: 5110
Iter 5110: loss 3.6284, lr 0.000984, 82064.91 tokens/sec
2025-04-25 13:14:57,660 - transformer_training - INFO - Main loop iteration: 5111
2025-04-25 13:14:58,161 - transformer_training - INFO - Main loop iteration: 5112
2025-04-25 13:14:58,561 - transformer_training - INFO - Main loop iteration: 5113
2025-04-25 13:14:59,021 - transformer_training - INFO - Main loop iteration: 5114
2025-04-25 13:14:59,472 - transformer_training - INFO - Main loop iteration: 5115
2025-04-25 13:14:59,970 - transformer_training - INFO - Main loop iteration: 5116
2025-04-25 13:15:00,371 - transformer_training - INFO - Main loop iteration: 5117
2025-04-25 13:15:00,831 - transformer_training - INFO - Main loop iteration: 5118
2025-04-25 13:15:01,281 - transformer_training - INFO - Main loop iteration: 5119
2025-04-25 13:15:01,781 - transformer_training - INFO - Main loop iteration: 5120
Iter 5120: loss 3.6429, lr 0.000984, 91997.06 tokens/sec
2025-04-25 13:15:02,182 - transformer_training - INFO - Main loop iteration: 5121
2025-04-25 13:15:02,643 - transformer_training - INFO - Main loop iteration: 5122
2025-04-25 13:15:03,094 - transformer_training - INFO - Main loop iteration: 5123
2025-04-25 13:15:03,592 - transformer_training - INFO - Main loop iteration: 5124
2025-04-25 13:15:03,993 - transformer_training - INFO - Main loop iteration: 5125
2025-04-25 13:15:04,454 - transformer_training - INFO - Main loop iteration: 5126
2025-04-25 13:15:04,905 - transformer_training - INFO - Main loop iteration: 5127
2025-04-25 13:15:05,403 - transformer_training - INFO - Main loop iteration: 5128
2025-04-25 13:15:05,804 - transformer_training - INFO - Main loop iteration: 5129
2025-04-25 13:15:06,264 - transformer_training - INFO - Main loop iteration: 5130
Iter 5130: loss 3.5265, lr 0.000983, 81979.41 tokens/sec
2025-04-25 13:15:06,715 - transformer_training - INFO - Main loop iteration: 5131
2025-04-25 13:15:07,213 - transformer_training - INFO - Main loop iteration: 5132
2025-04-25 13:15:07,614 - transformer_training - INFO - Main loop iteration: 5133
2025-04-25 13:15:08,075 - transformer_training - INFO - Main loop iteration: 5134
2025-04-25 13:15:08,525 - transformer_training - INFO - Main loop iteration: 5135
2025-04-25 13:15:09,024 - transformer_training - INFO - Main loop iteration: 5136
2025-04-25 13:15:09,424 - transformer_training - INFO - Main loop iteration: 5137
2025-04-25 13:15:09,885 - transformer_training - INFO - Main loop iteration: 5138
2025-04-25 13:15:10,335 - transformer_training - INFO - Main loop iteration: 5139
2025-04-25 13:15:10,834 - transformer_training - INFO - Main loop iteration: 5140
Iter 5140: loss 3.6701, lr 0.000983, 92144.33 tokens/sec
2025-04-25 13:15:11,235 - transformer_training - INFO - Main loop iteration: 5141
2025-04-25 13:15:11,695 - transformer_training - INFO - Main loop iteration: 5142
2025-04-25 13:15:12,146 - transformer_training - INFO - Main loop iteration: 5143
2025-04-25 13:15:12,645 - transformer_training - INFO - Main loop iteration: 5144
2025-04-25 13:15:13,046 - transformer_training - INFO - Main loop iteration: 5145
2025-04-25 13:15:13,506 - transformer_training - INFO - Main loop iteration: 5146
2025-04-25 13:15:13,957 - transformer_training - INFO - Main loop iteration: 5147
2025-04-25 13:15:14,456 - transformer_training - INFO - Main loop iteration: 5148
2025-04-25 13:15:14,857 - transformer_training - INFO - Main loop iteration: 5149
2025-04-25 13:15:15,317 - transformer_training - INFO - Main loop iteration: 5150
Iter 5150: loss 3.6543, lr 0.000983, 81965.42 tokens/sec
2025-04-25 13:15:15,768 - transformer_training - INFO - Main loop iteration: 5151
2025-04-25 13:15:16,266 - transformer_training - INFO - Main loop iteration: 5152
2025-04-25 13:15:16,667 - transformer_training - INFO - Main loop iteration: 5153
2025-04-25 13:15:17,128 - transformer_training - INFO - Main loop iteration: 5154
2025-04-25 13:15:17,578 - transformer_training - INFO - Main loop iteration: 5155
2025-04-25 13:15:18,077 - transformer_training - INFO - Main loop iteration: 5156
2025-04-25 13:15:18,478 - transformer_training - INFO - Main loop iteration: 5157
2025-04-25 13:15:18,939 - transformer_training - INFO - Main loop iteration: 5158
2025-04-25 13:15:19,390 - transformer_training - INFO - Main loop iteration: 5159
2025-04-25 13:15:19,889 - transformer_training - INFO - Main loop iteration: 5160
Iter 5160: loss 3.6651, lr 0.000983, 92110.40 tokens/sec
2025-04-25 13:15:20,290 - transformer_training - INFO - Main loop iteration: 5161
2025-04-25 13:15:20,750 - transformer_training - INFO - Main loop iteration: 5162
2025-04-25 13:15:21,201 - transformer_training - INFO - Main loop iteration: 5163
2025-04-25 13:15:21,700 - transformer_training - INFO - Main loop iteration: 5164
2025-04-25 13:15:22,102 - transformer_training - INFO - Main loop iteration: 5165
2025-04-25 13:15:22,564 - transformer_training - INFO - Main loop iteration: 5166
2025-04-25 13:15:23,014 - transformer_training - INFO - Main loop iteration: 5167
2025-04-25 13:15:23,513 - transformer_training - INFO - Main loop iteration: 5168
2025-04-25 13:15:23,914 - transformer_training - INFO - Main loop iteration: 5169
2025-04-25 13:15:24,375 - transformer_training - INFO - Main loop iteration: 5170
Iter 5170: loss 3.6382, lr 0.000983, 82015.72 tokens/sec
2025-04-25 13:15:24,825 - transformer_training - INFO - Main loop iteration: 5171
2025-04-25 13:15:25,324 - transformer_training - INFO - Main loop iteration: 5172
2025-04-25 13:15:25,725 - transformer_training - INFO - Main loop iteration: 5173
2025-04-25 13:15:26,186 - transformer_training - INFO - Main loop iteration: 5174
2025-04-25 13:15:26,637 - transformer_training - INFO - Main loop iteration: 5175
2025-04-25 13:15:27,136 - transformer_training - INFO - Main loop iteration: 5176
2025-04-25 13:15:27,537 - transformer_training - INFO - Main loop iteration: 5177
2025-04-25 13:15:27,998 - transformer_training - INFO - Main loop iteration: 5178
2025-04-25 13:15:28,448 - transformer_training - INFO - Main loop iteration: 5179
2025-04-25 13:15:28,947 - transformer_training - INFO - Main loop iteration: 5180
Iter 5180: loss 3.6895, lr 0.000983, 92082.15 tokens/sec
2025-04-25 13:15:29,348 - transformer_training - INFO - Main loop iteration: 5181
2025-04-25 13:15:29,809 - transformer_training - INFO - Main loop iteration: 5182
2025-04-25 13:15:30,259 - transformer_training - INFO - Main loop iteration: 5183
2025-04-25 13:15:30,758 - transformer_training - INFO - Main loop iteration: 5184
2025-04-25 13:15:31,159 - transformer_training - INFO - Main loop iteration: 5185
2025-04-25 13:15:31,620 - transformer_training - INFO - Main loop iteration: 5186
2025-04-25 13:15:32,070 - transformer_training - INFO - Main loop iteration: 5187
2025-04-25 13:15:32,570 - transformer_training - INFO - Main loop iteration: 5188
2025-04-25 13:15:32,971 - transformer_training - INFO - Main loop iteration: 5189
2025-04-25 13:15:33,432 - transformer_training - INFO - Main loop iteration: 5190
Iter 5190: loss 3.5614, lr 0.000983, 81853.68 tokens/sec
2025-04-25 13:15:33,883 - transformer_training - INFO - Main loop iteration: 5191
2025-04-25 13:15:34,382 - transformer_training - INFO - Main loop iteration: 5192
2025-04-25 13:15:34,783 - transformer_training - INFO - Main loop iteration: 5193
2025-04-25 13:15:35,244 - transformer_training - INFO - Main loop iteration: 5194
2025-04-25 13:15:35,695 - transformer_training - INFO - Main loop iteration: 5195
2025-04-25 13:15:36,195 - transformer_training - INFO - Main loop iteration: 5196
2025-04-25 13:15:36,595 - transformer_training - INFO - Main loop iteration: 5197
2025-04-25 13:15:37,056 - transformer_training - INFO - Main loop iteration: 5198
2025-04-25 13:15:37,508 - transformer_training - INFO - Main loop iteration: 5199
2025-04-25 13:15:38,008 - transformer_training - INFO - Main loop iteration: 5200
Iter 5200: loss 3.6065, lr 0.000983, 91890.89 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5200: train loss 3.5677, val loss 3.4815
New best model saved with val loss: 3.4815
2025-04-25 13:15:55,397 - transformer_training - INFO - Main loop iteration: 5201
2025-04-25 13:15:55,807 - transformer_training - INFO - Main loop iteration: 5202
2025-04-25 13:15:56,258 - transformer_training - INFO - Main loop iteration: 5203
2025-04-25 13:15:56,757 - transformer_training - INFO - Main loop iteration: 5204
2025-04-25 13:15:57,158 - transformer_training - INFO - Main loop iteration: 5205
2025-04-25 13:15:57,619 - transformer_training - INFO - Main loop iteration: 5206
2025-04-25 13:15:58,070 - transformer_training - INFO - Main loop iteration: 5207
2025-04-25 13:15:58,570 - transformer_training - INFO - Main loop iteration: 5208
2025-04-25 13:15:58,970 - transformer_training - INFO - Main loop iteration: 5209
2025-04-25 13:15:59,433 - transformer_training - INFO - Main loop iteration: 5210
Iter 5210: loss 3.6497, lr 0.000983, 81846.06 tokens/sec
2025-04-25 13:15:59,885 - transformer_training - INFO - Main loop iteration: 5211
2025-04-25 13:16:00,384 - transformer_training - INFO - Main loop iteration: 5212
2025-04-25 13:16:00,785 - transformer_training - INFO - Main loop iteration: 5213
2025-04-25 13:16:01,245 - transformer_training - INFO - Main loop iteration: 5214
2025-04-25 13:16:01,696 - transformer_training - INFO - Main loop iteration: 5215
2025-04-25 13:16:02,195 - transformer_training - INFO - Main loop iteration: 5216
2025-04-25 13:16:02,596 - transformer_training - INFO - Main loop iteration: 5217
2025-04-25 13:16:03,056 - transformer_training - INFO - Main loop iteration: 5218
2025-04-25 13:16:03,507 - transformer_training - INFO - Main loop iteration: 5219
2025-04-25 13:16:04,006 - transformer_training - INFO - Main loop iteration: 5220
Iter 5220: loss 3.5603, lr 0.000982, 92082.97 tokens/sec
2025-04-25 13:16:04,407 - transformer_training - INFO - Main loop iteration: 5221
2025-04-25 13:16:04,868 - transformer_training - INFO - Main loop iteration: 5222
2025-04-25 13:16:05,321 - transformer_training - INFO - Main loop iteration: 5223
2025-04-25 13:16:05,821 - transformer_training - INFO - Main loop iteration: 5224
2025-04-25 13:16:06,222 - transformer_training - INFO - Main loop iteration: 5225
2025-04-25 13:16:06,683 - transformer_training - INFO - Main loop iteration: 5226
2025-04-25 13:16:07,134 - transformer_training - INFO - Main loop iteration: 5227
2025-04-25 13:16:07,633 - transformer_training - INFO - Main loop iteration: 5228
2025-04-25 13:16:08,034 - transformer_training - INFO - Main loop iteration: 5229
2025-04-25 13:16:08,497 - transformer_training - INFO - Main loop iteration: 5230
Iter 5230: loss 3.6363, lr 0.000982, 82227.48 tokens/sec
2025-04-25 13:16:08,946 - transformer_training - INFO - Main loop iteration: 5231
2025-04-25 13:16:09,446 - transformer_training - INFO - Main loop iteration: 5232
2025-04-25 13:16:09,847 - transformer_training - INFO - Main loop iteration: 5233
2025-04-25 13:16:10,308 - transformer_training - INFO - Main loop iteration: 5234
2025-04-25 13:16:10,758 - transformer_training - INFO - Main loop iteration: 5235
2025-04-25 13:16:11,258 - transformer_training - INFO - Main loop iteration: 5236
2025-04-25 13:16:11,658 - transformer_training - INFO - Main loop iteration: 5237
2025-04-25 13:16:12,119 - transformer_training - INFO - Main loop iteration: 5238
2025-04-25 13:16:12,570 - transformer_training - INFO - Main loop iteration: 5239
2025-04-25 13:16:13,070 - transformer_training - INFO - Main loop iteration: 5240
Iter 5240: loss 3.5312, lr 0.000982, 92074.91 tokens/sec
2025-04-25 13:16:13,470 - transformer_training - INFO - Main loop iteration: 5241
2025-04-25 13:16:13,932 - transformer_training - INFO - Main loop iteration: 5242
2025-04-25 13:16:14,382 - transformer_training - INFO - Main loop iteration: 5243
2025-04-25 13:16:14,882 - transformer_training - INFO - Main loop iteration: 5244
2025-04-25 13:16:15,283 - transformer_training - INFO - Main loop iteration: 5245
2025-04-25 13:16:15,744 - transformer_training - INFO - Main loop iteration: 5246
2025-04-25 13:16:16,194 - transformer_training - INFO - Main loop iteration: 5247
2025-04-25 13:16:16,694 - transformer_training - INFO - Main loop iteration: 5248
2025-04-25 13:16:17,095 - transformer_training - INFO - Main loop iteration: 5249
2025-04-25 13:16:17,555 - transformer_training - INFO - Main loop iteration: 5250
Iter 5250: loss 3.6961, lr 0.000982, 81981.23 tokens/sec
2025-04-25 13:16:18,006 - transformer_training - INFO - Main loop iteration: 5251
2025-04-25 13:16:18,506 - transformer_training - INFO - Main loop iteration: 5252
2025-04-25 13:16:18,907 - transformer_training - INFO - Main loop iteration: 5253
2025-04-25 13:16:19,368 - transformer_training - INFO - Main loop iteration: 5254
2025-04-25 13:16:19,818 - transformer_training - INFO - Main loop iteration: 5255
2025-04-25 13:16:20,319 - transformer_training - INFO - Main loop iteration: 5256
2025-04-25 13:16:20,719 - transformer_training - INFO - Main loop iteration: 5257
2025-04-25 13:16:21,181 - transformer_training - INFO - Main loop iteration: 5258
2025-04-25 13:16:21,631 - transformer_training - INFO - Main loop iteration: 5259
2025-04-25 13:16:22,131 - transformer_training - INFO - Main loop iteration: 5260
Iter 5260: loss 3.5848, lr 0.000982, 92015.13 tokens/sec
2025-04-25 13:16:22,532 - transformer_training - INFO - Main loop iteration: 5261
2025-04-25 13:16:22,993 - transformer_training - INFO - Main loop iteration: 5262
2025-04-25 13:16:23,443 - transformer_training - INFO - Main loop iteration: 5263
2025-04-25 13:16:23,943 - transformer_training - INFO - Main loop iteration: 5264
2025-04-25 13:16:24,344 - transformer_training - INFO - Main loop iteration: 5265
2025-04-25 13:16:24,805 - transformer_training - INFO - Main loop iteration: 5266
2025-04-25 13:16:25,256 - transformer_training - INFO - Main loop iteration: 5267
2025-04-25 13:16:25,755 - transformer_training - INFO - Main loop iteration: 5268
2025-04-25 13:16:26,156 - transformer_training - INFO - Main loop iteration: 5269
2025-04-25 13:16:26,617 - transformer_training - INFO - Main loop iteration: 5270
Iter 5270: loss 3.6710, lr 0.000982, 82062.91 tokens/sec
2025-04-25 13:16:27,068 - transformer_training - INFO - Main loop iteration: 5271
2025-04-25 13:16:27,567 - transformer_training - INFO - Main loop iteration: 5272
2025-04-25 13:16:27,967 - transformer_training - INFO - Main loop iteration: 5273
2025-04-25 13:16:28,429 - transformer_training - INFO - Main loop iteration: 5274
2025-04-25 13:16:28,880 - transformer_training - INFO - Main loop iteration: 5275
2025-04-25 13:16:29,379 - transformer_training - INFO - Main loop iteration: 5276
2025-04-25 13:16:29,781 - transformer_training - INFO - Main loop iteration: 5277
2025-04-25 13:16:30,242 - transformer_training - INFO - Main loop iteration: 5278
2025-04-25 13:16:30,693 - transformer_training - INFO - Main loop iteration: 5279
2025-04-25 13:16:31,193 - transformer_training - INFO - Main loop iteration: 5280
Iter 5280: loss 3.6211, lr 0.000982, 91976.21 tokens/sec
2025-04-25 13:16:31,594 - transformer_training - INFO - Main loop iteration: 5281
2025-04-25 13:16:32,055 - transformer_training - INFO - Main loop iteration: 5282
2025-04-25 13:16:32,506 - transformer_training - INFO - Main loop iteration: 5283
2025-04-25 13:16:33,006 - transformer_training - INFO - Main loop iteration: 5284
2025-04-25 13:16:33,407 - transformer_training - INFO - Main loop iteration: 5285
2025-04-25 13:16:33,868 - transformer_training - INFO - Main loop iteration: 5286
2025-04-25 13:16:34,319 - transformer_training - INFO - Main loop iteration: 5287
2025-04-25 13:16:34,818 - transformer_training - INFO - Main loop iteration: 5288
2025-04-25 13:16:35,219 - transformer_training - INFO - Main loop iteration: 5289
2025-04-25 13:16:35,680 - transformer_training - INFO - Main loop iteration: 5290
Iter 5290: loss 3.6046, lr 0.000982, 82065.91 tokens/sec
2025-04-25 13:16:36,130 - transformer_training - INFO - Main loop iteration: 5291
2025-04-25 13:16:36,629 - transformer_training - INFO - Main loop iteration: 5292
2025-04-25 13:16:37,030 - transformer_training - INFO - Main loop iteration: 5293
2025-04-25 13:16:37,491 - transformer_training - INFO - Main loop iteration: 5294
2025-04-25 13:16:37,942 - transformer_training - INFO - Main loop iteration: 5295
2025-04-25 13:16:38,441 - transformer_training - INFO - Main loop iteration: 5296
2025-04-25 13:16:38,843 - transformer_training - INFO - Main loop iteration: 5297
2025-04-25 13:16:39,304 - transformer_training - INFO - Main loop iteration: 5298
2025-04-25 13:16:39,754 - transformer_training - INFO - Main loop iteration: 5299
2025-04-25 13:16:40,254 - transformer_training - INFO - Main loop iteration: 5300
Iter 5300: loss 3.5623, lr 0.000982, 92007.03 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5300: train loss 3.5644, val loss 3.4658
New best model saved with val loss: 3.4658
2025-04-25 13:16:58,025 - transformer_training - INFO - Main loop iteration: 5301
2025-04-25 13:16:58,439 - transformer_training - INFO - Main loop iteration: 5302
2025-04-25 13:16:58,890 - transformer_training - INFO - Main loop iteration: 5303
2025-04-25 13:16:59,389 - transformer_training - INFO - Main loop iteration: 5304
2025-04-25 13:16:59,789 - transformer_training - INFO - Main loop iteration: 5305
2025-04-25 13:17:00,250 - transformer_training - INFO - Main loop iteration: 5306
2025-04-25 13:17:00,702 - transformer_training - INFO - Main loop iteration: 5307
2025-04-25 13:17:01,201 - transformer_training - INFO - Main loop iteration: 5308
2025-04-25 13:17:01,603 - transformer_training - INFO - Main loop iteration: 5309
2025-04-25 13:17:02,064 - transformer_training - INFO - Main loop iteration: 5310
Iter 5310: loss 3.5874, lr 0.000981, 81830.20 tokens/sec
2025-04-25 13:17:02,515 - transformer_training - INFO - Main loop iteration: 5311
2025-04-25 13:17:03,014 - transformer_training - INFO - Main loop iteration: 5312
2025-04-25 13:17:03,414 - transformer_training - INFO - Main loop iteration: 5313
2025-04-25 13:17:03,874 - transformer_training - INFO - Main loop iteration: 5314
2025-04-25 13:17:04,325 - transformer_training - INFO - Main loop iteration: 5315
2025-04-25 13:17:04,824 - transformer_training - INFO - Main loop iteration: 5316
2025-04-25 13:17:05,225 - transformer_training - INFO - Main loop iteration: 5317
2025-04-25 13:17:05,686 - transformer_training - INFO - Main loop iteration: 5318
2025-04-25 13:17:06,136 - transformer_training - INFO - Main loop iteration: 5319
2025-04-25 13:17:06,636 - transformer_training - INFO - Main loop iteration: 5320
Iter 5320: loss 3.5915, lr 0.000981, 92078.26 tokens/sec
2025-04-25 13:17:07,037 - transformer_training - INFO - Main loop iteration: 5321
2025-04-25 13:17:07,498 - transformer_training - INFO - Main loop iteration: 5322
2025-04-25 13:17:07,948 - transformer_training - INFO - Main loop iteration: 5323
2025-04-25 13:17:08,448 - transformer_training - INFO - Main loop iteration: 5324
2025-04-25 13:17:08,849 - transformer_training - INFO - Main loop iteration: 5325
2025-04-25 13:17:09,310 - transformer_training - INFO - Main loop iteration: 5326
2025-04-25 13:17:09,760 - transformer_training - INFO - Main loop iteration: 5327
2025-04-25 13:17:10,260 - transformer_training - INFO - Main loop iteration: 5328
2025-04-25 13:17:10,661 - transformer_training - INFO - Main loop iteration: 5329
2025-04-25 13:17:11,122 - transformer_training - INFO - Main loop iteration: 5330
Iter 5330: loss 3.6999, lr 0.000981, 82073.23 tokens/sec
2025-04-25 13:17:11,572 - transformer_training - INFO - Main loop iteration: 5331
2025-04-25 13:17:12,072 - transformer_training - INFO - Main loop iteration: 5332
2025-04-25 13:17:12,473 - transformer_training - INFO - Main loop iteration: 5333
2025-04-25 13:17:12,934 - transformer_training - INFO - Main loop iteration: 5334
2025-04-25 13:17:13,384 - transformer_training - INFO - Main loop iteration: 5335
2025-04-25 13:17:13,885 - transformer_training - INFO - Main loop iteration: 5336
2025-04-25 13:17:14,286 - transformer_training - INFO - Main loop iteration: 5337
2025-04-25 13:17:14,747 - transformer_training - INFO - Main loop iteration: 5338
2025-04-25 13:17:15,197 - transformer_training - INFO - Main loop iteration: 5339
2025-04-25 13:17:15,696 - transformer_training - INFO - Main loop iteration: 5340
Iter 5340: loss 3.6779, lr 0.000981, 91996.46 tokens/sec
2025-04-25 13:17:16,098 - transformer_training - INFO - Main loop iteration: 5341
2025-04-25 13:17:16,559 - transformer_training - INFO - Main loop iteration: 5342
2025-04-25 13:17:17,010 - transformer_training - INFO - Main loop iteration: 5343
2025-04-25 13:17:17,509 - transformer_training - INFO - Main loop iteration: 5344
2025-04-25 13:17:17,910 - transformer_training - INFO - Main loop iteration: 5345
2025-04-25 13:17:18,372 - transformer_training - INFO - Main loop iteration: 5346
2025-04-25 13:17:18,822 - transformer_training - INFO - Main loop iteration: 5347
2025-04-25 13:17:19,321 - transformer_training - INFO - Main loop iteration: 5348
2025-04-25 13:17:19,723 - transformer_training - INFO - Main loop iteration: 5349
2025-04-25 13:17:20,183 - transformer_training - INFO - Main loop iteration: 5350
Iter 5350: loss 3.6083, lr 0.000981, 81975.32 tokens/sec
2025-04-25 13:17:20,634 - transformer_training - INFO - Main loop iteration: 5351
2025-04-25 13:17:21,133 - transformer_training - INFO - Main loop iteration: 5352
2025-04-25 13:17:21,534 - transformer_training - INFO - Main loop iteration: 5353
2025-04-25 13:17:21,996 - transformer_training - INFO - Main loop iteration: 5354
2025-04-25 13:17:22,446 - transformer_training - INFO - Main loop iteration: 5355
2025-04-25 13:17:22,946 - transformer_training - INFO - Main loop iteration: 5356
2025-04-25 13:17:23,347 - transformer_training - INFO - Main loop iteration: 5357
2025-04-25 13:17:23,808 - transformer_training - INFO - Main loop iteration: 5358
2025-04-25 13:17:24,259 - transformer_training - INFO - Main loop iteration: 5359
2025-04-25 13:17:24,758 - transformer_training - INFO - Main loop iteration: 5360
Iter 5360: loss 3.5905, lr 0.000981, 92045.64 tokens/sec
2025-04-25 13:17:25,159 - transformer_training - INFO - Main loop iteration: 5361
2025-04-25 13:17:25,620 - transformer_training - INFO - Main loop iteration: 5362
2025-04-25 13:17:26,070 - transformer_training - INFO - Main loop iteration: 5363
2025-04-25 13:17:26,570 - transformer_training - INFO - Main loop iteration: 5364
2025-04-25 13:17:26,971 - transformer_training - INFO - Main loop iteration: 5365
2025-04-25 13:17:27,431 - transformer_training - INFO - Main loop iteration: 5366
2025-04-25 13:17:27,882 - transformer_training - INFO - Main loop iteration: 5367
2025-04-25 13:17:28,381 - transformer_training - INFO - Main loop iteration: 5368
2025-04-25 13:17:28,782 - transformer_training - INFO - Main loop iteration: 5369
2025-04-25 13:17:29,243 - transformer_training - INFO - Main loop iteration: 5370
Iter 5370: loss 3.7066, lr 0.000981, 82062.95 tokens/sec
2025-04-25 13:17:29,694 - transformer_training - INFO - Main loop iteration: 5371
2025-04-25 13:17:30,193 - transformer_training - INFO - Main loop iteration: 5372
2025-04-25 13:17:30,594 - transformer_training - INFO - Main loop iteration: 5373
2025-04-25 13:17:31,055 - transformer_training - INFO - Main loop iteration: 5374
2025-04-25 13:17:31,505 - transformer_training - INFO - Main loop iteration: 5375
2025-04-25 13:17:32,005 - transformer_training - INFO - Main loop iteration: 5376
2025-04-25 13:17:32,406 - transformer_training - INFO - Main loop iteration: 5377
2025-04-25 13:17:32,868 - transformer_training - INFO - Main loop iteration: 5378
2025-04-25 13:17:33,318 - transformer_training - INFO - Main loop iteration: 5379
2025-04-25 13:17:33,818 - transformer_training - INFO - Main loop iteration: 5380
Iter 5380: loss 3.6069, lr 0.000981, 92041.42 tokens/sec
2025-04-25 13:17:34,219 - transformer_training - INFO - Main loop iteration: 5381
2025-04-25 13:17:34,681 - transformer_training - INFO - Main loop iteration: 5382
2025-04-25 13:17:35,131 - transformer_training - INFO - Main loop iteration: 5383
2025-04-25 13:17:35,631 - transformer_training - INFO - Main loop iteration: 5384
2025-04-25 13:17:36,032 - transformer_training - INFO - Main loop iteration: 5385
2025-04-25 13:17:36,494 - transformer_training - INFO - Main loop iteration: 5386
2025-04-25 13:17:36,944 - transformer_training - INFO - Main loop iteration: 5387
2025-04-25 13:17:37,443 - transformer_training - INFO - Main loop iteration: 5388
2025-04-25 13:17:37,843 - transformer_training - INFO - Main loop iteration: 5389
2025-04-25 13:17:38,304 - transformer_training - INFO - Main loop iteration: 5390
Iter 5390: loss 3.6663, lr 0.000981, 81917.26 tokens/sec
2025-04-25 13:17:38,755 - transformer_training - INFO - Main loop iteration: 5391
2025-04-25 13:17:39,253 - transformer_training - INFO - Main loop iteration: 5392
2025-04-25 13:17:39,655 - transformer_training - INFO - Main loop iteration: 5393
2025-04-25 13:17:40,116 - transformer_training - INFO - Main loop iteration: 5394
2025-04-25 13:17:40,566 - transformer_training - INFO - Main loop iteration: 5395
2025-04-25 13:17:41,065 - transformer_training - INFO - Main loop iteration: 5396
2025-04-25 13:17:41,466 - transformer_training - INFO - Main loop iteration: 5397
2025-04-25 13:17:41,927 - transformer_training - INFO - Main loop iteration: 5398
2025-04-25 13:17:42,378 - transformer_training - INFO - Main loop iteration: 5399
2025-04-25 13:17:42,877 - transformer_training - INFO - Main loop iteration: 5400
Iter 5400: loss 3.6112, lr 0.000980, 91967.57 tokens/sec
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5400: train loss 3.5509, val loss 3.4612
New best model saved with val loss: 3.4612
2025-04-25 13:17:59,941 - transformer_training - INFO - Main loop iteration: 5401
2025-04-25 13:18:00,352 - transformer_training - INFO - Main loop iteration: 5402
2025-04-25 13:18:00,803 - transformer_training - INFO - Main loop iteration: 5403
2025-04-25 13:18:01,301 - transformer_training - INFO - Main loop iteration: 5404
2025-04-25 13:18:01,702 - transformer_training - INFO - Main loop iteration: 5405
2025-04-25 13:18:02,163 - transformer_training - INFO - Main loop iteration: 5406
2025-04-25 13:18:02,613 - transformer_training - INFO - Main loop iteration: 5407
2025-04-25 13:18:03,112 - transformer_training - INFO - Main loop iteration: 5408
2025-04-25 13:18:03,513 - transformer_training - INFO - Main loop iteration: 5409
2025-04-25 13:18:03,974 - transformer_training - INFO - Main loop iteration: 5410
Iter 5410: loss 3.6484, lr 0.000980, 82034.87 tokens/sec
2025-04-25 13:18:04,424 - transformer_training - INFO - Main loop iteration: 5411
2025-04-25 13:18:04,922 - transformer_training - INFO - Main loop iteration: 5412
2025-04-25 13:18:05,323 - transformer_training - INFO - Main loop iteration: 5413
2025-04-25 13:18:05,784 - transformer_training - INFO - Main loop iteration: 5414
2025-04-25 13:18:06,236 - transformer_training - INFO - Main loop iteration: 5415
2025-04-25 13:18:06,734 - transformer_training - INFO - Main loop iteration: 5416
2025-04-25 13:18:07,136 - transformer_training - INFO - Main loop iteration: 5417
2025-04-25 13:18:07,597 - transformer_training - INFO - Main loop iteration: 5418
2025-04-25 13:18:08,047 - transformer_training - INFO - Main loop iteration: 5419
2025-04-25 13:18:08,547 - transformer_training - INFO - Main loop iteration: 5420
Iter 5420: loss 3.6666, lr 0.000980, 91799.07 tokens/sec
2025-04-25 13:18:08,949 - transformer_training - INFO - Main loop iteration: 5421
2025-04-25 13:18:09,410 - transformer_training - INFO - Main loop iteration: 5422
2025-04-25 13:18:09,860 - transformer_training - INFO - Main loop iteration: 5423
2025-04-25 13:18:10,359 - transformer_training - INFO - Main loop iteration: 5424
2025-04-25 13:18:10,760 - transformer_training - INFO - Main loop iteration: 5425
2025-04-25 13:18:11,222 - transformer_training - INFO - Main loop iteration: 5426
2025-04-25 13:18:11,673 - transformer_training - INFO - Main loop iteration: 5427
2025-04-25 13:18:12,172 - transformer_training - INFO - Main loop iteration: 5428
2025-04-25 13:18:12,574 - transformer_training - INFO - Main loop iteration: 5429
2025-04-25 13:18:13,035 - transformer_training - INFO - Main loop iteration: 5430
Iter 5430: loss 3.6865, lr 0.000980, 81944.78 tokens/sec
2025-04-25 13:18:13,485 - transformer_training - INFO - Main loop iteration: 5431
2025-04-25 13:18:13,985 - transformer_training - INFO - Main loop iteration: 5432
2025-04-25 13:18:14,386 - transformer_training - INFO - Main loop iteration: 5433
2025-04-25 13:18:14,847 - transformer_training - INFO - Main loop iteration: 5434
2025-04-25 13:18:15,298 - transformer_training - INFO - Main loop iteration: 5435
2025-04-25 13:18:15,797 - transformer_training - INFO - Main loop iteration: 5436
2025-04-25 13:18:16,198 - transformer_training - INFO - Main loop iteration: 5437
2025-04-25 13:18:16,660 - transformer_training - INFO - Main loop iteration: 5438
2025-04-25 13:18:17,111 - transformer_training - INFO - Main loop iteration: 5439
2025-04-25 13:18:17,609 - transformer_training - INFO - Main loop iteration: 5440
Iter 5440: loss 3.6554, lr 0.000980, 91796.02 tokens/sec
2025-04-25 13:18:18,011 - transformer_training - INFO - Main loop iteration: 5441
2025-04-25 13:18:18,473 - transformer_training - INFO - Main loop iteration: 5442
2025-04-25 13:18:18,924 - transformer_training - INFO - Main loop iteration: 5443
2025-04-25 13:18:19,423 - transformer_training - INFO - Main loop iteration: 5444
2025-04-25 13:18:19,825 - transformer_training - INFO - Main loop iteration: 5445
2025-04-25 13:18:20,285 - transformer_training - INFO - Main loop iteration: 5446
2025-04-25 13:18:20,736 - transformer_training - INFO - Main loop iteration: 5447
2025-04-25 13:18:21,235 - transformer_training - INFO - Main loop iteration: 5448
2025-04-25 13:18:21,637 - transformer_training - INFO - Main loop iteration: 5449
2025-04-25 13:18:22,098 - transformer_training - INFO - Main loop iteration: 5450
Iter 5450: loss 3.6312, lr 0.000980, 81842.24 tokens/sec
2025-04-25 13:18:22,549 - transformer_training - INFO - Main loop iteration: 5451
2025-04-25 13:18:23,048 - transformer_training - INFO - Main loop iteration: 5452
2025-04-25 13:18:23,449 - transformer_training - INFO - Main loop iteration: 5453
2025-04-25 13:18:23,911 - transformer_training - INFO - Main loop iteration: 5454
2025-04-25 13:18:24,361 - transformer_training - INFO - Main loop iteration: 5455
2025-04-25 13:18:24,860 - transformer_training - INFO - Main loop iteration: 5456
2025-04-25 13:18:25,262 - transformer_training - INFO - Main loop iteration: 5457
2025-04-25 13:18:25,723 - transformer_training - INFO - Main loop iteration: 5458
2025-04-25 13:18:26,175 - transformer_training - INFO - Main loop iteration: 5459
2025-04-25 13:18:26,674 - transformer_training - INFO - Main loop iteration: 5460
Iter 5460: loss 3.6175, lr 0.000980, 91859.61 tokens/sec
2025-04-25 13:18:27,076 - transformer_training - INFO - Main loop iteration: 5461
2025-04-25 13:18:27,537 - transformer_training - INFO - Main loop iteration: 5462
2025-04-25 13:18:27,988 - transformer_training - INFO - Main loop iteration: 5463
2025-04-25 13:18:28,486 - transformer_training - INFO - Main loop iteration: 5464
2025-04-25 13:18:28,888 - transformer_training - INFO - Main loop iteration: 5465
2025-04-25 13:18:29,349 - transformer_training - INFO - Main loop iteration: 5466
2025-04-25 13:18:29,880 - transformer_training - INFO - Main loop iteration: 5467
2025-04-25 13:18:30,379 - transformer_training - INFO - Main loop iteration: 5468
2025-04-25 13:18:30,781 - transformer_training - INFO - Main loop iteration: 5469
2025-04-25 13:18:31,241 - transformer_training - INFO - Main loop iteration: 5470
Iter 5470: loss 3.6184, lr 0.000980, 81878.65 tokens/sec
2025-04-25 13:18:31,693 - transformer_training - INFO - Main loop iteration: 5471
2025-04-25 13:18:32,192 - transformer_training - INFO - Main loop iteration: 5472
2025-04-25 13:18:32,593 - transformer_training - INFO - Main loop iteration: 5473
2025-04-25 13:18:33,054 - transformer_training - INFO - Main loop iteration: 5474
2025-04-25 13:18:33,505 - transformer_training - INFO - Main loop iteration: 5475
2025-04-25 13:18:34,003 - transformer_training - INFO - Main loop iteration: 5476
2025-04-25 13:18:34,405 - transformer_training - INFO - Main loop iteration: 5477
2025-04-25 13:18:34,866 - transformer_training - INFO - Main loop iteration: 5478
2025-04-25 13:18:35,316 - transformer_training - INFO - Main loop iteration: 5479
2025-04-25 13:18:35,815 - transformer_training - INFO - Main loop iteration: 5480
Iter 5480: loss 3.5300, lr 0.000979, 91832.65 tokens/sec
2025-04-25 13:18:36,217 - transformer_training - INFO - Main loop iteration: 5481
2025-04-25 13:18:36,678 - transformer_training - INFO - Main loop iteration: 5482
2025-04-25 13:18:37,129 - transformer_training - INFO - Main loop iteration: 5483
2025-04-25 13:18:37,627 - transformer_training - INFO - Main loop iteration: 5484
2025-04-25 13:18:38,029 - transformer_training - INFO - Main loop iteration: 5485
2025-04-25 13:18:38,490 - transformer_training - INFO - Main loop iteration: 5486
2025-04-25 13:18:38,941 - transformer_training - INFO - Main loop iteration: 5487
2025-04-25 13:18:39,440 - transformer_training - INFO - Main loop iteration: 5488
2025-04-25 13:18:39,841 - transformer_training - INFO - Main loop iteration: 5489
2025-04-25 13:18:40,303 - transformer_training - INFO - Main loop iteration: 5490
Iter 5490: loss 3.6186, lr 0.000979, 81860.75 tokens/sec
2025-04-25 13:18:40,754 - transformer_training - INFO - Main loop iteration: 5491
2025-04-25 13:18:41,253 - transformer_training - INFO - Main loop iteration: 5492
2025-04-25 13:18:41,654 - transformer_training - INFO - Main loop iteration: 5493
2025-04-25 13:18:42,115 - transformer_training - INFO - Main loop iteration: 5494
2025-04-25 13:18:42,566 - transformer_training - INFO - Main loop iteration: 5495
2025-04-25 13:18:43,066 - transformer_training - INFO - Main loop iteration: 5496
2025-04-25 13:18:43,467 - transformer_training - INFO - Main loop iteration: 5497
2025-04-25 13:18:43,927 - transformer_training - INFO - Main loop iteration: 5498
2025-04-25 13:18:44,378 - transformer_training - INFO - Main loop iteration: 5499
2025-04-25 13:18:44,877 - transformer_training - INFO - Main loop iteration: 5500
Iter 5500: loss 3.5645, lr 0.000979, 91786.70 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5500: train loss 3.5425, val loss 3.4548
New best model saved with val loss: 3.4548
2025-04-25 13:19:04,679 - transformer_training - INFO - Main loop iteration: 5501
2025-04-25 13:19:05,093 - transformer_training - INFO - Main loop iteration: 5502
2025-04-25 13:19:05,543 - transformer_training - INFO - Main loop iteration: 5503
2025-04-25 13:19:06,042 - transformer_training - INFO - Main loop iteration: 5504
2025-04-25 13:19:06,443 - transformer_training - INFO - Main loop iteration: 5505
2025-04-25 13:19:06,903 - transformer_training - INFO - Main loop iteration: 5506
2025-04-25 13:19:07,353 - transformer_training - INFO - Main loop iteration: 5507
2025-04-25 13:19:07,851 - transformer_training - INFO - Main loop iteration: 5508
2025-04-25 13:19:08,252 - transformer_training - INFO - Main loop iteration: 5509
2025-04-25 13:19:08,713 - transformer_training - INFO - Main loop iteration: 5510
Iter 5510: loss 3.5937, lr 0.000979, 81881.73 tokens/sec
2025-04-25 13:19:09,164 - transformer_training - INFO - Main loop iteration: 5511
2025-04-25 13:19:09,662 - transformer_training - INFO - Main loop iteration: 5512
2025-04-25 13:19:10,064 - transformer_training - INFO - Main loop iteration: 5513
2025-04-25 13:19:10,525 - transformer_training - INFO - Main loop iteration: 5514
2025-04-25 13:19:10,975 - transformer_training - INFO - Main loop iteration: 5515
2025-04-25 13:19:11,473 - transformer_training - INFO - Main loop iteration: 5516
2025-04-25 13:19:11,875 - transformer_training - INFO - Main loop iteration: 5517
2025-04-25 13:19:12,336 - transformer_training - INFO - Main loop iteration: 5518
2025-04-25 13:19:12,786 - transformer_training - INFO - Main loop iteration: 5519
2025-04-25 13:19:13,285 - transformer_training - INFO - Main loop iteration: 5520
Iter 5520: loss 3.5947, lr 0.000979, 92134.94 tokens/sec
2025-04-25 13:19:13,685 - transformer_training - INFO - Main loop iteration: 5521
2025-04-25 13:19:14,146 - transformer_training - INFO - Main loop iteration: 5522
2025-04-25 13:19:14,596 - transformer_training - INFO - Main loop iteration: 5523
2025-04-25 13:19:15,096 - transformer_training - INFO - Main loop iteration: 5524
2025-04-25 13:19:15,496 - transformer_training - INFO - Main loop iteration: 5525
2025-04-25 13:19:15,957 - transformer_training - INFO - Main loop iteration: 5526
2025-04-25 13:19:16,407 - transformer_training - INFO - Main loop iteration: 5527
2025-04-25 13:19:16,907 - transformer_training - INFO - Main loop iteration: 5528
2025-04-25 13:19:17,308 - transformer_training - INFO - Main loop iteration: 5529
2025-04-25 13:19:17,768 - transformer_training - INFO - Main loop iteration: 5530
Iter 5530: loss 3.6625, lr 0.000979, 82092.58 tokens/sec
2025-04-25 13:19:18,219 - transformer_training - INFO - Main loop iteration: 5531
2025-04-25 13:19:18,718 - transformer_training - INFO - Main loop iteration: 5532
2025-04-25 13:19:19,119 - transformer_training - INFO - Main loop iteration: 5533
2025-04-25 13:19:19,580 - transformer_training - INFO - Main loop iteration: 5534
2025-04-25 13:19:20,030 - transformer_training - INFO - Main loop iteration: 5535
2025-04-25 13:19:20,530 - transformer_training - INFO - Main loop iteration: 5536
2025-04-25 13:19:20,930 - transformer_training - INFO - Main loop iteration: 5537
2025-04-25 13:19:21,391 - transformer_training - INFO - Main loop iteration: 5538
2025-04-25 13:19:21,841 - transformer_training - INFO - Main loop iteration: 5539
2025-04-25 13:19:22,340 - transformer_training - INFO - Main loop iteration: 5540
Iter 5540: loss 3.6007, lr 0.000979, 92087.47 tokens/sec
2025-04-25 13:19:22,741 - transformer_training - INFO - Main loop iteration: 5541
2025-04-25 13:19:23,203 - transformer_training - INFO - Main loop iteration: 5542
2025-04-25 13:19:23,655 - transformer_training - INFO - Main loop iteration: 5543
2025-04-25 13:19:24,154 - transformer_training - INFO - Main loop iteration: 5544
2025-04-25 13:19:24,554 - transformer_training - INFO - Main loop iteration: 5545
2025-04-25 13:19:25,015 - transformer_training - INFO - Main loop iteration: 5546
2025-04-25 13:19:25,466 - transformer_training - INFO - Main loop iteration: 5547
2025-04-25 13:19:25,965 - transformer_training - INFO - Main loop iteration: 5548
2025-04-25 13:19:26,366 - transformer_training - INFO - Main loop iteration: 5549
2025-04-25 13:19:26,827 - transformer_training - INFO - Main loop iteration: 5550
Iter 5550: loss 3.6299, lr 0.000979, 81907.15 tokens/sec
2025-04-25 13:19:27,278 - transformer_training - INFO - Main loop iteration: 5551
2025-04-25 13:19:27,777 - transformer_training - INFO - Main loop iteration: 5552
2025-04-25 13:19:28,178 - transformer_training - INFO - Main loop iteration: 5553
2025-04-25 13:19:28,639 - transformer_training - INFO - Main loop iteration: 5554
2025-04-25 13:19:29,090 - transformer_training - INFO - Main loop iteration: 5555
2025-04-25 13:19:29,589 - transformer_training - INFO - Main loop iteration: 5556
2025-04-25 13:19:29,990 - transformer_training - INFO - Main loop iteration: 5557
2025-04-25 13:19:30,451 - transformer_training - INFO - Main loop iteration: 5558
2025-04-25 13:19:30,901 - transformer_training - INFO - Main loop iteration: 5559
2025-04-25 13:19:31,400 - transformer_training - INFO - Main loop iteration: 5560
Iter 5560: loss 3.6808, lr 0.000979, 92036.60 tokens/sec
2025-04-25 13:19:31,801 - transformer_training - INFO - Main loop iteration: 5561
2025-04-25 13:19:32,263 - transformer_training - INFO - Main loop iteration: 5562
2025-04-25 13:19:32,713 - transformer_training - INFO - Main loop iteration: 5563
2025-04-25 13:19:33,213 - transformer_training - INFO - Main loop iteration: 5564
2025-04-25 13:19:33,614 - transformer_training - INFO - Main loop iteration: 5565
2025-04-25 13:19:34,075 - transformer_training - INFO - Main loop iteration: 5566
2025-04-25 13:19:34,525 - transformer_training - INFO - Main loop iteration: 5567
2025-04-25 13:19:35,025 - transformer_training - INFO - Main loop iteration: 5568
2025-04-25 13:19:35,425 - transformer_training - INFO - Main loop iteration: 5569
2025-04-25 13:19:35,887 - transformer_training - INFO - Main loop iteration: 5570
Iter 5570: loss 3.6096, lr 0.000978, 81863.09 tokens/sec
2025-04-25 13:19:36,339 - transformer_training - INFO - Main loop iteration: 5571
2025-04-25 13:19:36,841 - transformer_training - INFO - Main loop iteration: 5572
2025-04-25 13:19:37,242 - transformer_training - INFO - Main loop iteration: 5573
2025-04-25 13:19:37,702 - transformer_training - INFO - Main loop iteration: 5574
2025-04-25 13:19:38,153 - transformer_training - INFO - Main loop iteration: 5575
2025-04-25 13:19:38,653 - transformer_training - INFO - Main loop iteration: 5576
2025-04-25 13:19:39,054 - transformer_training - INFO - Main loop iteration: 5577
2025-04-25 13:19:39,515 - transformer_training - INFO - Main loop iteration: 5578
2025-04-25 13:19:39,966 - transformer_training - INFO - Main loop iteration: 5579
2025-04-25 13:19:40,465 - transformer_training - INFO - Main loop iteration: 5580
Iter 5580: loss 3.5382, lr 0.000978, 92018.42 tokens/sec
2025-04-25 13:19:40,866 - transformer_training - INFO - Main loop iteration: 5581
2025-04-25 13:19:41,327 - transformer_training - INFO - Main loop iteration: 5582
2025-04-25 13:19:41,778 - transformer_training - INFO - Main loop iteration: 5583
2025-04-25 13:19:42,278 - transformer_training - INFO - Main loop iteration: 5584
2025-04-25 13:19:42,678 - transformer_training - INFO - Main loop iteration: 5585
2025-04-25 13:19:43,140 - transformer_training - INFO - Main loop iteration: 5586
2025-04-25 13:19:43,590 - transformer_training - INFO - Main loop iteration: 5587
2025-04-25 13:19:44,091 - transformer_training - INFO - Main loop iteration: 5588
2025-04-25 13:19:44,491 - transformer_training - INFO - Main loop iteration: 5589
2025-04-25 13:19:44,953 - transformer_training - INFO - Main loop iteration: 5590
Iter 5590: loss 3.5890, lr 0.000978, 81914.31 tokens/sec
2025-04-25 13:19:45,404 - transformer_training - INFO - Main loop iteration: 5591
2025-04-25 13:19:45,904 - transformer_training - INFO - Main loop iteration: 5592
2025-04-25 13:19:46,304 - transformer_training - INFO - Main loop iteration: 5593
2025-04-25 13:19:46,765 - transformer_training - INFO - Main loop iteration: 5594
2025-04-25 13:19:47,216 - transformer_training - INFO - Main loop iteration: 5595
2025-04-25 13:19:47,717 - transformer_training - INFO - Main loop iteration: 5596
2025-04-25 13:19:48,117 - transformer_training - INFO - Main loop iteration: 5597
2025-04-25 13:19:48,578 - transformer_training - INFO - Main loop iteration: 5598
2025-04-25 13:19:49,030 - transformer_training - INFO - Main loop iteration: 5599
2025-04-25 13:19:49,529 - transformer_training - INFO - Main loop iteration: 5600
Iter 5600: loss 3.5964, lr 0.000978, 91889.58 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5600: train loss 3.5407, val loss 3.4469
New best model saved with val loss: 3.4469
2025-04-25 13:20:07,423 - transformer_training - INFO - Main loop iteration: 5601
2025-04-25 13:20:07,846 - transformer_training - INFO - Main loop iteration: 5602
2025-04-25 13:20:08,294 - transformer_training - INFO - Main loop iteration: 5603
2025-04-25 13:20:08,793 - transformer_training - INFO - Main loop iteration: 5604
2025-04-25 13:20:09,193 - transformer_training - INFO - Main loop iteration: 5605
2025-04-25 13:20:09,653 - transformer_training - INFO - Main loop iteration: 5606
2025-04-25 13:20:10,103 - transformer_training - INFO - Main loop iteration: 5607
2025-04-25 13:20:10,601 - transformer_training - INFO - Main loop iteration: 5608
2025-04-25 13:20:11,002 - transformer_training - INFO - Main loop iteration: 5609
2025-04-25 13:20:11,463 - transformer_training - INFO - Main loop iteration: 5610
Iter 5610: loss 3.6447, lr 0.000978, 81981.10 tokens/sec
2025-04-25 13:20:11,913 - transformer_training - INFO - Main loop iteration: 5611
2025-04-25 13:20:12,411 - transformer_training - INFO - Main loop iteration: 5612
2025-04-25 13:20:12,812 - transformer_training - INFO - Main loop iteration: 5613
2025-04-25 13:20:13,277 - transformer_training - INFO - Main loop iteration: 5614
2025-04-25 13:20:13,728 - transformer_training - INFO - Main loop iteration: 5615
2025-04-25 13:20:14,227 - transformer_training - INFO - Main loop iteration: 5616
2025-04-25 13:20:14,627 - transformer_training - INFO - Main loop iteration: 5617
2025-04-25 13:20:15,088 - transformer_training - INFO - Main loop iteration: 5618
2025-04-25 13:20:15,538 - transformer_training - INFO - Main loop iteration: 5619
2025-04-25 13:20:16,036 - transformer_training - INFO - Main loop iteration: 5620
Iter 5620: loss 3.6414, lr 0.000978, 92031.07 tokens/sec
2025-04-25 13:20:16,437 - transformer_training - INFO - Main loop iteration: 5621
2025-04-25 13:20:16,898 - transformer_training - INFO - Main loop iteration: 5622
2025-04-25 13:20:17,348 - transformer_training - INFO - Main loop iteration: 5623
2025-04-25 13:20:17,847 - transformer_training - INFO - Main loop iteration: 5624
2025-04-25 13:20:18,248 - transformer_training - INFO - Main loop iteration: 5625
2025-04-25 13:20:18,709 - transformer_training - INFO - Main loop iteration: 5626
2025-04-25 13:20:19,160 - transformer_training - INFO - Main loop iteration: 5627
2025-04-25 13:20:19,658 - transformer_training - INFO - Main loop iteration: 5628
2025-04-25 13:20:20,059 - transformer_training - INFO - Main loop iteration: 5629
2025-04-25 13:20:20,520 - transformer_training - INFO - Main loop iteration: 5630
Iter 5630: loss 3.5982, lr 0.000978, 81927.85 tokens/sec
2025-04-25 13:20:20,971 - transformer_training - INFO - Main loop iteration: 5631
2025-04-25 13:20:21,470 - transformer_training - INFO - Main loop iteration: 5632
2025-04-25 13:20:21,870 - transformer_training - INFO - Main loop iteration: 5633
2025-04-25 13:20:22,331 - transformer_training - INFO - Main loop iteration: 5634
2025-04-25 13:20:22,781 - transformer_training - INFO - Main loop iteration: 5635
2025-04-25 13:20:23,282 - transformer_training - INFO - Main loop iteration: 5636
2025-04-25 13:20:23,684 - transformer_training - INFO - Main loop iteration: 5637
2025-04-25 13:20:24,145 - transformer_training - INFO - Main loop iteration: 5638
2025-04-25 13:20:24,595 - transformer_training - INFO - Main loop iteration: 5639
2025-04-25 13:20:25,094 - transformer_training - INFO - Main loop iteration: 5640
Iter 5640: loss 3.5517, lr 0.000978, 91862.39 tokens/sec
2025-04-25 13:20:25,496 - transformer_training - INFO - Main loop iteration: 5641
2025-04-25 13:20:25,957 - transformer_training - INFO - Main loop iteration: 5642
2025-04-25 13:20:26,407 - transformer_training - INFO - Main loop iteration: 5643
2025-04-25 13:20:26,906 - transformer_training - INFO - Main loop iteration: 5644
2025-04-25 13:20:27,307 - transformer_training - INFO - Main loop iteration: 5645
2025-04-25 13:20:27,770 - transformer_training - INFO - Main loop iteration: 5646
2025-04-25 13:20:28,221 - transformer_training - INFO - Main loop iteration: 5647
2025-04-25 13:20:28,720 - transformer_training - INFO - Main loop iteration: 5648
2025-04-25 13:20:29,121 - transformer_training - INFO - Main loop iteration: 5649
2025-04-25 13:20:29,582 - transformer_training - INFO - Main loop iteration: 5650
Iter 5650: loss 3.6244, lr 0.000977, 81843.76 tokens/sec
2025-04-25 13:20:30,033 - transformer_training - INFO - Main loop iteration: 5651
2025-04-25 13:20:30,531 - transformer_training - INFO - Main loop iteration: 5652
2025-04-25 13:20:30,934 - transformer_training - INFO - Main loop iteration: 5653
2025-04-25 13:20:31,395 - transformer_training - INFO - Main loop iteration: 5654
2025-04-25 13:20:31,846 - transformer_training - INFO - Main loop iteration: 5655
2025-04-25 13:20:32,346 - transformer_training - INFO - Main loop iteration: 5656
2025-04-25 13:20:32,748 - transformer_training - INFO - Main loop iteration: 5657
2025-04-25 13:20:33,209 - transformer_training - INFO - Main loop iteration: 5658
2025-04-25 13:20:33,659 - transformer_training - INFO - Main loop iteration: 5659
2025-04-25 13:20:34,158 - transformer_training - INFO - Main loop iteration: 5660
Iter 5660: loss 3.6413, lr 0.000977, 91904.92 tokens/sec
2025-04-25 13:20:34,560 - transformer_training - INFO - Main loop iteration: 5661
2025-04-25 13:20:35,020 - transformer_training - INFO - Main loop iteration: 5662
2025-04-25 13:20:35,472 - transformer_training - INFO - Main loop iteration: 5663
2025-04-25 13:20:35,970 - transformer_training - INFO - Main loop iteration: 5664
2025-04-25 13:20:36,372 - transformer_training - INFO - Main loop iteration: 5665
2025-04-25 13:20:36,832 - transformer_training - INFO - Main loop iteration: 5666
2025-04-25 13:20:37,283 - transformer_training - INFO - Main loop iteration: 5667
2025-04-25 13:20:37,782 - transformer_training - INFO - Main loop iteration: 5668
2025-04-25 13:20:38,183 - transformer_training - INFO - Main loop iteration: 5669
2025-04-25 13:20:38,645 - transformer_training - INFO - Main loop iteration: 5670
Iter 5670: loss 3.6779, lr 0.000977, 81882.07 tokens/sec
2025-04-25 13:20:39,095 - transformer_training - INFO - Main loop iteration: 5671
2025-04-25 13:20:39,594 - transformer_training - INFO - Main loop iteration: 5672
2025-04-25 13:20:39,996 - transformer_training - INFO - Main loop iteration: 5673
2025-04-25 13:20:40,457 - transformer_training - INFO - Main loop iteration: 5674
2025-04-25 13:20:40,907 - transformer_training - INFO - Main loop iteration: 5675
2025-04-25 13:20:41,406 - transformer_training - INFO - Main loop iteration: 5676
2025-04-25 13:20:41,807 - transformer_training - INFO - Main loop iteration: 5677
2025-04-25 13:20:42,268 - transformer_training - INFO - Main loop iteration: 5678
2025-04-25 13:20:42,718 - transformer_training - INFO - Main loop iteration: 5679
2025-04-25 13:20:43,217 - transformer_training - INFO - Main loop iteration: 5680
Iter 5680: loss 3.6770, lr 0.000977, 91858.40 tokens/sec
2025-04-25 13:20:43,618 - transformer_training - INFO - Main loop iteration: 5681
2025-04-25 13:20:44,079 - transformer_training - INFO - Main loop iteration: 5682
2025-04-25 13:20:44,529 - transformer_training - INFO - Main loop iteration: 5683
2025-04-25 13:20:45,027 - transformer_training - INFO - Main loop iteration: 5684
2025-04-25 13:20:45,429 - transformer_training - INFO - Main loop iteration: 5685
2025-04-25 13:20:45,890 - transformer_training - INFO - Main loop iteration: 5686
2025-04-25 13:20:46,341 - transformer_training - INFO - Main loop iteration: 5687
2025-04-25 13:20:46,839 - transformer_training - INFO - Main loop iteration: 5688
2025-04-25 13:20:47,241 - transformer_training - INFO - Main loop iteration: 5689
2025-04-25 13:20:47,701 - transformer_training - INFO - Main loop iteration: 5690
Iter 5690: loss 3.6711, lr 0.000977, 81925.89 tokens/sec
2025-04-25 13:20:48,152 - transformer_training - INFO - Main loop iteration: 5691
2025-04-25 13:20:48,651 - transformer_training - INFO - Main loop iteration: 5692
2025-04-25 13:20:49,052 - transformer_training - INFO - Main loop iteration: 5693
2025-04-25 13:20:49,513 - transformer_training - INFO - Main loop iteration: 5694
2025-04-25 13:20:49,963 - transformer_training - INFO - Main loop iteration: 5695
2025-04-25 13:20:50,462 - transformer_training - INFO - Main loop iteration: 5696
2025-04-25 13:20:50,864 - transformer_training - INFO - Main loop iteration: 5697
2025-04-25 13:20:51,326 - transformer_training - INFO - Main loop iteration: 5698
2025-04-25 13:20:51,776 - transformer_training - INFO - Main loop iteration: 5699
2025-04-25 13:20:52,278 - transformer_training - INFO - Main loop iteration: 5700
Iter 5700: loss 3.4978, lr 0.000977, 92212.63 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5700: train loss 3.5325, val loss 3.4277
New best model saved with val loss: 3.4277
2025-04-25 13:21:09,574 - transformer_training - INFO - Main loop iteration: 5701
2025-04-25 13:21:09,993 - transformer_training - INFO - Main loop iteration: 5702
2025-04-25 13:21:10,442 - transformer_training - INFO - Main loop iteration: 5703
2025-04-25 13:21:10,941 - transformer_training - INFO - Main loop iteration: 5704
2025-04-25 13:21:11,342 - transformer_training - INFO - Main loop iteration: 5705
2025-04-25 13:21:11,803 - transformer_training - INFO - Main loop iteration: 5706
2025-04-25 13:21:12,254 - transformer_training - INFO - Main loop iteration: 5707
2025-04-25 13:21:12,752 - transformer_training - INFO - Main loop iteration: 5708
2025-04-25 13:21:13,153 - transformer_training - INFO - Main loop iteration: 5709
2025-04-25 13:21:13,614 - transformer_training - INFO - Main loop iteration: 5710
Iter 5710: loss 3.5342, lr 0.000977, 82037.39 tokens/sec
2025-04-25 13:21:14,065 - transformer_training - INFO - Main loop iteration: 5711
2025-04-25 13:21:14,564 - transformer_training - INFO - Main loop iteration: 5712
2025-04-25 13:21:14,965 - transformer_training - INFO - Main loop iteration: 5713
2025-04-25 13:21:15,425 - transformer_training - INFO - Main loop iteration: 5714
2025-04-25 13:21:15,875 - transformer_training - INFO - Main loop iteration: 5715
2025-04-25 13:21:16,375 - transformer_training - INFO - Main loop iteration: 5716
2025-04-25 13:21:16,775 - transformer_training - INFO - Main loop iteration: 5717
2025-04-25 13:21:17,236 - transformer_training - INFO - Main loop iteration: 5718
2025-04-25 13:21:17,686 - transformer_training - INFO - Main loop iteration: 5719
2025-04-25 13:21:18,185 - transformer_training - INFO - Main loop iteration: 5720
Iter 5720: loss 3.6083, lr 0.000977, 92064.55 tokens/sec
2025-04-25 13:21:18,586 - transformer_training - INFO - Main loop iteration: 5721
2025-04-25 13:21:19,046 - transformer_training - INFO - Main loop iteration: 5722
2025-04-25 13:21:19,497 - transformer_training - INFO - Main loop iteration: 5723
2025-04-25 13:21:19,996 - transformer_training - INFO - Main loop iteration: 5724
2025-04-25 13:21:20,397 - transformer_training - INFO - Main loop iteration: 5725
2025-04-25 13:21:20,857 - transformer_training - INFO - Main loop iteration: 5726
2025-04-25 13:21:21,308 - transformer_training - INFO - Main loop iteration: 5727
2025-04-25 13:21:21,808 - transformer_training - INFO - Main loop iteration: 5728
2025-04-25 13:21:22,209 - transformer_training - INFO - Main loop iteration: 5729
2025-04-25 13:21:22,670 - transformer_training - INFO - Main loop iteration: 5730
Iter 5730: loss 3.5467, lr 0.000976, 82082.60 tokens/sec
2025-04-25 13:21:23,121 - transformer_training - INFO - Main loop iteration: 5731
2025-04-25 13:21:23,620 - transformer_training - INFO - Main loop iteration: 5732
2025-04-25 13:21:24,021 - transformer_training - INFO - Main loop iteration: 5733
2025-04-25 13:21:24,481 - transformer_training - INFO - Main loop iteration: 5734
2025-04-25 13:21:24,932 - transformer_training - INFO - Main loop iteration: 5735
2025-04-25 13:21:25,431 - transformer_training - INFO - Main loop iteration: 5736
2025-04-25 13:21:25,832 - transformer_training - INFO - Main loop iteration: 5737
2025-04-25 13:21:26,293 - transformer_training - INFO - Main loop iteration: 5738
2025-04-25 13:21:26,744 - transformer_training - INFO - Main loop iteration: 5739
2025-04-25 13:21:27,243 - transformer_training - INFO - Main loop iteration: 5740
Iter 5740: loss 3.6041, lr 0.000976, 91976.71 tokens/sec
2025-04-25 13:21:27,644 - transformer_training - INFO - Main loop iteration: 5741
2025-04-25 13:21:28,105 - transformer_training - INFO - Main loop iteration: 5742
2025-04-25 13:21:28,555 - transformer_training - INFO - Main loop iteration: 5743
2025-04-25 13:21:29,055 - transformer_training - INFO - Main loop iteration: 5744
2025-04-25 13:21:29,457 - transformer_training - INFO - Main loop iteration: 5745
2025-04-25 13:21:29,917 - transformer_training - INFO - Main loop iteration: 5746
2025-04-25 13:21:30,368 - transformer_training - INFO - Main loop iteration: 5747
2025-04-25 13:21:30,867 - transformer_training - INFO - Main loop iteration: 5748
2025-04-25 13:21:31,268 - transformer_training - INFO - Main loop iteration: 5749
2025-04-25 13:21:31,730 - transformer_training - INFO - Main loop iteration: 5750
Iter 5750: loss 3.6177, lr 0.000976, 81919.69 tokens/sec
2025-04-25 13:21:32,181 - transformer_training - INFO - Main loop iteration: 5751
2025-04-25 13:21:32,681 - transformer_training - INFO - Main loop iteration: 5752
2025-04-25 13:21:33,081 - transformer_training - INFO - Main loop iteration: 5753
2025-04-25 13:21:33,542 - transformer_training - INFO - Main loop iteration: 5754
2025-04-25 13:21:33,993 - transformer_training - INFO - Main loop iteration: 5755
2025-04-25 13:21:34,493 - transformer_training - INFO - Main loop iteration: 5756
2025-04-25 13:21:34,893 - transformer_training - INFO - Main loop iteration: 5757
2025-04-25 13:21:35,354 - transformer_training - INFO - Main loop iteration: 5758
2025-04-25 13:21:35,805 - transformer_training - INFO - Main loop iteration: 5759
2025-04-25 13:21:36,305 - transformer_training - INFO - Main loop iteration: 5760
Iter 5760: loss 3.5598, lr 0.000976, 91959.58 tokens/sec
2025-04-25 13:21:36,707 - transformer_training - INFO - Main loop iteration: 5761
2025-04-25 13:21:37,167 - transformer_training - INFO - Main loop iteration: 5762
2025-04-25 13:21:37,618 - transformer_training - INFO - Main loop iteration: 5763
2025-04-25 13:21:38,118 - transformer_training - INFO - Main loop iteration: 5764
2025-04-25 13:21:38,519 - transformer_training - INFO - Main loop iteration: 5765
2025-04-25 13:21:38,980 - transformer_training - INFO - Main loop iteration: 5766
2025-04-25 13:21:39,431 - transformer_training - INFO - Main loop iteration: 5767
2025-04-25 13:21:39,931 - transformer_training - INFO - Main loop iteration: 5768
2025-04-25 13:21:40,332 - transformer_training - INFO - Main loop iteration: 5769
2025-04-25 13:21:40,793 - transformer_training - INFO - Main loop iteration: 5770
Iter 5770: loss 3.4961, lr 0.000976, 81974.67 tokens/sec
2025-04-25 13:21:41,244 - transformer_training - INFO - Main loop iteration: 5771
2025-04-25 13:21:41,744 - transformer_training - INFO - Main loop iteration: 5772
2025-04-25 13:21:42,145 - transformer_training - INFO - Main loop iteration: 5773
2025-04-25 13:21:42,607 - transformer_training - INFO - Main loop iteration: 5774
2025-04-25 13:21:43,057 - transformer_training - INFO - Main loop iteration: 5775
2025-04-25 13:21:43,557 - transformer_training - INFO - Main loop iteration: 5776
2025-04-25 13:21:43,958 - transformer_training - INFO - Main loop iteration: 5777
2025-04-25 13:21:44,419 - transformer_training - INFO - Main loop iteration: 5778
2025-04-25 13:21:44,869 - transformer_training - INFO - Main loop iteration: 5779
2025-04-25 13:21:45,369 - transformer_training - INFO - Main loop iteration: 5780
Iter 5780: loss 3.5699, lr 0.000976, 91976.60 tokens/sec
2025-04-25 13:21:45,770 - transformer_training - INFO - Main loop iteration: 5781
2025-04-25 13:21:46,231 - transformer_training - INFO - Main loop iteration: 5782
2025-04-25 13:21:46,761 - transformer_training - INFO - Main loop iteration: 5783
2025-04-25 13:21:47,260 - transformer_training - INFO - Main loop iteration: 5784
2025-04-25 13:21:47,662 - transformer_training - INFO - Main loop iteration: 5785
2025-04-25 13:21:48,123 - transformer_training - INFO - Main loop iteration: 5786
2025-04-25 13:21:48,573 - transformer_training - INFO - Main loop iteration: 5787
2025-04-25 13:21:49,072 - transformer_training - INFO - Main loop iteration: 5788
2025-04-25 13:21:49,474 - transformer_training - INFO - Main loop iteration: 5789
2025-04-25 13:21:49,936 - transformer_training - INFO - Main loop iteration: 5790
Iter 5790: loss 3.5969, lr 0.000976, 81953.03 tokens/sec
2025-04-25 13:21:50,386 - transformer_training - INFO - Main loop iteration: 5791
2025-04-25 13:21:50,885 - transformer_training - INFO - Main loop iteration: 5792
2025-04-25 13:21:51,286 - transformer_training - INFO - Main loop iteration: 5793
2025-04-25 13:21:51,748 - transformer_training - INFO - Main loop iteration: 5794
2025-04-25 13:21:52,198 - transformer_training - INFO - Main loop iteration: 5795
2025-04-25 13:21:52,698 - transformer_training - INFO - Main loop iteration: 5796
2025-04-25 13:21:53,099 - transformer_training - INFO - Main loop iteration: 5797
2025-04-25 13:21:53,560 - transformer_training - INFO - Main loop iteration: 5798
2025-04-25 13:21:54,012 - transformer_training - INFO - Main loop iteration: 5799
2025-04-25 13:21:54,511 - transformer_training - INFO - Main loop iteration: 5800
Iter 5800: loss 3.6556, lr 0.000976, 91855.89 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 5800: train loss 3.5252, val loss 3.4194
New best model saved with val loss: 3.4194
2025-04-25 13:22:12,083 - transformer_training - INFO - Main loop iteration: 5801
2025-04-25 13:22:12,502 - transformer_training - INFO - Main loop iteration: 5802
2025-04-25 13:22:12,950 - transformer_training - INFO - Main loop iteration: 5803
2025-04-25 13:22:13,448 - transformer_training - INFO - Main loop iteration: 5804
2025-04-25 13:22:13,849 - transformer_training - INFO - Main loop iteration: 5805
2025-04-25 13:22:14,310 - transformer_training - INFO - Main loop iteration: 5806
2025-04-25 13:22:14,760 - transformer_training - INFO - Main loop iteration: 5807
2025-04-25 13:22:15,258 - transformer_training - INFO - Main loop iteration: 5808
2025-04-25 13:22:15,658 - transformer_training - INFO - Main loop iteration: 5809
2025-04-25 13:22:16,119 - transformer_training - INFO - Main loop iteration: 5810
Iter 5810: loss 3.4893, lr 0.000975, 81951.99 tokens/sec
2025-04-25 13:22:16,569 - transformer_training - INFO - Main loop iteration: 5811
2025-04-25 13:22:17,067 - transformer_training - INFO - Main loop iteration: 5812
2025-04-25 13:22:17,468 - transformer_training - INFO - Main loop iteration: 5813
2025-04-25 13:22:17,928 - transformer_training - INFO - Main loop iteration: 5814
2025-04-25 13:22:18,379 - transformer_training - INFO - Main loop iteration: 5815
2025-04-25 13:22:18,877 - transformer_training - INFO - Main loop iteration: 5816
2025-04-25 13:22:19,278 - transformer_training - INFO - Main loop iteration: 5817
2025-04-25 13:22:19,738 - transformer_training - INFO - Main loop iteration: 5818
2025-04-25 13:22:20,189 - transformer_training - INFO - Main loop iteration: 5819
2025-04-25 13:22:20,687 - transformer_training - INFO - Main loop iteration: 5820
Iter 5820: loss 3.5597, lr 0.000975, 92088.62 tokens/sec
2025-04-25 13:22:21,088 - transformer_training - INFO - Main loop iteration: 5821
2025-04-25 13:22:21,549 - transformer_training - INFO - Main loop iteration: 5822
2025-04-25 13:22:21,999 - transformer_training - INFO - Main loop iteration: 5823
2025-04-25 13:22:22,498 - transformer_training - INFO - Main loop iteration: 5824
2025-04-25 13:22:22,898 - transformer_training - INFO - Main loop iteration: 5825
2025-04-25 13:22:23,358 - transformer_training - INFO - Main loop iteration: 5826
2025-04-25 13:22:23,809 - transformer_training - INFO - Main loop iteration: 5827
2025-04-25 13:22:24,309 - transformer_training - INFO - Main loop iteration: 5828
2025-04-25 13:22:24,710 - transformer_training - INFO - Main loop iteration: 5829
2025-04-25 13:22:25,171 - transformer_training - INFO - Main loop iteration: 5830
Iter 5830: loss 3.5206, lr 0.000975, 81839.26 tokens/sec
2025-04-25 13:22:25,622 - transformer_training - INFO - Main loop iteration: 5831
2025-04-25 13:22:26,121 - transformer_training - INFO - Main loop iteration: 5832
2025-04-25 13:22:26,522 - transformer_training - INFO - Main loop iteration: 5833
2025-04-25 13:22:26,983 - transformer_training - INFO - Main loop iteration: 5834
2025-04-25 13:22:27,433 - transformer_training - INFO - Main loop iteration: 5835
2025-04-25 13:22:27,932 - transformer_training - INFO - Main loop iteration: 5836
2025-04-25 13:22:28,333 - transformer_training - INFO - Main loop iteration: 5837
2025-04-25 13:22:28,795 - transformer_training - INFO - Main loop iteration: 5838
2025-04-25 13:22:29,246 - transformer_training - INFO - Main loop iteration: 5839
2025-04-25 13:22:29,745 - transformer_training - INFO - Main loop iteration: 5840
Iter 5840: loss 3.6352, lr 0.000975, 91912.19 tokens/sec
2025-04-25 13:22:30,146 - transformer_training - INFO - Main loop iteration: 5841
2025-04-25 13:22:30,607 - transformer_training - INFO - Main loop iteration: 5842
2025-04-25 13:22:31,058 - transformer_training - INFO - Main loop iteration: 5843
2025-04-25 13:22:31,556 - transformer_training - INFO - Main loop iteration: 5844
2025-04-25 13:22:31,958 - transformer_training - INFO - Main loop iteration: 5845
2025-04-25 13:22:32,419 - transformer_training - INFO - Main loop iteration: 5846
2025-04-25 13:22:32,870 - transformer_training - INFO - Main loop iteration: 5847
2025-04-25 13:22:33,369 - transformer_training - INFO - Main loop iteration: 5848
2025-04-25 13:22:33,771 - transformer_training - INFO - Main loop iteration: 5849
2025-04-25 13:22:34,232 - transformer_training - INFO - Main loop iteration: 5850
Iter 5850: loss 3.5537, lr 0.000975, 81917.73 tokens/sec
2025-04-25 13:22:34,682 - transformer_training - INFO - Main loop iteration: 5851
2025-04-25 13:22:35,181 - transformer_training - INFO - Main loop iteration: 5852
2025-04-25 13:22:35,581 - transformer_training - INFO - Main loop iteration: 5853
2025-04-25 13:22:36,042 - transformer_training - INFO - Main loop iteration: 5854
2025-04-25 13:22:36,494 - transformer_training - INFO - Main loop iteration: 5855
2025-04-25 13:22:36,994 - transformer_training - INFO - Main loop iteration: 5856
2025-04-25 13:22:37,396 - transformer_training - INFO - Main loop iteration: 5857
2025-04-25 13:22:37,857 - transformer_training - INFO - Main loop iteration: 5858
2025-04-25 13:22:38,308 - transformer_training - INFO - Main loop iteration: 5859
2025-04-25 13:22:38,807 - transformer_training - INFO - Main loop iteration: 5860
Iter 5860: loss 3.6274, lr 0.000975, 91972.66 tokens/sec
2025-04-25 13:22:39,208 - transformer_training - INFO - Main loop iteration: 5861
2025-04-25 13:22:39,669 - transformer_training - INFO - Main loop iteration: 5862
2025-04-25 13:22:40,120 - transformer_training - INFO - Main loop iteration: 5863
2025-04-25 13:22:40,619 - transformer_training - INFO - Main loop iteration: 5864
2025-04-25 13:22:41,020 - transformer_training - INFO - Main loop iteration: 5865
2025-04-25 13:22:41,482 - transformer_training - INFO - Main loop iteration: 5866
2025-04-25 13:22:41,933 - transformer_training - INFO - Main loop iteration: 5867
2025-04-25 13:22:42,432 - transformer_training - INFO - Main loop iteration: 5868
2025-04-25 13:22:42,833 - transformer_training - INFO - Main loop iteration: 5869
2025-04-25 13:22:43,294 - transformer_training - INFO - Main loop iteration: 5870
Iter 5870: loss 3.6610, lr 0.000975, 81896.39 tokens/sec
2025-04-25 13:22:43,745 - transformer_training - INFO - Main loop iteration: 5871
2025-04-25 13:22:44,243 - transformer_training - INFO - Main loop iteration: 5872
2025-04-25 13:22:44,645 - transformer_training - INFO - Main loop iteration: 5873
2025-04-25 13:22:45,106 - transformer_training - INFO - Main loop iteration: 5874
2025-04-25 13:22:45,556 - transformer_training - INFO - Main loop iteration: 5875
2025-04-25 13:22:46,056 - transformer_training - INFO - Main loop iteration: 5876
2025-04-25 13:22:46,457 - transformer_training - INFO - Main loop iteration: 5877
2025-04-25 13:22:46,918 - transformer_training - INFO - Main loop iteration: 5878
2025-04-25 13:22:47,369 - transformer_training - INFO - Main loop iteration: 5879
2025-04-25 13:22:47,868 - transformer_training - INFO - Main loop iteration: 5880
Iter 5880: loss 3.5759, lr 0.000975, 91841.76 tokens/sec
2025-04-25 13:22:48,270 - transformer_training - INFO - Main loop iteration: 5881
2025-04-25 13:22:48,731 - transformer_training - INFO - Main loop iteration: 5882
2025-04-25 13:22:49,182 - transformer_training - INFO - Main loop iteration: 5883
2025-04-25 13:22:49,680 - transformer_training - INFO - Main loop iteration: 5884
2025-04-25 13:22:50,083 - transformer_training - INFO - Main loop iteration: 5885
2025-04-25 13:22:50,544 - transformer_training - INFO - Main loop iteration: 5886
2025-04-25 13:22:50,994 - transformer_training - INFO - Main loop iteration: 5887
2025-04-25 13:22:51,493 - transformer_training - INFO - Main loop iteration: 5888
2025-04-25 13:22:51,895 - transformer_training - INFO - Main loop iteration: 5889
2025-04-25 13:22:52,357 - transformer_training - INFO - Main loop iteration: 5890
Iter 5890: loss 3.5636, lr 0.000974, 81772.51 tokens/sec
2025-04-25 13:22:52,808 - transformer_training - INFO - Main loop iteration: 5891
2025-04-25 13:22:53,307 - transformer_training - INFO - Main loop iteration: 5892
2025-04-25 13:22:53,708 - transformer_training - INFO - Main loop iteration: 5893
2025-04-25 13:22:54,170 - transformer_training - INFO - Main loop iteration: 5894
2025-04-25 13:22:54,620 - transformer_training - INFO - Main loop iteration: 5895
2025-04-25 13:22:55,119 - transformer_training - INFO - Main loop iteration: 5896
2025-04-25 13:22:55,520 - transformer_training - INFO - Main loop iteration: 5897
2025-04-25 13:22:55,981 - transformer_training - INFO - Main loop iteration: 5898
2025-04-25 13:22:56,431 - transformer_training - INFO - Main loop iteration: 5899
2025-04-25 13:22:56,930 - transformer_training - INFO - Main loop iteration: 5900
Iter 5900: loss 3.5495, lr 0.000974, 91971.07 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 5900: train loss 3.5154, val loss 3.4073
New best model saved with val loss: 3.4073
2025-04-25 13:23:14,647 - transformer_training - INFO - Main loop iteration: 5901
2025-04-25 13:23:15,063 - transformer_training - INFO - Main loop iteration: 5902
2025-04-25 13:23:15,513 - transformer_training - INFO - Main loop iteration: 5903
2025-04-25 13:23:16,012 - transformer_training - INFO - Main loop iteration: 5904
2025-04-25 13:23:16,413 - transformer_training - INFO - Main loop iteration: 5905
2025-04-25 13:23:16,874 - transformer_training - INFO - Main loop iteration: 5906
2025-04-25 13:23:17,324 - transformer_training - INFO - Main loop iteration: 5907
2025-04-25 13:23:17,822 - transformer_training - INFO - Main loop iteration: 5908
2025-04-25 13:23:18,223 - transformer_training - INFO - Main loop iteration: 5909
2025-04-25 13:23:18,684 - transformer_training - INFO - Main loop iteration: 5910
Iter 5910: loss 3.5687, lr 0.000974, 81931.97 tokens/sec
2025-04-25 13:23:19,135 - transformer_training - INFO - Main loop iteration: 5911
2025-04-25 13:23:19,632 - transformer_training - INFO - Main loop iteration: 5912
2025-04-25 13:23:20,034 - transformer_training - INFO - Main loop iteration: 5913
2025-04-25 13:23:20,494 - transformer_training - INFO - Main loop iteration: 5914
2025-04-25 13:23:20,944 - transformer_training - INFO - Main loop iteration: 5915
2025-04-25 13:23:21,442 - transformer_training - INFO - Main loop iteration: 5916
2025-04-25 13:23:21,843 - transformer_training - INFO - Main loop iteration: 5917
2025-04-25 13:23:22,304 - transformer_training - INFO - Main loop iteration: 5918
2025-04-25 13:23:22,755 - transformer_training - INFO - Main loop iteration: 5919
2025-04-25 13:23:23,253 - transformer_training - INFO - Main loop iteration: 5920
Iter 5920: loss 3.7093, lr 0.000974, 92012.67 tokens/sec
2025-04-25 13:23:23,654 - transformer_training - INFO - Main loop iteration: 5921
2025-04-25 13:23:24,117 - transformer_training - INFO - Main loop iteration: 5922
2025-04-25 13:23:24,567 - transformer_training - INFO - Main loop iteration: 5923
2025-04-25 13:23:25,066 - transformer_training - INFO - Main loop iteration: 5924
2025-04-25 13:23:25,467 - transformer_training - INFO - Main loop iteration: 5925
2025-04-25 13:23:25,928 - transformer_training - INFO - Main loop iteration: 5926
2025-04-25 13:23:26,378 - transformer_training - INFO - Main loop iteration: 5927
2025-04-25 13:23:26,877 - transformer_training - INFO - Main loop iteration: 5928
2025-04-25 13:23:27,278 - transformer_training - INFO - Main loop iteration: 5929
2025-04-25 13:23:27,739 - transformer_training - INFO - Main loop iteration: 5930
Iter 5930: loss 3.5513, lr 0.000974, 81908.01 tokens/sec
2025-04-25 13:23:28,190 - transformer_training - INFO - Main loop iteration: 5931
2025-04-25 13:23:28,689 - transformer_training - INFO - Main loop iteration: 5932
2025-04-25 13:23:29,090 - transformer_training - INFO - Main loop iteration: 5933
2025-04-25 13:23:29,551 - transformer_training - INFO - Main loop iteration: 5934
2025-04-25 13:23:30,002 - transformer_training - INFO - Main loop iteration: 5935
2025-04-25 13:23:30,502 - transformer_training - INFO - Main loop iteration: 5936
2025-04-25 13:23:30,903 - transformer_training - INFO - Main loop iteration: 5937
2025-04-25 13:23:31,365 - transformer_training - INFO - Main loop iteration: 5938
2025-04-25 13:23:31,816 - transformer_training - INFO - Main loop iteration: 5939
2025-04-25 13:23:32,316 - transformer_training - INFO - Main loop iteration: 5940
Iter 5940: loss 3.6185, lr 0.000974, 91811.55 tokens/sec
2025-04-25 13:23:32,718 - transformer_training - INFO - Main loop iteration: 5941
2025-04-25 13:23:33,179 - transformer_training - INFO - Main loop iteration: 5942
2025-04-25 13:23:33,629 - transformer_training - INFO - Main loop iteration: 5943
2025-04-25 13:23:34,128 - transformer_training - INFO - Main loop iteration: 5944
2025-04-25 13:23:34,529 - transformer_training - INFO - Main loop iteration: 5945
2025-04-25 13:23:34,991 - transformer_training - INFO - Main loop iteration: 5946
2025-04-25 13:23:35,441 - transformer_training - INFO - Main loop iteration: 5947
2025-04-25 13:23:35,939 - transformer_training - INFO - Main loop iteration: 5948
2025-04-25 13:23:36,341 - transformer_training - INFO - Main loop iteration: 5949
2025-04-25 13:23:36,802 - transformer_training - INFO - Main loop iteration: 5950
Iter 5950: loss 3.5536, lr 0.000974, 81953.29 tokens/sec
2025-04-25 13:23:37,252 - transformer_training - INFO - Main loop iteration: 5951
2025-04-25 13:23:37,751 - transformer_training - INFO - Main loop iteration: 5952
2025-04-25 13:23:38,152 - transformer_training - INFO - Main loop iteration: 5953
2025-04-25 13:23:38,614 - transformer_training - INFO - Main loop iteration: 5954
2025-04-25 13:23:39,065 - transformer_training - INFO - Main loop iteration: 5955
2025-04-25 13:23:39,563 - transformer_training - INFO - Main loop iteration: 5956
2025-04-25 13:23:39,965 - transformer_training - INFO - Main loop iteration: 5957
2025-04-25 13:23:40,425 - transformer_training - INFO - Main loop iteration: 5958
2025-04-25 13:23:40,877 - transformer_training - INFO - Main loop iteration: 5959
2025-04-25 13:23:41,376 - transformer_training - INFO - Main loop iteration: 5960
Iter 5960: loss 3.5513, lr 0.000973, 91919.89 tokens/sec
2025-04-25 13:23:41,778 - transformer_training - INFO - Main loop iteration: 5961
2025-04-25 13:23:42,240 - transformer_training - INFO - Main loop iteration: 5962
2025-04-25 13:23:42,691 - transformer_training - INFO - Main loop iteration: 5963
2025-04-25 13:23:43,189 - transformer_training - INFO - Main loop iteration: 5964
2025-04-25 13:23:43,591 - transformer_training - INFO - Main loop iteration: 5965
2025-04-25 13:23:44,052 - transformer_training - INFO - Main loop iteration: 5966
2025-04-25 13:23:44,503 - transformer_training - INFO - Main loop iteration: 5967
2025-04-25 13:23:45,002 - transformer_training - INFO - Main loop iteration: 5968
2025-04-25 13:23:45,403 - transformer_training - INFO - Main loop iteration: 5969
2025-04-25 13:23:45,864 - transformer_training - INFO - Main loop iteration: 5970
Iter 5970: loss 3.5613, lr 0.000973, 81813.23 tokens/sec
2025-04-25 13:23:46,315 - transformer_training - INFO - Main loop iteration: 5971
2025-04-25 13:23:46,813 - transformer_training - INFO - Main loop iteration: 5972
2025-04-25 13:23:47,215 - transformer_training - INFO - Main loop iteration: 5973
2025-04-25 13:23:47,676 - transformer_training - INFO - Main loop iteration: 5974
2025-04-25 13:23:48,127 - transformer_training - INFO - Main loop iteration: 5975
2025-04-25 13:23:48,626 - transformer_training - INFO - Main loop iteration: 5976
2025-04-25 13:23:49,028 - transformer_training - INFO - Main loop iteration: 5977
2025-04-25 13:23:49,488 - transformer_training - INFO - Main loop iteration: 5978
2025-04-25 13:23:49,939 - transformer_training - INFO - Main loop iteration: 5979
2025-04-25 13:23:50,438 - transformer_training - INFO - Main loop iteration: 5980
Iter 5980: loss 3.5491, lr 0.000973, 91876.80 tokens/sec
2025-04-25 13:23:50,840 - transformer_training - INFO - Main loop iteration: 5981
2025-04-25 13:23:51,300 - transformer_training - INFO - Main loop iteration: 5982
2025-04-25 13:23:51,751 - transformer_training - INFO - Main loop iteration: 5983
2025-04-25 13:23:52,250 - transformer_training - INFO - Main loop iteration: 5984
2025-04-25 13:23:52,651 - transformer_training - INFO - Main loop iteration: 5985
2025-04-25 13:23:53,112 - transformer_training - INFO - Main loop iteration: 5986
2025-04-25 13:23:53,563 - transformer_training - INFO - Main loop iteration: 5987
2025-04-25 13:23:54,062 - transformer_training - INFO - Main loop iteration: 5988
2025-04-25 13:23:54,463 - transformer_training - INFO - Main loop iteration: 5989
2025-04-25 13:23:54,924 - transformer_training - INFO - Main loop iteration: 5990
Iter 5990: loss 3.5901, lr 0.000973, 81969.59 tokens/sec
2025-04-25 13:23:55,374 - transformer_training - INFO - Main loop iteration: 5991
2025-04-25 13:23:55,873 - transformer_training - INFO - Main loop iteration: 5992
2025-04-25 13:23:56,273 - transformer_training - INFO - Main loop iteration: 5993
2025-04-25 13:23:56,734 - transformer_training - INFO - Main loop iteration: 5994
2025-04-25 13:23:57,184 - transformer_training - INFO - Main loop iteration: 5995
2025-04-25 13:23:57,684 - transformer_training - INFO - Main loop iteration: 5996
2025-04-25 13:23:58,085 - transformer_training - INFO - Main loop iteration: 5997
2025-04-25 13:23:58,546 - transformer_training - INFO - Main loop iteration: 5998
2025-04-25 13:23:58,996 - transformer_training - INFO - Main loop iteration: 5999
2025-04-25 13:23:59,496 - transformer_training - INFO - Main loop iteration: 6000
Iter 6000: loss 3.5100, lr 0.000973, 91995.53 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 6000: train loss 3.5082, val loss 3.3841
New best model saved with val loss: 3.3841
2025-04-25 13:24:18,480 - transformer_training - INFO - Main loop iteration: 6001
2025-04-25 13:24:18,897 - transformer_training - INFO - Main loop iteration: 6002
2025-04-25 13:24:19,347 - transformer_training - INFO - Main loop iteration: 6003
2025-04-25 13:24:19,845 - transformer_training - INFO - Main loop iteration: 6004
2025-04-25 13:24:20,245 - transformer_training - INFO - Main loop iteration: 6005
2025-04-25 13:24:20,706 - transformer_training - INFO - Main loop iteration: 6006
2025-04-25 13:24:21,155 - transformer_training - INFO - Main loop iteration: 6007
2025-04-25 13:24:21,654 - transformer_training - INFO - Main loop iteration: 6008
2025-04-25 13:24:22,055 - transformer_training - INFO - Main loop iteration: 6009
2025-04-25 13:24:22,515 - transformer_training - INFO - Main loop iteration: 6010
Iter 6010: loss 3.5848, lr 0.000973, 82078.33 tokens/sec
2025-04-25 13:24:22,965 - transformer_training - INFO - Main loop iteration: 6011
2025-04-25 13:24:23,464 - transformer_training - INFO - Main loop iteration: 6012
2025-04-25 13:24:23,864 - transformer_training - INFO - Main loop iteration: 6013
2025-04-25 13:24:24,324 - transformer_training - INFO - Main loop iteration: 6014
2025-04-25 13:24:24,774 - transformer_training - INFO - Main loop iteration: 6015
2025-04-25 13:24:25,273 - transformer_training - INFO - Main loop iteration: 6016
2025-04-25 13:24:25,673 - transformer_training - INFO - Main loop iteration: 6017
2025-04-25 13:24:26,133 - transformer_training - INFO - Main loop iteration: 6018
2025-04-25 13:24:26,584 - transformer_training - INFO - Main loop iteration: 6019
2025-04-25 13:24:27,084 - transformer_training - INFO - Main loop iteration: 6020
Iter 6020: loss 3.5402, lr 0.000973, 91906.29 tokens/sec
2025-04-25 13:24:27,485 - transformer_training - INFO - Main loop iteration: 6021
2025-04-25 13:24:27,945 - transformer_training - INFO - Main loop iteration: 6022
2025-04-25 13:24:28,396 - transformer_training - INFO - Main loop iteration: 6023
2025-04-25 13:24:28,895 - transformer_training - INFO - Main loop iteration: 6024
2025-04-25 13:24:29,295 - transformer_training - INFO - Main loop iteration: 6025
2025-04-25 13:24:29,756 - transformer_training - INFO - Main loop iteration: 6026
2025-04-25 13:24:30,206 - transformer_training - INFO - Main loop iteration: 6027
2025-04-25 13:24:30,704 - transformer_training - INFO - Main loop iteration: 6028
2025-04-25 13:24:31,105 - transformer_training - INFO - Main loop iteration: 6029
2025-04-25 13:24:31,566 - transformer_training - INFO - Main loop iteration: 6030
Iter 6030: loss 3.6152, lr 0.000973, 81976.37 tokens/sec
2025-04-25 13:24:32,016 - transformer_training - INFO - Main loop iteration: 6031
2025-04-25 13:24:32,515 - transformer_training - INFO - Main loop iteration: 6032
2025-04-25 13:24:32,916 - transformer_training - INFO - Main loop iteration: 6033
2025-04-25 13:24:33,376 - transformer_training - INFO - Main loop iteration: 6034
2025-04-25 13:24:33,826 - transformer_training - INFO - Main loop iteration: 6035
2025-04-25 13:24:34,325 - transformer_training - INFO - Main loop iteration: 6036
2025-04-25 13:24:34,726 - transformer_training - INFO - Main loop iteration: 6037
2025-04-25 13:24:35,187 - transformer_training - INFO - Main loop iteration: 6038
2025-04-25 13:24:35,637 - transformer_training - INFO - Main loop iteration: 6039
2025-04-25 13:24:36,136 - transformer_training - INFO - Main loop iteration: 6040
Iter 6040: loss 3.5904, lr 0.000972, 92049.92 tokens/sec
2025-04-25 13:24:36,536 - transformer_training - INFO - Main loop iteration: 6041
2025-04-25 13:24:36,997 - transformer_training - INFO - Main loop iteration: 6042
2025-04-25 13:24:37,448 - transformer_training - INFO - Main loop iteration: 6043
2025-04-25 13:24:37,946 - transformer_training - INFO - Main loop iteration: 6044
2025-04-25 13:24:38,348 - transformer_training - INFO - Main loop iteration: 6045
2025-04-25 13:24:38,809 - transformer_training - INFO - Main loop iteration: 6046
2025-04-25 13:24:39,260 - transformer_training - INFO - Main loop iteration: 6047
2025-04-25 13:24:39,759 - transformer_training - INFO - Main loop iteration: 6048
2025-04-25 13:24:40,159 - transformer_training - INFO - Main loop iteration: 6049
2025-04-25 13:24:40,620 - transformer_training - INFO - Main loop iteration: 6050
Iter 6050: loss 3.5538, lr 0.000972, 81851.39 tokens/sec
2025-04-25 13:24:41,071 - transformer_training - INFO - Main loop iteration: 6051
2025-04-25 13:24:41,570 - transformer_training - INFO - Main loop iteration: 6052
2025-04-25 13:24:41,971 - transformer_training - INFO - Main loop iteration: 6053
2025-04-25 13:24:42,432 - transformer_training - INFO - Main loop iteration: 6054
2025-04-25 13:24:42,882 - transformer_training - INFO - Main loop iteration: 6055
2025-04-25 13:24:43,382 - transformer_training - INFO - Main loop iteration: 6056
2025-04-25 13:24:43,783 - transformer_training - INFO - Main loop iteration: 6057
2025-04-25 13:24:44,244 - transformer_training - INFO - Main loop iteration: 6058
2025-04-25 13:24:44,695 - transformer_training - INFO - Main loop iteration: 6059
2025-04-25 13:24:45,194 - transformer_training - INFO - Main loop iteration: 6060
Iter 6060: loss 3.4920, lr 0.000972, 92112.76 tokens/sec
2025-04-25 13:24:45,595 - transformer_training - INFO - Main loop iteration: 6061
2025-04-25 13:24:46,056 - transformer_training - INFO - Main loop iteration: 6062
2025-04-25 13:24:46,507 - transformer_training - INFO - Main loop iteration: 6063
2025-04-25 13:24:47,007 - transformer_training - INFO - Main loop iteration: 6064
2025-04-25 13:24:47,408 - transformer_training - INFO - Main loop iteration: 6065
2025-04-25 13:24:47,870 - transformer_training - INFO - Main loop iteration: 6066
2025-04-25 13:24:48,320 - transformer_training - INFO - Main loop iteration: 6067
2025-04-25 13:24:48,821 - transformer_training - INFO - Main loop iteration: 6068
2025-04-25 13:24:49,222 - transformer_training - INFO - Main loop iteration: 6069
2025-04-25 13:24:49,683 - transformer_training - INFO - Main loop iteration: 6070
Iter 6070: loss 3.5737, lr 0.000972, 82029.64 tokens/sec
2025-04-25 13:24:50,133 - transformer_training - INFO - Main loop iteration: 6071
2025-04-25 13:24:50,633 - transformer_training - INFO - Main loop iteration: 6072
2025-04-25 13:24:51,034 - transformer_training - INFO - Main loop iteration: 6073
2025-04-25 13:24:51,495 - transformer_training - INFO - Main loop iteration: 6074
2025-04-25 13:24:51,946 - transformer_training - INFO - Main loop iteration: 6075
2025-04-25 13:24:52,447 - transformer_training - INFO - Main loop iteration: 6076
2025-04-25 13:24:52,847 - transformer_training - INFO - Main loop iteration: 6077
2025-04-25 13:24:53,308 - transformer_training - INFO - Main loop iteration: 6078
2025-04-25 13:24:53,759 - transformer_training - INFO - Main loop iteration: 6079
2025-04-25 13:24:54,258 - transformer_training - INFO - Main loop iteration: 6080
Iter 6080: loss 3.5667, lr 0.000972, 91997.06 tokens/sec
2025-04-25 13:24:54,659 - transformer_training - INFO - Main loop iteration: 6081
2025-04-25 13:24:55,120 - transformer_training - INFO - Main loop iteration: 6082
2025-04-25 13:24:55,570 - transformer_training - INFO - Main loop iteration: 6083
2025-04-25 13:24:56,069 - transformer_training - INFO - Main loop iteration: 6084
2025-04-25 13:24:56,470 - transformer_training - INFO - Main loop iteration: 6085
2025-04-25 13:24:56,931 - transformer_training - INFO - Main loop iteration: 6086
2025-04-25 13:24:57,381 - transformer_training - INFO - Main loop iteration: 6087
2025-04-25 13:24:57,879 - transformer_training - INFO - Main loop iteration: 6088
2025-04-25 13:24:58,280 - transformer_training - INFO - Main loop iteration: 6089
2025-04-25 13:24:58,742 - transformer_training - INFO - Main loop iteration: 6090
Iter 6090: loss 3.4958, lr 0.000972, 82134.83 tokens/sec
2025-04-25 13:24:59,192 - transformer_training - INFO - Main loop iteration: 6091
2025-04-25 13:24:59,691 - transformer_training - INFO - Main loop iteration: 6092
2025-04-25 13:25:00,092 - transformer_training - INFO - Main loop iteration: 6093
2025-04-25 13:25:00,553 - transformer_training - INFO - Main loop iteration: 6094
2025-04-25 13:25:01,003 - transformer_training - INFO - Main loop iteration: 6095
2025-04-25 13:25:01,502 - transformer_training - INFO - Main loop iteration: 6096
2025-04-25 13:25:01,903 - transformer_training - INFO - Main loop iteration: 6097
2025-04-25 13:25:02,366 - transformer_training - INFO - Main loop iteration: 6098
2025-04-25 13:25:02,816 - transformer_training - INFO - Main loop iteration: 6099
2025-04-25 13:25:03,316 - transformer_training - INFO - Main loop iteration: 6100
Iter 6100: loss 3.5432, lr 0.000972, 92002.05 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6100: train loss 3.5058, val loss 3.3900
2025-04-25 13:25:19,149 - transformer_training - INFO - Main loop iteration: 6101
2025-04-25 13:25:19,559 - transformer_training - INFO - Main loop iteration: 6102
2025-04-25 13:25:20,009 - transformer_training - INFO - Main loop iteration: 6103
2025-04-25 13:25:20,508 - transformer_training - INFO - Main loop iteration: 6104
2025-04-25 13:25:20,908 - transformer_training - INFO - Main loop iteration: 6105
2025-04-25 13:25:21,369 - transformer_training - INFO - Main loop iteration: 6106
2025-04-25 13:25:21,818 - transformer_training - INFO - Main loop iteration: 6107
2025-04-25 13:25:22,317 - transformer_training - INFO - Main loop iteration: 6108
2025-04-25 13:25:22,718 - transformer_training - INFO - Main loop iteration: 6109
2025-04-25 13:25:23,127 - transformer_training - INFO - Main loop iteration: 6110
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6110: loss 3.4915, lr 0.000971, 12159.82 tokens/sec
2025-04-25 13:25:26,159 - transformer_training - INFO - Main loop iteration: 6111
2025-04-25 13:25:26,657 - transformer_training - INFO - Main loop iteration: 6112
2025-04-25 13:25:27,058 - transformer_training - INFO - Main loop iteration: 6113
2025-04-25 13:25:27,518 - transformer_training - INFO - Main loop iteration: 6114
2025-04-25 13:25:27,968 - transformer_training - INFO - Main loop iteration: 6115
2025-04-25 13:25:28,468 - transformer_training - INFO - Main loop iteration: 6116
2025-04-25 13:25:28,868 - transformer_training - INFO - Main loop iteration: 6117
2025-04-25 13:25:29,328 - transformer_training - INFO - Main loop iteration: 6118
2025-04-25 13:25:29,779 - transformer_training - INFO - Main loop iteration: 6119
2025-04-25 13:25:30,279 - transformer_training - INFO - Main loop iteration: 6120
Iter 6120: loss 3.4722, lr 0.000971, 91841.00 tokens/sec
2025-04-25 13:25:30,681 - transformer_training - INFO - Main loop iteration: 6121
2025-04-25 13:25:31,142 - transformer_training - INFO - Main loop iteration: 6122
2025-04-25 13:25:31,593 - transformer_training - INFO - Main loop iteration: 6123
2025-04-25 13:25:32,092 - transformer_training - INFO - Main loop iteration: 6124
2025-04-25 13:25:32,542 - transformer_training - INFO - Main loop iteration: 6125
2025-04-25 13:25:33,004 - transformer_training - INFO - Main loop iteration: 6126
2025-04-25 13:25:33,454 - transformer_training - INFO - Main loop iteration: 6127
2025-04-25 13:25:33,953 - transformer_training - INFO - Main loop iteration: 6128
2025-04-25 13:25:34,354 - transformer_training - INFO - Main loop iteration: 6129
2025-04-25 13:25:34,815 - transformer_training - INFO - Main loop iteration: 6130
Iter 6130: loss 3.4212, lr 0.000971, 82112.54 tokens/sec
2025-04-25 13:25:35,264 - transformer_training - INFO - Main loop iteration: 6131
2025-04-25 13:25:35,764 - transformer_training - INFO - Main loop iteration: 6132
2025-04-25 13:25:36,165 - transformer_training - INFO - Main loop iteration: 6133
2025-04-25 13:25:36,626 - transformer_training - INFO - Main loop iteration: 6134
2025-04-25 13:25:37,076 - transformer_training - INFO - Main loop iteration: 6135
2025-04-25 13:25:37,575 - transformer_training - INFO - Main loop iteration: 6136
2025-04-25 13:25:37,975 - transformer_training - INFO - Main loop iteration: 6137
2025-04-25 13:25:38,436 - transformer_training - INFO - Main loop iteration: 6138
2025-04-25 13:25:38,888 - transformer_training - INFO - Main loop iteration: 6139
2025-04-25 13:25:39,386 - transformer_training - INFO - Main loop iteration: 6140
Iter 6140: loss 3.4298, lr 0.000971, 91948.05 tokens/sec
2025-04-25 13:25:39,788 - transformer_training - INFO - Main loop iteration: 6141
2025-04-25 13:25:40,249 - transformer_training - INFO - Main loop iteration: 6142
2025-04-25 13:25:40,700 - transformer_training - INFO - Main loop iteration: 6143
2025-04-25 13:25:41,199 - transformer_training - INFO - Main loop iteration: 6144
2025-04-25 13:25:41,600 - transformer_training - INFO - Main loop iteration: 6145
2025-04-25 13:25:42,062 - transformer_training - INFO - Main loop iteration: 6146
2025-04-25 13:25:42,513 - transformer_training - INFO - Main loop iteration: 6147
2025-04-25 13:25:43,012 - transformer_training - INFO - Main loop iteration: 6148
2025-04-25 13:25:43,414 - transformer_training - INFO - Main loop iteration: 6149
2025-04-25 13:25:43,875 - transformer_training - INFO - Main loop iteration: 6150
Iter 6150: loss 3.4664, lr 0.000971, 82026.51 tokens/sec
2025-04-25 13:25:44,325 - transformer_training - INFO - Main loop iteration: 6151
2025-04-25 13:25:44,823 - transformer_training - INFO - Main loop iteration: 6152
2025-04-25 13:25:45,224 - transformer_training - INFO - Main loop iteration: 6153
2025-04-25 13:25:45,685 - transformer_training - INFO - Main loop iteration: 6154
2025-04-25 13:25:46,136 - transformer_training - INFO - Main loop iteration: 6155
2025-04-25 13:25:46,634 - transformer_training - INFO - Main loop iteration: 6156
2025-04-25 13:25:47,036 - transformer_training - INFO - Main loop iteration: 6157
2025-04-25 13:25:47,497 - transformer_training - INFO - Main loop iteration: 6158
2025-04-25 13:25:47,947 - transformer_training - INFO - Main loop iteration: 6159
2025-04-25 13:25:48,446 - transformer_training - INFO - Main loop iteration: 6160
Iter 6160: loss 3.4641, lr 0.000971, 91864.41 tokens/sec
2025-04-25 13:25:48,847 - transformer_training - INFO - Main loop iteration: 6161
2025-04-25 13:25:49,308 - transformer_training - INFO - Main loop iteration: 6162
2025-04-25 13:25:49,758 - transformer_training - INFO - Main loop iteration: 6163
2025-04-25 13:25:50,257 - transformer_training - INFO - Main loop iteration: 6164
2025-04-25 13:25:50,658 - transformer_training - INFO - Main loop iteration: 6165
2025-04-25 13:25:51,119 - transformer_training - INFO - Main loop iteration: 6166
2025-04-25 13:25:51,569 - transformer_training - INFO - Main loop iteration: 6167
2025-04-25 13:25:52,067 - transformer_training - INFO - Main loop iteration: 6168
2025-04-25 13:25:52,468 - transformer_training - INFO - Main loop iteration: 6169
2025-04-25 13:25:52,929 - transformer_training - INFO - Main loop iteration: 6170
Iter 6170: loss 3.5236, lr 0.000971, 81924.38 tokens/sec
2025-04-25 13:25:53,379 - transformer_training - INFO - Main loop iteration: 6171
2025-04-25 13:25:53,878 - transformer_training - INFO - Main loop iteration: 6172
2025-04-25 13:25:54,280 - transformer_training - INFO - Main loop iteration: 6173
2025-04-25 13:25:54,741 - transformer_training - INFO - Main loop iteration: 6174
2025-04-25 13:25:55,191 - transformer_training - INFO - Main loop iteration: 6175
2025-04-25 13:25:55,690 - transformer_training - INFO - Main loop iteration: 6176
2025-04-25 13:25:56,091 - transformer_training - INFO - Main loop iteration: 6177
2025-04-25 13:25:56,551 - transformer_training - INFO - Main loop iteration: 6178
2025-04-25 13:25:57,001 - transformer_training - INFO - Main loop iteration: 6179
2025-04-25 13:25:57,500 - transformer_training - INFO - Main loop iteration: 6180
Iter 6180: loss 3.4663, lr 0.000970, 92007.19 tokens/sec
2025-04-25 13:25:57,901 - transformer_training - INFO - Main loop iteration: 6181
2025-04-25 13:25:58,362 - transformer_training - INFO - Main loop iteration: 6182
2025-04-25 13:25:58,813 - transformer_training - INFO - Main loop iteration: 6183
2025-04-25 13:25:59,311 - transformer_training - INFO - Main loop iteration: 6184
2025-04-25 13:25:59,712 - transformer_training - INFO - Main loop iteration: 6185
2025-04-25 13:26:00,173 - transformer_training - INFO - Main loop iteration: 6186
2025-04-25 13:26:00,624 - transformer_training - INFO - Main loop iteration: 6187
2025-04-25 13:26:01,123 - transformer_training - INFO - Main loop iteration: 6188
2025-04-25 13:26:01,523 - transformer_training - INFO - Main loop iteration: 6189
2025-04-25 13:26:01,985 - transformer_training - INFO - Main loop iteration: 6190
Iter 6190: loss 3.4417, lr 0.000970, 81864.47 tokens/sec
2025-04-25 13:26:02,435 - transformer_training - INFO - Main loop iteration: 6191
2025-04-25 13:26:02,934 - transformer_training - INFO - Main loop iteration: 6192
2025-04-25 13:26:03,335 - transformer_training - INFO - Main loop iteration: 6193
2025-04-25 13:26:03,795 - transformer_training - INFO - Main loop iteration: 6194
2025-04-25 13:26:04,245 - transformer_training - INFO - Main loop iteration: 6195
2025-04-25 13:26:04,744 - transformer_training - INFO - Main loop iteration: 6196
2025-04-25 13:26:05,144 - transformer_training - INFO - Main loop iteration: 6197
2025-04-25 13:26:05,605 - transformer_training - INFO - Main loop iteration: 6198
2025-04-25 13:26:06,056 - transformer_training - INFO - Main loop iteration: 6199
2025-04-25 13:26:06,554 - transformer_training - INFO - Main loop iteration: 6200
Iter 6200: loss 3.4975, lr 0.000970, 91958.76 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 6200: train loss 3.0489, val loss 3.3920
2025-04-25 13:26:22,545 - transformer_training - INFO - Main loop iteration: 6201
2025-04-25 13:26:22,954 - transformer_training - INFO - Main loop iteration: 6202
2025-04-25 13:26:23,403 - transformer_training - INFO - Main loop iteration: 6203
2025-04-25 13:26:23,902 - transformer_training - INFO - Main loop iteration: 6204
2025-04-25 13:26:24,303 - transformer_training - INFO - Main loop iteration: 6205
2025-04-25 13:26:24,763 - transformer_training - INFO - Main loop iteration: 6206
2025-04-25 13:26:25,213 - transformer_training - INFO - Main loop iteration: 6207
2025-04-25 13:26:25,711 - transformer_training - INFO - Main loop iteration: 6208
2025-04-25 13:26:26,112 - transformer_training - INFO - Main loop iteration: 6209
2025-04-25 13:26:26,572 - transformer_training - INFO - Main loop iteration: 6210
Iter 6210: loss 3.3829, lr 0.000970, 81931.58 tokens/sec
2025-04-25 13:26:27,022 - transformer_training - INFO - Main loop iteration: 6211
2025-04-25 13:26:27,521 - transformer_training - INFO - Main loop iteration: 6212
2025-04-25 13:26:27,921 - transformer_training - INFO - Main loop iteration: 6213
2025-04-25 13:26:28,382 - transformer_training - INFO - Main loop iteration: 6214
2025-04-25 13:26:28,832 - transformer_training - INFO - Main loop iteration: 6215
2025-04-25 13:26:29,331 - transformer_training - INFO - Main loop iteration: 6216
2025-04-25 13:26:29,732 - transformer_training - INFO - Main loop iteration: 6217
2025-04-25 13:26:30,192 - transformer_training - INFO - Main loop iteration: 6218
2025-04-25 13:26:30,642 - transformer_training - INFO - Main loop iteration: 6219
2025-04-25 13:26:31,141 - transformer_training - INFO - Main loop iteration: 6220
Iter 6220: loss 3.4713, lr 0.000970, 92015.24 tokens/sec
2025-04-25 13:26:31,542 - transformer_training - INFO - Main loop iteration: 6221
2025-04-25 13:26:32,003 - transformer_training - INFO - Main loop iteration: 6222
2025-04-25 13:26:32,453 - transformer_training - INFO - Main loop iteration: 6223
2025-04-25 13:26:32,952 - transformer_training - INFO - Main loop iteration: 6224
2025-04-25 13:26:33,352 - transformer_training - INFO - Main loop iteration: 6225
2025-04-25 13:26:33,814 - transformer_training - INFO - Main loop iteration: 6226
2025-04-25 13:26:34,264 - transformer_training - INFO - Main loop iteration: 6227
2025-04-25 13:26:34,763 - transformer_training - INFO - Main loop iteration: 6228
2025-04-25 13:26:35,164 - transformer_training - INFO - Main loop iteration: 6229
2025-04-25 13:26:35,624 - transformer_training - INFO - Main loop iteration: 6230
Iter 6230: loss 3.3650, lr 0.000970, 81908.97 tokens/sec
2025-04-25 13:26:36,075 - transformer_training - INFO - Main loop iteration: 6231
2025-04-25 13:26:36,573 - transformer_training - INFO - Main loop iteration: 6232
2025-04-25 13:26:36,974 - transformer_training - INFO - Main loop iteration: 6233
2025-04-25 13:26:37,435 - transformer_training - INFO - Main loop iteration: 6234
2025-04-25 13:26:37,885 - transformer_training - INFO - Main loop iteration: 6235
2025-04-25 13:26:38,384 - transformer_training - INFO - Main loop iteration: 6236
2025-04-25 13:26:38,785 - transformer_training - INFO - Main loop iteration: 6237
2025-04-25 13:26:39,247 - transformer_training - INFO - Main loop iteration: 6238
2025-04-25 13:26:39,697 - transformer_training - INFO - Main loop iteration: 6239
2025-04-25 13:26:40,195 - transformer_training - INFO - Main loop iteration: 6240
Iter 6240: loss 3.4460, lr 0.000970, 91978.84 tokens/sec
2025-04-25 13:26:40,596 - transformer_training - INFO - Main loop iteration: 6241
2025-04-25 13:26:41,058 - transformer_training - INFO - Main loop iteration: 6242
2025-04-25 13:26:41,508 - transformer_training - INFO - Main loop iteration: 6243
2025-04-25 13:26:42,007 - transformer_training - INFO - Main loop iteration: 6244
2025-04-25 13:26:42,408 - transformer_training - INFO - Main loop iteration: 6245
2025-04-25 13:26:42,869 - transformer_training - INFO - Main loop iteration: 6246
2025-04-25 13:26:43,319 - transformer_training - INFO - Main loop iteration: 6247
2025-04-25 13:26:43,818 - transformer_training - INFO - Main loop iteration: 6248
2025-04-25 13:26:44,219 - transformer_training - INFO - Main loop iteration: 6249
2025-04-25 13:26:44,680 - transformer_training - INFO - Main loop iteration: 6250
Iter 6250: loss 3.3831, lr 0.000970, 81893.09 tokens/sec
2025-04-25 13:26:45,131 - transformer_training - INFO - Main loop iteration: 6251
2025-04-25 13:26:45,629 - transformer_training - INFO - Main loop iteration: 6252
2025-04-25 13:26:46,030 - transformer_training - INFO - Main loop iteration: 6253
2025-04-25 13:26:46,491 - transformer_training - INFO - Main loop iteration: 6254
2025-04-25 13:26:46,941 - transformer_training - INFO - Main loop iteration: 6255
2025-04-25 13:26:47,440 - transformer_training - INFO - Main loop iteration: 6256
2025-04-25 13:26:47,841 - transformer_training - INFO - Main loop iteration: 6257
2025-04-25 13:26:48,302 - transformer_training - INFO - Main loop iteration: 6258
2025-04-25 13:26:48,752 - transformer_training - INFO - Main loop iteration: 6259
2025-04-25 13:26:49,251 - transformer_training - INFO - Main loop iteration: 6260
Iter 6260: loss 3.3837, lr 0.000969, 91977.20 tokens/sec
2025-04-25 13:26:49,653 - transformer_training - INFO - Main loop iteration: 6261
2025-04-25 13:26:50,113 - transformer_training - INFO - Main loop iteration: 6262
2025-04-25 13:26:50,564 - transformer_training - INFO - Main loop iteration: 6263
2025-04-25 13:26:51,063 - transformer_training - INFO - Main loop iteration: 6264
2025-04-25 13:26:51,464 - transformer_training - INFO - Main loop iteration: 6265
2025-04-25 13:26:51,925 - transformer_training - INFO - Main loop iteration: 6266
2025-04-25 13:26:52,376 - transformer_training - INFO - Main loop iteration: 6267
2025-04-25 13:26:52,874 - transformer_training - INFO - Main loop iteration: 6268
2025-04-25 13:26:53,275 - transformer_training - INFO - Main loop iteration: 6269
2025-04-25 13:26:53,737 - transformer_training - INFO - Main loop iteration: 6270
Iter 6270: loss 3.4056, lr 0.000969, 81818.21 tokens/sec
2025-04-25 13:26:54,188 - transformer_training - INFO - Main loop iteration: 6271
2025-04-25 13:26:54,687 - transformer_training - INFO - Main loop iteration: 6272
2025-04-25 13:26:55,088 - transformer_training - INFO - Main loop iteration: 6273
2025-04-25 13:26:55,549 - transformer_training - INFO - Main loop iteration: 6274
2025-04-25 13:26:56,000 - transformer_training - INFO - Main loop iteration: 6275
2025-04-25 13:26:56,499 - transformer_training - INFO - Main loop iteration: 6276
2025-04-25 13:26:56,900 - transformer_training - INFO - Main loop iteration: 6277
2025-04-25 13:26:57,361 - transformer_training - INFO - Main loop iteration: 6278
2025-04-25 13:26:57,811 - transformer_training - INFO - Main loop iteration: 6279
2025-04-25 13:26:58,310 - transformer_training - INFO - Main loop iteration: 6280
Iter 6280: loss 3.5170, lr 0.000969, 91843.13 tokens/sec
2025-04-25 13:26:58,712 - transformer_training - INFO - Main loop iteration: 6281
2025-04-25 13:26:59,172 - transformer_training - INFO - Main loop iteration: 6282
2025-04-25 13:26:59,623 - transformer_training - INFO - Main loop iteration: 6283
2025-04-25 13:27:00,121 - transformer_training - INFO - Main loop iteration: 6284
2025-04-25 13:27:00,523 - transformer_training - INFO - Main loop iteration: 6285
2025-04-25 13:27:00,985 - transformer_training - INFO - Main loop iteration: 6286
2025-04-25 13:27:01,435 - transformer_training - INFO - Main loop iteration: 6287
2025-04-25 13:27:01,934 - transformer_training - INFO - Main loop iteration: 6288
2025-04-25 13:27:02,336 - transformer_training - INFO - Main loop iteration: 6289
2025-04-25 13:27:02,797 - transformer_training - INFO - Main loop iteration: 6290
Iter 6290: loss 3.4131, lr 0.000969, 81744.02 tokens/sec
2025-04-25 13:27:03,248 - transformer_training - INFO - Main loop iteration: 6291
2025-04-25 13:27:03,747 - transformer_training - INFO - Main loop iteration: 6292
2025-04-25 13:27:04,148 - transformer_training - INFO - Main loop iteration: 6293
2025-04-25 13:27:04,609 - transformer_training - INFO - Main loop iteration: 6294
2025-04-25 13:27:05,060 - transformer_training - INFO - Main loop iteration: 6295
2025-04-25 13:27:05,559 - transformer_training - INFO - Main loop iteration: 6296
2025-04-25 13:27:05,961 - transformer_training - INFO - Main loop iteration: 6297
2025-04-25 13:27:06,423 - transformer_training - INFO - Main loop iteration: 6298
2025-04-25 13:27:06,874 - transformer_training - INFO - Main loop iteration: 6299
2025-04-25 13:27:07,373 - transformer_training - INFO - Main loop iteration: 6300
Iter 6300: loss 3.5492, lr 0.000969, 91806.86 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6300: train loss 3.1327, val loss 3.3712
New best model saved with val loss: 3.3712
2025-04-25 13:27:25,297 - transformer_training - INFO - Main loop iteration: 6301
2025-04-25 13:27:25,710 - transformer_training - INFO - Main loop iteration: 6302
2025-04-25 13:27:26,161 - transformer_training - INFO - Main loop iteration: 6303
2025-04-25 13:27:26,659 - transformer_training - INFO - Main loop iteration: 6304
2025-04-25 13:27:27,059 - transformer_training - INFO - Main loop iteration: 6305
2025-04-25 13:27:27,520 - transformer_training - INFO - Main loop iteration: 6306
2025-04-25 13:27:27,969 - transformer_training - INFO - Main loop iteration: 6307
2025-04-25 13:27:28,468 - transformer_training - INFO - Main loop iteration: 6308
2025-04-25 13:27:28,868 - transformer_training - INFO - Main loop iteration: 6309
2025-04-25 13:27:29,328 - transformer_training - INFO - Main loop iteration: 6310
Iter 6310: loss 3.4306, lr 0.000969, 81862.39 tokens/sec
2025-04-25 13:27:29,779 - transformer_training - INFO - Main loop iteration: 6311
2025-04-25 13:27:30,277 - transformer_training - INFO - Main loop iteration: 6312
2025-04-25 13:27:30,680 - transformer_training - INFO - Main loop iteration: 6313
2025-04-25 13:27:31,140 - transformer_training - INFO - Main loop iteration: 6314
2025-04-25 13:27:31,590 - transformer_training - INFO - Main loop iteration: 6315
2025-04-25 13:27:32,090 - transformer_training - INFO - Main loop iteration: 6316
2025-04-25 13:27:32,490 - transformer_training - INFO - Main loop iteration: 6317
2025-04-25 13:27:32,953 - transformer_training - INFO - Main loop iteration: 6318
2025-04-25 13:27:33,404 - transformer_training - INFO - Main loop iteration: 6319
2025-04-25 13:27:33,902 - transformer_training - INFO - Main loop iteration: 6320
Iter 6320: loss 3.4626, lr 0.000969, 91916.78 tokens/sec
2025-04-25 13:27:34,304 - transformer_training - INFO - Main loop iteration: 6321
2025-04-25 13:27:34,764 - transformer_training - INFO - Main loop iteration: 6322
2025-04-25 13:27:35,215 - transformer_training - INFO - Main loop iteration: 6323
2025-04-25 13:27:35,714 - transformer_training - INFO - Main loop iteration: 6324
2025-04-25 13:27:36,115 - transformer_training - INFO - Main loop iteration: 6325
2025-04-25 13:27:36,576 - transformer_training - INFO - Main loop iteration: 6326
2025-04-25 13:27:37,027 - transformer_training - INFO - Main loop iteration: 6327
2025-04-25 13:27:37,525 - transformer_training - INFO - Main loop iteration: 6328
2025-04-25 13:27:37,927 - transformer_training - INFO - Main loop iteration: 6329
2025-04-25 13:27:38,388 - transformer_training - INFO - Main loop iteration: 6330
Iter 6330: loss 3.5262, lr 0.000968, 81929.63 tokens/sec
2025-04-25 13:27:38,839 - transformer_training - INFO - Main loop iteration: 6331
2025-04-25 13:27:39,337 - transformer_training - INFO - Main loop iteration: 6332
2025-04-25 13:27:39,739 - transformer_training - INFO - Main loop iteration: 6333
2025-04-25 13:27:40,200 - transformer_training - INFO - Main loop iteration: 6334
2025-04-25 13:27:40,651 - transformer_training - INFO - Main loop iteration: 6335
2025-04-25 13:27:41,149 - transformer_training - INFO - Main loop iteration: 6336
2025-04-25 13:27:41,551 - transformer_training - INFO - Main loop iteration: 6337
2025-04-25 13:27:42,012 - transformer_training - INFO - Main loop iteration: 6338
2025-04-25 13:27:42,463 - transformer_training - INFO - Main loop iteration: 6339
2025-04-25 13:27:42,961 - transformer_training - INFO - Main loop iteration: 6340
Iter 6340: loss 3.4286, lr 0.000968, 91779.07 tokens/sec
2025-04-25 13:27:43,363 - transformer_training - INFO - Main loop iteration: 6341
2025-04-25 13:27:43,824 - transformer_training - INFO - Main loop iteration: 6342
2025-04-25 13:27:44,275 - transformer_training - INFO - Main loop iteration: 6343
2025-04-25 13:27:44,773 - transformer_training - INFO - Main loop iteration: 6344
2025-04-25 13:27:45,174 - transformer_training - INFO - Main loop iteration: 6345
2025-04-25 13:27:45,635 - transformer_training - INFO - Main loop iteration: 6346
2025-04-25 13:27:46,086 - transformer_training - INFO - Main loop iteration: 6347
2025-04-25 13:27:46,584 - transformer_training - INFO - Main loop iteration: 6348
2025-04-25 13:27:46,986 - transformer_training - INFO - Main loop iteration: 6349
2025-04-25 13:27:47,447 - transformer_training - INFO - Main loop iteration: 6350
Iter 6350: loss 3.4159, lr 0.000968, 81845.45 tokens/sec
2025-04-25 13:27:47,898 - transformer_training - INFO - Main loop iteration: 6351
2025-04-25 13:27:48,396 - transformer_training - INFO - Main loop iteration: 6352
2025-04-25 13:27:48,798 - transformer_training - INFO - Main loop iteration: 6353
2025-04-25 13:27:49,259 - transformer_training - INFO - Main loop iteration: 6354
2025-04-25 13:27:49,709 - transformer_training - INFO - Main loop iteration: 6355
2025-04-25 13:27:50,209 - transformer_training - INFO - Main loop iteration: 6356
2025-04-25 13:27:50,609 - transformer_training - INFO - Main loop iteration: 6357
2025-04-25 13:27:51,070 - transformer_training - INFO - Main loop iteration: 6358
2025-04-25 13:27:51,521 - transformer_training - INFO - Main loop iteration: 6359
2025-04-25 13:27:52,020 - transformer_training - INFO - Main loop iteration: 6360
Iter 6360: loss 3.5377, lr 0.000968, 91968.39 tokens/sec
2025-04-25 13:27:52,422 - transformer_training - INFO - Main loop iteration: 6361
2025-04-25 13:27:52,882 - transformer_training - INFO - Main loop iteration: 6362
2025-04-25 13:27:53,334 - transformer_training - INFO - Main loop iteration: 6363
2025-04-25 13:27:53,832 - transformer_training - INFO - Main loop iteration: 6364
2025-04-25 13:27:54,233 - transformer_training - INFO - Main loop iteration: 6365
2025-04-25 13:27:54,694 - transformer_training - INFO - Main loop iteration: 6366
2025-04-25 13:27:55,146 - transformer_training - INFO - Main loop iteration: 6367
2025-04-25 13:27:55,645 - transformer_training - INFO - Main loop iteration: 6368
2025-04-25 13:27:56,046 - transformer_training - INFO - Main loop iteration: 6369
2025-04-25 13:27:56,507 - transformer_training - INFO - Main loop iteration: 6370
Iter 6370: loss 3.4761, lr 0.000968, 81817.21 tokens/sec
2025-04-25 13:27:56,958 - transformer_training - INFO - Main loop iteration: 6371
2025-04-25 13:27:57,457 - transformer_training - INFO - Main loop iteration: 6372
2025-04-25 13:27:57,858 - transformer_training - INFO - Main loop iteration: 6373
2025-04-25 13:27:58,319 - transformer_training - INFO - Main loop iteration: 6374
2025-04-25 13:27:58,770 - transformer_training - INFO - Main loop iteration: 6375
2025-04-25 13:27:59,268 - transformer_training - INFO - Main loop iteration: 6376
2025-04-25 13:27:59,669 - transformer_training - INFO - Main loop iteration: 6377
2025-04-25 13:28:00,130 - transformer_training - INFO - Main loop iteration: 6378
2025-04-25 13:28:00,581 - transformer_training - INFO - Main loop iteration: 6379
2025-04-25 13:28:01,080 - transformer_training - INFO - Main loop iteration: 6380
Iter 6380: loss 3.4361, lr 0.000968, 91757.12 tokens/sec
2025-04-25 13:28:01,482 - transformer_training - INFO - Main loop iteration: 6381
2025-04-25 13:28:01,943 - transformer_training - INFO - Main loop iteration: 6382
2025-04-25 13:28:02,394 - transformer_training - INFO - Main loop iteration: 6383
2025-04-25 13:28:02,892 - transformer_training - INFO - Main loop iteration: 6384
2025-04-25 13:28:03,294 - transformer_training - INFO - Main loop iteration: 6385
2025-04-25 13:28:03,755 - transformer_training - INFO - Main loop iteration: 6386
2025-04-25 13:28:04,206 - transformer_training - INFO - Main loop iteration: 6387
2025-04-25 13:28:04,705 - transformer_training - INFO - Main loop iteration: 6388
2025-04-25 13:28:05,106 - transformer_training - INFO - Main loop iteration: 6389
2025-04-25 13:28:05,567 - transformer_training - INFO - Main loop iteration: 6390
Iter 6390: loss 3.4279, lr 0.000968, 81859.84 tokens/sec
2025-04-25 13:28:06,018 - transformer_training - INFO - Main loop iteration: 6391
2025-04-25 13:28:06,517 - transformer_training - INFO - Main loop iteration: 6392
2025-04-25 13:28:06,918 - transformer_training - INFO - Main loop iteration: 6393
2025-04-25 13:28:07,380 - transformer_training - INFO - Main loop iteration: 6394
2025-04-25 13:28:07,830 - transformer_training - INFO - Main loop iteration: 6395
2025-04-25 13:28:08,329 - transformer_training - INFO - Main loop iteration: 6396
2025-04-25 13:28:08,731 - transformer_training - INFO - Main loop iteration: 6397
2025-04-25 13:28:09,192 - transformer_training - INFO - Main loop iteration: 6398
2025-04-25 13:28:09,642 - transformer_training - INFO - Main loop iteration: 6399
2025-04-25 13:28:10,141 - transformer_training - INFO - Main loop iteration: 6400
Iter 6400: loss 3.4392, lr 0.000967, 91936.07 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 6400: train loss 3.1850, val loss 3.3763
2025-04-25 13:28:25,769 - transformer_training - INFO - Main loop iteration: 6401
2025-04-25 13:28:26,177 - transformer_training - INFO - Main loop iteration: 6402
2025-04-25 13:28:26,627 - transformer_training - INFO - Main loop iteration: 6403
2025-04-25 13:28:27,125 - transformer_training - INFO - Main loop iteration: 6404
2025-04-25 13:28:27,526 - transformer_training - INFO - Main loop iteration: 6405
2025-04-25 13:28:27,987 - transformer_training - INFO - Main loop iteration: 6406
2025-04-25 13:28:28,437 - transformer_training - INFO - Main loop iteration: 6407
2025-04-25 13:28:28,936 - transformer_training - INFO - Main loop iteration: 6408
2025-04-25 13:28:29,337 - transformer_training - INFO - Main loop iteration: 6409
2025-04-25 13:28:29,797 - transformer_training - INFO - Main loop iteration: 6410
Iter 6410: loss 3.4539, lr 0.000967, 81903.59 tokens/sec
2025-04-25 13:28:30,248 - transformer_training - INFO - Main loop iteration: 6411
2025-04-25 13:28:30,746 - transformer_training - INFO - Main loop iteration: 6412
2025-04-25 13:28:31,147 - transformer_training - INFO - Main loop iteration: 6413
2025-04-25 13:28:31,608 - transformer_training - INFO - Main loop iteration: 6414
2025-04-25 13:28:32,058 - transformer_training - INFO - Main loop iteration: 6415
2025-04-25 13:28:32,557 - transformer_training - INFO - Main loop iteration: 6416
2025-04-25 13:28:32,960 - transformer_training - INFO - Main loop iteration: 6417
2025-04-25 13:28:33,419 - transformer_training - INFO - Main loop iteration: 6418
2025-04-25 13:28:33,869 - transformer_training - INFO - Main loop iteration: 6419
2025-04-25 13:28:34,368 - transformer_training - INFO - Main loop iteration: 6420
Iter 6420: loss 3.4135, lr 0.000967, 92026.08 tokens/sec
2025-04-25 13:28:34,769 - transformer_training - INFO - Main loop iteration: 6421
2025-04-25 13:28:35,230 - transformer_training - INFO - Main loop iteration: 6422
2025-04-25 13:28:35,681 - transformer_training - INFO - Main loop iteration: 6423
2025-04-25 13:28:36,180 - transformer_training - INFO - Main loop iteration: 6424
2025-04-25 13:28:36,580 - transformer_training - INFO - Main loop iteration: 6425
2025-04-25 13:28:37,041 - transformer_training - INFO - Main loop iteration: 6426
2025-04-25 13:28:37,492 - transformer_training - INFO - Main loop iteration: 6427
2025-04-25 13:28:37,990 - transformer_training - INFO - Main loop iteration: 6428
2025-04-25 13:28:38,391 - transformer_training - INFO - Main loop iteration: 6429
2025-04-25 13:28:38,853 - transformer_training - INFO - Main loop iteration: 6430
Iter 6430: loss 3.4249, lr 0.000967, 81760.54 tokens/sec
2025-04-25 13:28:39,304 - transformer_training - INFO - Main loop iteration: 6431
2025-04-25 13:28:39,803 - transformer_training - INFO - Main loop iteration: 6432
2025-04-25 13:28:40,204 - transformer_training - INFO - Main loop iteration: 6433
2025-04-25 13:28:40,666 - transformer_training - INFO - Main loop iteration: 6434
2025-04-25 13:28:41,116 - transformer_training - INFO - Main loop iteration: 6435
2025-04-25 13:28:41,615 - transformer_training - INFO - Main loop iteration: 6436
2025-04-25 13:28:42,016 - transformer_training - INFO - Main loop iteration: 6437
2025-04-25 13:28:42,477 - transformer_training - INFO - Main loop iteration: 6438
2025-04-25 13:28:42,928 - transformer_training - INFO - Main loop iteration: 6439
2025-04-25 13:28:43,428 - transformer_training - INFO - Main loop iteration: 6440
Iter 6440: loss 3.3746, lr 0.000967, 92109.19 tokens/sec
2025-04-25 13:28:43,829 - transformer_training - INFO - Main loop iteration: 6441
2025-04-25 13:28:44,290 - transformer_training - INFO - Main loop iteration: 6442
2025-04-25 13:28:44,740 - transformer_training - INFO - Main loop iteration: 6443
2025-04-25 13:28:45,239 - transformer_training - INFO - Main loop iteration: 6444
2025-04-25 13:28:45,641 - transformer_training - INFO - Main loop iteration: 6445
2025-04-25 13:28:46,101 - transformer_training - INFO - Main loop iteration: 6446
2025-04-25 13:28:46,552 - transformer_training - INFO - Main loop iteration: 6447
2025-04-25 13:28:47,050 - transformer_training - INFO - Main loop iteration: 6448
2025-04-25 13:28:47,452 - transformer_training - INFO - Main loop iteration: 6449
2025-04-25 13:28:47,912 - transformer_training - INFO - Main loop iteration: 6450
Iter 6450: loss 3.5362, lr 0.000967, 81872.67 tokens/sec
2025-04-25 13:28:48,363 - transformer_training - INFO - Main loop iteration: 6451
2025-04-25 13:28:48,862 - transformer_training - INFO - Main loop iteration: 6452
2025-04-25 13:28:49,263 - transformer_training - INFO - Main loop iteration: 6453
2025-04-25 13:28:49,724 - transformer_training - INFO - Main loop iteration: 6454
2025-04-25 13:28:50,174 - transformer_training - INFO - Main loop iteration: 6455
2025-04-25 13:28:50,673 - transformer_training - INFO - Main loop iteration: 6456
2025-04-25 13:28:51,074 - transformer_training - INFO - Main loop iteration: 6457
2025-04-25 13:28:51,535 - transformer_training - INFO - Main loop iteration: 6458
2025-04-25 13:28:51,985 - transformer_training - INFO - Main loop iteration: 6459
2025-04-25 13:28:52,485 - transformer_training - INFO - Main loop iteration: 6460
Iter 6460: loss 3.4244, lr 0.000966, 92039.18 tokens/sec
2025-04-25 13:28:52,886 - transformer_training - INFO - Main loop iteration: 6461
2025-04-25 13:28:53,347 - transformer_training - INFO - Main loop iteration: 6462
2025-04-25 13:28:53,798 - transformer_training - INFO - Main loop iteration: 6463
2025-04-25 13:28:54,296 - transformer_training - INFO - Main loop iteration: 6464
2025-04-25 13:28:54,697 - transformer_training - INFO - Main loop iteration: 6465
2025-04-25 13:28:55,160 - transformer_training - INFO - Main loop iteration: 6466
2025-04-25 13:28:55,611 - transformer_training - INFO - Main loop iteration: 6467
2025-04-25 13:28:56,111 - transformer_training - INFO - Main loop iteration: 6468
2025-04-25 13:28:56,513 - transformer_training - INFO - Main loop iteration: 6469
2025-04-25 13:28:56,974 - transformer_training - INFO - Main loop iteration: 6470
Iter 6470: loss 3.4403, lr 0.000966, 81852.73 tokens/sec
2025-04-25 13:28:57,425 - transformer_training - INFO - Main loop iteration: 6471
2025-04-25 13:28:57,924 - transformer_training - INFO - Main loop iteration: 6472
2025-04-25 13:28:58,325 - transformer_training - INFO - Main loop iteration: 6473
2025-04-25 13:28:58,786 - transformer_training - INFO - Main loop iteration: 6474
2025-04-25 13:28:59,237 - transformer_training - INFO - Main loop iteration: 6475
2025-04-25 13:28:59,736 - transformer_training - INFO - Main loop iteration: 6476
2025-04-25 13:29:00,138 - transformer_training - INFO - Main loop iteration: 6477
2025-04-25 13:29:00,599 - transformer_training - INFO - Main loop iteration: 6478
2025-04-25 13:29:01,050 - transformer_training - INFO - Main loop iteration: 6479
2025-04-25 13:29:01,549 - transformer_training - INFO - Main loop iteration: 6480
Iter 6480: loss 3.4665, lr 0.000966, 91597.09 tokens/sec
2025-04-25 13:29:01,952 - transformer_training - INFO - Main loop iteration: 6481
2025-04-25 13:29:02,413 - transformer_training - INFO - Main loop iteration: 6482
2025-04-25 13:29:02,863 - transformer_training - INFO - Main loop iteration: 6483
2025-04-25 13:29:03,362 - transformer_training - INFO - Main loop iteration: 6484
2025-04-25 13:29:03,765 - transformer_training - INFO - Main loop iteration: 6485
2025-04-25 13:29:04,227 - transformer_training - INFO - Main loop iteration: 6486
2025-04-25 13:29:04,678 - transformer_training - INFO - Main loop iteration: 6487
2025-04-25 13:29:05,177 - transformer_training - INFO - Main loop iteration: 6488
2025-04-25 13:29:05,579 - transformer_training - INFO - Main loop iteration: 6489
2025-04-25 13:29:06,118 - transformer_training - INFO - Main loop iteration: 6490
Iter 6490: loss 3.4143, lr 0.000966, 81882.99 tokens/sec
2025-04-25 13:29:06,569 - transformer_training - INFO - Main loop iteration: 6491
2025-04-25 13:29:07,068 - transformer_training - INFO - Main loop iteration: 6492
2025-04-25 13:29:07,469 - transformer_training - INFO - Main loop iteration: 6493
2025-04-25 13:29:07,931 - transformer_training - INFO - Main loop iteration: 6494
2025-04-25 13:29:08,381 - transformer_training - INFO - Main loop iteration: 6495
2025-04-25 13:29:08,880 - transformer_training - INFO - Main loop iteration: 6496
2025-04-25 13:29:09,282 - transformer_training - INFO - Main loop iteration: 6497
2025-04-25 13:29:09,743 - transformer_training - INFO - Main loop iteration: 6498
2025-04-25 13:29:10,193 - transformer_training - INFO - Main loop iteration: 6499
2025-04-25 13:29:10,693 - transformer_training - INFO - Main loop iteration: 6500
Iter 6500: loss 3.5113, lr 0.000966, 91932.47 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6500: train loss 3.2186, val loss 3.3728
2025-04-25 13:29:27,514 - transformer_training - INFO - Main loop iteration: 6501
2025-04-25 13:29:27,924 - transformer_training - INFO - Main loop iteration: 6502
2025-04-25 13:29:28,374 - transformer_training - INFO - Main loop iteration: 6503
2025-04-25 13:29:28,873 - transformer_training - INFO - Main loop iteration: 6504
2025-04-25 13:29:29,274 - transformer_training - INFO - Main loop iteration: 6505
2025-04-25 13:29:29,735 - transformer_training - INFO - Main loop iteration: 6506
2025-04-25 13:29:30,186 - transformer_training - INFO - Main loop iteration: 6507
2025-04-25 13:29:30,684 - transformer_training - INFO - Main loop iteration: 6508
2025-04-25 13:29:31,085 - transformer_training - INFO - Main loop iteration: 6509
2025-04-25 13:29:31,545 - transformer_training - INFO - Main loop iteration: 6510
Iter 6510: loss 3.4884, lr 0.000966, 81951.82 tokens/sec
2025-04-25 13:29:31,996 - transformer_training - INFO - Main loop iteration: 6511
2025-04-25 13:29:32,497 - transformer_training - INFO - Main loop iteration: 6512
2025-04-25 13:29:32,897 - transformer_training - INFO - Main loop iteration: 6513
2025-04-25 13:29:33,358 - transformer_training - INFO - Main loop iteration: 6514
2025-04-25 13:29:33,809 - transformer_training - INFO - Main loop iteration: 6515
2025-04-25 13:29:34,307 - transformer_training - INFO - Main loop iteration: 6516
2025-04-25 13:29:34,707 - transformer_training - INFO - Main loop iteration: 6517
2025-04-25 13:29:35,168 - transformer_training - INFO - Main loop iteration: 6518
2025-04-25 13:29:35,619 - transformer_training - INFO - Main loop iteration: 6519
2025-04-25 13:29:36,119 - transformer_training - INFO - Main loop iteration: 6520
Iter 6520: loss 3.3837, lr 0.000966, 92175.42 tokens/sec
2025-04-25 13:29:36,519 - transformer_training - INFO - Main loop iteration: 6521
2025-04-25 13:29:36,980 - transformer_training - INFO - Main loop iteration: 6522
2025-04-25 13:29:37,430 - transformer_training - INFO - Main loop iteration: 6523
2025-04-25 13:29:37,930 - transformer_training - INFO - Main loop iteration: 6524
2025-04-25 13:29:38,330 - transformer_training - INFO - Main loop iteration: 6525
2025-04-25 13:29:38,791 - transformer_training - INFO - Main loop iteration: 6526
2025-04-25 13:29:39,242 - transformer_training - INFO - Main loop iteration: 6527
2025-04-25 13:29:39,741 - transformer_training - INFO - Main loop iteration: 6528
2025-04-25 13:29:40,142 - transformer_training - INFO - Main loop iteration: 6529
2025-04-25 13:29:40,602 - transformer_training - INFO - Main loop iteration: 6530
Iter 6530: loss 3.3700, lr 0.000965, 81959.03 tokens/sec
2025-04-25 13:29:41,053 - transformer_training - INFO - Main loop iteration: 6531
2025-04-25 13:29:41,552 - transformer_training - INFO - Main loop iteration: 6532
2025-04-25 13:29:41,953 - transformer_training - INFO - Main loop iteration: 6533
2025-04-25 13:29:42,414 - transformer_training - INFO - Main loop iteration: 6534
2025-04-25 13:29:42,864 - transformer_training - INFO - Main loop iteration: 6535
2025-04-25 13:29:43,363 - transformer_training - INFO - Main loop iteration: 6536
2025-04-25 13:29:43,764 - transformer_training - INFO - Main loop iteration: 6537
2025-04-25 13:29:44,225 - transformer_training - INFO - Main loop iteration: 6538
2025-04-25 13:29:44,675 - transformer_training - INFO - Main loop iteration: 6539
2025-04-25 13:29:45,175 - transformer_training - INFO - Main loop iteration: 6540
Iter 6540: loss 3.5263, lr 0.000965, 92033.53 tokens/sec
2025-04-25 13:29:45,576 - transformer_training - INFO - Main loop iteration: 6541
2025-04-25 13:29:46,037 - transformer_training - INFO - Main loop iteration: 6542
2025-04-25 13:29:46,487 - transformer_training - INFO - Main loop iteration: 6543
2025-04-25 13:29:46,986 - transformer_training - INFO - Main loop iteration: 6544
2025-04-25 13:29:47,387 - transformer_training - INFO - Main loop iteration: 6545
2025-04-25 13:29:47,848 - transformer_training - INFO - Main loop iteration: 6546
2025-04-25 13:29:48,298 - transformer_training - INFO - Main loop iteration: 6547
2025-04-25 13:29:48,797 - transformer_training - INFO - Main loop iteration: 6548
2025-04-25 13:29:49,198 - transformer_training - INFO - Main loop iteration: 6549
2025-04-25 13:29:49,659 - transformer_training - INFO - Main loop iteration: 6550
Iter 6550: loss 3.4662, lr 0.000965, 81992.32 tokens/sec
2025-04-25 13:29:50,110 - transformer_training - INFO - Main loop iteration: 6551
2025-04-25 13:29:50,608 - transformer_training - INFO - Main loop iteration: 6552
2025-04-25 13:29:51,009 - transformer_training - INFO - Main loop iteration: 6553
2025-04-25 13:29:51,470 - transformer_training - INFO - Main loop iteration: 6554
2025-04-25 13:29:51,920 - transformer_training - INFO - Main loop iteration: 6555
2025-04-25 13:29:52,420 - transformer_training - INFO - Main loop iteration: 6556
2025-04-25 13:29:52,821 - transformer_training - INFO - Main loop iteration: 6557
2025-04-25 13:29:53,281 - transformer_training - INFO - Main loop iteration: 6558
2025-04-25 13:29:53,732 - transformer_training - INFO - Main loop iteration: 6559
2025-04-25 13:29:54,230 - transformer_training - INFO - Main loop iteration: 6560
Iter 6560: loss 3.4711, lr 0.000965, 92098.39 tokens/sec
2025-04-25 13:29:54,631 - transformer_training - INFO - Main loop iteration: 6561
2025-04-25 13:29:55,092 - transformer_training - INFO - Main loop iteration: 6562
2025-04-25 13:29:55,542 - transformer_training - INFO - Main loop iteration: 6563
2025-04-25 13:29:56,041 - transformer_training - INFO - Main loop iteration: 6564
2025-04-25 13:29:56,442 - transformer_training - INFO - Main loop iteration: 6565
2025-04-25 13:29:56,903 - transformer_training - INFO - Main loop iteration: 6566
2025-04-25 13:29:57,353 - transformer_training - INFO - Main loop iteration: 6567
2025-04-25 13:29:57,853 - transformer_training - INFO - Main loop iteration: 6568
2025-04-25 13:29:58,254 - transformer_training - INFO - Main loop iteration: 6569
2025-04-25 13:29:58,715 - transformer_training - INFO - Main loop iteration: 6570
Iter 6570: loss 3.4566, lr 0.000965, 81939.27 tokens/sec
2025-04-25 13:29:59,166 - transformer_training - INFO - Main loop iteration: 6571
2025-04-25 13:29:59,665 - transformer_training - INFO - Main loop iteration: 6572
2025-04-25 13:30:00,066 - transformer_training - INFO - Main loop iteration: 6573
2025-04-25 13:30:00,527 - transformer_training - INFO - Main loop iteration: 6574
2025-04-25 13:30:00,978 - transformer_training - INFO - Main loop iteration: 6575
2025-04-25 13:30:01,477 - transformer_training - INFO - Main loop iteration: 6576
2025-04-25 13:30:01,878 - transformer_training - INFO - Main loop iteration: 6577
2025-04-25 13:30:02,339 - transformer_training - INFO - Main loop iteration: 6578
2025-04-25 13:30:02,790 - transformer_training - INFO - Main loop iteration: 6579
2025-04-25 13:30:03,289 - transformer_training - INFO - Main loop iteration: 6580
Iter 6580: loss 3.5274, lr 0.000965, 92004.29 tokens/sec
2025-04-25 13:30:03,690 - transformer_training - INFO - Main loop iteration: 6581
2025-04-25 13:30:04,151 - transformer_training - INFO - Main loop iteration: 6582
2025-04-25 13:30:04,601 - transformer_training - INFO - Main loop iteration: 6583
2025-04-25 13:30:05,100 - transformer_training - INFO - Main loop iteration: 6584
2025-04-25 13:30:05,500 - transformer_training - INFO - Main loop iteration: 6585
2025-04-25 13:30:05,961 - transformer_training - INFO - Main loop iteration: 6586
2025-04-25 13:30:06,412 - transformer_training - INFO - Main loop iteration: 6587
2025-04-25 13:30:06,910 - transformer_training - INFO - Main loop iteration: 6588
2025-04-25 13:30:07,311 - transformer_training - INFO - Main loop iteration: 6589
2025-04-25 13:30:07,772 - transformer_training - INFO - Main loop iteration: 6590
Iter 6590: loss 3.5494, lr 0.000965, 81909.19 tokens/sec
2025-04-25 13:30:08,223 - transformer_training - INFO - Main loop iteration: 6591
2025-04-25 13:30:08,722 - transformer_training - INFO - Main loop iteration: 6592
2025-04-25 13:30:09,122 - transformer_training - INFO - Main loop iteration: 6593
2025-04-25 13:30:09,583 - transformer_training - INFO - Main loop iteration: 6594
2025-04-25 13:30:10,033 - transformer_training - INFO - Main loop iteration: 6595
2025-04-25 13:30:10,532 - transformer_training - INFO - Main loop iteration: 6596
2025-04-25 13:30:10,933 - transformer_training - INFO - Main loop iteration: 6597
2025-04-25 13:30:11,394 - transformer_training - INFO - Main loop iteration: 6598
2025-04-25 13:30:11,844 - transformer_training - INFO - Main loop iteration: 6599
2025-04-25 13:30:12,344 - transformer_training - INFO - Main loop iteration: 6600
Iter 6600: loss 3.3544, lr 0.000964, 92021.98 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6600: train loss 3.2392, val loss 3.3625
New best model saved with val loss: 3.3625
2025-04-25 13:30:29,868 - transformer_training - INFO - Main loop iteration: 6601
2025-04-25 13:30:30,281 - transformer_training - INFO - Main loop iteration: 6602
2025-04-25 13:30:30,731 - transformer_training - INFO - Main loop iteration: 6603
2025-04-25 13:30:31,229 - transformer_training - INFO - Main loop iteration: 6604
2025-04-25 13:30:31,629 - transformer_training - INFO - Main loop iteration: 6605
2025-04-25 13:30:32,090 - transformer_training - INFO - Main loop iteration: 6606
2025-04-25 13:30:32,540 - transformer_training - INFO - Main loop iteration: 6607
2025-04-25 13:30:33,039 - transformer_training - INFO - Main loop iteration: 6608
2025-04-25 13:30:33,439 - transformer_training - INFO - Main loop iteration: 6609
2025-04-25 13:30:33,900 - transformer_training - INFO - Main loop iteration: 6610
Iter 6610: loss 3.3781, lr 0.000964, 81900.29 tokens/sec
2025-04-25 13:30:34,351 - transformer_training - INFO - Main loop iteration: 6611
2025-04-25 13:30:34,849 - transformer_training - INFO - Main loop iteration: 6612
2025-04-25 13:30:35,249 - transformer_training - INFO - Main loop iteration: 6613
2025-04-25 13:30:35,710 - transformer_training - INFO - Main loop iteration: 6614
2025-04-25 13:30:36,160 - transformer_training - INFO - Main loop iteration: 6615
2025-04-25 13:30:36,658 - transformer_training - INFO - Main loop iteration: 6616
2025-04-25 13:30:37,058 - transformer_training - INFO - Main loop iteration: 6617
2025-04-25 13:30:37,519 - transformer_training - INFO - Main loop iteration: 6618
2025-04-25 13:30:37,969 - transformer_training - INFO - Main loop iteration: 6619
2025-04-25 13:30:38,468 - transformer_training - INFO - Main loop iteration: 6620
Iter 6620: loss 3.4382, lr 0.000964, 92086.04 tokens/sec
2025-04-25 13:30:38,869 - transformer_training - INFO - Main loop iteration: 6621
2025-04-25 13:30:39,330 - transformer_training - INFO - Main loop iteration: 6622
2025-04-25 13:30:39,781 - transformer_training - INFO - Main loop iteration: 6623
2025-04-25 13:30:40,281 - transformer_training - INFO - Main loop iteration: 6624
2025-04-25 13:30:40,681 - transformer_training - INFO - Main loop iteration: 6625
2025-04-25 13:30:41,142 - transformer_training - INFO - Main loop iteration: 6626
2025-04-25 13:30:41,592 - transformer_training - INFO - Main loop iteration: 6627
2025-04-25 13:30:42,092 - transformer_training - INFO - Main loop iteration: 6628
2025-04-25 13:30:42,492 - transformer_training - INFO - Main loop iteration: 6629
2025-04-25 13:30:42,953 - transformer_training - INFO - Main loop iteration: 6630
Iter 6630: loss 3.3601, lr 0.000964, 81942.61 tokens/sec
2025-04-25 13:30:43,403 - transformer_training - INFO - Main loop iteration: 6631
2025-04-25 13:30:43,902 - transformer_training - INFO - Main loop iteration: 6632
2025-04-25 13:30:44,303 - transformer_training - INFO - Main loop iteration: 6633
2025-04-25 13:30:44,764 - transformer_training - INFO - Main loop iteration: 6634
2025-04-25 13:30:45,214 - transformer_training - INFO - Main loop iteration: 6635
2025-04-25 13:30:45,714 - transformer_training - INFO - Main loop iteration: 6636
2025-04-25 13:30:46,114 - transformer_training - INFO - Main loop iteration: 6637
2025-04-25 13:30:46,575 - transformer_training - INFO - Main loop iteration: 6638
2025-04-25 13:30:47,025 - transformer_training - INFO - Main loop iteration: 6639
2025-04-25 13:30:47,524 - transformer_training - INFO - Main loop iteration: 6640
Iter 6640: loss 3.4464, lr 0.000964, 91999.91 tokens/sec
2025-04-25 13:30:47,925 - transformer_training - INFO - Main loop iteration: 6641
2025-04-25 13:30:48,389 - transformer_training - INFO - Main loop iteration: 6642
2025-04-25 13:30:48,839 - transformer_training - INFO - Main loop iteration: 6643
2025-04-25 13:30:49,339 - transformer_training - INFO - Main loop iteration: 6644
2025-04-25 13:30:49,741 - transformer_training - INFO - Main loop iteration: 6645
2025-04-25 13:30:50,202 - transformer_training - INFO - Main loop iteration: 6646
2025-04-25 13:30:50,652 - transformer_training - INFO - Main loop iteration: 6647
2025-04-25 13:30:51,151 - transformer_training - INFO - Main loop iteration: 6648
2025-04-25 13:30:51,552 - transformer_training - INFO - Main loop iteration: 6649
2025-04-25 13:30:52,013 - transformer_training - INFO - Main loop iteration: 6650
Iter 6650: loss 3.3839, lr 0.000964, 81815.74 tokens/sec
2025-04-25 13:30:52,465 - transformer_training - INFO - Main loop iteration: 6651
2025-04-25 13:30:52,963 - transformer_training - INFO - Main loop iteration: 6652
2025-04-25 13:30:53,364 - transformer_training - INFO - Main loop iteration: 6653
2025-04-25 13:30:53,825 - transformer_training - INFO - Main loop iteration: 6654
2025-04-25 13:30:54,275 - transformer_training - INFO - Main loop iteration: 6655
2025-04-25 13:30:54,774 - transformer_training - INFO - Main loop iteration: 6656
2025-04-25 13:30:55,174 - transformer_training - INFO - Main loop iteration: 6657
2025-04-25 13:30:55,635 - transformer_training - INFO - Main loop iteration: 6658
2025-04-25 13:30:56,086 - transformer_training - INFO - Main loop iteration: 6659
2025-04-25 13:30:56,586 - transformer_training - INFO - Main loop iteration: 6660
Iter 6660: loss 3.5282, lr 0.000963, 92022.31 tokens/sec
2025-04-25 13:30:56,987 - transformer_training - INFO - Main loop iteration: 6661
2025-04-25 13:30:57,447 - transformer_training - INFO - Main loop iteration: 6662
2025-04-25 13:30:57,898 - transformer_training - INFO - Main loop iteration: 6663
2025-04-25 13:30:58,397 - transformer_training - INFO - Main loop iteration: 6664
2025-04-25 13:30:58,798 - transformer_training - INFO - Main loop iteration: 6665
2025-04-25 13:30:59,259 - transformer_training - INFO - Main loop iteration: 6666
2025-04-25 13:30:59,710 - transformer_training - INFO - Main loop iteration: 6667
2025-04-25 13:31:00,210 - transformer_training - INFO - Main loop iteration: 6668
2025-04-25 13:31:00,611 - transformer_training - INFO - Main loop iteration: 6669
2025-04-25 13:31:01,072 - transformer_training - INFO - Main loop iteration: 6670
Iter 6670: loss 3.4203, lr 0.000963, 81991.02 tokens/sec
2025-04-25 13:31:01,522 - transformer_training - INFO - Main loop iteration: 6671
2025-04-25 13:31:02,021 - transformer_training - INFO - Main loop iteration: 6672
2025-04-25 13:31:02,423 - transformer_training - INFO - Main loop iteration: 6673
2025-04-25 13:31:02,884 - transformer_training - INFO - Main loop iteration: 6674
2025-04-25 13:31:03,335 - transformer_training - INFO - Main loop iteration: 6675
2025-04-25 13:31:03,834 - transformer_training - INFO - Main loop iteration: 6676
2025-04-25 13:31:04,235 - transformer_training - INFO - Main loop iteration: 6677
2025-04-25 13:31:04,696 - transformer_training - INFO - Main loop iteration: 6678
2025-04-25 13:31:05,146 - transformer_training - INFO - Main loop iteration: 6679
2025-04-25 13:31:05,644 - transformer_training - INFO - Main loop iteration: 6680
Iter 6680: loss 3.4095, lr 0.000963, 91878.82 tokens/sec
2025-04-25 13:31:06,046 - transformer_training - INFO - Main loop iteration: 6681
2025-04-25 13:31:06,507 - transformer_training - INFO - Main loop iteration: 6682
2025-04-25 13:31:06,957 - transformer_training - INFO - Main loop iteration: 6683
2025-04-25 13:31:07,456 - transformer_training - INFO - Main loop iteration: 6684
2025-04-25 13:31:07,857 - transformer_training - INFO - Main loop iteration: 6685
2025-04-25 13:31:08,319 - transformer_training - INFO - Main loop iteration: 6686
2025-04-25 13:31:08,769 - transformer_training - INFO - Main loop iteration: 6687
2025-04-25 13:31:09,269 - transformer_training - INFO - Main loop iteration: 6688
2025-04-25 13:31:09,669 - transformer_training - INFO - Main loop iteration: 6689
2025-04-25 13:31:10,130 - transformer_training - INFO - Main loop iteration: 6690
Iter 6690: loss 3.4480, lr 0.000963, 81882.12 tokens/sec
2025-04-25 13:31:10,581 - transformer_training - INFO - Main loop iteration: 6691
2025-04-25 13:31:11,080 - transformer_training - INFO - Main loop iteration: 6692
2025-04-25 13:31:11,481 - transformer_training - INFO - Main loop iteration: 6693
2025-04-25 13:31:11,942 - transformer_training - INFO - Main loop iteration: 6694
2025-04-25 13:31:12,393 - transformer_training - INFO - Main loop iteration: 6695
2025-04-25 13:31:12,894 - transformer_training - INFO - Main loop iteration: 6696
2025-04-25 13:31:13,294 - transformer_training - INFO - Main loop iteration: 6697
2025-04-25 13:31:13,756 - transformer_training - INFO - Main loop iteration: 6698
2025-04-25 13:31:14,206 - transformer_training - INFO - Main loop iteration: 6699
2025-04-25 13:31:14,705 - transformer_training - INFO - Main loop iteration: 6700
Iter 6700: loss 3.4310, lr 0.000963, 91875.93 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.jsonTokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json

Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.jsonTokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json

Flash Attention is available!Flash Attention is available!

Flash Attention is available!Flash Attention is available!

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 6700: train loss 3.2595, val loss 3.3638
2025-04-25 13:31:31,204 - transformer_training - INFO - Main loop iteration: 6701
2025-04-25 13:31:31,612 - transformer_training - INFO - Main loop iteration: 6702
2025-04-25 13:31:32,063 - transformer_training - INFO - Main loop iteration: 6703
2025-04-25 13:31:32,563 - transformer_training - INFO - Main loop iteration: 6704
2025-04-25 13:31:32,963 - transformer_training - INFO - Main loop iteration: 6705
2025-04-25 13:31:33,425 - transformer_training - INFO - Main loop iteration: 6706
2025-04-25 13:31:33,875 - transformer_training - INFO - Main loop iteration: 6707
2025-04-25 13:31:34,375 - transformer_training - INFO - Main loop iteration: 6708
2025-04-25 13:31:34,775 - transformer_training - INFO - Main loop iteration: 6709
2025-04-25 13:31:35,236 - transformer_training - INFO - Main loop iteration: 6710
Iter 6710: loss 3.5231, lr 0.000963, 82061.60 tokens/sec
2025-04-25 13:31:35,686 - transformer_training - INFO - Main loop iteration: 6711
2025-04-25 13:31:36,185 - transformer_training - INFO - Main loop iteration: 6712
2025-04-25 13:31:36,586 - transformer_training - INFO - Main loop iteration: 6713
2025-04-25 13:31:37,047 - transformer_training - INFO - Main loop iteration: 6714
2025-04-25 13:31:37,497 - transformer_training - INFO - Main loop iteration: 6715
2025-04-25 13:31:37,996 - transformer_training - INFO - Main loop iteration: 6716
2025-04-25 13:31:38,397 - transformer_training - INFO - Main loop iteration: 6717
2025-04-25 13:31:38,857 - transformer_training - INFO - Main loop iteration: 6718
2025-04-25 13:31:39,308 - transformer_training - INFO - Main loop iteration: 6719
2025-04-25 13:31:39,807 - transformer_training - INFO - Main loop iteration: 6720
Iter 6720: loss 3.3927, lr 0.000962, 92006.48 tokens/sec
2025-04-25 13:31:40,208 - transformer_training - INFO - Main loop iteration: 6721
2025-04-25 13:31:40,669 - transformer_training - INFO - Main loop iteration: 6722
2025-04-25 13:31:41,119 - transformer_training - INFO - Main loop iteration: 6723
2025-04-25 13:31:41,619 - transformer_training - INFO - Main loop iteration: 6724
2025-04-25 13:31:42,020 - transformer_training - INFO - Main loop iteration: 6725
2025-04-25 13:31:42,481 - transformer_training - INFO - Main loop iteration: 6726
2025-04-25 13:31:42,932 - transformer_training - INFO - Main loop iteration: 6727
2025-04-25 13:31:43,431 - transformer_training - INFO - Main loop iteration: 6728
2025-04-25 13:31:43,832 - transformer_training - INFO - Main loop iteration: 6729
2025-04-25 13:31:44,293 - transformer_training - INFO - Main loop iteration: 6730
Iter 6730: loss 3.4627, lr 0.000962, 82087.39 tokens/sec
2025-04-25 13:31:44,744 - transformer_training - INFO - Main loop iteration: 6731
2025-04-25 13:31:45,243 - transformer_training - INFO - Main loop iteration: 6732
2025-04-25 13:31:45,644 - transformer_training - INFO - Main loop iteration: 6733
2025-04-25 13:31:46,105 - transformer_training - INFO - Main loop iteration: 6734
2025-04-25 13:31:46,556 - transformer_training - INFO - Main loop iteration: 6735
2025-04-25 13:31:47,055 - transformer_training - INFO - Main loop iteration: 6736
2025-04-25 13:31:47,456 - transformer_training - INFO - Main loop iteration: 6737
2025-04-25 13:31:47,917 - transformer_training - INFO - Main loop iteration: 6738
2025-04-25 13:31:48,367 - transformer_training - INFO - Main loop iteration: 6739
2025-04-25 13:31:48,867 - transformer_training - INFO - Main loop iteration: 6740
Iter 6740: loss 3.4219, lr 0.000962, 92009.88 tokens/sec
2025-04-25 13:31:49,268 - transformer_training - INFO - Main loop iteration: 6741
2025-04-25 13:31:49,729 - transformer_training - INFO - Main loop iteration: 6742
2025-04-25 13:31:50,179 - transformer_training - INFO - Main loop iteration: 6743
2025-04-25 13:31:50,679 - transformer_training - INFO - Main loop iteration: 6744
2025-04-25 13:31:51,080 - transformer_training - INFO - Main loop iteration: 6745
2025-04-25 13:31:51,541 - transformer_training - INFO - Main loop iteration: 6746
2025-04-25 13:31:51,991 - transformer_training - INFO - Main loop iteration: 6747
2025-04-25 13:31:52,491 - transformer_training - INFO - Main loop iteration: 6748
2025-04-25 13:31:52,891 - transformer_training - INFO - Main loop iteration: 6749
2025-04-25 13:31:53,353 - transformer_training - INFO - Main loop iteration: 6750
Iter 6750: loss 3.4501, lr 0.000962, 82051.02 tokens/sec
2025-04-25 13:31:53,803 - transformer_training - INFO - Main loop iteration: 6751
2025-04-25 13:31:54,302 - transformer_training - INFO - Main loop iteration: 6752
2025-04-25 13:31:54,703 - transformer_training - INFO - Main loop iteration: 6753
2025-04-25 13:31:55,164 - transformer_training - INFO - Main loop iteration: 6754
2025-04-25 13:31:55,614 - transformer_training - INFO - Main loop iteration: 6755
2025-04-25 13:31:56,113 - transformer_training - INFO - Main loop iteration: 6756
2025-04-25 13:31:56,514 - transformer_training - INFO - Main loop iteration: 6757
2025-04-25 13:31:56,975 - transformer_training - INFO - Main loop iteration: 6758
2025-04-25 13:31:57,426 - transformer_training - INFO - Main loop iteration: 6759
2025-04-25 13:31:57,925 - transformer_training - INFO - Main loop iteration: 6760
Iter 6760: loss 3.4177, lr 0.000962, 91991.59 tokens/sec
2025-04-25 13:31:58,326 - transformer_training - INFO - Main loop iteration: 6761
2025-04-25 13:31:58,787 - transformer_training - INFO - Main loop iteration: 6762
2025-04-25 13:31:59,237 - transformer_training - INFO - Main loop iteration: 6763
2025-04-25 13:31:59,736 - transformer_training - INFO - Main loop iteration: 6764
2025-04-25 13:32:00,137 - transformer_training - INFO - Main loop iteration: 6765
2025-04-25 13:32:00,598 - transformer_training - INFO - Main loop iteration: 6766
2025-04-25 13:32:01,048 - transformer_training - INFO - Main loop iteration: 6767
2025-04-25 13:32:01,548 - transformer_training - INFO - Main loop iteration: 6768
2025-04-25 13:32:01,949 - transformer_training - INFO - Main loop iteration: 6769
2025-04-25 13:32:02,410 - transformer_training - INFO - Main loop iteration: 6770
Iter 6770: loss 3.3896, lr 0.000962, 81890.53 tokens/sec
2025-04-25 13:32:02,861 - transformer_training - INFO - Main loop iteration: 6771
2025-04-25 13:32:03,360 - transformer_training - INFO - Main loop iteration: 6772
2025-04-25 13:32:03,760 - transformer_training - INFO - Main loop iteration: 6773
2025-04-25 13:32:04,221 - transformer_training - INFO - Main loop iteration: 6774
2025-04-25 13:32:04,672 - transformer_training - INFO - Main loop iteration: 6775
2025-04-25 13:32:05,171 - transformer_training - INFO - Main loop iteration: 6776
2025-04-25 13:32:05,572 - transformer_training - INFO - Main loop iteration: 6777
2025-04-25 13:32:06,033 - transformer_training - INFO - Main loop iteration: 6778
2025-04-25 13:32:06,484 - transformer_training - INFO - Main loop iteration: 6779
2025-04-25 13:32:06,983 - transformer_training - INFO - Main loop iteration: 6780
Iter 6780: loss 3.4793, lr 0.000962, 92088.68 tokens/sec
2025-04-25 13:32:07,383 - transformer_training - INFO - Main loop iteration: 6781
2025-04-25 13:32:07,843 - transformer_training - INFO - Main loop iteration: 6782
2025-04-25 13:32:08,294 - transformer_training - INFO - Main loop iteration: 6783
2025-04-25 13:32:08,793 - transformer_training - INFO - Main loop iteration: 6784
2025-04-25 13:32:09,194 - transformer_training - INFO - Main loop iteration: 6785
2025-04-25 13:32:09,654 - transformer_training - INFO - Main loop iteration: 6786
2025-04-25 13:32:10,105 - transformer_training - INFO - Main loop iteration: 6787
2025-04-25 13:32:10,604 - transformer_training - INFO - Main loop iteration: 6788
2025-04-25 13:32:11,005 - transformer_training - INFO - Main loop iteration: 6789
2025-04-25 13:32:11,465 - transformer_training - INFO - Main loop iteration: 6790
Iter 6790: loss 3.4485, lr 0.000961, 81905.50 tokens/sec
2025-04-25 13:32:11,916 - transformer_training - INFO - Main loop iteration: 6791
2025-04-25 13:32:12,416 - transformer_training - INFO - Main loop iteration: 6792
2025-04-25 13:32:12,816 - transformer_training - INFO - Main loop iteration: 6793
2025-04-25 13:32:13,277 - transformer_training - INFO - Main loop iteration: 6794
2025-04-25 13:32:13,727 - transformer_training - INFO - Main loop iteration: 6795
2025-04-25 13:32:14,227 - transformer_training - INFO - Main loop iteration: 6796
2025-04-25 13:32:14,628 - transformer_training - INFO - Main loop iteration: 6797
2025-04-25 13:32:15,089 - transformer_training - INFO - Main loop iteration: 6798
2025-04-25 13:32:15,540 - transformer_training - INFO - Main loop iteration: 6799
2025-04-25 13:32:16,039 - transformer_training - INFO - Main loop iteration: 6800
Iter 6800: loss 3.3732, lr 0.000961, 91935.58 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6800: train loss 3.2741, val loss 3.3560
New best model saved with val loss: 3.3560
2025-04-25 13:32:35,256 - transformer_training - INFO - Main loop iteration: 6801
2025-04-25 13:32:35,668 - transformer_training - INFO - Main loop iteration: 6802
2025-04-25 13:32:36,123 - transformer_training - INFO - Main loop iteration: 6803
2025-04-25 13:32:36,619 - transformer_training - INFO - Main loop iteration: 6804
2025-04-25 13:32:37,020 - transformer_training - INFO - Main loop iteration: 6805
2025-04-25 13:32:37,480 - transformer_training - INFO - Main loop iteration: 6806
2025-04-25 13:32:37,930 - transformer_training - INFO - Main loop iteration: 6807
2025-04-25 13:32:38,430 - transformer_training - INFO - Main loop iteration: 6808
2025-04-25 13:32:38,830 - transformer_training - INFO - Main loop iteration: 6809
2025-04-25 13:32:39,290 - transformer_training - INFO - Main loop iteration: 6810
Iter 6810: loss 3.3817, lr 0.000961, 82060.25 tokens/sec
2025-04-25 13:32:39,740 - transformer_training - INFO - Main loop iteration: 6811
2025-04-25 13:32:40,239 - transformer_training - INFO - Main loop iteration: 6812
2025-04-25 13:32:40,639 - transformer_training - INFO - Main loop iteration: 6813
2025-04-25 13:32:41,100 - transformer_training - INFO - Main loop iteration: 6814
2025-04-25 13:32:41,550 - transformer_training - INFO - Main loop iteration: 6815
2025-04-25 13:32:42,050 - transformer_training - INFO - Main loop iteration: 6816
2025-04-25 13:32:42,450 - transformer_training - INFO - Main loop iteration: 6817
2025-04-25 13:32:42,911 - transformer_training - INFO - Main loop iteration: 6818
2025-04-25 13:32:43,361 - transformer_training - INFO - Main loop iteration: 6819
2025-04-25 13:32:43,860 - transformer_training - INFO - Main loop iteration: 6820
Iter 6820: loss 3.4489, lr 0.000961, 92060.93 tokens/sec
2025-04-25 13:32:44,261 - transformer_training - INFO - Main loop iteration: 6821
2025-04-25 13:32:44,722 - transformer_training - INFO - Main loop iteration: 6822
2025-04-25 13:32:45,172 - transformer_training - INFO - Main loop iteration: 6823
2025-04-25 13:32:45,671 - transformer_training - INFO - Main loop iteration: 6824
2025-04-25 13:32:46,072 - transformer_training - INFO - Main loop iteration: 6825
2025-04-25 13:32:46,533 - transformer_training - INFO - Main loop iteration: 6826
2025-04-25 13:32:46,984 - transformer_training - INFO - Main loop iteration: 6827
2025-04-25 13:32:47,483 - transformer_training - INFO - Main loop iteration: 6828
2025-04-25 13:32:47,884 - transformer_training - INFO - Main loop iteration: 6829
2025-04-25 13:32:48,345 - transformer_training - INFO - Main loop iteration: 6830
Iter 6830: loss 3.4694, lr 0.000961, 82040.09 tokens/sec
2025-04-25 13:32:48,796 - transformer_training - INFO - Main loop iteration: 6831
2025-04-25 13:32:49,298 - transformer_training - INFO - Main loop iteration: 6832
2025-04-25 13:32:49,698 - transformer_training - INFO - Main loop iteration: 6833
2025-04-25 13:32:50,159 - transformer_training - INFO - Main loop iteration: 6834
2025-04-25 13:32:50,609 - transformer_training - INFO - Main loop iteration: 6835
2025-04-25 13:32:51,109 - transformer_training - INFO - Main loop iteration: 6836
2025-04-25 13:32:51,509 - transformer_training - INFO - Main loop iteration: 6837
2025-04-25 13:32:51,971 - transformer_training - INFO - Main loop iteration: 6838
2025-04-25 13:32:52,422 - transformer_training - INFO - Main loop iteration: 6839
2025-04-25 13:32:52,921 - transformer_training - INFO - Main loop iteration: 6840
Iter 6840: loss 3.5299, lr 0.000961, 91937.38 tokens/sec
2025-04-25 13:32:53,323 - transformer_training - INFO - Main loop iteration: 6841
2025-04-25 13:32:53,784 - transformer_training - INFO - Main loop iteration: 6842
2025-04-25 13:32:54,234 - transformer_training - INFO - Main loop iteration: 6843
2025-04-25 13:32:54,733 - transformer_training - INFO - Main loop iteration: 6844
2025-04-25 13:32:55,134 - transformer_training - INFO - Main loop iteration: 6845
2025-04-25 13:32:55,595 - transformer_training - INFO - Main loop iteration: 6846
2025-04-25 13:32:56,046 - transformer_training - INFO - Main loop iteration: 6847
2025-04-25 13:32:56,545 - transformer_training - INFO - Main loop iteration: 6848
2025-04-25 13:32:56,950 - transformer_training - INFO - Main loop iteration: 6849
2025-04-25 13:32:57,412 - transformer_training - INFO - Main loop iteration: 6850
Iter 6850: loss 3.4316, lr 0.000960, 82070.96 tokens/sec
2025-04-25 13:32:57,863 - transformer_training - INFO - Main loop iteration: 6851
2025-04-25 13:32:58,362 - transformer_training - INFO - Main loop iteration: 6852
2025-04-25 13:32:58,839 - transformer_training - INFO - Main loop iteration: 6853
2025-04-25 13:32:59,300 - transformer_training - INFO - Main loop iteration: 6854
2025-04-25 13:32:59,751 - transformer_training - INFO - Main loop iteration: 6855
2025-04-25 13:33:00,251 - transformer_training - INFO - Main loop iteration: 6856
2025-04-25 13:33:00,651 - transformer_training - INFO - Main loop iteration: 6857
2025-04-25 13:33:01,113 - transformer_training - INFO - Main loop iteration: 6858
2025-04-25 13:33:01,564 - transformer_training - INFO - Main loop iteration: 6859
2025-04-25 13:33:02,063 - transformer_training - INFO - Main loop iteration: 6860
Iter 6860: loss 3.3851, lr 0.000960, 91965.33 tokens/sec
2025-04-25 13:33:02,465 - transformer_training - INFO - Main loop iteration: 6861
2025-04-25 13:33:02,925 - transformer_training - INFO - Main loop iteration: 6862
2025-04-25 13:33:03,377 - transformer_training - INFO - Main loop iteration: 6863
2025-04-25 13:33:03,876 - transformer_training - INFO - Main loop iteration: 6864
2025-04-25 13:33:04,276 - transformer_training - INFO - Main loop iteration: 6865
2025-04-25 13:33:04,737 - transformer_training - INFO - Main loop iteration: 6866
2025-04-25 13:33:05,188 - transformer_training - INFO - Main loop iteration: 6867
2025-04-25 13:33:05,687 - transformer_training - INFO - Main loop iteration: 6868
2025-04-25 13:33:06,088 - transformer_training - INFO - Main loop iteration: 6869
2025-04-25 13:33:06,550 - transformer_training - INFO - Main loop iteration: 6870
Iter 6870: loss 3.3761, lr 0.000960, 81823.75 tokens/sec
2025-04-25 13:33:07,001 - transformer_training - INFO - Main loop iteration: 6871
2025-04-25 13:33:07,500 - transformer_training - INFO - Main loop iteration: 6872
2025-04-25 13:33:07,902 - transformer_training - INFO - Main loop iteration: 6873
2025-04-25 13:33:08,362 - transformer_training - INFO - Main loop iteration: 6874
2025-04-25 13:33:08,815 - transformer_training - INFO - Main loop iteration: 6875
2025-04-25 13:33:09,314 - transformer_training - INFO - Main loop iteration: 6876
2025-04-25 13:33:09,715 - transformer_training - INFO - Main loop iteration: 6877
2025-04-25 13:33:10,176 - transformer_training - INFO - Main loop iteration: 6878
2025-04-25 13:33:10,626 - transformer_training - INFO - Main loop iteration: 6879
2025-04-25 13:33:11,126 - transformer_training - INFO - Main loop iteration: 6880
Iter 6880: loss 3.3829, lr 0.000960, 91924.81 tokens/sec
2025-04-25 13:33:11,527 - transformer_training - INFO - Main loop iteration: 6881
2025-04-25 13:33:11,988 - transformer_training - INFO - Main loop iteration: 6882
2025-04-25 13:33:12,440 - transformer_training - INFO - Main loop iteration: 6883
2025-04-25 13:33:12,939 - transformer_training - INFO - Main loop iteration: 6884
2025-04-25 13:33:13,341 - transformer_training - INFO - Main loop iteration: 6885
2025-04-25 13:33:13,802 - transformer_training - INFO - Main loop iteration: 6886
2025-04-25 13:33:14,253 - transformer_training - INFO - Main loop iteration: 6887
2025-04-25 13:33:14,752 - transformer_training - INFO - Main loop iteration: 6888
2025-04-25 13:33:15,154 - transformer_training - INFO - Main loop iteration: 6889
2025-04-25 13:33:15,615 - transformer_training - INFO - Main loop iteration: 6890
Iter 6890: loss 3.4326, lr 0.000960, 81807.99 tokens/sec
2025-04-25 13:33:16,066 - transformer_training - INFO - Main loop iteration: 6891
2025-04-25 13:33:16,565 - transformer_training - INFO - Main loop iteration: 6892
2025-04-25 13:33:16,966 - transformer_training - INFO - Main loop iteration: 6893
2025-04-25 13:33:17,428 - transformer_training - INFO - Main loop iteration: 6894
2025-04-25 13:33:17,878 - transformer_training - INFO - Main loop iteration: 6895
2025-04-25 13:33:18,378 - transformer_training - INFO - Main loop iteration: 6896
2025-04-25 13:33:18,780 - transformer_training - INFO - Main loop iteration: 6897
2025-04-25 13:33:19,240 - transformer_training - INFO - Main loop iteration: 6898
2025-04-25 13:33:19,692 - transformer_training - INFO - Main loop iteration: 6899
2025-04-25 13:33:20,190 - transformer_training - INFO - Main loop iteration: 6900
Iter 6900: loss 3.4856, lr 0.000960, 91658.56 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 6900: train loss 3.2834, val loss 3.3486
New best model saved with val loss: 3.3486
2025-04-25 13:33:37,362 - transformer_training - INFO - Main loop iteration: 6901
2025-04-25 13:33:37,775 - transformer_training - INFO - Main loop iteration: 6902
2025-04-25 13:33:38,225 - transformer_training - INFO - Main loop iteration: 6903
2025-04-25 13:33:38,725 - transformer_training - INFO - Main loop iteration: 6904
2025-04-25 13:33:39,125 - transformer_training - INFO - Main loop iteration: 6905
2025-04-25 13:33:39,585 - transformer_training - INFO - Main loop iteration: 6906
2025-04-25 13:33:40,035 - transformer_training - INFO - Main loop iteration: 6907
2025-04-25 13:33:40,535 - transformer_training - INFO - Main loop iteration: 6908
2025-04-25 13:33:40,935 - transformer_training - INFO - Main loop iteration: 6909
2025-04-25 13:33:41,396 - transformer_training - INFO - Main loop iteration: 6910
Iter 6910: loss 3.4225, lr 0.000959, 82067.17 tokens/sec
2025-04-25 13:33:41,846 - transformer_training - INFO - Main loop iteration: 6911
2025-04-25 13:33:42,345 - transformer_training - INFO - Main loop iteration: 6912
2025-04-25 13:33:42,746 - transformer_training - INFO - Main loop iteration: 6913
2025-04-25 13:33:43,207 - transformer_training - INFO - Main loop iteration: 6914
2025-04-25 13:33:43,658 - transformer_training - INFO - Main loop iteration: 6915
2025-04-25 13:33:44,157 - transformer_training - INFO - Main loop iteration: 6916
2025-04-25 13:33:44,558 - transformer_training - INFO - Main loop iteration: 6917
2025-04-25 13:33:45,019 - transformer_training - INFO - Main loop iteration: 6918
2025-04-25 13:33:45,470 - transformer_training - INFO - Main loop iteration: 6919
2025-04-25 13:33:45,969 - transformer_training - INFO - Main loop iteration: 6920
Iter 6920: loss 3.5533, lr 0.000959, 91977.80 tokens/sec
2025-04-25 13:33:46,370 - transformer_training - INFO - Main loop iteration: 6921
2025-04-25 13:33:46,831 - transformer_training - INFO - Main loop iteration: 6922
2025-04-25 13:33:47,281 - transformer_training - INFO - Main loop iteration: 6923
2025-04-25 13:33:47,781 - transformer_training - INFO - Main loop iteration: 6924
2025-04-25 13:33:48,183 - transformer_training - INFO - Main loop iteration: 6925
2025-04-25 13:33:48,644 - transformer_training - INFO - Main loop iteration: 6926
2025-04-25 13:33:49,095 - transformer_training - INFO - Main loop iteration: 6927
2025-04-25 13:33:49,594 - transformer_training - INFO - Main loop iteration: 6928
2025-04-25 13:33:49,995 - transformer_training - INFO - Main loop iteration: 6929
2025-04-25 13:33:50,456 - transformer_training - INFO - Main loop iteration: 6930
Iter 6930: loss 3.5270, lr 0.000959, 82040.61 tokens/sec
2025-04-25 13:33:50,906 - transformer_training - INFO - Main loop iteration: 6931
2025-04-25 13:33:51,406 - transformer_training - INFO - Main loop iteration: 6932
2025-04-25 13:33:51,807 - transformer_training - INFO - Main loop iteration: 6933
2025-04-25 13:33:52,268 - transformer_training - INFO - Main loop iteration: 6934
2025-04-25 13:33:52,719 - transformer_training - INFO - Main loop iteration: 6935
2025-04-25 13:33:53,218 - transformer_training - INFO - Main loop iteration: 6936
2025-04-25 13:33:53,618 - transformer_training - INFO - Main loop iteration: 6937
2025-04-25 13:33:54,080 - transformer_training - INFO - Main loop iteration: 6938
2025-04-25 13:33:54,532 - transformer_training - INFO - Main loop iteration: 6939
2025-04-25 13:33:55,031 - transformer_training - INFO - Main loop iteration: 6940
Iter 6940: loss 3.4317, lr 0.000959, 91978.24 tokens/sec
2025-04-25 13:33:55,433 - transformer_training - INFO - Main loop iteration: 6941
2025-04-25 13:33:55,894 - transformer_training - INFO - Main loop iteration: 6942
2025-04-25 13:33:56,344 - transformer_training - INFO - Main loop iteration: 6943
2025-04-25 13:33:56,844 - transformer_training - INFO - Main loop iteration: 6944
2025-04-25 13:33:57,244 - transformer_training - INFO - Main loop iteration: 6945
2025-04-25 13:33:57,706 - transformer_training - INFO - Main loop iteration: 6946
2025-04-25 13:33:58,158 - transformer_training - INFO - Main loop iteration: 6947
2025-04-25 13:33:58,659 - transformer_training - INFO - Main loop iteration: 6948
2025-04-25 13:33:59,060 - transformer_training - INFO - Main loop iteration: 6949
2025-04-25 13:33:59,521 - transformer_training - INFO - Main loop iteration: 6950
Iter 6950: loss 3.4167, lr 0.000959, 82035.82 tokens/sec
2025-04-25 13:33:59,971 - transformer_training - INFO - Main loop iteration: 6951
2025-04-25 13:34:00,470 - transformer_training - INFO - Main loop iteration: 6952
2025-04-25 13:34:00,871 - transformer_training - INFO - Main loop iteration: 6953
2025-04-25 13:34:01,332 - transformer_training - INFO - Main loop iteration: 6954
2025-04-25 13:34:01,783 - transformer_training - INFO - Main loop iteration: 6955
2025-04-25 13:34:02,283 - transformer_training - INFO - Main loop iteration: 6956
2025-04-25 13:34:02,684 - transformer_training - INFO - Main loop iteration: 6957
2025-04-25 13:34:03,145 - transformer_training - INFO - Main loop iteration: 6958
2025-04-25 13:34:03,596 - transformer_training - INFO - Main loop iteration: 6959
2025-04-25 13:34:04,097 - transformer_training - INFO - Main loop iteration: 6960
Iter 6960: loss 3.4816, lr 0.000959, 91953.62 tokens/sec
2025-04-25 13:34:04,498 - transformer_training - INFO - Main loop iteration: 6961
2025-04-25 13:34:04,959 - transformer_training - INFO - Main loop iteration: 6962
2025-04-25 13:34:05,409 - transformer_training - INFO - Main loop iteration: 6963
2025-04-25 13:34:05,909 - transformer_training - INFO - Main loop iteration: 6964
2025-04-25 13:34:06,310 - transformer_training - INFO - Main loop iteration: 6965
2025-04-25 13:34:06,771 - transformer_training - INFO - Main loop iteration: 6966
2025-04-25 13:34:07,222 - transformer_training - INFO - Main loop iteration: 6967
2025-04-25 13:34:07,721 - transformer_training - INFO - Main loop iteration: 6968
2025-04-25 13:34:08,122 - transformer_training - INFO - Main loop iteration: 6969
2025-04-25 13:34:08,583 - transformer_training - INFO - Main loop iteration: 6970
Iter 6970: loss 3.3874, lr 0.000958, 82000.80 tokens/sec
2025-04-25 13:34:09,034 - transformer_training - INFO - Main loop iteration: 6971
2025-04-25 13:34:09,533 - transformer_training - INFO - Main loop iteration: 6972
2025-04-25 13:34:09,934 - transformer_training - INFO - Main loop iteration: 6973
2025-04-25 13:34:10,396 - transformer_training - INFO - Main loop iteration: 6974
2025-04-25 13:34:10,847 - transformer_training - INFO - Main loop iteration: 6975
2025-04-25 13:34:11,346 - transformer_training - INFO - Main loop iteration: 6976
2025-04-25 13:34:11,747 - transformer_training - INFO - Main loop iteration: 6977
2025-04-25 13:34:12,208 - transformer_training - INFO - Main loop iteration: 6978
2025-04-25 13:34:12,659 - transformer_training - INFO - Main loop iteration: 6979
2025-04-25 13:34:13,159 - transformer_training - INFO - Main loop iteration: 6980
Iter 6980: loss 3.4487, lr 0.000958, 91892.63 tokens/sec
2025-04-25 13:34:13,561 - transformer_training - INFO - Main loop iteration: 6981
2025-04-25 13:34:14,022 - transformer_training - INFO - Main loop iteration: 6982
2025-04-25 13:34:14,473 - transformer_training - INFO - Main loop iteration: 6983
2025-04-25 13:34:14,973 - transformer_training - INFO - Main loop iteration: 6984
2025-04-25 13:34:15,374 - transformer_training - INFO - Main loop iteration: 6985
2025-04-25 13:34:15,835 - transformer_training - INFO - Main loop iteration: 6986
2025-04-25 13:34:16,285 - transformer_training - INFO - Main loop iteration: 6987
2025-04-25 13:34:16,785 - transformer_training - INFO - Main loop iteration: 6988
2025-04-25 13:34:17,186 - transformer_training - INFO - Main loop iteration: 6989
2025-04-25 13:34:17,647 - transformer_training - INFO - Main loop iteration: 6990
Iter 6990: loss 3.4253, lr 0.000958, 82071.14 tokens/sec
2025-04-25 13:34:18,098 - transformer_training - INFO - Main loop iteration: 6991
2025-04-25 13:34:18,598 - transformer_training - INFO - Main loop iteration: 6992
2025-04-25 13:34:18,999 - transformer_training - INFO - Main loop iteration: 6993
2025-04-25 13:34:19,460 - transformer_training - INFO - Main loop iteration: 6994
2025-04-25 13:34:19,910 - transformer_training - INFO - Main loop iteration: 6995
2025-04-25 13:34:20,410 - transformer_training - INFO - Main loop iteration: 6996
2025-04-25 13:34:20,811 - transformer_training - INFO - Main loop iteration: 6997
2025-04-25 13:34:21,272 - transformer_training - INFO - Main loop iteration: 6998
2025-04-25 13:34:21,723 - transformer_training - INFO - Main loop iteration: 6999
2025-04-25 13:34:22,224 - transformer_training - INFO - Main loop iteration: 7000
Iter 7000: loss 3.4576, lr 0.000958, 91769.70 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7000: train loss 3.2855, val loss 3.3550
2025-04-25 13:34:39,146 - transformer_training - INFO - Main loop iteration: 7001
2025-04-25 13:34:39,554 - transformer_training - INFO - Main loop iteration: 7002
2025-04-25 13:34:40,004 - transformer_training - INFO - Main loop iteration: 7003
2025-04-25 13:34:40,504 - transformer_training - INFO - Main loop iteration: 7004
2025-04-25 13:34:40,905 - transformer_training - INFO - Main loop iteration: 7005
2025-04-25 13:34:41,366 - transformer_training - INFO - Main loop iteration: 7006
2025-04-25 13:34:41,816 - transformer_training - INFO - Main loop iteration: 7007
2025-04-25 13:34:42,315 - transformer_training - INFO - Main loop iteration: 7008
2025-04-25 13:34:42,716 - transformer_training - INFO - Main loop iteration: 7009
2025-04-25 13:34:43,177 - transformer_training - INFO - Main loop iteration: 7010
Iter 7010: loss 3.4062, lr 0.000958, 82085.73 tokens/sec
2025-04-25 13:34:43,627 - transformer_training - INFO - Main loop iteration: 7011
2025-04-25 13:34:44,127 - transformer_training - INFO - Main loop iteration: 7012
2025-04-25 13:34:44,527 - transformer_training - INFO - Main loop iteration: 7013
2025-04-25 13:34:44,988 - transformer_training - INFO - Main loop iteration: 7014
2025-04-25 13:34:45,438 - transformer_training - INFO - Main loop iteration: 7015
2025-04-25 13:34:45,937 - transformer_training - INFO - Main loop iteration: 7016
2025-04-25 13:34:46,338 - transformer_training - INFO - Main loop iteration: 7017
2025-04-25 13:34:46,799 - transformer_training - INFO - Main loop iteration: 7018
2025-04-25 13:34:47,250 - transformer_training - INFO - Main loop iteration: 7019
2025-04-25 13:34:47,749 - transformer_training - INFO - Main loop iteration: 7020
Iter 7020: loss 3.4220, lr 0.000958, 92191.35 tokens/sec
2025-04-25 13:34:48,149 - transformer_training - INFO - Main loop iteration: 7021
2025-04-25 13:34:48,610 - transformer_training - INFO - Main loop iteration: 7022
2025-04-25 13:34:49,060 - transformer_training - INFO - Main loop iteration: 7023
2025-04-25 13:34:49,558 - transformer_training - INFO - Main loop iteration: 7024
2025-04-25 13:34:49,959 - transformer_training - INFO - Main loop iteration: 7025
2025-04-25 13:34:50,420 - transformer_training - INFO - Main loop iteration: 7026
2025-04-25 13:34:50,870 - transformer_training - INFO - Main loop iteration: 7027
2025-04-25 13:34:51,369 - transformer_training - INFO - Main loop iteration: 7028
2025-04-25 13:34:51,770 - transformer_training - INFO - Main loop iteration: 7029
2025-04-25 13:34:52,231 - transformer_training - INFO - Main loop iteration: 7030
Iter 7030: loss 3.4051, lr 0.000957, 81967.68 tokens/sec
2025-04-25 13:34:52,681 - transformer_training - INFO - Main loop iteration: 7031
2025-04-25 13:34:53,180 - transformer_training - INFO - Main loop iteration: 7032
2025-04-25 13:34:53,580 - transformer_training - INFO - Main loop iteration: 7033
2025-04-25 13:34:54,041 - transformer_training - INFO - Main loop iteration: 7034
2025-04-25 13:34:54,492 - transformer_training - INFO - Main loop iteration: 7035
2025-04-25 13:34:54,991 - transformer_training - INFO - Main loop iteration: 7036
2025-04-25 13:34:55,391 - transformer_training - INFO - Main loop iteration: 7037
2025-04-25 13:34:55,853 - transformer_training - INFO - Main loop iteration: 7038
2025-04-25 13:34:56,303 - transformer_training - INFO - Main loop iteration: 7039
2025-04-25 13:34:56,802 - transformer_training - INFO - Main loop iteration: 7040
Iter 7040: loss 3.3562, lr 0.000957, 91936.07 tokens/sec
2025-04-25 13:34:57,203 - transformer_training - INFO - Main loop iteration: 7041
2025-04-25 13:34:57,664 - transformer_training - INFO - Main loop iteration: 7042
2025-04-25 13:34:58,115 - transformer_training - INFO - Main loop iteration: 7043
2025-04-25 13:34:58,615 - transformer_training - INFO - Main loop iteration: 7044
2025-04-25 13:34:59,016 - transformer_training - INFO - Main loop iteration: 7045
2025-04-25 13:34:59,476 - transformer_training - INFO - Main loop iteration: 7046
2025-04-25 13:34:59,927 - transformer_training - INFO - Main loop iteration: 7047
2025-04-25 13:35:00,426 - transformer_training - INFO - Main loop iteration: 7048
2025-04-25 13:35:00,827 - transformer_training - INFO - Main loop iteration: 7049
2025-04-25 13:35:01,288 - transformer_training - INFO - Main loop iteration: 7050
Iter 7050: loss 3.4440, lr 0.000957, 81975.58 tokens/sec
2025-04-25 13:35:01,738 - transformer_training - INFO - Main loop iteration: 7051
2025-04-25 13:35:02,238 - transformer_training - INFO - Main loop iteration: 7052
2025-04-25 13:35:02,638 - transformer_training - INFO - Main loop iteration: 7053
2025-04-25 13:35:03,099 - transformer_training - INFO - Main loop iteration: 7054
2025-04-25 13:35:03,549 - transformer_training - INFO - Main loop iteration: 7055
2025-04-25 13:35:04,049 - transformer_training - INFO - Main loop iteration: 7056
2025-04-25 13:35:04,450 - transformer_training - INFO - Main loop iteration: 7057
2025-04-25 13:35:04,911 - transformer_training - INFO - Main loop iteration: 7058
2025-04-25 13:35:05,361 - transformer_training - INFO - Main loop iteration: 7059
2025-04-25 13:35:05,861 - transformer_training - INFO - Main loop iteration: 7060
Iter 7060: loss 3.4641, lr 0.000957, 91872.65 tokens/sec
2025-04-25 13:35:06,263 - transformer_training - INFO - Main loop iteration: 7061
2025-04-25 13:35:06,723 - transformer_training - INFO - Main loop iteration: 7062
2025-04-25 13:35:07,174 - transformer_training - INFO - Main loop iteration: 7063
2025-04-25 13:35:07,673 - transformer_training - INFO - Main loop iteration: 7064
2025-04-25 13:35:08,074 - transformer_training - INFO - Main loop iteration: 7065
2025-04-25 13:35:08,535 - transformer_training - INFO - Main loop iteration: 7066
2025-04-25 13:35:08,985 - transformer_training - INFO - Main loop iteration: 7067
2025-04-25 13:35:09,484 - transformer_training - INFO - Main loop iteration: 7068
2025-04-25 13:35:09,885 - transformer_training - INFO - Main loop iteration: 7069
2025-04-25 13:35:10,346 - transformer_training - INFO - Main loop iteration: 7070
Iter 7070: loss 3.4760, lr 0.000957, 81924.29 tokens/sec
2025-04-25 13:35:10,796 - transformer_training - INFO - Main loop iteration: 7071
2025-04-25 13:35:11,295 - transformer_training - INFO - Main loop iteration: 7072
2025-04-25 13:35:11,696 - transformer_training - INFO - Main loop iteration: 7073
2025-04-25 13:35:12,157 - transformer_training - INFO - Main loop iteration: 7074
2025-04-25 13:35:12,607 - transformer_training - INFO - Main loop iteration: 7075
2025-04-25 13:35:13,106 - transformer_training - INFO - Main loop iteration: 7076
2025-04-25 13:35:13,507 - transformer_training - INFO - Main loop iteration: 7077
2025-04-25 13:35:13,968 - transformer_training - INFO - Main loop iteration: 7078
2025-04-25 13:35:14,418 - transformer_training - INFO - Main loop iteration: 7079
2025-04-25 13:35:14,917 - transformer_training - INFO - Main loop iteration: 7080
Iter 7080: loss 3.4256, lr 0.000957, 92045.97 tokens/sec
2025-04-25 13:35:15,318 - transformer_training - INFO - Main loop iteration: 7081
2025-04-25 13:35:15,778 - transformer_training - INFO - Main loop iteration: 7082
2025-04-25 13:35:16,228 - transformer_training - INFO - Main loop iteration: 7083
2025-04-25 13:35:16,727 - transformer_training - INFO - Main loop iteration: 7084
2025-04-25 13:35:17,128 - transformer_training - INFO - Main loop iteration: 7085
2025-04-25 13:35:17,588 - transformer_training - INFO - Main loop iteration: 7086
2025-04-25 13:35:18,038 - transformer_training - INFO - Main loop iteration: 7087
2025-04-25 13:35:18,537 - transformer_training - INFO - Main loop iteration: 7088
2025-04-25 13:35:18,938 - transformer_training - INFO - Main loop iteration: 7089
2025-04-25 13:35:19,399 - transformer_training - INFO - Main loop iteration: 7090
Iter 7090: loss 3.4452, lr 0.000956, 82024.99 tokens/sec
2025-04-25 13:35:19,849 - transformer_training - INFO - Main loop iteration: 7091
2025-04-25 13:35:20,347 - transformer_training - INFO - Main loop iteration: 7092
2025-04-25 13:35:20,748 - transformer_training - INFO - Main loop iteration: 7093
2025-04-25 13:35:21,209 - transformer_training - INFO - Main loop iteration: 7094
2025-04-25 13:35:21,659 - transformer_training - INFO - Main loop iteration: 7095
2025-04-25 13:35:22,158 - transformer_training - INFO - Main loop iteration: 7096
2025-04-25 13:35:22,559 - transformer_training - INFO - Main loop iteration: 7097
2025-04-25 13:35:23,020 - transformer_training - INFO - Main loop iteration: 7098
2025-04-25 13:35:23,471 - transformer_training - INFO - Main loop iteration: 7099
2025-04-25 13:35:23,970 - transformer_training - INFO - Main loop iteration: 7100
Iter 7100: loss 3.4191, lr 0.000956, 91957.89 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7100: train loss 3.2881, val loss 3.3411
New best model saved with val loss: 3.3411
2025-04-25 13:35:41,826 - transformer_training - INFO - Main loop iteration: 7101
2025-04-25 13:35:42,246 - transformer_training - INFO - Main loop iteration: 7102
2025-04-25 13:35:42,697 - transformer_training - INFO - Main loop iteration: 7103
2025-04-25 13:35:43,196 - transformer_training - INFO - Main loop iteration: 7104
2025-04-25 13:35:43,596 - transformer_training - INFO - Main loop iteration: 7105
2025-04-25 13:35:44,057 - transformer_training - INFO - Main loop iteration: 7106
2025-04-25 13:35:44,507 - transformer_training - INFO - Main loop iteration: 7107
2025-04-25 13:35:45,006 - transformer_training - INFO - Main loop iteration: 7108
2025-04-25 13:35:45,407 - transformer_training - INFO - Main loop iteration: 7109
2025-04-25 13:35:45,868 - transformer_training - INFO - Main loop iteration: 7110
Iter 7110: loss 3.3484, lr 0.000956, 82047.36 tokens/sec
2025-04-25 13:35:46,318 - transformer_training - INFO - Main loop iteration: 7111
2025-04-25 13:35:46,818 - transformer_training - INFO - Main loop iteration: 7112
2025-04-25 13:35:47,219 - transformer_training - INFO - Main loop iteration: 7113
2025-04-25 13:35:47,680 - transformer_training - INFO - Main loop iteration: 7114
2025-04-25 13:35:48,130 - transformer_training - INFO - Main loop iteration: 7115
2025-04-25 13:35:48,629 - transformer_training - INFO - Main loop iteration: 7116
2025-04-25 13:35:49,030 - transformer_training - INFO - Main loop iteration: 7117
2025-04-25 13:35:49,490 - transformer_training - INFO - Main loop iteration: 7118
2025-04-25 13:35:49,941 - transformer_training - INFO - Main loop iteration: 7119
2025-04-25 13:35:50,441 - transformer_training - INFO - Main loop iteration: 7120
Iter 7120: loss 3.3704, lr 0.000956, 92136.36 tokens/sec
2025-04-25 13:35:50,841 - transformer_training - INFO - Main loop iteration: 7121
2025-04-25 13:35:51,302 - transformer_training - INFO - Main loop iteration: 7122
2025-04-25 13:35:51,752 - transformer_training - INFO - Main loop iteration: 7123
2025-04-25 13:35:52,251 - transformer_training - INFO - Main loop iteration: 7124
2025-04-25 13:35:52,652 - transformer_training - INFO - Main loop iteration: 7125
2025-04-25 13:35:53,113 - transformer_training - INFO - Main loop iteration: 7126
2025-04-25 13:35:53,563 - transformer_training - INFO - Main loop iteration: 7127
2025-04-25 13:35:54,061 - transformer_training - INFO - Main loop iteration: 7128
2025-04-25 13:35:54,462 - transformer_training - INFO - Main loop iteration: 7129
2025-04-25 13:35:54,923 - transformer_training - INFO - Main loop iteration: 7130
Iter 7130: loss 3.4255, lr 0.000956, 81948.26 tokens/sec
2025-04-25 13:35:55,374 - transformer_training - INFO - Main loop iteration: 7131
2025-04-25 13:35:55,872 - transformer_training - INFO - Main loop iteration: 7132
2025-04-25 13:35:56,273 - transformer_training - INFO - Main loop iteration: 7133
2025-04-25 13:35:56,734 - transformer_training - INFO - Main loop iteration: 7134
2025-04-25 13:35:57,184 - transformer_training - INFO - Main loop iteration: 7135
2025-04-25 13:35:57,683 - transformer_training - INFO - Main loop iteration: 7136
2025-04-25 13:35:58,084 - transformer_training - INFO - Main loop iteration: 7137
2025-04-25 13:35:58,546 - transformer_training - INFO - Main loop iteration: 7138
2025-04-25 13:35:58,997 - transformer_training - INFO - Main loop iteration: 7139
2025-04-25 13:35:59,497 - transformer_training - INFO - Main loop iteration: 7140
Iter 7140: loss 3.3728, lr 0.000956, 92027.78 tokens/sec
2025-04-25 13:35:59,898 - transformer_training - INFO - Main loop iteration: 7141
2025-04-25 13:36:00,359 - transformer_training - INFO - Main loop iteration: 7142
2025-04-25 13:36:00,809 - transformer_training - INFO - Main loop iteration: 7143
2025-04-25 13:36:01,309 - transformer_training - INFO - Main loop iteration: 7144
2025-04-25 13:36:01,710 - transformer_training - INFO - Main loop iteration: 7145
2025-04-25 13:36:02,171 - transformer_training - INFO - Main loop iteration: 7146
2025-04-25 13:36:02,621 - transformer_training - INFO - Main loop iteration: 7147
2025-04-25 13:36:03,122 - transformer_training - INFO - Main loop iteration: 7148
2025-04-25 13:36:03,523 - transformer_training - INFO - Main loop iteration: 7149
2025-04-25 13:36:03,984 - transformer_training - INFO - Main loop iteration: 7150
Iter 7150: loss 3.4103, lr 0.000955, 82092.49 tokens/sec
2025-04-25 13:36:04,435 - transformer_training - INFO - Main loop iteration: 7151
2025-04-25 13:36:04,934 - transformer_training - INFO - Main loop iteration: 7152
2025-04-25 13:36:05,335 - transformer_training - INFO - Main loop iteration: 7153
2025-04-25 13:36:05,796 - transformer_training - INFO - Main loop iteration: 7154
2025-04-25 13:36:06,246 - transformer_training - INFO - Main loop iteration: 7155
2025-04-25 13:36:06,745 - transformer_training - INFO - Main loop iteration: 7156
2025-04-25 13:36:07,146 - transformer_training - INFO - Main loop iteration: 7157
2025-04-25 13:36:07,607 - transformer_training - INFO - Main loop iteration: 7158
2025-04-25 13:36:08,057 - transformer_training - INFO - Main loop iteration: 7159
2025-04-25 13:36:08,556 - transformer_training - INFO - Main loop iteration: 7160
Iter 7160: loss 3.4447, lr 0.000955, 91982.45 tokens/sec
2025-04-25 13:36:08,958 - transformer_training - INFO - Main loop iteration: 7161
2025-04-25 13:36:09,418 - transformer_training - INFO - Main loop iteration: 7162
2025-04-25 13:36:09,868 - transformer_training - INFO - Main loop iteration: 7163
2025-04-25 13:36:10,368 - transformer_training - INFO - Main loop iteration: 7164
2025-04-25 13:36:10,769 - transformer_training - INFO - Main loop iteration: 7165
2025-04-25 13:36:11,229 - transformer_training - INFO - Main loop iteration: 7166
2025-04-25 13:36:11,680 - transformer_training - INFO - Main loop iteration: 7167
2025-04-25 13:36:12,179 - transformer_training - INFO - Main loop iteration: 7168
2025-04-25 13:36:12,580 - transformer_training - INFO - Main loop iteration: 7169
2025-04-25 13:36:13,041 - transformer_training - INFO - Main loop iteration: 7170
Iter 7170: loss 3.3861, lr 0.000955, 82059.77 tokens/sec
2025-04-25 13:36:13,491 - transformer_training - INFO - Main loop iteration: 7171
2025-04-25 13:36:13,990 - transformer_training - INFO - Main loop iteration: 7172
2025-04-25 13:36:14,390 - transformer_training - INFO - Main loop iteration: 7173
2025-04-25 13:36:14,851 - transformer_training - INFO - Main loop iteration: 7174
2025-04-25 13:36:15,301 - transformer_training - INFO - Main loop iteration: 7175
2025-04-25 13:36:15,805 - transformer_training - INFO - Main loop iteration: 7176
2025-04-25 13:36:16,204 - transformer_training - INFO - Main loop iteration: 7177
2025-04-25 13:36:16,665 - transformer_training - INFO - Main loop iteration: 7178
2025-04-25 13:36:17,116 - transformer_training - INFO - Main loop iteration: 7179
2025-04-25 13:36:17,615 - transformer_training - INFO - Main loop iteration: 7180
Iter 7180: loss 3.4772, lr 0.000955, 92099.15 tokens/sec
2025-04-25 13:36:18,016 - transformer_training - INFO - Main loop iteration: 7181
2025-04-25 13:36:18,477 - transformer_training - INFO - Main loop iteration: 7182
2025-04-25 13:36:18,927 - transformer_training - INFO - Main loop iteration: 7183
2025-04-25 13:36:19,426 - transformer_training - INFO - Main loop iteration: 7184
2025-04-25 13:36:19,826 - transformer_training - INFO - Main loop iteration: 7185
2025-04-25 13:36:20,287 - transformer_training - INFO - Main loop iteration: 7186
2025-04-25 13:36:20,738 - transformer_training - INFO - Main loop iteration: 7187
2025-04-25 13:36:21,237 - transformer_training - INFO - Main loop iteration: 7188
2025-04-25 13:36:21,638 - transformer_training - INFO - Main loop iteration: 7189
2025-04-25 13:36:22,099 - transformer_training - INFO - Main loop iteration: 7190
Iter 7190: loss 3.4159, lr 0.000955, 81969.37 tokens/sec
2025-04-25 13:36:22,549 - transformer_training - INFO - Main loop iteration: 7191
2025-04-25 13:36:23,049 - transformer_training - INFO - Main loop iteration: 7192
2025-04-25 13:36:23,450 - transformer_training - INFO - Main loop iteration: 7193
2025-04-25 13:36:23,912 - transformer_training - INFO - Main loop iteration: 7194
2025-04-25 13:36:24,362 - transformer_training - INFO - Main loop iteration: 7195
2025-04-25 13:36:24,861 - transformer_training - INFO - Main loop iteration: 7196
2025-04-25 13:36:25,261 - transformer_training - INFO - Main loop iteration: 7197
2025-04-25 13:36:25,722 - transformer_training - INFO - Main loop iteration: 7198
2025-04-25 13:36:26,172 - transformer_training - INFO - Main loop iteration: 7199
2025-04-25 13:36:26,671 - transformer_training - INFO - Main loop iteration: 7200
Iter 7200: loss 3.4844, lr 0.000955, 92089.66 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 7200: train loss 3.2990, val loss 3.3291
New best model saved with val loss: 3.3291
2025-04-25 13:36:44,916 - transformer_training - INFO - Main loop iteration: 7201
2025-04-25 13:36:45,336 - transformer_training - INFO - Main loop iteration: 7202
2025-04-25 13:36:45,786 - transformer_training - INFO - Main loop iteration: 7203
2025-04-25 13:36:46,284 - transformer_training - INFO - Main loop iteration: 7204
2025-04-25 13:36:46,684 - transformer_training - INFO - Main loop iteration: 7205
2025-04-25 13:36:47,145 - transformer_training - INFO - Main loop iteration: 7206
2025-04-25 13:36:47,594 - transformer_training - INFO - Main loop iteration: 7207
2025-04-25 13:36:48,093 - transformer_training - INFO - Main loop iteration: 7208
2025-04-25 13:36:48,493 - transformer_training - INFO - Main loop iteration: 7209
2025-04-25 13:36:48,954 - transformer_training - INFO - Main loop iteration: 7210
Iter 7210: loss 3.4282, lr 0.000954, 82050.54 tokens/sec
2025-04-25 13:36:49,404 - transformer_training - INFO - Main loop iteration: 7211
2025-04-25 13:36:49,903 - transformer_training - INFO - Main loop iteration: 7212
2025-04-25 13:36:50,304 - transformer_training - INFO - Main loop iteration: 7213
2025-04-25 13:36:50,764 - transformer_training - INFO - Main loop iteration: 7214
2025-04-25 13:36:51,214 - transformer_training - INFO - Main loop iteration: 7215
2025-04-25 13:36:51,713 - transformer_training - INFO - Main loop iteration: 7216
2025-04-25 13:36:52,113 - transformer_training - INFO - Main loop iteration: 7217
2025-04-25 13:36:52,574 - transformer_training - INFO - Main loop iteration: 7218
2025-04-25 13:36:53,024 - transformer_training - INFO - Main loop iteration: 7219
2025-04-25 13:36:53,523 - transformer_training - INFO - Main loop iteration: 7220
Iter 7220: loss 3.4834, lr 0.000954, 92125.82 tokens/sec
2025-04-25 13:36:53,923 - transformer_training - INFO - Main loop iteration: 7221
2025-04-25 13:36:54,384 - transformer_training - INFO - Main loop iteration: 7222
2025-04-25 13:36:54,834 - transformer_training - INFO - Main loop iteration: 7223
2025-04-25 13:36:55,332 - transformer_training - INFO - Main loop iteration: 7224
2025-04-25 13:36:55,733 - transformer_training - INFO - Main loop iteration: 7225
2025-04-25 13:36:56,193 - transformer_training - INFO - Main loop iteration: 7226
2025-04-25 13:36:56,643 - transformer_training - INFO - Main loop iteration: 7227
2025-04-25 13:36:57,142 - transformer_training - INFO - Main loop iteration: 7228
2025-04-25 13:36:57,542 - transformer_training - INFO - Main loop iteration: 7229
2025-04-25 13:36:58,003 - transformer_training - INFO - Main loop iteration: 7230
Iter 7230: loss 3.4715, lr 0.000954, 81925.46 tokens/sec
2025-04-25 13:36:58,454 - transformer_training - INFO - Main loop iteration: 7231
2025-04-25 13:36:58,952 - transformer_training - INFO - Main loop iteration: 7232
2025-04-25 13:36:59,353 - transformer_training - INFO - Main loop iteration: 7233
2025-04-25 13:36:59,814 - transformer_training - INFO - Main loop iteration: 7234
2025-04-25 13:37:00,264 - transformer_training - INFO - Main loop iteration: 7235
2025-04-25 13:37:00,762 - transformer_training - INFO - Main loop iteration: 7236
2025-04-25 13:37:01,163 - transformer_training - INFO - Main loop iteration: 7237
2025-04-25 13:37:01,623 - transformer_training - INFO - Main loop iteration: 7238
2025-04-25 13:37:02,073 - transformer_training - INFO - Main loop iteration: 7239
2025-04-25 13:37:02,572 - transformer_training - INFO - Main loop iteration: 7240
Iter 7240: loss 3.4849, lr 0.000954, 92140.15 tokens/sec
2025-04-25 13:37:02,973 - transformer_training - INFO - Main loop iteration: 7241
2025-04-25 13:37:03,433 - transformer_training - INFO - Main loop iteration: 7242
2025-04-25 13:37:03,883 - transformer_training - INFO - Main loop iteration: 7243
2025-04-25 13:37:04,382 - transformer_training - INFO - Main loop iteration: 7244
2025-04-25 13:37:04,782 - transformer_training - INFO - Main loop iteration: 7245
2025-04-25 13:37:05,243 - transformer_training - INFO - Main loop iteration: 7246
2025-04-25 13:37:05,694 - transformer_training - INFO - Main loop iteration: 7247
2025-04-25 13:37:06,192 - transformer_training - INFO - Main loop iteration: 7248
2025-04-25 13:37:06,593 - transformer_training - INFO - Main loop iteration: 7249
2025-04-25 13:37:07,053 - transformer_training - INFO - Main loop iteration: 7250
Iter 7250: loss 3.5400, lr 0.000954, 81954.29 tokens/sec
2025-04-25 13:37:07,504 - transformer_training - INFO - Main loop iteration: 7251
2025-04-25 13:37:08,003 - transformer_training - INFO - Main loop iteration: 7252
2025-04-25 13:37:08,403 - transformer_training - INFO - Main loop iteration: 7253
2025-04-25 13:37:08,864 - transformer_training - INFO - Main loop iteration: 7254
2025-04-25 13:37:09,314 - transformer_training - INFO - Main loop iteration: 7255
2025-04-25 13:37:09,814 - transformer_training - INFO - Main loop iteration: 7256
2025-04-25 13:37:10,214 - transformer_training - INFO - Main loop iteration: 7257
2025-04-25 13:37:10,675 - transformer_training - INFO - Main loop iteration: 7258
2025-04-25 13:37:11,125 - transformer_training - INFO - Main loop iteration: 7259
2025-04-25 13:37:11,624 - transformer_training - INFO - Main loop iteration: 7260
Iter 7260: loss 3.4341, lr 0.000954, 92024.11 tokens/sec
2025-04-25 13:37:12,025 - transformer_training - INFO - Main loop iteration: 7261
2025-04-25 13:37:12,487 - transformer_training - INFO - Main loop iteration: 7262
2025-04-25 13:37:12,937 - transformer_training - INFO - Main loop iteration: 7263
2025-04-25 13:37:13,436 - transformer_training - INFO - Main loop iteration: 7264
2025-04-25 13:37:13,836 - transformer_training - INFO - Main loop iteration: 7265
2025-04-25 13:37:14,298 - transformer_training - INFO - Main loop iteration: 7266
2025-04-25 13:37:14,748 - transformer_training - INFO - Main loop iteration: 7267
2025-04-25 13:37:15,247 - transformer_training - INFO - Main loop iteration: 7268
2025-04-25 13:37:15,648 - transformer_training - INFO - Main loop iteration: 7269
2025-04-25 13:37:16,109 - transformer_training - INFO - Main loop iteration: 7270
Iter 7270: loss 3.3896, lr 0.000953, 81991.32 tokens/sec
2025-04-25 13:37:16,559 - transformer_training - INFO - Main loop iteration: 7271
2025-04-25 13:37:17,058 - transformer_training - INFO - Main loop iteration: 7272
2025-04-25 13:37:17,459 - transformer_training - INFO - Main loop iteration: 7273
2025-04-25 13:37:17,919 - transformer_training - INFO - Main loop iteration: 7274
2025-04-25 13:37:18,370 - transformer_training - INFO - Main loop iteration: 7275
2025-04-25 13:37:18,870 - transformer_training - INFO - Main loop iteration: 7276
2025-04-25 13:37:19,271 - transformer_training - INFO - Main loop iteration: 7277
2025-04-25 13:37:19,732 - transformer_training - INFO - Main loop iteration: 7278
2025-04-25 13:37:20,182 - transformer_training - INFO - Main loop iteration: 7279
2025-04-25 13:37:20,680 - transformer_training - INFO - Main loop iteration: 7280
Iter 7280: loss 3.4131, lr 0.000953, 91958.87 tokens/sec
2025-04-25 13:37:21,082 - transformer_training - INFO - Main loop iteration: 7281
2025-04-25 13:37:21,542 - transformer_training - INFO - Main loop iteration: 7282
2025-04-25 13:37:21,993 - transformer_training - INFO - Main loop iteration: 7283
2025-04-25 13:37:22,492 - transformer_training - INFO - Main loop iteration: 7284
2025-04-25 13:37:22,893 - transformer_training - INFO - Main loop iteration: 7285
2025-04-25 13:37:23,354 - transformer_training - INFO - Main loop iteration: 7286
2025-04-25 13:37:23,804 - transformer_training - INFO - Main loop iteration: 7287
2025-04-25 13:37:24,303 - transformer_training - INFO - Main loop iteration: 7288
2025-04-25 13:37:24,703 - transformer_training - INFO - Main loop iteration: 7289
2025-04-25 13:37:25,164 - transformer_training - INFO - Main loop iteration: 7290
Iter 7290: loss 3.3477, lr 0.000953, 81934.23 tokens/sec
2025-04-25 13:37:25,615 - transformer_training - INFO - Main loop iteration: 7291
2025-04-25 13:37:26,113 - transformer_training - INFO - Main loop iteration: 7292
2025-04-25 13:37:26,514 - transformer_training - INFO - Main loop iteration: 7293
2025-04-25 13:37:26,974 - transformer_training - INFO - Main loop iteration: 7294
2025-04-25 13:37:27,425 - transformer_training - INFO - Main loop iteration: 7295
2025-04-25 13:37:27,924 - transformer_training - INFO - Main loop iteration: 7296
2025-04-25 13:37:28,324 - transformer_training - INFO - Main loop iteration: 7297
2025-04-25 13:37:28,786 - transformer_training - INFO - Main loop iteration: 7298
2025-04-25 13:37:29,236 - transformer_training - INFO - Main loop iteration: 7299
2025-04-25 13:37:29,734 - transformer_training - INFO - Main loop iteration: 7300
Iter 7300: loss 3.4315, lr 0.000953, 92010.20 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7300: train loss 3.3046, val loss 3.3303
2025-04-25 13:37:46,136 - transformer_training - INFO - Main loop iteration: 7301
2025-04-25 13:37:46,544 - transformer_training - INFO - Main loop iteration: 7302
2025-04-25 13:37:46,995 - transformer_training - INFO - Main loop iteration: 7303
2025-04-25 13:37:47,493 - transformer_training - INFO - Main loop iteration: 7304
2025-04-25 13:37:47,894 - transformer_training - INFO - Main loop iteration: 7305
2025-04-25 13:37:48,354 - transformer_training - INFO - Main loop iteration: 7306
2025-04-25 13:37:48,805 - transformer_training - INFO - Main loop iteration: 7307
2025-04-25 13:37:49,303 - transformer_training - INFO - Main loop iteration: 7308
2025-04-25 13:37:49,704 - transformer_training - INFO - Main loop iteration: 7309
2025-04-25 13:37:50,164 - transformer_training - INFO - Main loop iteration: 7310
Iter 7310: loss 3.3187, lr 0.000953, 82076.32 tokens/sec
2025-04-25 13:37:50,614 - transformer_training - INFO - Main loop iteration: 7311
2025-04-25 13:37:51,112 - transformer_training - INFO - Main loop iteration: 7312
2025-04-25 13:37:51,512 - transformer_training - INFO - Main loop iteration: 7313
2025-04-25 13:37:51,973 - transformer_training - INFO - Main loop iteration: 7314
2025-04-25 13:37:52,424 - transformer_training - INFO - Main loop iteration: 7315
2025-04-25 13:37:52,923 - transformer_training - INFO - Main loop iteration: 7316
2025-04-25 13:37:53,324 - transformer_training - INFO - Main loop iteration: 7317
2025-04-25 13:37:53,784 - transformer_training - INFO - Main loop iteration: 7318
2025-04-25 13:37:54,235 - transformer_training - INFO - Main loop iteration: 7319
2025-04-25 13:37:54,734 - transformer_training - INFO - Main loop iteration: 7320
Iter 7320: loss 3.3886, lr 0.000952, 92064.00 tokens/sec
2025-04-25 13:37:55,135 - transformer_training - INFO - Main loop iteration: 7321
2025-04-25 13:37:55,595 - transformer_training - INFO - Main loop iteration: 7322
2025-04-25 13:37:56,046 - transformer_training - INFO - Main loop iteration: 7323
2025-04-25 13:37:56,545 - transformer_training - INFO - Main loop iteration: 7324
2025-04-25 13:37:56,945 - transformer_training - INFO - Main loop iteration: 7325
2025-04-25 13:37:57,406 - transformer_training - INFO - Main loop iteration: 7326
2025-04-25 13:37:57,856 - transformer_training - INFO - Main loop iteration: 7327
2025-04-25 13:37:58,356 - transformer_training - INFO - Main loop iteration: 7328
2025-04-25 13:37:58,756 - transformer_training - INFO - Main loop iteration: 7329
2025-04-25 13:37:59,217 - transformer_training - INFO - Main loop iteration: 7330
Iter 7330: loss 3.4417, lr 0.000952, 81930.15 tokens/sec
2025-04-25 13:37:59,668 - transformer_training - INFO - Main loop iteration: 7331
2025-04-25 13:38:00,167 - transformer_training - INFO - Main loop iteration: 7332
2025-04-25 13:38:00,567 - transformer_training - INFO - Main loop iteration: 7333
2025-04-25 13:38:01,028 - transformer_training - INFO - Main loop iteration: 7334
2025-04-25 13:38:01,479 - transformer_training - INFO - Main loop iteration: 7335
2025-04-25 13:38:01,978 - transformer_training - INFO - Main loop iteration: 7336
2025-04-25 13:38:02,379 - transformer_training - INFO - Main loop iteration: 7337
2025-04-25 13:38:02,841 - transformer_training - INFO - Main loop iteration: 7338
2025-04-25 13:38:03,291 - transformer_training - INFO - Main loop iteration: 7339
2025-04-25 13:38:03,791 - transformer_training - INFO - Main loop iteration: 7340
Iter 7340: loss 3.4011, lr 0.000952, 92014.80 tokens/sec
2025-04-25 13:38:04,192 - transformer_training - INFO - Main loop iteration: 7341
2025-04-25 13:38:04,652 - transformer_training - INFO - Main loop iteration: 7342
2025-04-25 13:38:05,103 - transformer_training - INFO - Main loop iteration: 7343
2025-04-25 13:38:05,602 - transformer_training - INFO - Main loop iteration: 7344
2025-04-25 13:38:06,002 - transformer_training - INFO - Main loop iteration: 7345
2025-04-25 13:38:06,463 - transformer_training - INFO - Main loop iteration: 7346
2025-04-25 13:38:06,914 - transformer_training - INFO - Main loop iteration: 7347
2025-04-25 13:38:07,413 - transformer_training - INFO - Main loop iteration: 7348
2025-04-25 13:38:07,814 - transformer_training - INFO - Main loop iteration: 7349
2025-04-25 13:38:08,275 - transformer_training - INFO - Main loop iteration: 7350
Iter 7350: loss 3.4700, lr 0.000952, 81967.46 tokens/sec
2025-04-25 13:38:08,725 - transformer_training - INFO - Main loop iteration: 7351
2025-04-25 13:38:09,224 - transformer_training - INFO - Main loop iteration: 7352
2025-04-25 13:38:09,625 - transformer_training - INFO - Main loop iteration: 7353
2025-04-25 13:38:10,086 - transformer_training - INFO - Main loop iteration: 7354
2025-04-25 13:38:10,537 - transformer_training - INFO - Main loop iteration: 7355
2025-04-25 13:38:11,036 - transformer_training - INFO - Main loop iteration: 7356
2025-04-25 13:38:11,437 - transformer_training - INFO - Main loop iteration: 7357
2025-04-25 13:38:11,898 - transformer_training - INFO - Main loop iteration: 7358
2025-04-25 13:38:12,348 - transformer_training - INFO - Main loop iteration: 7359
2025-04-25 13:38:12,847 - transformer_training - INFO - Main loop iteration: 7360
Iter 7360: loss 3.4673, lr 0.000952, 91995.31 tokens/sec
2025-04-25 13:38:13,248 - transformer_training - INFO - Main loop iteration: 7361
2025-04-25 13:38:13,709 - transformer_training - INFO - Main loop iteration: 7362
2025-04-25 13:38:14,160 - transformer_training - INFO - Main loop iteration: 7363
2025-04-25 13:38:14,659 - transformer_training - INFO - Main loop iteration: 7364
2025-04-25 13:38:15,060 - transformer_training - INFO - Main loop iteration: 7365
2025-04-25 13:38:15,521 - transformer_training - INFO - Main loop iteration: 7366
2025-04-25 13:38:15,971 - transformer_training - INFO - Main loop iteration: 7367
2025-04-25 13:38:16,470 - transformer_training - INFO - Main loop iteration: 7368
2025-04-25 13:38:16,871 - transformer_training - INFO - Main loop iteration: 7369
2025-04-25 13:38:17,332 - transformer_training - INFO - Main loop iteration: 7370
Iter 7370: loss 3.4055, lr 0.000952, 81976.24 tokens/sec
2025-04-25 13:38:17,782 - transformer_training - INFO - Main loop iteration: 7371
2025-04-25 13:38:18,282 - transformer_training - INFO - Main loop iteration: 7372
2025-04-25 13:38:18,682 - transformer_training - INFO - Main loop iteration: 7373
2025-04-25 13:38:19,143 - transformer_training - INFO - Main loop iteration: 7374
2025-04-25 13:38:19,594 - transformer_training - INFO - Main loop iteration: 7375
2025-04-25 13:38:20,093 - transformer_training - INFO - Main loop iteration: 7376
2025-04-25 13:38:20,493 - transformer_training - INFO - Main loop iteration: 7377
2025-04-25 13:38:20,954 - transformer_training - INFO - Main loop iteration: 7378
2025-04-25 13:38:21,404 - transformer_training - INFO - Main loop iteration: 7379
2025-04-25 13:38:21,905 - transformer_training - INFO - Main loop iteration: 7380
Iter 7380: loss 3.3920, lr 0.000951, 92263.48 tokens/sec
2025-04-25 13:38:22,305 - transformer_training - INFO - Main loop iteration: 7381
2025-04-25 13:38:22,766 - transformer_training - INFO - Main loop iteration: 7382
2025-04-25 13:38:23,216 - transformer_training - INFO - Main loop iteration: 7383
2025-04-25 13:38:23,715 - transformer_training - INFO - Main loop iteration: 7384
2025-04-25 13:38:24,115 - transformer_training - INFO - Main loop iteration: 7385
2025-04-25 13:38:24,576 - transformer_training - INFO - Main loop iteration: 7386
2025-04-25 13:38:25,027 - transformer_training - INFO - Main loop iteration: 7387
2025-04-25 13:38:25,526 - transformer_training - INFO - Main loop iteration: 7388
2025-04-25 13:38:25,927 - transformer_training - INFO - Main loop iteration: 7389
2025-04-25 13:38:26,388 - transformer_training - INFO - Main loop iteration: 7390
Iter 7390: loss 3.4007, lr 0.000951, 81951.86 tokens/sec
2025-04-25 13:38:26,839 - transformer_training - INFO - Main loop iteration: 7391
2025-04-25 13:38:27,337 - transformer_training - INFO - Main loop iteration: 7392
2025-04-25 13:38:27,738 - transformer_training - INFO - Main loop iteration: 7393
2025-04-25 13:38:28,199 - transformer_training - INFO - Main loop iteration: 7394
2025-04-25 13:38:28,649 - transformer_training - INFO - Main loop iteration: 7395
2025-04-25 13:38:29,148 - transformer_training - INFO - Main loop iteration: 7396
2025-04-25 13:38:29,549 - transformer_training - INFO - Main loop iteration: 7397
2025-04-25 13:38:30,010 - transformer_training - INFO - Main loop iteration: 7398
2025-04-25 13:38:30,460 - transformer_training - INFO - Main loop iteration: 7399
2025-04-25 13:38:30,959 - transformer_training - INFO - Main loop iteration: 7400
Iter 7400: loss 3.3622, lr 0.000951, 92074.36 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7400: train loss 3.3000, val loss 3.3189
New best model saved with val loss: 3.3189
2025-04-25 13:38:48,828 - transformer_training - INFO - Main loop iteration: 7401
2025-04-25 13:38:49,238 - transformer_training - INFO - Main loop iteration: 7402
2025-04-25 13:38:49,688 - transformer_training - INFO - Main loop iteration: 7403
2025-04-25 13:38:50,186 - transformer_training - INFO - Main loop iteration: 7404
2025-04-25 13:38:50,587 - transformer_training - INFO - Main loop iteration: 7405
2025-04-25 13:38:51,047 - transformer_training - INFO - Main loop iteration: 7406
2025-04-25 13:38:51,497 - transformer_training - INFO - Main loop iteration: 7407
2025-04-25 13:38:51,996 - transformer_training - INFO - Main loop iteration: 7408
2025-04-25 13:38:52,397 - transformer_training - INFO - Main loop iteration: 7409
2025-04-25 13:38:52,858 - transformer_training - INFO - Main loop iteration: 7410
Iter 7410: loss 3.3963, lr 0.000951, 81930.80 tokens/sec
2025-04-25 13:38:53,308 - transformer_training - INFO - Main loop iteration: 7411
2025-04-25 13:38:53,807 - transformer_training - INFO - Main loop iteration: 7412
2025-04-25 13:38:54,208 - transformer_training - INFO - Main loop iteration: 7413
2025-04-25 13:38:54,669 - transformer_training - INFO - Main loop iteration: 7414
2025-04-25 13:38:55,119 - transformer_training - INFO - Main loop iteration: 7415
2025-04-25 13:38:55,617 - transformer_training - INFO - Main loop iteration: 7416
2025-04-25 13:38:56,017 - transformer_training - INFO - Main loop iteration: 7417
2025-04-25 13:38:56,478 - transformer_training - INFO - Main loop iteration: 7418
2025-04-25 13:38:56,928 - transformer_training - INFO - Main loop iteration: 7419
2025-04-25 13:38:57,427 - transformer_training - INFO - Main loop iteration: 7420
Iter 7420: loss 3.4341, lr 0.000951, 92111.17 tokens/sec
2025-04-25 13:38:57,827 - transformer_training - INFO - Main loop iteration: 7421
2025-04-25 13:38:58,288 - transformer_training - INFO - Main loop iteration: 7422
2025-04-25 13:38:58,738 - transformer_training - INFO - Main loop iteration: 7423
2025-04-25 13:38:59,237 - transformer_training - INFO - Main loop iteration: 7424
2025-04-25 13:38:59,638 - transformer_training - INFO - Main loop iteration: 7425
2025-04-25 13:39:00,098 - transformer_training - INFO - Main loop iteration: 7426
2025-04-25 13:39:00,549 - transformer_training - INFO - Main loop iteration: 7427
2025-04-25 13:39:01,048 - transformer_training - INFO - Main loop iteration: 7428
2025-04-25 13:39:01,448 - transformer_training - INFO - Main loop iteration: 7429
2025-04-25 13:39:01,910 - transformer_training - INFO - Main loop iteration: 7430
Iter 7430: loss 3.3994, lr 0.000951, 81921.68 tokens/sec
2025-04-25 13:39:02,360 - transformer_training - INFO - Main loop iteration: 7431
2025-04-25 13:39:02,859 - transformer_training - INFO - Main loop iteration: 7432
2025-04-25 13:39:03,259 - transformer_training - INFO - Main loop iteration: 7433
2025-04-25 13:39:03,720 - transformer_training - INFO - Main loop iteration: 7434
2025-04-25 13:39:04,170 - transformer_training - INFO - Main loop iteration: 7435
2025-04-25 13:39:04,669 - transformer_training - INFO - Main loop iteration: 7436
2025-04-25 13:39:05,070 - transformer_training - INFO - Main loop iteration: 7437
2025-04-25 13:39:05,530 - transformer_training - INFO - Main loop iteration: 7438
2025-04-25 13:39:05,980 - transformer_training - INFO - Main loop iteration: 7439
2025-04-25 13:39:06,479 - transformer_training - INFO - Main loop iteration: 7440
Iter 7440: loss 3.4228, lr 0.000950, 92054.58 tokens/sec
2025-04-25 13:39:06,880 - transformer_training - INFO - Main loop iteration: 7441
2025-04-25 13:39:07,341 - transformer_training - INFO - Main loop iteration: 7442
2025-04-25 13:39:07,791 - transformer_training - INFO - Main loop iteration: 7443
2025-04-25 13:39:08,290 - transformer_training - INFO - Main loop iteration: 7444
2025-04-25 13:39:08,690 - transformer_training - INFO - Main loop iteration: 7445
2025-04-25 13:39:09,151 - transformer_training - INFO - Main loop iteration: 7446
2025-04-25 13:39:09,601 - transformer_training - INFO - Main loop iteration: 7447
2025-04-25 13:39:10,099 - transformer_training - INFO - Main loop iteration: 7448
2025-04-25 13:39:10,500 - transformer_training - INFO - Main loop iteration: 7449
2025-04-25 13:39:10,961 - transformer_training - INFO - Main loop iteration: 7450
Iter 7450: loss 3.4537, lr 0.000950, 81927.89 tokens/sec
2025-04-25 13:39:11,411 - transformer_training - INFO - Main loop iteration: 7451
2025-04-25 13:39:11,910 - transformer_training - INFO - Main loop iteration: 7452
2025-04-25 13:39:12,311 - transformer_training - INFO - Main loop iteration: 7453
2025-04-25 13:39:12,772 - transformer_training - INFO - Main loop iteration: 7454
2025-04-25 13:39:13,222 - transformer_training - INFO - Main loop iteration: 7455
2025-04-25 13:39:13,721 - transformer_training - INFO - Main loop iteration: 7456
2025-04-25 13:39:14,121 - transformer_training - INFO - Main loop iteration: 7457
2025-04-25 13:39:14,582 - transformer_training - INFO - Main loop iteration: 7458
2025-04-25 13:39:15,032 - transformer_training - INFO - Main loop iteration: 7459
2025-04-25 13:39:15,531 - transformer_training - INFO - Main loop iteration: 7460
Iter 7460: loss 3.4373, lr 0.000950, 92062.14 tokens/sec
2025-04-25 13:39:15,932 - transformer_training - INFO - Main loop iteration: 7461
2025-04-25 13:39:16,393 - transformer_training - INFO - Main loop iteration: 7462
2025-04-25 13:39:16,844 - transformer_training - INFO - Main loop iteration: 7463
2025-04-25 13:39:17,343 - transformer_training - INFO - Main loop iteration: 7464
2025-04-25 13:39:17,743 - transformer_training - INFO - Main loop iteration: 7465
2025-04-25 13:39:18,204 - transformer_training - INFO - Main loop iteration: 7466
2025-04-25 13:39:18,655 - transformer_training - INFO - Main loop iteration: 7467
2025-04-25 13:39:19,153 - transformer_training - INFO - Main loop iteration: 7468
2025-04-25 13:39:19,554 - transformer_training - INFO - Main loop iteration: 7469
2025-04-25 13:39:20,015 - transformer_training - INFO - Main loop iteration: 7470
Iter 7470: loss 3.3716, lr 0.000950, 82010.98 tokens/sec
2025-04-25 13:39:20,465 - transformer_training - INFO - Main loop iteration: 7471
2025-04-25 13:39:20,964 - transformer_training - INFO - Main loop iteration: 7472
2025-04-25 13:39:21,364 - transformer_training - INFO - Main loop iteration: 7473
2025-04-25 13:39:21,825 - transformer_training - INFO - Main loop iteration: 7474
2025-04-25 13:39:22,275 - transformer_training - INFO - Main loop iteration: 7475
2025-04-25 13:39:22,774 - transformer_training - INFO - Main loop iteration: 7476
2025-04-25 13:39:23,174 - transformer_training - INFO - Main loop iteration: 7477
2025-04-25 13:39:23,635 - transformer_training - INFO - Main loop iteration: 7478
2025-04-25 13:39:24,085 - transformer_training - INFO - Main loop iteration: 7479
2025-04-25 13:39:24,585 - transformer_training - INFO - Main loop iteration: 7480
Iter 7480: loss 3.5140, lr 0.000950, 92147.89 tokens/sec
2025-04-25 13:39:24,985 - transformer_training - INFO - Main loop iteration: 7481
2025-04-25 13:39:25,446 - transformer_training - INFO - Main loop iteration: 7482
2025-04-25 13:39:25,896 - transformer_training - INFO - Main loop iteration: 7483
2025-04-25 13:39:26,396 - transformer_training - INFO - Main loop iteration: 7484
2025-04-25 13:39:26,796 - transformer_training - INFO - Main loop iteration: 7485
2025-04-25 13:39:27,257 - transformer_training - INFO - Main loop iteration: 7486
2025-04-25 13:39:27,707 - transformer_training - INFO - Main loop iteration: 7487
2025-04-25 13:39:28,206 - transformer_training - INFO - Main loop iteration: 7488
2025-04-25 13:39:28,607 - transformer_training - INFO - Main loop iteration: 7489
2025-04-25 13:39:29,068 - transformer_training - INFO - Main loop iteration: 7490
Iter 7490: loss 3.4616, lr 0.000949, 81911.40 tokens/sec
2025-04-25 13:39:29,519 - transformer_training - INFO - Main loop iteration: 7491
2025-04-25 13:39:30,018 - transformer_training - INFO - Main loop iteration: 7492
2025-04-25 13:39:30,419 - transformer_training - INFO - Main loop iteration: 7493
2025-04-25 13:39:30,880 - transformer_training - INFO - Main loop iteration: 7494
2025-04-25 13:39:31,330 - transformer_training - INFO - Main loop iteration: 7495
2025-04-25 13:39:31,829 - transformer_training - INFO - Main loop iteration: 7496
2025-04-25 13:39:32,230 - transformer_training - INFO - Main loop iteration: 7497
2025-04-25 13:39:32,691 - transformer_training - INFO - Main loop iteration: 7498
2025-04-25 13:39:33,141 - transformer_training - INFO - Main loop iteration: 7499
2025-04-25 13:39:33,640 - transformer_training - INFO - Main loop iteration: 7500
Iter 7500: loss 3.3937, lr 0.000949, 92040.88 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7500: train loss 3.3000, val loss 3.3196
2025-04-25 13:39:50,648 - transformer_training - INFO - Main loop iteration: 7501
2025-04-25 13:39:51,056 - transformer_training - INFO - Main loop iteration: 7502
2025-04-25 13:39:51,506 - transformer_training - INFO - Main loop iteration: 7503
2025-04-25 13:39:52,005 - transformer_training - INFO - Main loop iteration: 7504
2025-04-25 13:39:52,405 - transformer_training - INFO - Main loop iteration: 7505
2025-04-25 13:39:52,865 - transformer_training - INFO - Main loop iteration: 7506
2025-04-25 13:39:53,315 - transformer_training - INFO - Main loop iteration: 7507
2025-04-25 13:39:53,814 - transformer_training - INFO - Main loop iteration: 7508
2025-04-25 13:39:54,214 - transformer_training - INFO - Main loop iteration: 7509
2025-04-25 13:39:54,675 - transformer_training - INFO - Main loop iteration: 7510
Iter 7510: loss 3.4742, lr 0.000949, 81976.58 tokens/sec
2025-04-25 13:39:55,126 - transformer_training - INFO - Main loop iteration: 7511
2025-04-25 13:39:55,624 - transformer_training - INFO - Main loop iteration: 7512
2025-04-25 13:39:56,025 - transformer_training - INFO - Main loop iteration: 7513
2025-04-25 13:39:56,485 - transformer_training - INFO - Main loop iteration: 7514
2025-04-25 13:39:56,935 - transformer_training - INFO - Main loop iteration: 7515
2025-04-25 13:39:57,434 - transformer_training - INFO - Main loop iteration: 7516
2025-04-25 13:39:57,835 - transformer_training - INFO - Main loop iteration: 7517
2025-04-25 13:39:58,295 - transformer_training - INFO - Main loop iteration: 7518
2025-04-25 13:39:58,746 - transformer_training - INFO - Main loop iteration: 7519
2025-04-25 13:39:59,245 - transformer_training - INFO - Main loop iteration: 7520
Iter 7520: loss 3.3806, lr 0.000949, 91995.75 tokens/sec
2025-04-25 13:39:59,646 - transformer_training - INFO - Main loop iteration: 7521
2025-04-25 13:40:00,106 - transformer_training - INFO - Main loop iteration: 7522
2025-04-25 13:40:00,557 - transformer_training - INFO - Main loop iteration: 7523
2025-04-25 13:40:01,057 - transformer_training - INFO - Main loop iteration: 7524
2025-04-25 13:40:01,457 - transformer_training - INFO - Main loop iteration: 7525
2025-04-25 13:40:01,919 - transformer_training - INFO - Main loop iteration: 7526
2025-04-25 13:40:02,370 - transformer_training - INFO - Main loop iteration: 7527
2025-04-25 13:40:02,869 - transformer_training - INFO - Main loop iteration: 7528
2025-04-25 13:40:03,269 - transformer_training - INFO - Main loop iteration: 7529
2025-04-25 13:40:03,730 - transformer_training - INFO - Main loop iteration: 7530
Iter 7530: loss 3.4063, lr 0.000949, 81931.76 tokens/sec
2025-04-25 13:40:04,181 - transformer_training - INFO - Main loop iteration: 7531
2025-04-25 13:40:04,680 - transformer_training - INFO - Main loop iteration: 7532
2025-04-25 13:40:05,081 - transformer_training - INFO - Main loop iteration: 7533
2025-04-25 13:40:05,541 - transformer_training - INFO - Main loop iteration: 7534
2025-04-25 13:40:05,991 - transformer_training - INFO - Main loop iteration: 7535
2025-04-25 13:40:06,491 - transformer_training - INFO - Main loop iteration: 7536
2025-04-25 13:40:06,891 - transformer_training - INFO - Main loop iteration: 7537
2025-04-25 13:40:07,351 - transformer_training - INFO - Main loop iteration: 7538
2025-04-25 13:40:07,802 - transformer_training - INFO - Main loop iteration: 7539
2025-04-25 13:40:08,301 - transformer_training - INFO - Main loop iteration: 7540
Iter 7540: loss 3.4383, lr 0.000949, 91978.18 tokens/sec
2025-04-25 13:40:08,702 - transformer_training - INFO - Main loop iteration: 7541
2025-04-25 13:40:09,163 - transformer_training - INFO - Main loop iteration: 7542
2025-04-25 13:40:09,613 - transformer_training - INFO - Main loop iteration: 7543
2025-04-25 13:40:10,112 - transformer_training - INFO - Main loop iteration: 7544
2025-04-25 13:40:10,513 - transformer_training - INFO - Main loop iteration: 7545
2025-04-25 13:40:10,974 - transformer_training - INFO - Main loop iteration: 7546
2025-04-25 13:40:11,424 - transformer_training - INFO - Main loop iteration: 7547
2025-04-25 13:40:11,923 - transformer_training - INFO - Main loop iteration: 7548
2025-04-25 13:40:12,324 - transformer_training - INFO - Main loop iteration: 7549
2025-04-25 13:40:12,785 - transformer_training - INFO - Main loop iteration: 7550
Iter 7550: loss 3.4750, lr 0.000948, 81992.49 tokens/sec
2025-04-25 13:40:13,235 - transformer_training - INFO - Main loop iteration: 7551
2025-04-25 13:40:13,735 - transformer_training - INFO - Main loop iteration: 7552
2025-04-25 13:40:14,135 - transformer_training - INFO - Main loop iteration: 7553
2025-04-25 13:40:14,596 - transformer_training - INFO - Main loop iteration: 7554
2025-04-25 13:40:15,046 - transformer_training - INFO - Main loop iteration: 7555
2025-04-25 13:40:15,545 - transformer_training - INFO - Main loop iteration: 7556
2025-04-25 13:40:15,946 - transformer_training - INFO - Main loop iteration: 7557
2025-04-25 13:40:16,407 - transformer_training - INFO - Main loop iteration: 7558
2025-04-25 13:40:16,857 - transformer_training - INFO - Main loop iteration: 7559
2025-04-25 13:40:17,356 - transformer_training - INFO - Main loop iteration: 7560
Iter 7560: loss 3.4455, lr 0.000948, 92122.48 tokens/sec
2025-04-25 13:40:17,757 - transformer_training - INFO - Main loop iteration: 7561
2025-04-25 13:40:18,217 - transformer_training - INFO - Main loop iteration: 7562
2025-04-25 13:40:18,669 - transformer_training - INFO - Main loop iteration: 7563
2025-04-25 13:40:19,168 - transformer_training - INFO - Main loop iteration: 7564
2025-04-25 13:40:19,568 - transformer_training - INFO - Main loop iteration: 7565
2025-04-25 13:40:20,029 - transformer_training - INFO - Main loop iteration: 7566
2025-04-25 13:40:20,479 - transformer_training - INFO - Main loop iteration: 7567
2025-04-25 13:40:20,979 - transformer_training - INFO - Main loop iteration: 7568
2025-04-25 13:40:21,380 - transformer_training - INFO - Main loop iteration: 7569
2025-04-25 13:40:21,841 - transformer_training - INFO - Main loop iteration: 7570
Iter 7570: loss 3.3926, lr 0.000948, 81912.96 tokens/sec
2025-04-25 13:40:22,292 - transformer_training - INFO - Main loop iteration: 7571
2025-04-25 13:40:22,790 - transformer_training - INFO - Main loop iteration: 7572
2025-04-25 13:40:23,191 - transformer_training - INFO - Main loop iteration: 7573
2025-04-25 13:40:23,652 - transformer_training - INFO - Main loop iteration: 7574
2025-04-25 13:40:24,102 - transformer_training - INFO - Main loop iteration: 7575
2025-04-25 13:40:24,602 - transformer_training - INFO - Main loop iteration: 7576
2025-04-25 13:40:25,002 - transformer_training - INFO - Main loop iteration: 7577
2025-04-25 13:40:25,463 - transformer_training - INFO - Main loop iteration: 7578
2025-04-25 13:40:25,913 - transformer_training - INFO - Main loop iteration: 7579
2025-04-25 13:40:26,413 - transformer_training - INFO - Main loop iteration: 7580
Iter 7580: loss 3.3715, lr 0.000948, 92006.21 tokens/sec
2025-04-25 13:40:26,814 - transformer_training - INFO - Main loop iteration: 7581
2025-04-25 13:40:27,275 - transformer_training - INFO - Main loop iteration: 7582
2025-04-25 13:40:27,725 - transformer_training - INFO - Main loop iteration: 7583
2025-04-25 13:40:28,224 - transformer_training - INFO - Main loop iteration: 7584
2025-04-25 13:40:28,625 - transformer_training - INFO - Main loop iteration: 7585
2025-04-25 13:40:29,085 - transformer_training - INFO - Main loop iteration: 7586
2025-04-25 13:40:29,536 - transformer_training - INFO - Main loop iteration: 7587
2025-04-25 13:40:30,034 - transformer_training - INFO - Main loop iteration: 7588
2025-04-25 13:40:30,436 - transformer_training - INFO - Main loop iteration: 7589
2025-04-25 13:40:30,897 - transformer_training - INFO - Main loop iteration: 7590
Iter 7590: loss 3.4301, lr 0.000948, 81900.42 tokens/sec
2025-04-25 13:40:31,348 - transformer_training - INFO - Main loop iteration: 7591
2025-04-25 13:40:31,847 - transformer_training - INFO - Main loop iteration: 7592
2025-04-25 13:40:32,248 - transformer_training - INFO - Main loop iteration: 7593
2025-04-25 13:40:32,709 - transformer_training - INFO - Main loop iteration: 7594
2025-04-25 13:40:33,159 - transformer_training - INFO - Main loop iteration: 7595
2025-04-25 13:40:33,658 - transformer_training - INFO - Main loop iteration: 7596
2025-04-25 13:40:34,059 - transformer_training - INFO - Main loop iteration: 7597
2025-04-25 13:40:34,520 - transformer_training - INFO - Main loop iteration: 7598
2025-04-25 13:40:34,970 - transformer_training - INFO - Main loop iteration: 7599
2025-04-25 13:40:35,469 - transformer_training - INFO - Main loop iteration: 7600
Iter 7600: loss 3.3568, lr 0.000947, 91983.82 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7600: train loss 3.2957, val loss 3.3141
New best model saved with val loss: 3.3141
2025-04-25 13:40:53,292 - transformer_training - INFO - Main loop iteration: 7601
2025-04-25 13:40:53,707 - transformer_training - INFO - Main loop iteration: 7602
2025-04-25 13:40:54,155 - transformer_training - INFO - Main loop iteration: 7603
2025-04-25 13:40:54,654 - transformer_training - INFO - Main loop iteration: 7604
2025-04-25 13:40:55,054 - transformer_training - INFO - Main loop iteration: 7605
2025-04-25 13:40:55,514 - transformer_training - INFO - Main loop iteration: 7606
2025-04-25 13:40:55,965 - transformer_training - INFO - Main loop iteration: 7607
2025-04-25 13:40:56,463 - transformer_training - INFO - Main loop iteration: 7608
2025-04-25 13:40:56,864 - transformer_training - INFO - Main loop iteration: 7609
2025-04-25 13:40:57,324 - transformer_training - INFO - Main loop iteration: 7610
Iter 7610: loss 3.4263, lr 0.000947, 81888.23 tokens/sec
2025-04-25 13:40:57,774 - transformer_training - INFO - Main loop iteration: 7611
2025-04-25 13:40:58,273 - transformer_training - INFO - Main loop iteration: 7612
2025-04-25 13:40:58,674 - transformer_training - INFO - Main loop iteration: 7613
2025-04-25 13:40:59,134 - transformer_training - INFO - Main loop iteration: 7614
2025-04-25 13:40:59,584 - transformer_training - INFO - Main loop iteration: 7615
2025-04-25 13:41:00,083 - transformer_training - INFO - Main loop iteration: 7616
2025-04-25 13:41:00,483 - transformer_training - INFO - Main loop iteration: 7617
2025-04-25 13:41:00,944 - transformer_training - INFO - Main loop iteration: 7618
2025-04-25 13:41:01,395 - transformer_training - INFO - Main loop iteration: 7619
2025-04-25 13:41:01,894 - transformer_training - INFO - Main loop iteration: 7620
Iter 7620: loss 3.3117, lr 0.000947, 92004.29 tokens/sec
2025-04-25 13:41:02,296 - transformer_training - INFO - Main loop iteration: 7621
2025-04-25 13:41:02,757 - transformer_training - INFO - Main loop iteration: 7622
2025-04-25 13:41:03,207 - transformer_training - INFO - Main loop iteration: 7623
2025-04-25 13:41:03,705 - transformer_training - INFO - Main loop iteration: 7624
2025-04-25 13:41:04,106 - transformer_training - INFO - Main loop iteration: 7625
2025-04-25 13:41:04,567 - transformer_training - INFO - Main loop iteration: 7626
2025-04-25 13:41:05,017 - transformer_training - INFO - Main loop iteration: 7627
2025-04-25 13:41:05,515 - transformer_training - INFO - Main loop iteration: 7628
2025-04-25 13:41:05,915 - transformer_training - INFO - Main loop iteration: 7629
2025-04-25 13:41:06,376 - transformer_training - INFO - Main loop iteration: 7630
Iter 7630: loss 3.4577, lr 0.000947, 81939.70 tokens/sec
2025-04-25 13:41:06,826 - transformer_training - INFO - Main loop iteration: 7631
2025-04-25 13:41:07,325 - transformer_training - INFO - Main loop iteration: 7632
2025-04-25 13:41:07,726 - transformer_training - INFO - Main loop iteration: 7633
2025-04-25 13:41:08,186 - transformer_training - INFO - Main loop iteration: 7634
2025-04-25 13:41:08,637 - transformer_training - INFO - Main loop iteration: 7635
2025-04-25 13:41:09,135 - transformer_training - INFO - Main loop iteration: 7636
2025-04-25 13:41:09,536 - transformer_training - INFO - Main loop iteration: 7637
2025-04-25 13:41:09,997 - transformer_training - INFO - Main loop iteration: 7638
2025-04-25 13:41:10,448 - transformer_training - INFO - Main loop iteration: 7639
2025-04-25 13:41:10,946 - transformer_training - INFO - Main loop iteration: 7640
Iter 7640: loss 3.4312, lr 0.000947, 92002.16 tokens/sec
2025-04-25 13:41:11,348 - transformer_training - INFO - Main loop iteration: 7641
2025-04-25 13:41:11,808 - transformer_training - INFO - Main loop iteration: 7642
2025-04-25 13:41:12,259 - transformer_training - INFO - Main loop iteration: 7643
2025-04-25 13:41:12,757 - transformer_training - INFO - Main loop iteration: 7644
2025-04-25 13:41:13,158 - transformer_training - INFO - Main loop iteration: 7645
2025-04-25 13:41:13,619 - transformer_training - INFO - Main loop iteration: 7646
2025-04-25 13:41:14,069 - transformer_training - INFO - Main loop iteration: 7647
2025-04-25 13:41:14,568 - transformer_training - INFO - Main loop iteration: 7648
2025-04-25 13:41:14,969 - transformer_training - INFO - Main loop iteration: 7649
2025-04-25 13:41:15,430 - transformer_training - INFO - Main loop iteration: 7650
Iter 7650: loss 3.4189, lr 0.000947, 81995.15 tokens/sec
2025-04-25 13:41:15,880 - transformer_training - INFO - Main loop iteration: 7651
2025-04-25 13:41:16,378 - transformer_training - INFO - Main loop iteration: 7652
2025-04-25 13:41:16,779 - transformer_training - INFO - Main loop iteration: 7653
2025-04-25 13:41:17,240 - transformer_training - INFO - Main loop iteration: 7654
2025-04-25 13:41:17,690 - transformer_training - INFO - Main loop iteration: 7655
2025-04-25 13:41:18,189 - transformer_training - INFO - Main loop iteration: 7656
2025-04-25 13:41:18,589 - transformer_training - INFO - Main loop iteration: 7657
2025-04-25 13:41:19,050 - transformer_training - INFO - Main loop iteration: 7658
2025-04-25 13:41:19,500 - transformer_training - INFO - Main loop iteration: 7659
2025-04-25 13:41:19,998 - transformer_training - INFO - Main loop iteration: 7660
Iter 7660: loss 3.4550, lr 0.000946, 92081.93 tokens/sec
2025-04-25 13:41:20,399 - transformer_training - INFO - Main loop iteration: 7661
2025-04-25 13:41:20,860 - transformer_training - INFO - Main loop iteration: 7662
2025-04-25 13:41:21,310 - transformer_training - INFO - Main loop iteration: 7663
2025-04-25 13:41:21,809 - transformer_training - INFO - Main loop iteration: 7664
2025-04-25 13:41:22,212 - transformer_training - INFO - Main loop iteration: 7665
2025-04-25 13:41:22,674 - transformer_training - INFO - Main loop iteration: 7666
2025-04-25 13:41:23,124 - transformer_training - INFO - Main loop iteration: 7667
2025-04-25 13:41:23,623 - transformer_training - INFO - Main loop iteration: 7668
2025-04-25 13:41:24,024 - transformer_training - INFO - Main loop iteration: 7669
2025-04-25 13:41:24,484 - transformer_training - INFO - Main loop iteration: 7670
Iter 7670: loss 3.3612, lr 0.000946, 81891.83 tokens/sec
2025-04-25 13:41:24,935 - transformer_training - INFO - Main loop iteration: 7671
2025-04-25 13:41:25,435 - transformer_training - INFO - Main loop iteration: 7672
2025-04-25 13:41:25,836 - transformer_training - INFO - Main loop iteration: 7673
2025-04-25 13:41:26,297 - transformer_training - INFO - Main loop iteration: 7674
2025-04-25 13:41:26,747 - transformer_training - INFO - Main loop iteration: 7675
2025-04-25 13:41:27,245 - transformer_training - INFO - Main loop iteration: 7676
2025-04-25 13:41:27,646 - transformer_training - INFO - Main loop iteration: 7677
2025-04-25 13:41:28,107 - transformer_training - INFO - Main loop iteration: 7678
2025-04-25 13:41:28,557 - transformer_training - INFO - Main loop iteration: 7679
2025-04-25 13:41:29,056 - transformer_training - INFO - Main loop iteration: 7680
Iter 7680: loss 3.4164, lr 0.000946, 92000.18 tokens/sec
2025-04-25 13:41:29,457 - transformer_training - INFO - Main loop iteration: 7681
2025-04-25 13:41:29,918 - transformer_training - INFO - Main loop iteration: 7682
2025-04-25 13:41:30,368 - transformer_training - INFO - Main loop iteration: 7683
2025-04-25 13:41:30,867 - transformer_training - INFO - Main loop iteration: 7684
2025-04-25 13:41:31,268 - transformer_training - INFO - Main loop iteration: 7685
2025-04-25 13:41:31,729 - transformer_training - INFO - Main loop iteration: 7686
2025-04-25 13:41:32,180 - transformer_training - INFO - Main loop iteration: 7687
2025-04-25 13:41:32,678 - transformer_training - INFO - Main loop iteration: 7688
2025-04-25 13:41:33,079 - transformer_training - INFO - Main loop iteration: 7689
2025-04-25 13:41:33,540 - transformer_training - INFO - Main loop iteration: 7690
Iter 7690: loss 3.3632, lr 0.000946, 81950.17 tokens/sec
2025-04-25 13:41:33,990 - transformer_training - INFO - Main loop iteration: 7691
2025-04-25 13:41:34,488 - transformer_training - INFO - Main loop iteration: 7692
2025-04-25 13:41:34,890 - transformer_training - INFO - Main loop iteration: 7693
2025-04-25 13:41:35,350 - transformer_training - INFO - Main loop iteration: 7694
2025-04-25 13:41:35,800 - transformer_training - INFO - Main loop iteration: 7695
2025-04-25 13:41:36,299 - transformer_training - INFO - Main loop iteration: 7696
2025-04-25 13:41:36,700 - transformer_training - INFO - Main loop iteration: 7697
2025-04-25 13:41:37,161 - transformer_training - INFO - Main loop iteration: 7698
2025-04-25 13:41:37,611 - transformer_training - INFO - Main loop iteration: 7699
2025-04-25 13:41:38,110 - transformer_training - INFO - Main loop iteration: 7700
Iter 7700: loss 3.4174, lr 0.000946, 91932.96 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7700: train loss 3.3039, val loss 3.3002
New best model saved with val loss: 3.3002
2025-04-25 13:41:55,405 - transformer_training - INFO - Main loop iteration: 7701
2025-04-25 13:41:55,820 - transformer_training - INFO - Main loop iteration: 7702
2025-04-25 13:41:56,270 - transformer_training - INFO - Main loop iteration: 7703
2025-04-25 13:41:56,768 - transformer_training - INFO - Main loop iteration: 7704
2025-04-25 13:41:57,169 - transformer_training - INFO - Main loop iteration: 7705
2025-04-25 13:41:57,630 - transformer_training - INFO - Main loop iteration: 7706
2025-04-25 13:41:58,080 - transformer_training - INFO - Main loop iteration: 7707
2025-04-25 13:41:58,579 - transformer_training - INFO - Main loop iteration: 7708
2025-04-25 13:41:58,979 - transformer_training - INFO - Main loop iteration: 7709
2025-04-25 13:41:59,441 - transformer_training - INFO - Main loop iteration: 7710
Iter 7710: loss 3.3528, lr 0.000945, 82083.51 tokens/sec
2025-04-25 13:41:59,891 - transformer_training - INFO - Main loop iteration: 7711
2025-04-25 13:42:00,390 - transformer_training - INFO - Main loop iteration: 7712
2025-04-25 13:42:00,791 - transformer_training - INFO - Main loop iteration: 7713
2025-04-25 13:42:01,252 - transformer_training - INFO - Main loop iteration: 7714
2025-04-25 13:42:01,702 - transformer_training - INFO - Main loop iteration: 7715
2025-04-25 13:42:02,202 - transformer_training - INFO - Main loop iteration: 7716
2025-04-25 13:42:02,602 - transformer_training - INFO - Main loop iteration: 7717
2025-04-25 13:42:03,062 - transformer_training - INFO - Main loop iteration: 7718
2025-04-25 13:42:03,513 - transformer_training - INFO - Main loop iteration: 7719
2025-04-25 13:42:04,011 - transformer_training - INFO - Main loop iteration: 7720
Iter 7720: loss 3.4843, lr 0.000945, 92135.81 tokens/sec
2025-04-25 13:42:04,412 - transformer_training - INFO - Main loop iteration: 7721
2025-04-25 13:42:04,872 - transformer_training - INFO - Main loop iteration: 7722
2025-04-25 13:42:05,322 - transformer_training - INFO - Main loop iteration: 7723
2025-04-25 13:42:05,821 - transformer_training - INFO - Main loop iteration: 7724
2025-04-25 13:42:06,222 - transformer_training - INFO - Main loop iteration: 7725
2025-04-25 13:42:06,683 - transformer_training - INFO - Main loop iteration: 7726
2025-04-25 13:42:07,133 - transformer_training - INFO - Main loop iteration: 7727
2025-04-25 13:42:07,632 - transformer_training - INFO - Main loop iteration: 7728
2025-04-25 13:42:08,033 - transformer_training - INFO - Main loop iteration: 7729
2025-04-25 13:42:08,494 - transformer_training - INFO - Main loop iteration: 7730
Iter 7730: loss 3.4782, lr 0.000945, 81968.89 tokens/sec
2025-04-25 13:42:08,945 - transformer_training - INFO - Main loop iteration: 7731
2025-04-25 13:42:09,443 - transformer_training - INFO - Main loop iteration: 7732
2025-04-25 13:42:09,844 - transformer_training - INFO - Main loop iteration: 7733
2025-04-25 13:42:10,305 - transformer_training - INFO - Main loop iteration: 7734
2025-04-25 13:42:10,755 - transformer_training - INFO - Main loop iteration: 7735
2025-04-25 13:42:11,254 - transformer_training - INFO - Main loop iteration: 7736
2025-04-25 13:42:11,655 - transformer_training - INFO - Main loop iteration: 7737
2025-04-25 13:42:12,116 - transformer_training - INFO - Main loop iteration: 7738
2025-04-25 13:42:12,567 - transformer_training - INFO - Main loop iteration: 7739
2025-04-25 13:42:13,066 - transformer_training - INFO - Main loop iteration: 7740
Iter 7740: loss 3.3514, lr 0.000945, 92084.02 tokens/sec
2025-04-25 13:42:13,467 - transformer_training - INFO - Main loop iteration: 7741
2025-04-25 13:42:13,927 - transformer_training - INFO - Main loop iteration: 7742
2025-04-25 13:42:14,377 - transformer_training - INFO - Main loop iteration: 7743
2025-04-25 13:42:14,876 - transformer_training - INFO - Main loop iteration: 7744
2025-04-25 13:42:15,277 - transformer_training - INFO - Main loop iteration: 7745
2025-04-25 13:42:15,737 - transformer_training - INFO - Main loop iteration: 7746
2025-04-25 13:42:16,188 - transformer_training - INFO - Main loop iteration: 7747
2025-04-25 13:42:16,687 - transformer_training - INFO - Main loop iteration: 7748
2025-04-25 13:42:17,087 - transformer_training - INFO - Main loop iteration: 7749
2025-04-25 13:42:17,548 - transformer_training - INFO - Main loop iteration: 7750
Iter 7750: loss 3.4605, lr 0.000945, 81954.08 tokens/sec
2025-04-25 13:42:17,998 - transformer_training - INFO - Main loop iteration: 7751
2025-04-25 13:42:18,497 - transformer_training - INFO - Main loop iteration: 7752
2025-04-25 13:42:18,898 - transformer_training - INFO - Main loop iteration: 7753
2025-04-25 13:42:19,358 - transformer_training - INFO - Main loop iteration: 7754
2025-04-25 13:42:19,809 - transformer_training - INFO - Main loop iteration: 7755
2025-04-25 13:42:20,307 - transformer_training - INFO - Main loop iteration: 7756
2025-04-25 13:42:20,708 - transformer_training - INFO - Main loop iteration: 7757
2025-04-25 13:42:21,168 - transformer_training - INFO - Main loop iteration: 7758
2025-04-25 13:42:21,619 - transformer_training - INFO - Main loop iteration: 7759
2025-04-25 13:42:22,118 - transformer_training - INFO - Main loop iteration: 7760
Iter 7760: loss 3.3350, lr 0.000944, 92032.44 tokens/sec
2025-04-25 13:42:22,519 - transformer_training - INFO - Main loop iteration: 7761
2025-04-25 13:42:22,979 - transformer_training - INFO - Main loop iteration: 7762
2025-04-25 13:42:23,429 - transformer_training - INFO - Main loop iteration: 7763
2025-04-25 13:42:23,928 - transformer_training - INFO - Main loop iteration: 7764
2025-04-25 13:42:24,329 - transformer_training - INFO - Main loop iteration: 7765
2025-04-25 13:42:24,790 - transformer_training - INFO - Main loop iteration: 7766
2025-04-25 13:42:25,240 - transformer_training - INFO - Main loop iteration: 7767
2025-04-25 13:42:25,739 - transformer_training - INFO - Main loop iteration: 7768
2025-04-25 13:42:26,140 - transformer_training - INFO - Main loop iteration: 7769
2025-04-25 13:42:26,600 - transformer_training - INFO - Main loop iteration: 7770
Iter 7770: loss 3.3564, lr 0.000944, 81958.20 tokens/sec
2025-04-25 13:42:27,051 - transformer_training - INFO - Main loop iteration: 7771
2025-04-25 13:42:27,550 - transformer_training - INFO - Main loop iteration: 7772
2025-04-25 13:42:27,950 - transformer_training - INFO - Main loop iteration: 7773
2025-04-25 13:42:28,411 - transformer_training - INFO - Main loop iteration: 7774
2025-04-25 13:42:28,861 - transformer_training - INFO - Main loop iteration: 7775
2025-04-25 13:42:29,360 - transformer_training - INFO - Main loop iteration: 7776
2025-04-25 13:42:29,761 - transformer_training - INFO - Main loop iteration: 7777
2025-04-25 13:42:30,223 - transformer_training - INFO - Main loop iteration: 7778
2025-04-25 13:42:30,674 - transformer_training - INFO - Main loop iteration: 7779
2025-04-25 13:42:31,173 - transformer_training - INFO - Main loop iteration: 7780
Iter 7780: loss 3.3785, lr 0.000944, 92035.07 tokens/sec
2025-04-25 13:42:31,574 - transformer_training - INFO - Main loop iteration: 7781
2025-04-25 13:42:32,035 - transformer_training - INFO - Main loop iteration: 7782
2025-04-25 13:42:32,486 - transformer_training - INFO - Main loop iteration: 7783
2025-04-25 13:42:32,985 - transformer_training - INFO - Main loop iteration: 7784
2025-04-25 13:42:33,385 - transformer_training - INFO - Main loop iteration: 7785
2025-04-25 13:42:33,846 - transformer_training - INFO - Main loop iteration: 7786
2025-04-25 13:42:34,296 - transformer_training - INFO - Main loop iteration: 7787
2025-04-25 13:42:34,795 - transformer_training - INFO - Main loop iteration: 7788
2025-04-25 13:42:35,196 - transformer_training - INFO - Main loop iteration: 7789
2025-04-25 13:42:35,656 - transformer_training - INFO - Main loop iteration: 7790
Iter 7790: loss 3.3632, lr 0.000944, 82001.54 tokens/sec
2025-04-25 13:42:36,107 - transformer_training - INFO - Main loop iteration: 7791
2025-04-25 13:42:36,605 - transformer_training - INFO - Main loop iteration: 7792
2025-04-25 13:42:37,006 - transformer_training - INFO - Main loop iteration: 7793
2025-04-25 13:42:37,467 - transformer_training - INFO - Main loop iteration: 7794
2025-04-25 13:42:37,918 - transformer_training - INFO - Main loop iteration: 7795
2025-04-25 13:42:38,416 - transformer_training - INFO - Main loop iteration: 7796
2025-04-25 13:42:38,817 - transformer_training - INFO - Main loop iteration: 7797
2025-04-25 13:42:39,278 - transformer_training - INFO - Main loop iteration: 7798
2025-04-25 13:42:39,728 - transformer_training - INFO - Main loop iteration: 7799
2025-04-25 13:42:40,227 - transformer_training - INFO - Main loop iteration: 7800
Iter 7800: loss 3.3595, lr 0.000944, 91960.46 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7800: train loss 3.3064, val loss 3.3029
2025-04-25 13:42:55,697 - transformer_training - INFO - Main loop iteration: 7801
2025-04-25 13:42:56,107 - transformer_training - INFO - Main loop iteration: 7802
2025-04-25 13:42:56,557 - transformer_training - INFO - Main loop iteration: 7803
2025-04-25 13:42:57,057 - transformer_training - INFO - Main loop iteration: 7804
2025-04-25 13:42:57,457 - transformer_training - INFO - Main loop iteration: 7805
2025-04-25 13:42:57,918 - transformer_training - INFO - Main loop iteration: 7806
2025-04-25 13:42:58,368 - transformer_training - INFO - Main loop iteration: 7807
2025-04-25 13:42:58,867 - transformer_training - INFO - Main loop iteration: 7808
2025-04-25 13:42:59,268 - transformer_training - INFO - Main loop iteration: 7809
2025-04-25 13:42:59,728 - transformer_training - INFO - Main loop iteration: 7810
Iter 7810: loss 3.3823, lr 0.000944, 81947.30 tokens/sec
2025-04-25 13:43:00,179 - transformer_training - INFO - Main loop iteration: 7811
2025-04-25 13:43:00,677 - transformer_training - INFO - Main loop iteration: 7812
2025-04-25 13:43:01,078 - transformer_training - INFO - Main loop iteration: 7813
2025-04-25 13:43:01,539 - transformer_training - INFO - Main loop iteration: 7814
2025-04-25 13:43:01,989 - transformer_training - INFO - Main loop iteration: 7815
2025-04-25 13:43:02,490 - transformer_training - INFO - Main loop iteration: 7816
2025-04-25 13:43:02,891 - transformer_training - INFO - Main loop iteration: 7817
2025-04-25 13:43:03,351 - transformer_training - INFO - Main loop iteration: 7818
2025-04-25 13:43:03,802 - transformer_training - INFO - Main loop iteration: 7819
2025-04-25 13:43:04,300 - transformer_training - INFO - Main loop iteration: 7820
Iter 7820: loss 3.4017, lr 0.000943, 92062.80 tokens/sec
2025-04-25 13:43:04,701 - transformer_training - INFO - Main loop iteration: 7821
2025-04-25 13:43:05,162 - transformer_training - INFO - Main loop iteration: 7822
2025-04-25 13:43:05,612 - transformer_training - INFO - Main loop iteration: 7823
2025-04-25 13:43:06,111 - transformer_training - INFO - Main loop iteration: 7824
2025-04-25 13:43:06,512 - transformer_training - INFO - Main loop iteration: 7825
2025-04-25 13:43:06,973 - transformer_training - INFO - Main loop iteration: 7826
2025-04-25 13:43:07,423 - transformer_training - INFO - Main loop iteration: 7827
2025-04-25 13:43:07,922 - transformer_training - INFO - Main loop iteration: 7828
2025-04-25 13:43:08,323 - transformer_training - INFO - Main loop iteration: 7829
2025-04-25 13:43:08,783 - transformer_training - INFO - Main loop iteration: 7830
Iter 7830: loss 3.3201, lr 0.000943, 81849.44 tokens/sec
2025-04-25 13:43:09,234 - transformer_training - INFO - Main loop iteration: 7831
2025-04-25 13:43:09,733 - transformer_training - INFO - Main loop iteration: 7832
2025-04-25 13:43:10,134 - transformer_training - INFO - Main loop iteration: 7833
2025-04-25 13:43:10,595 - transformer_training - INFO - Main loop iteration: 7834
2025-04-25 13:43:11,046 - transformer_training - INFO - Main loop iteration: 7835
2025-04-25 13:43:11,545 - transformer_training - INFO - Main loop iteration: 7836
2025-04-25 13:43:11,947 - transformer_training - INFO - Main loop iteration: 7837
2025-04-25 13:43:12,408 - transformer_training - INFO - Main loop iteration: 7838
2025-04-25 13:43:12,858 - transformer_training - INFO - Main loop iteration: 7839
2025-04-25 13:43:13,357 - transformer_training - INFO - Main loop iteration: 7840
Iter 7840: loss 3.3637, lr 0.000943, 91955.92 tokens/sec
2025-04-25 13:43:13,759 - transformer_training - INFO - Main loop iteration: 7841
2025-04-25 13:43:14,219 - transformer_training - INFO - Main loop iteration: 7842
2025-04-25 13:43:14,670 - transformer_training - INFO - Main loop iteration: 7843
2025-04-25 13:43:15,169 - transformer_training - INFO - Main loop iteration: 7844
2025-04-25 13:43:15,569 - transformer_training - INFO - Main loop iteration: 7845
2025-04-25 13:43:16,030 - transformer_training - INFO - Main loop iteration: 7846
2025-04-25 13:43:16,481 - transformer_training - INFO - Main loop iteration: 7847
2025-04-25 13:43:16,981 - transformer_training - INFO - Main loop iteration: 7848
2025-04-25 13:43:17,381 - transformer_training - INFO - Main loop iteration: 7849
2025-04-25 13:43:17,842 - transformer_training - INFO - Main loop iteration: 7850
Iter 7850: loss 3.3413, lr 0.000943, 81908.27 tokens/sec
2025-04-25 13:43:18,293 - transformer_training - INFO - Main loop iteration: 7851
2025-04-25 13:43:18,792 - transformer_training - INFO - Main loop iteration: 7852
2025-04-25 13:43:19,193 - transformer_training - INFO - Main loop iteration: 7853
2025-04-25 13:43:19,654 - transformer_training - INFO - Main loop iteration: 7854
2025-04-25 13:43:20,104 - transformer_training - INFO - Main loop iteration: 7855
2025-04-25 13:43:20,603 - transformer_training - INFO - Main loop iteration: 7856
2025-04-25 13:43:21,003 - transformer_training - INFO - Main loop iteration: 7857
2025-04-25 13:43:21,465 - transformer_training - INFO - Main loop iteration: 7858
2025-04-25 13:43:21,916 - transformer_training - INFO - Main loop iteration: 7859
2025-04-25 13:43:22,415 - transformer_training - INFO - Main loop iteration: 7860
Iter 7860: loss 3.4268, lr 0.000943, 92092.02 tokens/sec
2025-04-25 13:43:22,816 - transformer_training - INFO - Main loop iteration: 7861
2025-04-25 13:43:23,277 - transformer_training - INFO - Main loop iteration: 7862
2025-04-25 13:43:23,727 - transformer_training - INFO - Main loop iteration: 7863
2025-04-25 13:43:24,226 - transformer_training - INFO - Main loop iteration: 7864
2025-04-25 13:43:24,627 - transformer_training - INFO - Main loop iteration: 7865
2025-04-25 13:43:25,087 - transformer_training - INFO - Main loop iteration: 7866
2025-04-25 13:43:25,537 - transformer_training - INFO - Main loop iteration: 7867
2025-04-25 13:43:26,036 - transformer_training - INFO - Main loop iteration: 7868
2025-04-25 13:43:26,436 - transformer_training - INFO - Main loop iteration: 7869
2025-04-25 13:43:26,897 - transformer_training - INFO - Main loop iteration: 7870
Iter 7870: loss 3.3240, lr 0.000942, 81929.41 tokens/sec
2025-04-25 13:43:27,348 - transformer_training - INFO - Main loop iteration: 7871
2025-04-25 13:43:27,846 - transformer_training - INFO - Main loop iteration: 7872
2025-04-25 13:43:28,248 - transformer_training - INFO - Main loop iteration: 7873
2025-04-25 13:43:28,709 - transformer_training - INFO - Main loop iteration: 7874
2025-04-25 13:43:29,160 - transformer_training - INFO - Main loop iteration: 7875
2025-04-25 13:43:29,658 - transformer_training - INFO - Main loop iteration: 7876
2025-04-25 13:43:30,061 - transformer_training - INFO - Main loop iteration: 7877
2025-04-25 13:43:30,522 - transformer_training - INFO - Main loop iteration: 7878
2025-04-25 13:43:30,972 - transformer_training - INFO - Main loop iteration: 7879
2025-04-25 13:43:31,471 - transformer_training - INFO - Main loop iteration: 7880
Iter 7880: loss 3.3159, lr 0.000942, 91964.29 tokens/sec
2025-04-25 13:43:31,872 - transformer_training - INFO - Main loop iteration: 7881
2025-04-25 13:43:32,333 - transformer_training - INFO - Main loop iteration: 7882
2025-04-25 13:43:32,784 - transformer_training - INFO - Main loop iteration: 7883
2025-04-25 13:43:33,282 - transformer_training - INFO - Main loop iteration: 7884
2025-04-25 13:43:33,683 - transformer_training - INFO - Main loop iteration: 7885
2025-04-25 13:43:34,144 - transformer_training - INFO - Main loop iteration: 7886
2025-04-25 13:43:34,594 - transformer_training - INFO - Main loop iteration: 7887
2025-04-25 13:43:35,093 - transformer_training - INFO - Main loop iteration: 7888
2025-04-25 13:43:35,493 - transformer_training - INFO - Main loop iteration: 7889
2025-04-25 13:43:35,954 - transformer_training - INFO - Main loop iteration: 7890
Iter 7890: loss 3.4382, lr 0.000942, 81949.39 tokens/sec
2025-04-25 13:43:36,404 - transformer_training - INFO - Main loop iteration: 7891
2025-04-25 13:43:36,903 - transformer_training - INFO - Main loop iteration: 7892
2025-04-25 13:43:37,304 - transformer_training - INFO - Main loop iteration: 7893
2025-04-25 13:43:37,765 - transformer_training - INFO - Main loop iteration: 7894
2025-04-25 13:43:38,215 - transformer_training - INFO - Main loop iteration: 7895
2025-04-25 13:43:38,714 - transformer_training - INFO - Main loop iteration: 7896
2025-04-25 13:43:39,115 - transformer_training - INFO - Main loop iteration: 7897
2025-04-25 13:43:39,575 - transformer_training - INFO - Main loop iteration: 7898
2025-04-25 13:43:40,025 - transformer_training - INFO - Main loop iteration: 7899
2025-04-25 13:43:40,524 - transformer_training - INFO - Main loop iteration: 7900
Iter 7900: loss 3.4090, lr 0.000942, 91933.72 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 7900: train loss 3.3004, val loss 3.2899
New best model saved with val loss: 3.2899
2025-04-25 13:43:58,532 - transformer_training - INFO - Main loop iteration: 7901
2025-04-25 13:43:58,946 - transformer_training - INFO - Main loop iteration: 7902
2025-04-25 13:43:59,396 - transformer_training - INFO - Main loop iteration: 7903
2025-04-25 13:43:59,895 - transformer_training - INFO - Main loop iteration: 7904
2025-04-25 13:44:00,294 - transformer_training - INFO - Main loop iteration: 7905
2025-04-25 13:44:00,755 - transformer_training - INFO - Main loop iteration: 7906
2025-04-25 13:44:01,205 - transformer_training - INFO - Main loop iteration: 7907
2025-04-25 13:44:01,704 - transformer_training - INFO - Main loop iteration: 7908
2025-04-25 13:44:02,105 - transformer_training - INFO - Main loop iteration: 7909
2025-04-25 13:44:02,566 - transformer_training - INFO - Main loop iteration: 7910
Iter 7910: loss 3.3937, lr 0.000942, 81958.51 tokens/sec
2025-04-25 13:44:03,016 - transformer_training - INFO - Main loop iteration: 7911
2025-04-25 13:44:03,515 - transformer_training - INFO - Main loop iteration: 7912
2025-04-25 13:44:03,915 - transformer_training - INFO - Main loop iteration: 7913
2025-04-25 13:44:04,375 - transformer_training - INFO - Main loop iteration: 7914
2025-04-25 13:44:04,825 - transformer_training - INFO - Main loop iteration: 7915
2025-04-25 13:44:05,330 - transformer_training - INFO - Main loop iteration: 7916
2025-04-25 13:44:05,731 - transformer_training - INFO - Main loop iteration: 7917
2025-04-25 13:44:06,192 - transformer_training - INFO - Main loop iteration: 7918
2025-04-25 13:44:06,642 - transformer_training - INFO - Main loop iteration: 7919
2025-04-25 13:44:07,143 - transformer_training - INFO - Main loop iteration: 7920
Iter 7920: loss 3.4219, lr 0.000941, 92075.24 tokens/sec
2025-04-25 13:44:07,544 - transformer_training - INFO - Main loop iteration: 7921
2025-04-25 13:44:08,005 - transformer_training - INFO - Main loop iteration: 7922
2025-04-25 13:44:08,455 - transformer_training - INFO - Main loop iteration: 7923
2025-04-25 13:44:08,954 - transformer_training - INFO - Main loop iteration: 7924
2025-04-25 13:44:09,355 - transformer_training - INFO - Main loop iteration: 7925
2025-04-25 13:44:09,816 - transformer_training - INFO - Main loop iteration: 7926
2025-04-25 13:44:10,266 - transformer_training - INFO - Main loop iteration: 7927
2025-04-25 13:44:10,765 - transformer_training - INFO - Main loop iteration: 7928
2025-04-25 13:44:11,165 - transformer_training - INFO - Main loop iteration: 7929
2025-04-25 13:44:11,626 - transformer_training - INFO - Main loop iteration: 7930
Iter 7930: loss 3.4336, lr 0.000941, 81933.19 tokens/sec
2025-04-25 13:44:12,076 - transformer_training - INFO - Main loop iteration: 7931
2025-04-25 13:44:12,576 - transformer_training - INFO - Main loop iteration: 7932
2025-04-25 13:44:12,976 - transformer_training - INFO - Main loop iteration: 7933
2025-04-25 13:44:13,437 - transformer_training - INFO - Main loop iteration: 7934
2025-04-25 13:44:13,888 - transformer_training - INFO - Main loop iteration: 7935
2025-04-25 13:44:14,388 - transformer_training - INFO - Main loop iteration: 7936
2025-04-25 13:44:14,788 - transformer_training - INFO - Main loop iteration: 7937
2025-04-25 13:44:15,249 - transformer_training - INFO - Main loop iteration: 7938
2025-04-25 13:44:15,699 - transformer_training - INFO - Main loop iteration: 7939
2025-04-25 13:44:16,198 - transformer_training - INFO - Main loop iteration: 7940
Iter 7940: loss 3.4666, lr 0.000941, 92056.44 tokens/sec
2025-04-25 13:44:16,599 - transformer_training - INFO - Main loop iteration: 7941
2025-04-25 13:44:17,136 - transformer_training - INFO - Main loop iteration: 7942
2025-04-25 13:44:17,586 - transformer_training - INFO - Main loop iteration: 7943
2025-04-25 13:44:18,085 - transformer_training - INFO - Main loop iteration: 7944
2025-04-25 13:44:18,486 - transformer_training - INFO - Main loop iteration: 7945
2025-04-25 13:44:18,947 - transformer_training - INFO - Main loop iteration: 7946
2025-04-25 13:44:19,397 - transformer_training - INFO - Main loop iteration: 7947
2025-04-25 13:44:19,896 - transformer_training - INFO - Main loop iteration: 7948
2025-04-25 13:44:20,296 - transformer_training - INFO - Main loop iteration: 7949
2025-04-25 13:44:20,757 - transformer_training - INFO - Main loop iteration: 7950
Iter 7950: loss 3.4603, lr 0.000941, 81937.62 tokens/sec
2025-04-25 13:44:21,208 - transformer_training - INFO - Main loop iteration: 7951
2025-04-25 13:44:21,706 - transformer_training - INFO - Main loop iteration: 7952
2025-04-25 13:44:22,108 - transformer_training - INFO - Main loop iteration: 7953
2025-04-25 13:44:22,569 - transformer_training - INFO - Main loop iteration: 7954
2025-04-25 13:44:23,019 - transformer_training - INFO - Main loop iteration: 7955
2025-04-25 13:44:23,518 - transformer_training - INFO - Main loop iteration: 7956
2025-04-25 13:44:23,919 - transformer_training - INFO - Main loop iteration: 7957
2025-04-25 13:44:24,380 - transformer_training - INFO - Main loop iteration: 7958
2025-04-25 13:44:24,831 - transformer_training - INFO - Main loop iteration: 7959
2025-04-25 13:44:25,329 - transformer_training - INFO - Main loop iteration: 7960
Iter 7960: loss 3.3301, lr 0.000941, 92054.74 tokens/sec
2025-04-25 13:44:25,730 - transformer_training - INFO - Main loop iteration: 7961
2025-04-25 13:44:26,191 - transformer_training - INFO - Main loop iteration: 7962
2025-04-25 13:44:26,642 - transformer_training - INFO - Main loop iteration: 7963
2025-04-25 13:44:27,141 - transformer_training - INFO - Main loop iteration: 7964
2025-04-25 13:44:27,542 - transformer_training - INFO - Main loop iteration: 7965
2025-04-25 13:44:28,002 - transformer_training - INFO - Main loop iteration: 7966
2025-04-25 13:44:28,453 - transformer_training - INFO - Main loop iteration: 7967
2025-04-25 13:44:28,951 - transformer_training - INFO - Main loop iteration: 7968
2025-04-25 13:44:29,352 - transformer_training - INFO - Main loop iteration: 7969
2025-04-25 13:44:29,813 - transformer_training - INFO - Main loop iteration: 7970
Iter 7970: loss 3.3648, lr 0.000940, 81890.75 tokens/sec
2025-04-25 13:44:30,264 - transformer_training - INFO - Main loop iteration: 7971
2025-04-25 13:44:30,762 - transformer_training - INFO - Main loop iteration: 7972
2025-04-25 13:44:31,163 - transformer_training - INFO - Main loop iteration: 7973
2025-04-25 13:44:31,624 - transformer_training - INFO - Main loop iteration: 7974
2025-04-25 13:44:32,074 - transformer_training - INFO - Main loop iteration: 7975
2025-04-25 13:44:32,573 - transformer_training - INFO - Main loop iteration: 7976
2025-04-25 13:44:32,974 - transformer_training - INFO - Main loop iteration: 7977
2025-04-25 13:44:33,435 - transformer_training - INFO - Main loop iteration: 7978
2025-04-25 13:44:33,886 - transformer_training - INFO - Main loop iteration: 7979
2025-04-25 13:44:34,384 - transformer_training - INFO - Main loop iteration: 7980
Iter 7980: loss 3.3841, lr 0.000940, 92081.99 tokens/sec
2025-04-25 13:44:34,785 - transformer_training - INFO - Main loop iteration: 7981
2025-04-25 13:44:35,246 - transformer_training - INFO - Main loop iteration: 7982
2025-04-25 13:44:35,696 - transformer_training - INFO - Main loop iteration: 7983
2025-04-25 13:44:36,195 - transformer_training - INFO - Main loop iteration: 7984
2025-04-25 13:44:36,596 - transformer_training - INFO - Main loop iteration: 7985
2025-04-25 13:44:37,057 - transformer_training - INFO - Main loop iteration: 7986
2025-04-25 13:44:37,508 - transformer_training - INFO - Main loop iteration: 7987
2025-04-25 13:44:38,006 - transformer_training - INFO - Main loop iteration: 7988
2025-04-25 13:44:38,408 - transformer_training - INFO - Main loop iteration: 7989
2025-04-25 13:44:38,869 - transformer_training - INFO - Main loop iteration: 7990
Iter 7990: loss 3.3524, lr 0.000940, 81749.25 tokens/sec
2025-04-25 13:44:39,320 - transformer_training - INFO - Main loop iteration: 7991
2025-04-25 13:44:39,820 - transformer_training - INFO - Main loop iteration: 7992
2025-04-25 13:44:40,220 - transformer_training - INFO - Main loop iteration: 7993
2025-04-25 13:44:40,681 - transformer_training - INFO - Main loop iteration: 7994
2025-04-25 13:44:41,132 - transformer_training - INFO - Main loop iteration: 7995
2025-04-25 13:44:41,631 - transformer_training - INFO - Main loop iteration: 7996
2025-04-25 13:44:42,032 - transformer_training - INFO - Main loop iteration: 7997
2025-04-25 13:44:42,494 - transformer_training - INFO - Main loop iteration: 7998
2025-04-25 13:44:42,945 - transformer_training - INFO - Main loop iteration: 7999
2025-04-25 13:44:43,443 - transformer_training - INFO - Main loop iteration: 8000
Iter 8000: loss 3.4131, lr 0.000940, 91916.45 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 8000: train loss 3.3030, val loss 3.2894
New best model saved with val loss: 3.2894
2025-04-25 13:45:03,156 - transformer_training - INFO - Main loop iteration: 8001
2025-04-25 13:45:03,577 - transformer_training - INFO - Main loop iteration: 8002
2025-04-25 13:45:04,026 - transformer_training - INFO - Main loop iteration: 8003
2025-04-25 13:45:04,524 - transformer_training - INFO - Main loop iteration: 8004
2025-04-25 13:45:04,924 - transformer_training - INFO - Main loop iteration: 8005
2025-04-25 13:45:05,385 - transformer_training - INFO - Main loop iteration: 8006
2025-04-25 13:45:05,835 - transformer_training - INFO - Main loop iteration: 8007
2025-04-25 13:45:06,333 - transformer_training - INFO - Main loop iteration: 8008
2025-04-25 13:45:06,734 - transformer_training - INFO - Main loop iteration: 8009
2025-04-25 13:45:07,194 - transformer_training - INFO - Main loop iteration: 8010
Iter 8010: loss 3.3866, lr 0.000940, 81918.82 tokens/sec
2025-04-25 13:45:07,645 - transformer_training - INFO - Main loop iteration: 8011
2025-04-25 13:45:08,143 - transformer_training - INFO - Main loop iteration: 8012
2025-04-25 13:45:08,544 - transformer_training - INFO - Main loop iteration: 8013
2025-04-25 13:45:09,004 - transformer_training - INFO - Main loop iteration: 8014
2025-04-25 13:45:09,455 - transformer_training - INFO - Main loop iteration: 8015
2025-04-25 13:45:09,953 - transformer_training - INFO - Main loop iteration: 8016
2025-04-25 13:45:10,354 - transformer_training - INFO - Main loop iteration: 8017
2025-04-25 13:45:10,814 - transformer_training - INFO - Main loop iteration: 8018
2025-04-25 13:45:11,265 - transformer_training - INFO - Main loop iteration: 8019
2025-04-25 13:45:11,763 - transformer_training - INFO - Main loop iteration: 8020
Iter 8020: loss 3.3070, lr 0.000939, 91938.81 tokens/sec
2025-04-25 13:45:12,165 - transformer_training - INFO - Main loop iteration: 8021
2025-04-25 13:45:12,625 - transformer_training - INFO - Main loop iteration: 8022
2025-04-25 13:45:13,076 - transformer_training - INFO - Main loop iteration: 8023
2025-04-25 13:45:13,574 - transformer_training - INFO - Main loop iteration: 8024
2025-04-25 13:45:13,975 - transformer_training - INFO - Main loop iteration: 8025
2025-04-25 13:45:14,436 - transformer_training - INFO - Main loop iteration: 8026
2025-04-25 13:45:14,886 - transformer_training - INFO - Main loop iteration: 8027
2025-04-25 13:45:15,385 - transformer_training - INFO - Main loop iteration: 8028
2025-04-25 13:45:15,786 - transformer_training - INFO - Main loop iteration: 8029
2025-04-25 13:45:16,246 - transformer_training - INFO - Main loop iteration: 8030
Iter 8030: loss 3.4216, lr 0.000939, 81883.38 tokens/sec
2025-04-25 13:45:16,697 - transformer_training - INFO - Main loop iteration: 8031
2025-04-25 13:45:17,195 - transformer_training - INFO - Main loop iteration: 8032
2025-04-25 13:45:17,596 - transformer_training - INFO - Main loop iteration: 8033
2025-04-25 13:45:18,058 - transformer_training - INFO - Main loop iteration: 8034
2025-04-25 13:45:18,508 - transformer_training - INFO - Main loop iteration: 8035
2025-04-25 13:45:19,007 - transformer_training - INFO - Main loop iteration: 8036
2025-04-25 13:45:19,408 - transformer_training - INFO - Main loop iteration: 8037
2025-04-25 13:45:19,869 - transformer_training - INFO - Main loop iteration: 8038
2025-04-25 13:45:20,319 - transformer_training - INFO - Main loop iteration: 8039
2025-04-25 13:45:20,818 - transformer_training - INFO - Main loop iteration: 8040
Iter 8040: loss 3.4196, lr 0.000939, 91901.43 tokens/sec
2025-04-25 13:45:21,220 - transformer_training - INFO - Main loop iteration: 8041
2025-04-25 13:45:21,681 - transformer_training - INFO - Main loop iteration: 8042
2025-04-25 13:45:22,131 - transformer_training - INFO - Main loop iteration: 8043
2025-04-25 13:45:22,631 - transformer_training - INFO - Main loop iteration: 8044
2025-04-25 13:45:23,032 - transformer_training - INFO - Main loop iteration: 8045
2025-04-25 13:45:23,492 - transformer_training - INFO - Main loop iteration: 8046
2025-04-25 13:45:23,943 - transformer_training - INFO - Main loop iteration: 8047
2025-04-25 13:45:24,442 - transformer_training - INFO - Main loop iteration: 8048
2025-04-25 13:45:24,843 - transformer_training - INFO - Main loop iteration: 8049
2025-04-25 13:45:25,304 - transformer_training - INFO - Main loop iteration: 8050
Iter 8050: loss 3.4438, lr 0.000939, 81856.24 tokens/sec
2025-04-25 13:45:25,755 - transformer_training - INFO - Main loop iteration: 8051
2025-04-25 13:45:26,254 - transformer_training - INFO - Main loop iteration: 8052
2025-04-25 13:45:26,655 - transformer_training - INFO - Main loop iteration: 8053
2025-04-25 13:45:27,116 - transformer_training - INFO - Main loop iteration: 8054
2025-04-25 13:45:27,566 - transformer_training - INFO - Main loop iteration: 8055
2025-04-25 13:45:28,065 - transformer_training - INFO - Main loop iteration: 8056
2025-04-25 13:45:28,466 - transformer_training - INFO - Main loop iteration: 8057
2025-04-25 13:45:28,927 - transformer_training - INFO - Main loop iteration: 8058
2025-04-25 13:45:29,378 - transformer_training - INFO - Main loop iteration: 8059
2025-04-25 13:45:29,876 - transformer_training - INFO - Main loop iteration: 8060
Iter 8060: loss 3.3984, lr 0.000939, 92044.82 tokens/sec
2025-04-25 13:45:30,277 - transformer_training - INFO - Main loop iteration: 8061
2025-04-25 13:45:30,738 - transformer_training - INFO - Main loop iteration: 8062
2025-04-25 13:45:31,188 - transformer_training - INFO - Main loop iteration: 8063
2025-04-25 13:45:31,687 - transformer_training - INFO - Main loop iteration: 8064
2025-04-25 13:45:32,089 - transformer_training - INFO - Main loop iteration: 8065
2025-04-25 13:45:32,552 - transformer_training - INFO - Main loop iteration: 8066
2025-04-25 13:45:33,008 - transformer_training - INFO - Main loop iteration: 8067
2025-04-25 13:45:33,507 - transformer_training - INFO - Main loop iteration: 8068
2025-04-25 13:45:33,908 - transformer_training - INFO - Main loop iteration: 8069
2025-04-25 13:45:34,369 - transformer_training - INFO - Main loop iteration: 8070
Iter 8070: loss 3.3569, lr 0.000938, 81923.38 tokens/sec
2025-04-25 13:45:34,820 - transformer_training - INFO - Main loop iteration: 8071
2025-04-25 13:45:35,318 - transformer_training - INFO - Main loop iteration: 8072
2025-04-25 13:45:35,719 - transformer_training - INFO - Main loop iteration: 8073
2025-04-25 13:45:36,181 - transformer_training - INFO - Main loop iteration: 8074
2025-04-25 13:45:36,632 - transformer_training - INFO - Main loop iteration: 8075
2025-04-25 13:45:37,131 - transformer_training - INFO - Main loop iteration: 8076
2025-04-25 13:45:37,531 - transformer_training - INFO - Main loop iteration: 8077
2025-04-25 13:45:37,992 - transformer_training - INFO - Main loop iteration: 8078
2025-04-25 13:45:38,443 - transformer_training - INFO - Main loop iteration: 8079
2025-04-25 13:45:38,941 - transformer_training - INFO - Main loop iteration: 8080
Iter 8080: loss 3.3917, lr 0.000938, 92001.22 tokens/sec
2025-04-25 13:45:39,343 - transformer_training - INFO - Main loop iteration: 8081
2025-04-25 13:45:39,804 - transformer_training - INFO - Main loop iteration: 8082
2025-04-25 13:45:40,255 - transformer_training - INFO - Main loop iteration: 8083
2025-04-25 13:45:40,754 - transformer_training - INFO - Main loop iteration: 8084
2025-04-25 13:45:41,155 - transformer_training - INFO - Main loop iteration: 8085
2025-04-25 13:45:41,617 - transformer_training - INFO - Main loop iteration: 8086
2025-04-25 13:45:42,068 - transformer_training - INFO - Main loop iteration: 8087
2025-04-25 13:45:42,567 - transformer_training - INFO - Main loop iteration: 8088
2025-04-25 13:45:42,968 - transformer_training - INFO - Main loop iteration: 8089
2025-04-25 13:45:43,429 - transformer_training - INFO - Main loop iteration: 8090
Iter 8090: loss 3.3816, lr 0.000938, 81697.20 tokens/sec
2025-04-25 13:45:43,880 - transformer_training - INFO - Main loop iteration: 8091
2025-04-25 13:45:44,379 - transformer_training - INFO - Main loop iteration: 8092
2025-04-25 13:45:44,780 - transformer_training - INFO - Main loop iteration: 8093
2025-04-25 13:45:45,241 - transformer_training - INFO - Main loop iteration: 8094
2025-04-25 13:45:45,692 - transformer_training - INFO - Main loop iteration: 8095
2025-04-25 13:45:46,191 - transformer_training - INFO - Main loop iteration: 8096
2025-04-25 13:45:46,592 - transformer_training - INFO - Main loop iteration: 8097
2025-04-25 13:45:47,053 - transformer_training - INFO - Main loop iteration: 8098
2025-04-25 13:45:47,504 - transformer_training - INFO - Main loop iteration: 8099
2025-04-25 13:45:48,003 - transformer_training - INFO - Main loop iteration: 8100
Iter 8100: loss 3.3411, lr 0.000938, 91807.08 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 8100: train loss 3.3058, val loss 3.2844
New best model saved with val loss: 3.2844
2025-04-25 13:46:05,413 - transformer_training - INFO - Main loop iteration: 8101
2025-04-25 13:46:05,825 - transformer_training - INFO - Main loop iteration: 8102
2025-04-25 13:46:06,275 - transformer_training - INFO - Main loop iteration: 8103
2025-04-25 13:46:06,774 - transformer_training - INFO - Main loop iteration: 8104
2025-04-25 13:46:07,175 - transformer_training - INFO - Main loop iteration: 8105
2025-04-25 13:46:07,636 - transformer_training - INFO - Main loop iteration: 8106
2025-04-25 13:46:08,086 - transformer_training - INFO - Main loop iteration: 8107
2025-04-25 13:46:08,585 - transformer_training - INFO - Main loop iteration: 8108
2025-04-25 13:46:08,985 - transformer_training - INFO - Main loop iteration: 8109
2025-04-25 13:46:09,446 - transformer_training - INFO - Main loop iteration: 8110
Iter 8110: loss 3.4043, lr 0.000938, 81892.79 tokens/sec
2025-04-25 13:46:09,897 - transformer_training - INFO - Main loop iteration: 8111
2025-04-25 13:46:10,395 - transformer_training - INFO - Main loop iteration: 8112
2025-04-25 13:46:10,796 - transformer_training - INFO - Main loop iteration: 8113
2025-04-25 13:46:11,257 - transformer_training - INFO - Main loop iteration: 8114
2025-04-25 13:46:11,707 - transformer_training - INFO - Main loop iteration: 8115
2025-04-25 13:46:12,206 - transformer_training - INFO - Main loop iteration: 8116
2025-04-25 13:46:12,607 - transformer_training - INFO - Main loop iteration: 8117
2025-04-25 13:46:13,067 - transformer_training - INFO - Main loop iteration: 8118
2025-04-25 13:46:13,521 - transformer_training - INFO - Main loop iteration: 8119
2025-04-25 13:46:14,019 - transformer_training - INFO - Main loop iteration: 8120
Iter 8120: loss 3.3324, lr 0.000937, 91877.07 tokens/sec
2025-04-25 13:46:14,421 - transformer_training - INFO - Main loop iteration: 8121
2025-04-25 13:46:14,881 - transformer_training - INFO - Main loop iteration: 8122
2025-04-25 13:46:15,332 - transformer_training - INFO - Main loop iteration: 8123
2025-04-25 13:46:15,831 - transformer_training - INFO - Main loop iteration: 8124
2025-04-25 13:46:16,233 - transformer_training - INFO - Main loop iteration: 8125
2025-04-25 13:46:16,694 - transformer_training - INFO - Main loop iteration: 8126
2025-04-25 13:46:17,145 - transformer_training - INFO - Main loop iteration: 8127
2025-04-25 13:46:17,643 - transformer_training - INFO - Main loop iteration: 8128
2025-04-25 13:46:18,045 - transformer_training - INFO - Main loop iteration: 8129
2025-04-25 13:46:18,508 - transformer_training - INFO - Main loop iteration: 8130
Iter 8130: loss 3.4033, lr 0.000937, 81728.64 tokens/sec
2025-04-25 13:46:18,959 - transformer_training - INFO - Main loop iteration: 8131
2025-04-25 13:46:19,458 - transformer_training - INFO - Main loop iteration: 8132
2025-04-25 13:46:19,859 - transformer_training - INFO - Main loop iteration: 8133
2025-04-25 13:46:20,321 - transformer_training - INFO - Main loop iteration: 8134
2025-04-25 13:46:20,772 - transformer_training - INFO - Main loop iteration: 8135
2025-04-25 13:46:21,270 - transformer_training - INFO - Main loop iteration: 8136
2025-04-25 13:46:21,672 - transformer_training - INFO - Main loop iteration: 8137
2025-04-25 13:46:22,133 - transformer_training - INFO - Main loop iteration: 8138
2025-04-25 13:46:22,584 - transformer_training - INFO - Main loop iteration: 8139
2025-04-25 13:46:23,082 - transformer_training - INFO - Main loop iteration: 8140
Iter 8140: loss 3.3986, lr 0.000937, 91858.51 tokens/sec
2025-04-25 13:46:23,484 - transformer_training - INFO - Main loop iteration: 8141
2025-04-25 13:46:23,945 - transformer_training - INFO - Main loop iteration: 8142
2025-04-25 13:46:24,396 - transformer_training - INFO - Main loop iteration: 8143
2025-04-25 13:46:24,895 - transformer_training - INFO - Main loop iteration: 8144
2025-04-25 13:46:25,296 - transformer_training - INFO - Main loop iteration: 8145
2025-04-25 13:46:25,758 - transformer_training - INFO - Main loop iteration: 8146
2025-04-25 13:46:26,209 - transformer_training - INFO - Main loop iteration: 8147
2025-04-25 13:46:26,707 - transformer_training - INFO - Main loop iteration: 8148
2025-04-25 13:46:27,109 - transformer_training - INFO - Main loop iteration: 8149
2025-04-25 13:46:27,570 - transformer_training - INFO - Main loop iteration: 8150
Iter 8150: loss 3.3767, lr 0.000937, 81988.71 tokens/sec
2025-04-25 13:46:28,020 - transformer_training - INFO - Main loop iteration: 8151
2025-04-25 13:46:28,519 - transformer_training - INFO - Main loop iteration: 8152
2025-04-25 13:46:28,920 - transformer_training - INFO - Main loop iteration: 8153
2025-04-25 13:46:29,382 - transformer_training - INFO - Main loop iteration: 8154
2025-04-25 13:46:29,833 - transformer_training - INFO - Main loop iteration: 8155
2025-04-25 13:46:30,332 - transformer_training - INFO - Main loop iteration: 8156
2025-04-25 13:46:30,734 - transformer_training - INFO - Main loop iteration: 8157
2025-04-25 13:46:31,196 - transformer_training - INFO - Main loop iteration: 8158
2025-04-25 13:46:31,646 - transformer_training - INFO - Main loop iteration: 8159
2025-04-25 13:46:32,145 - transformer_training - INFO - Main loop iteration: 8160
Iter 8160: loss 3.2808, lr 0.000937, 91801.96 tokens/sec
2025-04-25 13:46:32,547 - transformer_training - INFO - Main loop iteration: 8161
2025-04-25 13:46:33,009 - transformer_training - INFO - Main loop iteration: 8162
2025-04-25 13:46:33,460 - transformer_training - INFO - Main loop iteration: 8163
2025-04-25 13:46:33,958 - transformer_training - INFO - Main loop iteration: 8164
2025-04-25 13:46:34,360 - transformer_training - INFO - Main loop iteration: 8165
2025-04-25 13:46:34,821 - transformer_training - INFO - Main loop iteration: 8166
2025-04-25 13:46:35,272 - transformer_training - INFO - Main loop iteration: 8167
2025-04-25 13:46:35,770 - transformer_training - INFO - Main loop iteration: 8168
2025-04-25 13:46:36,172 - transformer_training - INFO - Main loop iteration: 8169
2025-04-25 13:46:36,633 - transformer_training - INFO - Main loop iteration: 8170
Iter 8170: loss 3.4276, lr 0.000936, 81801.46 tokens/sec
2025-04-25 13:46:37,084 - transformer_training - INFO - Main loop iteration: 8171
2025-04-25 13:46:37,582 - transformer_training - INFO - Main loop iteration: 8172
2025-04-25 13:46:37,984 - transformer_training - INFO - Main loop iteration: 8173
2025-04-25 13:46:38,446 - transformer_training - INFO - Main loop iteration: 8174
2025-04-25 13:46:38,896 - transformer_training - INFO - Main loop iteration: 8175
2025-04-25 13:46:39,395 - transformer_training - INFO - Main loop iteration: 8176
2025-04-25 13:46:39,796 - transformer_training - INFO - Main loop iteration: 8177
2025-04-25 13:46:40,258 - transformer_training - INFO - Main loop iteration: 8178
2025-04-25 13:46:40,709 - transformer_training - INFO - Main loop iteration: 8179
2025-04-25 13:46:41,208 - transformer_training - INFO - Main loop iteration: 8180
Iter 8180: loss 3.4057, lr 0.000936, 91838.22 tokens/sec
2025-04-25 13:46:41,609 - transformer_training - INFO - Main loop iteration: 8181
2025-04-25 13:46:42,071 - transformer_training - INFO - Main loop iteration: 8182
2025-04-25 13:46:42,521 - transformer_training - INFO - Main loop iteration: 8183
2025-04-25 13:46:43,020 - transformer_training - INFO - Main loop iteration: 8184
2025-04-25 13:46:43,422 - transformer_training - INFO - Main loop iteration: 8185
2025-04-25 13:46:43,883 - transformer_training - INFO - Main loop iteration: 8186
2025-04-25 13:46:44,334 - transformer_training - INFO - Main loop iteration: 8187
2025-04-25 13:46:44,832 - transformer_training - INFO - Main loop iteration: 8188
2025-04-25 13:46:45,234 - transformer_training - INFO - Main loop iteration: 8189
2025-04-25 13:46:45,696 - transformer_training - INFO - Main loop iteration: 8190
Iter 8190: loss 3.3693, lr 0.000936, 81883.68 tokens/sec
2025-04-25 13:46:46,147 - transformer_training - INFO - Main loop iteration: 8191
2025-04-25 13:46:46,646 - transformer_training - INFO - Main loop iteration: 8192
2025-04-25 13:46:47,047 - transformer_training - INFO - Main loop iteration: 8193
2025-04-25 13:46:47,509 - transformer_training - INFO - Main loop iteration: 8194
2025-04-25 13:46:47,960 - transformer_training - INFO - Main loop iteration: 8195
2025-04-25 13:46:48,459 - transformer_training - INFO - Main loop iteration: 8196
2025-04-25 13:46:48,861 - transformer_training - INFO - Main loop iteration: 8197
2025-04-25 13:46:49,322 - transformer_training - INFO - Main loop iteration: 8198
2025-04-25 13:46:49,773 - transformer_training - INFO - Main loop iteration: 8199
2025-04-25 13:46:50,272 - transformer_training - INFO - Main loop iteration: 8200
Iter 8200: loss 3.3925, lr 0.000936, 91337.48 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 8200: train loss 3.3066, val loss 3.2744
New best model saved with val loss: 3.2744
2025-04-25 13:47:08,448 - transformer_training - INFO - Main loop iteration: 8201
2025-04-25 13:47:08,866 - transformer_training - INFO - Main loop iteration: 8202
2025-04-25 13:47:09,316 - transformer_training - INFO - Main loop iteration: 8203
2025-04-25 13:47:09,814 - transformer_training - INFO - Main loop iteration: 8204
2025-04-25 13:47:10,215 - transformer_training - INFO - Main loop iteration: 8205
2025-04-25 13:47:10,676 - transformer_training - INFO - Main loop iteration: 8206
2025-04-25 13:47:11,126 - transformer_training - INFO - Main loop iteration: 8207
2025-04-25 13:47:11,625 - transformer_training - INFO - Main loop iteration: 8208
2025-04-25 13:47:12,026 - transformer_training - INFO - Main loop iteration: 8209
2025-04-25 13:47:12,487 - transformer_training - INFO - Main loop iteration: 8210
Iter 8210: loss 3.3544, lr 0.000936, 81949.04 tokens/sec
2025-04-25 13:47:12,938 - transformer_training - INFO - Main loop iteration: 8211
2025-04-25 13:47:13,436 - transformer_training - INFO - Main loop iteration: 8212
2025-04-25 13:47:13,837 - transformer_training - INFO - Main loop iteration: 8213
2025-04-25 13:47:14,299 - transformer_training - INFO - Main loop iteration: 8214
2025-04-25 13:47:14,749 - transformer_training - INFO - Main loop iteration: 8215
2025-04-25 13:47:15,248 - transformer_training - INFO - Main loop iteration: 8216
2025-04-25 13:47:15,650 - transformer_training - INFO - Main loop iteration: 8217
2025-04-25 13:47:16,112 - transformer_training - INFO - Main loop iteration: 8218
2025-04-25 13:47:16,562 - transformer_training - INFO - Main loop iteration: 8219
2025-04-25 13:47:17,062 - transformer_training - INFO - Main loop iteration: 8220
Iter 8220: loss 3.3574, lr 0.000935, 91985.02 tokens/sec
2025-04-25 13:47:17,463 - transformer_training - INFO - Main loop iteration: 8221
2025-04-25 13:47:17,925 - transformer_training - INFO - Main loop iteration: 8222
2025-04-25 13:47:18,376 - transformer_training - INFO - Main loop iteration: 8223
2025-04-25 13:47:18,875 - transformer_training - INFO - Main loop iteration: 8224
2025-04-25 13:47:19,276 - transformer_training - INFO - Main loop iteration: 8225
2025-04-25 13:47:19,737 - transformer_training - INFO - Main loop iteration: 8226
2025-04-25 13:47:20,187 - transformer_training - INFO - Main loop iteration: 8227
2025-04-25 13:47:20,687 - transformer_training - INFO - Main loop iteration: 8228
2025-04-25 13:47:21,088 - transformer_training - INFO - Main loop iteration: 8229
2025-04-25 13:47:21,549 - transformer_training - INFO - Main loop iteration: 8230
Iter 8230: loss 3.4076, lr 0.000935, 81944.65 tokens/sec
2025-04-25 13:47:21,999 - transformer_training - INFO - Main loop iteration: 8231
2025-04-25 13:47:22,498 - transformer_training - INFO - Main loop iteration: 8232
2025-04-25 13:47:22,900 - transformer_training - INFO - Main loop iteration: 8233
2025-04-25 13:47:23,361 - transformer_training - INFO - Main loop iteration: 8234
2025-04-25 13:47:23,812 - transformer_training - INFO - Main loop iteration: 8235
2025-04-25 13:47:24,311 - transformer_training - INFO - Main loop iteration: 8236
2025-04-25 13:47:24,712 - transformer_training - INFO - Main loop iteration: 8237
2025-04-25 13:47:25,173 - transformer_training - INFO - Main loop iteration: 8238
2025-04-25 13:47:25,623 - transformer_training - INFO - Main loop iteration: 8239
2025-04-25 13:47:26,122 - transformer_training - INFO - Main loop iteration: 8240
Iter 8240: loss 3.3718, lr 0.000935, 91850.06 tokens/sec
2025-04-25 13:47:26,524 - transformer_training - INFO - Main loop iteration: 8241
2025-04-25 13:47:26,985 - transformer_training - INFO - Main loop iteration: 8242
2025-04-25 13:47:27,435 - transformer_training - INFO - Main loop iteration: 8243
2025-04-25 13:47:27,934 - transformer_training - INFO - Main loop iteration: 8244
2025-04-25 13:47:28,336 - transformer_training - INFO - Main loop iteration: 8245
2025-04-25 13:47:28,797 - transformer_training - INFO - Main loop iteration: 8246
2025-04-25 13:47:29,248 - transformer_training - INFO - Main loop iteration: 8247
2025-04-25 13:47:29,747 - transformer_training - INFO - Main loop iteration: 8248
2025-04-25 13:47:30,149 - transformer_training - INFO - Main loop iteration: 8249
2025-04-25 13:47:30,610 - transformer_training - INFO - Main loop iteration: 8250
Iter 8250: loss 3.4313, lr 0.000935, 81836.79 tokens/sec
2025-04-25 13:47:31,061 - transformer_training - INFO - Main loop iteration: 8251
2025-04-25 13:47:31,559 - transformer_training - INFO - Main loop iteration: 8252
2025-04-25 13:47:31,961 - transformer_training - INFO - Main loop iteration: 8253
2025-04-25 13:47:32,423 - transformer_training - INFO - Main loop iteration: 8254
2025-04-25 13:47:32,874 - transformer_training - INFO - Main loop iteration: 8255
2025-04-25 13:47:33,373 - transformer_training - INFO - Main loop iteration: 8256
2025-04-25 13:47:33,774 - transformer_training - INFO - Main loop iteration: 8257
2025-04-25 13:47:34,237 - transformer_training - INFO - Main loop iteration: 8258
2025-04-25 13:47:34,687 - transformer_training - INFO - Main loop iteration: 8259
2025-04-25 13:47:35,186 - transformer_training - INFO - Main loop iteration: 8260
Iter 8260: loss 3.3501, lr 0.000935, 91898.64 tokens/sec
2025-04-25 13:47:35,588 - transformer_training - INFO - Main loop iteration: 8261
2025-04-25 13:47:36,049 - transformer_training - INFO - Main loop iteration: 8262
2025-04-25 13:47:36,500 - transformer_training - INFO - Main loop iteration: 8263
2025-04-25 13:47:36,999 - transformer_training - INFO - Main loop iteration: 8264
2025-04-25 13:47:37,400 - transformer_training - INFO - Main loop iteration: 8265
2025-04-25 13:47:37,861 - transformer_training - INFO - Main loop iteration: 8266
2025-04-25 13:47:38,313 - transformer_training - INFO - Main loop iteration: 8267
2025-04-25 13:47:38,812 - transformer_training - INFO - Main loop iteration: 8268
2025-04-25 13:47:39,213 - transformer_training - INFO - Main loop iteration: 8269
2025-04-25 13:47:39,674 - transformer_training - INFO - Main loop iteration: 8270
Iter 8270: loss 3.3713, lr 0.000934, 81796.26 tokens/sec
2025-04-25 13:47:40,125 - transformer_training - INFO - Main loop iteration: 8271
2025-04-25 13:47:40,624 - transformer_training - INFO - Main loop iteration: 8272
2025-04-25 13:47:41,025 - transformer_training - INFO - Main loop iteration: 8273
2025-04-25 13:47:41,487 - transformer_training - INFO - Main loop iteration: 8274
2025-04-25 13:47:41,937 - transformer_training - INFO - Main loop iteration: 8275
2025-04-25 13:47:42,437 - transformer_training - INFO - Main loop iteration: 8276
2025-04-25 13:47:42,839 - transformer_training - INFO - Main loop iteration: 8277
2025-04-25 13:47:43,300 - transformer_training - INFO - Main loop iteration: 8278
2025-04-25 13:47:43,751 - transformer_training - INFO - Main loop iteration: 8279
2025-04-25 13:47:44,250 - transformer_training - INFO - Main loop iteration: 8280
Iter 8280: loss 3.3477, lr 0.000934, 91775.86 tokens/sec
2025-04-25 13:47:44,652 - transformer_training - INFO - Main loop iteration: 8281
2025-04-25 13:47:45,113 - transformer_training - INFO - Main loop iteration: 8282
2025-04-25 13:47:45,564 - transformer_training - INFO - Main loop iteration: 8283
2025-04-25 13:47:46,063 - transformer_training - INFO - Main loop iteration: 8284
2025-04-25 13:47:46,465 - transformer_training - INFO - Main loop iteration: 8285
2025-04-25 13:47:46,926 - transformer_training - INFO - Main loop iteration: 8286
2025-04-25 13:47:47,377 - transformer_training - INFO - Main loop iteration: 8287
2025-04-25 13:47:47,876 - transformer_training - INFO - Main loop iteration: 8288
2025-04-25 13:47:48,278 - transformer_training - INFO - Main loop iteration: 8289
2025-04-25 13:47:48,739 - transformer_training - INFO - Main loop iteration: 8290
Iter 8290: loss 3.3708, lr 0.000934, 81812.49 tokens/sec
2025-04-25 13:47:49,190 - transformer_training - INFO - Main loop iteration: 8291
2025-04-25 13:47:49,689 - transformer_training - INFO - Main loop iteration: 8292
2025-04-25 13:47:50,091 - transformer_training - INFO - Main loop iteration: 8293
2025-04-25 13:47:50,552 - transformer_training - INFO - Main loop iteration: 8294
2025-04-25 13:47:51,003 - transformer_training - INFO - Main loop iteration: 8295
2025-04-25 13:47:51,501 - transformer_training - INFO - Main loop iteration: 8296
2025-04-25 13:47:51,904 - transformer_training - INFO - Main loop iteration: 8297
2025-04-25 13:47:52,366 - transformer_training - INFO - Main loop iteration: 8298
2025-04-25 13:47:52,817 - transformer_training - INFO - Main loop iteration: 8299
2025-04-25 13:47:53,316 - transformer_training - INFO - Main loop iteration: 8300
Iter 8300: loss 3.3357, lr 0.000934, 91899.08 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 8300: train loss 3.3050, val loss 3.2723
New best model saved with val loss: 3.2723
2025-04-25 13:48:11,503 - transformer_training - INFO - Main loop iteration: 8301
2025-04-25 13:48:11,927 - transformer_training - INFO - Main loop iteration: 8302
2025-04-25 13:48:12,375 - transformer_training - INFO - Main loop iteration: 8303
2025-04-25 13:48:12,874 - transformer_training - INFO - Main loop iteration: 8304
2025-04-25 13:48:13,276 - transformer_training - INFO - Main loop iteration: 8305
2025-04-25 13:48:13,736 - transformer_training - INFO - Main loop iteration: 8306
2025-04-25 13:48:14,186 - transformer_training - INFO - Main loop iteration: 8307
2025-04-25 13:48:14,686 - transformer_training - INFO - Main loop iteration: 8308
2025-04-25 13:48:15,087 - transformer_training - INFO - Main loop iteration: 8309
2025-04-25 13:48:15,548 - transformer_training - INFO - Main loop iteration: 8310
Iter 8310: loss 3.3138, lr 0.000934, 81965.33 tokens/sec
2025-04-25 13:48:15,998 - transformer_training - INFO - Main loop iteration: 8311
2025-04-25 13:48:16,497 - transformer_training - INFO - Main loop iteration: 8312
2025-04-25 13:48:16,898 - transformer_training - INFO - Main loop iteration: 8313
2025-04-25 13:48:17,359 - transformer_training - INFO - Main loop iteration: 8314
2025-04-25 13:48:17,809 - transformer_training - INFO - Main loop iteration: 8315
2025-04-25 13:48:18,308 - transformer_training - INFO - Main loop iteration: 8316
2025-04-25 13:48:18,710 - transformer_training - INFO - Main loop iteration: 8317
2025-04-25 13:48:19,171 - transformer_training - INFO - Main loop iteration: 8318
2025-04-25 13:48:19,621 - transformer_training - INFO - Main loop iteration: 8319
2025-04-25 13:48:20,120 - transformer_training - INFO - Main loop iteration: 8320
Iter 8320: loss 3.3616, lr 0.000933, 91809.86 tokens/sec
2025-04-25 13:48:20,522 - transformer_training - INFO - Main loop iteration: 8321
2025-04-25 13:48:20,982 - transformer_training - INFO - Main loop iteration: 8322
2025-04-25 13:48:21,433 - transformer_training - INFO - Main loop iteration: 8323
2025-04-25 13:48:21,931 - transformer_training - INFO - Main loop iteration: 8324
2025-04-25 13:48:22,333 - transformer_training - INFO - Main loop iteration: 8325
2025-04-25 13:48:22,794 - transformer_training - INFO - Main loop iteration: 8326
2025-04-25 13:48:23,245 - transformer_training - INFO - Main loop iteration: 8327
2025-04-25 13:48:23,743 - transformer_training - INFO - Main loop iteration: 8328
2025-04-25 13:48:24,145 - transformer_training - INFO - Main loop iteration: 8329
2025-04-25 13:48:24,606 - transformer_training - INFO - Main loop iteration: 8330
Iter 8330: loss 3.3782, lr 0.000933, 81902.46 tokens/sec
2025-04-25 13:48:25,057 - transformer_training - INFO - Main loop iteration: 8331
2025-04-25 13:48:25,555 - transformer_training - INFO - Main loop iteration: 8332
2025-04-25 13:48:25,957 - transformer_training - INFO - Main loop iteration: 8333
2025-04-25 13:48:26,417 - transformer_training - INFO - Main loop iteration: 8334
2025-04-25 13:48:26,867 - transformer_training - INFO - Main loop iteration: 8335
2025-04-25 13:48:27,366 - transformer_training - INFO - Main loop iteration: 8336
2025-04-25 13:48:27,767 - transformer_training - INFO - Main loop iteration: 8337
2025-04-25 13:48:28,228 - transformer_training - INFO - Main loop iteration: 8338
2025-04-25 13:48:28,679 - transformer_training - INFO - Main loop iteration: 8339
2025-04-25 13:48:29,178 - transformer_training - INFO - Main loop iteration: 8340
Iter 8340: loss 3.4317, lr 0.000933, 92073.32 tokens/sec
2025-04-25 13:48:29,579 - transformer_training - INFO - Main loop iteration: 8341
2025-04-25 13:48:30,039 - transformer_training - INFO - Main loop iteration: 8342
2025-04-25 13:48:30,489 - transformer_training - INFO - Main loop iteration: 8343
2025-04-25 13:48:30,989 - transformer_training - INFO - Main loop iteration: 8344
2025-04-25 13:48:31,389 - transformer_training - INFO - Main loop iteration: 8345
2025-04-25 13:48:31,850 - transformer_training - INFO - Main loop iteration: 8346
2025-04-25 13:48:32,301 - transformer_training - INFO - Main loop iteration: 8347
2025-04-25 13:48:32,800 - transformer_training - INFO - Main loop iteration: 8348
2025-04-25 13:48:33,201 - transformer_training - INFO - Main loop iteration: 8349
2025-04-25 13:48:33,662 - transformer_training - INFO - Main loop iteration: 8350
Iter 8350: loss 3.4134, lr 0.000933, 81923.51 tokens/sec
2025-04-25 13:48:34,112 - transformer_training - INFO - Main loop iteration: 8351
2025-04-25 13:48:34,611 - transformer_training - INFO - Main loop iteration: 8352
2025-04-25 13:48:35,012 - transformer_training - INFO - Main loop iteration: 8353
2025-04-25 13:48:35,473 - transformer_training - INFO - Main loop iteration: 8354
2025-04-25 13:48:35,924 - transformer_training - INFO - Main loop iteration: 8355
2025-04-25 13:48:36,422 - transformer_training - INFO - Main loop iteration: 8356
2025-04-25 13:48:36,823 - transformer_training - INFO - Main loop iteration: 8357
2025-04-25 13:48:37,284 - transformer_training - INFO - Main loop iteration: 8358
2025-04-25 13:48:37,734 - transformer_training - INFO - Main loop iteration: 8359
2025-04-25 13:48:38,232 - transformer_training - INFO - Main loop iteration: 8360
Iter 8360: loss 3.4769, lr 0.000933, 91890.67 tokens/sec
2025-04-25 13:48:38,634 - transformer_training - INFO - Main loop iteration: 8361
2025-04-25 13:48:39,095 - transformer_training - INFO - Main loop iteration: 8362
2025-04-25 13:48:39,545 - transformer_training - INFO - Main loop iteration: 8363
2025-04-25 13:48:40,044 - transformer_training - INFO - Main loop iteration: 8364
2025-04-25 13:48:40,445 - transformer_training - INFO - Main loop iteration: 8365
2025-04-25 13:48:40,906 - transformer_training - INFO - Main loop iteration: 8366
2025-04-25 13:48:41,357 - transformer_training - INFO - Main loop iteration: 8367
2025-04-25 13:48:41,856 - transformer_training - INFO - Main loop iteration: 8368
2025-04-25 13:48:42,258 - transformer_training - INFO - Main loop iteration: 8369
2025-04-25 13:48:42,719 - transformer_training - INFO - Main loop iteration: 8370
Iter 8370: loss 3.3433, lr 0.000932, 81925.94 tokens/sec
2025-04-25 13:48:43,169 - transformer_training - INFO - Main loop iteration: 8371
2025-04-25 13:48:43,668 - transformer_training - INFO - Main loop iteration: 8372
2025-04-25 13:48:44,069 - transformer_training - INFO - Main loop iteration: 8373
2025-04-25 13:48:44,530 - transformer_training - INFO - Main loop iteration: 8374
2025-04-25 13:48:44,981 - transformer_training - INFO - Main loop iteration: 8375
2025-04-25 13:48:45,480 - transformer_training - INFO - Main loop iteration: 8376
2025-04-25 13:48:45,881 - transformer_training - INFO - Main loop iteration: 8377
2025-04-25 13:48:46,342 - transformer_training - INFO - Main loop iteration: 8378
2025-04-25 13:48:46,793 - transformer_training - INFO - Main loop iteration: 8379
2025-04-25 13:48:47,292 - transformer_training - INFO - Main loop iteration: 8380
Iter 8380: loss 3.4559, lr 0.000932, 91966.09 tokens/sec
2025-04-25 13:48:47,693 - transformer_training - INFO - Main loop iteration: 8381
2025-04-25 13:48:48,154 - transformer_training - INFO - Main loop iteration: 8382
2025-04-25 13:48:48,605 - transformer_training - INFO - Main loop iteration: 8383
2025-04-25 13:48:49,104 - transformer_training - INFO - Main loop iteration: 8384
2025-04-25 13:48:49,505 - transformer_training - INFO - Main loop iteration: 8385
2025-04-25 13:48:49,966 - transformer_training - INFO - Main loop iteration: 8386
2025-04-25 13:48:50,417 - transformer_training - INFO - Main loop iteration: 8387
2025-04-25 13:48:50,916 - transformer_training - INFO - Main loop iteration: 8388
2025-04-25 13:48:51,317 - transformer_training - INFO - Main loop iteration: 8389
2025-04-25 13:48:51,781 - transformer_training - INFO - Main loop iteration: 8390
Iter 8390: loss 3.3951, lr 0.000932, 81798.82 tokens/sec
2025-04-25 13:48:52,232 - transformer_training - INFO - Main loop iteration: 8391
2025-04-25 13:48:52,731 - transformer_training - INFO - Main loop iteration: 8392
2025-04-25 13:48:53,133 - transformer_training - INFO - Main loop iteration: 8393
2025-04-25 13:48:53,594 - transformer_training - INFO - Main loop iteration: 8394
2025-04-25 13:48:54,045 - transformer_training - INFO - Main loop iteration: 8395
2025-04-25 13:48:54,544 - transformer_training - INFO - Main loop iteration: 8396
2025-04-25 13:48:54,945 - transformer_training - INFO - Main loop iteration: 8397
2025-04-25 13:48:55,407 - transformer_training - INFO - Main loop iteration: 8398
2025-04-25 13:48:55,858 - transformer_training - INFO - Main loop iteration: 8399
2025-04-25 13:48:56,357 - transformer_training - INFO - Main loop iteration: 8400
Iter 8400: loss 3.3080, lr 0.000932, 91891.60 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 8400: train loss 3.3017, val loss 3.2737
2025-04-25 13:49:11,694 - transformer_training - INFO - Main loop iteration: 8401
2025-04-25 13:49:12,104 - transformer_training - INFO - Main loop iteration: 8402
2025-04-25 13:49:12,555 - transformer_training - INFO - Main loop iteration: 8403
2025-04-25 13:49:13,053 - transformer_training - INFO - Main loop iteration: 8404
2025-04-25 13:49:13,455 - transformer_training - INFO - Main loop iteration: 8405
2025-04-25 13:49:13,915 - transformer_training - INFO - Main loop iteration: 8406
2025-04-25 13:49:14,365 - transformer_training - INFO - Main loop iteration: 8407
2025-04-25 13:49:14,865 - transformer_training - INFO - Main loop iteration: 8408
2025-04-25 13:49:15,265 - transformer_training - INFO - Main loop iteration: 8409
2025-04-25 13:49:15,726 - transformer_training - INFO - Main loop iteration: 8410
Iter 8410: loss 3.3868, lr 0.000932, 81913.18 tokens/sec
2025-04-25 13:49:16,178 - transformer_training - INFO - Main loop iteration: 8411
2025-04-25 13:49:16,677 - transformer_training - INFO - Main loop iteration: 8412
2025-04-25 13:49:17,078 - transformer_training - INFO - Main loop iteration: 8413
2025-04-25 13:49:17,539 - transformer_training - INFO - Main loop iteration: 8414
2025-04-25 13:49:17,989 - transformer_training - INFO - Main loop iteration: 8415
2025-04-25 13:49:18,488 - transformer_training - INFO - Main loop iteration: 8416
2025-04-25 13:49:18,890 - transformer_training - INFO - Main loop iteration: 8417
2025-04-25 13:49:19,351 - transformer_training - INFO - Main loop iteration: 8418
2025-04-25 13:49:19,802 - transformer_training - INFO - Main loop iteration: 8419
2025-04-25 13:49:20,300 - transformer_training - INFO - Main loop iteration: 8420
Iter 8420: loss 3.3894, lr 0.000931, 91831.40 tokens/sec
2025-04-25 13:49:20,702 - transformer_training - INFO - Main loop iteration: 8421
2025-04-25 13:49:21,163 - transformer_training - INFO - Main loop iteration: 8422
2025-04-25 13:49:21,615 - transformer_training - INFO - Main loop iteration: 8423
2025-04-25 13:49:22,116 - transformer_training - INFO - Main loop iteration: 8424
2025-04-25 13:49:22,517 - transformer_training - INFO - Main loop iteration: 8425
2025-04-25 13:49:22,978 - transformer_training - INFO - Main loop iteration: 8426
2025-04-25 13:49:23,428 - transformer_training - INFO - Main loop iteration: 8427
2025-04-25 13:49:23,928 - transformer_training - INFO - Main loop iteration: 8428
2025-04-25 13:49:24,329 - transformer_training - INFO - Main loop iteration: 8429
2025-04-25 13:49:24,790 - transformer_training - INFO - Main loop iteration: 8430
Iter 8430: loss 3.2047, lr 0.000931, 81744.63 tokens/sec
2025-04-25 13:49:25,241 - transformer_training - INFO - Main loop iteration: 8431
2025-04-25 13:49:25,740 - transformer_training - INFO - Main loop iteration: 8432
2025-04-25 13:49:26,142 - transformer_training - INFO - Main loop iteration: 8433
2025-04-25 13:49:26,603 - transformer_training - INFO - Main loop iteration: 8434
2025-04-25 13:49:27,054 - transformer_training - INFO - Main loop iteration: 8435
2025-04-25 13:49:27,553 - transformer_training - INFO - Main loop iteration: 8436
2025-04-25 13:49:27,955 - transformer_training - INFO - Main loop iteration: 8437
2025-04-25 13:49:28,416 - transformer_training - INFO - Main loop iteration: 8438
2025-04-25 13:49:28,867 - transformer_training - INFO - Main loop iteration: 8439
2025-04-25 13:49:29,367 - transformer_training - INFO - Main loop iteration: 8440
Iter 8440: loss 3.3170, lr 0.000931, 91938.04 tokens/sec
2025-04-25 13:49:29,768 - transformer_training - INFO - Main loop iteration: 8441
2025-04-25 13:49:30,228 - transformer_training - INFO - Main loop iteration: 8442
2025-04-25 13:49:30,679 - transformer_training - INFO - Main loop iteration: 8443
2025-04-25 13:49:31,178 - transformer_training - INFO - Main loop iteration: 8444
2025-04-25 13:49:31,579 - transformer_training - INFO - Main loop iteration: 8445
2025-04-25 13:49:32,041 - transformer_training - INFO - Main loop iteration: 8446
2025-04-25 13:49:32,492 - transformer_training - INFO - Main loop iteration: 8447
2025-04-25 13:49:32,991 - transformer_training - INFO - Main loop iteration: 8448
2025-04-25 13:49:33,392 - transformer_training - INFO - Main loop iteration: 8449
2025-04-25 13:49:33,853 - transformer_training - INFO - Main loop iteration: 8450
Iter 8450: loss 3.3298, lr 0.000931, 81890.75 tokens/sec
2025-04-25 13:49:34,304 - transformer_training - INFO - Main loop iteration: 8451
2025-04-25 13:49:34,802 - transformer_training - INFO - Main loop iteration: 8452
2025-04-25 13:49:35,204 - transformer_training - INFO - Main loop iteration: 8453
2025-04-25 13:49:35,665 - transformer_training - INFO - Main loop iteration: 8454
2025-04-25 13:49:36,115 - transformer_training - INFO - Main loop iteration: 8455
2025-04-25 13:49:36,615 - transformer_training - INFO - Main loop iteration: 8456
2025-04-25 13:49:37,016 - transformer_training - INFO - Main loop iteration: 8457
2025-04-25 13:49:37,477 - transformer_training - INFO - Main loop iteration: 8458
2025-04-25 13:49:37,927 - transformer_training - INFO - Main loop iteration: 8459
2025-04-25 13:49:38,426 - transformer_training - INFO - Main loop iteration: 8460
Iter 8460: loss 3.3537, lr 0.000930, 91927.33 tokens/sec
2025-04-25 13:49:38,827 - transformer_training - INFO - Main loop iteration: 8461
2025-04-25 13:49:39,289 - transformer_training - INFO - Main loop iteration: 8462
2025-04-25 13:49:39,739 - transformer_training - INFO - Main loop iteration: 8463
2025-04-25 13:49:40,239 - transformer_training - INFO - Main loop iteration: 8464
2025-04-25 13:49:40,640 - transformer_training - INFO - Main loop iteration: 8465
2025-04-25 13:49:41,102 - transformer_training - INFO - Main loop iteration: 8466
2025-04-25 13:49:41,552 - transformer_training - INFO - Main loop iteration: 8467
2025-04-25 13:49:42,051 - transformer_training - INFO - Main loop iteration: 8468
2025-04-25 13:49:42,453 - transformer_training - INFO - Main loop iteration: 8469
2025-04-25 13:49:42,914 - transformer_training - INFO - Main loop iteration: 8470
Iter 8470: loss 3.3651, lr 0.000930, 81855.85 tokens/sec
2025-04-25 13:49:43,365 - transformer_training - INFO - Main loop iteration: 8471
2025-04-25 13:49:43,863 - transformer_training - INFO - Main loop iteration: 8472
2025-04-25 13:49:44,264 - transformer_training - INFO - Main loop iteration: 8473
2025-04-25 13:49:44,725 - transformer_training - INFO - Main loop iteration: 8474
2025-04-25 13:49:45,176 - transformer_training - INFO - Main loop iteration: 8475
2025-04-25 13:49:45,675 - transformer_training - INFO - Main loop iteration: 8476
2025-04-25 13:49:46,076 - transformer_training - INFO - Main loop iteration: 8477
2025-04-25 13:49:46,537 - transformer_training - INFO - Main loop iteration: 8478
2025-04-25 13:49:46,988 - transformer_training - INFO - Main loop iteration: 8479
2025-04-25 13:49:47,486 - transformer_training - INFO - Main loop iteration: 8480
Iter 8480: loss 3.3267, lr 0.000930, 91976.43 tokens/sec
2025-04-25 13:49:47,888 - transformer_training - INFO - Main loop iteration: 8481
2025-04-25 13:49:48,349 - transformer_training - INFO - Main loop iteration: 8482
2025-04-25 13:49:48,799 - transformer_training - INFO - Main loop iteration: 8483
2025-04-25 13:49:49,298 - transformer_training - INFO - Main loop iteration: 8484
2025-04-25 13:49:49,699 - transformer_training - INFO - Main loop iteration: 8485
2025-04-25 13:49:50,160 - transformer_training - INFO - Main loop iteration: 8486
2025-04-25 13:49:50,611 - transformer_training - INFO - Main loop iteration: 8487
2025-04-25 13:49:51,110 - transformer_training - INFO - Main loop iteration: 8488
2025-04-25 13:49:51,511 - transformer_training - INFO - Main loop iteration: 8489
2025-04-25 13:49:51,972 - transformer_training - INFO - Main loop iteration: 8490
Iter 8490: loss 3.3984, lr 0.000930, 81876.61 tokens/sec
2025-04-25 13:49:52,423 - transformer_training - INFO - Main loop iteration: 8491
2025-04-25 13:49:52,922 - transformer_training - INFO - Main loop iteration: 8492
2025-04-25 13:49:53,323 - transformer_training - INFO - Main loop iteration: 8493
2025-04-25 13:49:53,784 - transformer_training - INFO - Main loop iteration: 8494
2025-04-25 13:49:54,235 - transformer_training - INFO - Main loop iteration: 8495
2025-04-25 13:49:54,734 - transformer_training - INFO - Main loop iteration: 8496
2025-04-25 13:49:55,135 - transformer_training - INFO - Main loop iteration: 8497
2025-04-25 13:49:55,596 - transformer_training - INFO - Main loop iteration: 8498
2025-04-25 13:49:56,047 - transformer_training - INFO - Main loop iteration: 8499
2025-04-25 13:49:56,545 - transformer_training - INFO - Main loop iteration: 8500
Iter 8500: loss 3.3783, lr 0.000930, 91998.49 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 8500: train loss 3.3038, val loss 3.2683
New best model saved with val loss: 3.2683
2025-04-25 13:50:16,431 - transformer_training - INFO - Main loop iteration: 8501
2025-04-25 13:50:16,843 - transformer_training - INFO - Main loop iteration: 8502
2025-04-25 13:50:17,293 - transformer_training - INFO - Main loop iteration: 8503
2025-04-25 13:50:17,792 - transformer_training - INFO - Main loop iteration: 8504
2025-04-25 13:50:18,193 - transformer_training - INFO - Main loop iteration: 8505
2025-04-25 13:50:18,653 - transformer_training - INFO - Main loop iteration: 8506
2025-04-25 13:50:19,103 - transformer_training - INFO - Main loop iteration: 8507
2025-04-25 13:50:19,602 - transformer_training - INFO - Main loop iteration: 8508
2025-04-25 13:50:20,083 - transformer_training - INFO - Main loop iteration: 8509
2025-04-25 13:50:20,495 - transformer_training - INFO - Main loop iteration: 8510
Iter 8510: loss 3.3829, lr 0.000929, 81990.63 tokens/sec
2025-04-25 13:50:20,945 - transformer_training - INFO - Main loop iteration: 8511
2025-04-25 13:50:21,444 - transformer_training - INFO - Main loop iteration: 8512
2025-04-25 13:50:21,844 - transformer_training - INFO - Main loop iteration: 8513
2025-04-25 13:50:22,306 - transformer_training - INFO - Main loop iteration: 8514
2025-04-25 13:50:22,756 - transformer_training - INFO - Main loop iteration: 8515
2025-04-25 13:50:23,255 - transformer_training - INFO - Main loop iteration: 8516
2025-04-25 13:50:23,656 - transformer_training - INFO - Main loop iteration: 8517
2025-04-25 13:50:24,116 - transformer_training - INFO - Main loop iteration: 8518
2025-04-25 13:50:24,566 - transformer_training - INFO - Main loop iteration: 8519
2025-04-25 13:50:25,067 - transformer_training - INFO - Main loop iteration: 8520
Iter 8520: loss 3.2877, lr 0.000929, 92077.49 tokens/sec
2025-04-25 13:50:25,468 - transformer_training - INFO - Main loop iteration: 8521
2025-04-25 13:50:25,929 - transformer_training - INFO - Main loop iteration: 8522
2025-04-25 13:50:26,380 - transformer_training - INFO - Main loop iteration: 8523
2025-04-25 13:50:26,879 - transformer_training - INFO - Main loop iteration: 8524
2025-04-25 13:50:27,281 - transformer_training - INFO - Main loop iteration: 8525
2025-04-25 13:50:27,742 - transformer_training - INFO - Main loop iteration: 8526
2025-04-25 13:50:28,192 - transformer_training - INFO - Main loop iteration: 8527
2025-04-25 13:50:28,691 - transformer_training - INFO - Main loop iteration: 8528
2025-04-25 13:50:29,093 - transformer_training - INFO - Main loop iteration: 8529
2025-04-25 13:50:29,554 - transformer_training - INFO - Main loop iteration: 8530
Iter 8530: loss 3.4011, lr 0.000929, 81911.62 tokens/sec
2025-04-25 13:50:30,004 - transformer_training - INFO - Main loop iteration: 8531
2025-04-25 13:50:30,503 - transformer_training - INFO - Main loop iteration: 8532
2025-04-25 13:50:30,904 - transformer_training - INFO - Main loop iteration: 8533
2025-04-25 13:50:31,366 - transformer_training - INFO - Main loop iteration: 8534
2025-04-25 13:50:31,816 - transformer_training - INFO - Main loop iteration: 8535
2025-04-25 13:50:32,315 - transformer_training - INFO - Main loop iteration: 8536
2025-04-25 13:50:32,717 - transformer_training - INFO - Main loop iteration: 8537
2025-04-25 13:50:33,178 - transformer_training - INFO - Main loop iteration: 8538
2025-04-25 13:50:33,628 - transformer_training - INFO - Main loop iteration: 8539
2025-04-25 13:50:34,128 - transformer_training - INFO - Main loop iteration: 8540
Iter 8540: loss 3.4047, lr 0.000929, 91967.52 tokens/sec
2025-04-25 13:50:34,529 - transformer_training - INFO - Main loop iteration: 8541
2025-04-25 13:50:34,990 - transformer_training - INFO - Main loop iteration: 8542
2025-04-25 13:50:35,441 - transformer_training - INFO - Main loop iteration: 8543
2025-04-25 13:50:35,940 - transformer_training - INFO - Main loop iteration: 8544
2025-04-25 13:50:36,341 - transformer_training - INFO - Main loop iteration: 8545
2025-04-25 13:50:36,802 - transformer_training - INFO - Main loop iteration: 8546
2025-04-25 13:50:37,253 - transformer_training - INFO - Main loop iteration: 8547
2025-04-25 13:50:37,752 - transformer_training - INFO - Main loop iteration: 8548
2025-04-25 13:50:38,153 - transformer_training - INFO - Main loop iteration: 8549
2025-04-25 13:50:38,614 - transformer_training - INFO - Main loop iteration: 8550
Iter 8550: loss 3.3845, lr 0.000929, 81922.42 tokens/sec
2025-04-25 13:50:39,064 - transformer_training - INFO - Main loop iteration: 8551
2025-04-25 13:50:39,562 - transformer_training - INFO - Main loop iteration: 8552
2025-04-25 13:50:39,964 - transformer_training - INFO - Main loop iteration: 8553
2025-04-25 13:50:40,425 - transformer_training - INFO - Main loop iteration: 8554
2025-04-25 13:50:40,875 - transformer_training - INFO - Main loop iteration: 8555
2025-04-25 13:50:41,374 - transformer_training - INFO - Main loop iteration: 8556
2025-04-25 13:50:41,775 - transformer_training - INFO - Main loop iteration: 8557
2025-04-25 13:50:42,236 - transformer_training - INFO - Main loop iteration: 8558
2025-04-25 13:50:42,687 - transformer_training - INFO - Main loop iteration: 8559
2025-04-25 13:50:43,186 - transformer_training - INFO - Main loop iteration: 8560
Iter 8560: loss 3.4532, lr 0.000928, 91871.45 tokens/sec
2025-04-25 13:50:43,588 - transformer_training - INFO - Main loop iteration: 8561
2025-04-25 13:50:44,049 - transformer_training - INFO - Main loop iteration: 8562
2025-04-25 13:50:44,499 - transformer_training - INFO - Main loop iteration: 8563
2025-04-25 13:50:44,998 - transformer_training - INFO - Main loop iteration: 8564
2025-04-25 13:50:45,399 - transformer_training - INFO - Main loop iteration: 8565
2025-04-25 13:50:45,860 - transformer_training - INFO - Main loop iteration: 8566
2025-04-25 13:50:46,311 - transformer_training - INFO - Main loop iteration: 8567
2025-04-25 13:50:46,809 - transformer_training - INFO - Main loop iteration: 8568
2025-04-25 13:50:47,211 - transformer_training - INFO - Main loop iteration: 8569
2025-04-25 13:50:47,672 - transformer_training - INFO - Main loop iteration: 8570
Iter 8570: loss 3.4316, lr 0.000928, 81856.33 tokens/sec
2025-04-25 13:50:48,123 - transformer_training - INFO - Main loop iteration: 8571
2025-04-25 13:50:48,621 - transformer_training - INFO - Main loop iteration: 8572
2025-04-25 13:50:49,023 - transformer_training - INFO - Main loop iteration: 8573
2025-04-25 13:50:49,484 - transformer_training - INFO - Main loop iteration: 8574
2025-04-25 13:50:49,934 - transformer_training - INFO - Main loop iteration: 8575
2025-04-25 13:50:50,433 - transformer_training - INFO - Main loop iteration: 8576
2025-04-25 13:50:50,834 - transformer_training - INFO - Main loop iteration: 8577
2025-04-25 13:50:51,296 - transformer_training - INFO - Main loop iteration: 8578
2025-04-25 13:50:51,746 - transformer_training - INFO - Main loop iteration: 8579
2025-04-25 13:50:52,245 - transformer_training - INFO - Main loop iteration: 8580
Iter 8580: loss 3.3235, lr 0.000928, 91903.01 tokens/sec
2025-04-25 13:50:52,646 - transformer_training - INFO - Main loop iteration: 8581
2025-04-25 13:50:53,107 - transformer_training - INFO - Main loop iteration: 8582
2025-04-25 13:50:53,558 - transformer_training - INFO - Main loop iteration: 8583
2025-04-25 13:50:54,057 - transformer_training - INFO - Main loop iteration: 8584
2025-04-25 13:50:54,458 - transformer_training - INFO - Main loop iteration: 8585
2025-04-25 13:50:54,920 - transformer_training - INFO - Main loop iteration: 8586
2025-04-25 13:50:55,370 - transformer_training - INFO - Main loop iteration: 8587
2025-04-25 13:50:55,868 - transformer_training - INFO - Main loop iteration: 8588
2025-04-25 13:50:56,270 - transformer_training - INFO - Main loop iteration: 8589
2025-04-25 13:50:56,731 - transformer_training - INFO - Main loop iteration: 8590
Iter 8590: loss 3.4341, lr 0.000928, 81881.51 tokens/sec
2025-04-25 13:50:57,181 - transformer_training - INFO - Main loop iteration: 8591
2025-04-25 13:50:57,679 - transformer_training - INFO - Main loop iteration: 8592
2025-04-25 13:50:58,080 - transformer_training - INFO - Main loop iteration: 8593
2025-04-25 13:50:58,542 - transformer_training - INFO - Main loop iteration: 8594
2025-04-25 13:50:58,993 - transformer_training - INFO - Main loop iteration: 8595
2025-04-25 13:50:59,491 - transformer_training - INFO - Main loop iteration: 8596
2025-04-25 13:50:59,893 - transformer_training - INFO - Main loop iteration: 8597
2025-04-25 13:51:00,354 - transformer_training - INFO - Main loop iteration: 8598
2025-04-25 13:51:00,804 - transformer_training - INFO - Main loop iteration: 8599
2025-04-25 13:51:01,304 - transformer_training - INFO - Main loop iteration: 8600
Iter 8600: loss 3.3330, lr 0.000927, 91911.86 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 8600: train loss 3.2987, val loss 3.2600
New best model saved with val loss: 3.2600
2025-04-25 13:51:20,060 - transformer_training - INFO - Main loop iteration: 8601
2025-04-25 13:51:20,469 - transformer_training - INFO - Main loop iteration: 8602
2025-04-25 13:51:20,919 - transformer_training - INFO - Main loop iteration: 8603
2025-04-25 13:51:21,417 - transformer_training - INFO - Main loop iteration: 8604
2025-04-25 13:51:21,818 - transformer_training - INFO - Main loop iteration: 8605
2025-04-25 13:51:22,279 - transformer_training - INFO - Main loop iteration: 8606
2025-04-25 13:51:22,728 - transformer_training - INFO - Main loop iteration: 8607
2025-04-25 13:51:23,227 - transformer_training - INFO - Main loop iteration: 8608
2025-04-25 13:51:23,627 - transformer_training - INFO - Main loop iteration: 8609
2025-04-25 13:51:24,088 - transformer_training - INFO - Main loop iteration: 8610
Iter 8610: loss 3.2944, lr 0.000927, 81973.80 tokens/sec
2025-04-25 13:51:24,538 - transformer_training - INFO - Main loop iteration: 8611
2025-04-25 13:51:25,037 - transformer_training - INFO - Main loop iteration: 8612
2025-04-25 13:51:25,437 - transformer_training - INFO - Main loop iteration: 8613
2025-04-25 13:51:25,898 - transformer_training - INFO - Main loop iteration: 8614
2025-04-25 13:51:26,348 - transformer_training - INFO - Main loop iteration: 8615
2025-04-25 13:51:26,846 - transformer_training - INFO - Main loop iteration: 8616
2025-04-25 13:51:27,247 - transformer_training - INFO - Main loop iteration: 8617
2025-04-25 13:51:27,708 - transformer_training - INFO - Main loop iteration: 8618
2025-04-25 13:51:28,158 - transformer_training - INFO - Main loop iteration: 8619
2025-04-25 13:51:28,656 - transformer_training - INFO - Main loop iteration: 8620
Iter 8620: loss 3.3157, lr 0.000927, 92002.54 tokens/sec
2025-04-25 13:51:29,057 - transformer_training - INFO - Main loop iteration: 8621
2025-04-25 13:51:29,519 - transformer_training - INFO - Main loop iteration: 8622
2025-04-25 13:51:29,969 - transformer_training - INFO - Main loop iteration: 8623
2025-04-25 13:51:30,468 - transformer_training - INFO - Main loop iteration: 8624
2025-04-25 13:51:30,868 - transformer_training - INFO - Main loop iteration: 8625
2025-04-25 13:51:31,329 - transformer_training - INFO - Main loop iteration: 8626
2025-04-25 13:51:31,779 - transformer_training - INFO - Main loop iteration: 8627
2025-04-25 13:51:32,278 - transformer_training - INFO - Main loop iteration: 8628
2025-04-25 13:51:32,679 - transformer_training - INFO - Main loop iteration: 8629
2025-04-25 13:51:33,140 - transformer_training - INFO - Main loop iteration: 8630
Iter 8630: loss 3.3963, lr 0.000927, 81901.59 tokens/sec
2025-04-25 13:51:33,591 - transformer_training - INFO - Main loop iteration: 8631
2025-04-25 13:51:34,089 - transformer_training - INFO - Main loop iteration: 8632
2025-04-25 13:51:34,490 - transformer_training - INFO - Main loop iteration: 8633
2025-04-25 13:51:34,951 - transformer_training - INFO - Main loop iteration: 8634
2025-04-25 13:51:35,401 - transformer_training - INFO - Main loop iteration: 8635
2025-04-25 13:51:35,901 - transformer_training - INFO - Main loop iteration: 8636
2025-04-25 13:51:36,302 - transformer_training - INFO - Main loop iteration: 8637
2025-04-25 13:51:36,762 - transformer_training - INFO - Main loop iteration: 8638
2025-04-25 13:51:37,213 - transformer_training - INFO - Main loop iteration: 8639
2025-04-25 13:51:37,712 - transformer_training - INFO - Main loop iteration: 8640
Iter 8640: loss 3.3584, lr 0.000927, 92056.16 tokens/sec
2025-04-25 13:51:38,113 - transformer_training - INFO - Main loop iteration: 8641
2025-04-25 13:51:38,574 - transformer_training - INFO - Main loop iteration: 8642
2025-04-25 13:51:39,024 - transformer_training - INFO - Main loop iteration: 8643
2025-04-25 13:51:39,524 - transformer_training - INFO - Main loop iteration: 8644
2025-04-25 13:51:39,925 - transformer_training - INFO - Main loop iteration: 8645
2025-04-25 13:51:40,386 - transformer_training - INFO - Main loop iteration: 8646
2025-04-25 13:51:40,836 - transformer_training - INFO - Main loop iteration: 8647
2025-04-25 13:51:41,334 - transformer_training - INFO - Main loop iteration: 8648
2025-04-25 13:51:41,735 - transformer_training - INFO - Main loop iteration: 8649
2025-04-25 13:51:42,196 - transformer_training - INFO - Main loop iteration: 8650
Iter 8650: loss 3.3916, lr 0.000926, 81888.80 tokens/sec
2025-04-25 13:51:42,647 - transformer_training - INFO - Main loop iteration: 8651
2025-04-25 13:51:43,146 - transformer_training - INFO - Main loop iteration: 8652
2025-04-25 13:51:43,546 - transformer_training - INFO - Main loop iteration: 8653
2025-04-25 13:51:44,007 - transformer_training - INFO - Main loop iteration: 8654
2025-04-25 13:51:44,458 - transformer_training - INFO - Main loop iteration: 8655
2025-04-25 13:51:44,956 - transformer_training - INFO - Main loop iteration: 8656
2025-04-25 13:51:45,357 - transformer_training - INFO - Main loop iteration: 8657
2025-04-25 13:51:45,818 - transformer_training - INFO - Main loop iteration: 8658
2025-04-25 13:51:46,269 - transformer_training - INFO - Main loop iteration: 8659
2025-04-25 13:51:46,768 - transformer_training - INFO - Main loop iteration: 8660
Iter 8660: loss 3.3412, lr 0.000926, 92052.44 tokens/sec
2025-04-25 13:51:47,169 - transformer_training - INFO - Main loop iteration: 8661
2025-04-25 13:51:47,630 - transformer_training - INFO - Main loop iteration: 8662
2025-04-25 13:51:48,080 - transformer_training - INFO - Main loop iteration: 8663
2025-04-25 13:51:48,579 - transformer_training - INFO - Main loop iteration: 8664
2025-04-25 13:51:48,979 - transformer_training - INFO - Main loop iteration: 8665
2025-04-25 13:51:49,440 - transformer_training - INFO - Main loop iteration: 8666
2025-04-25 13:51:49,891 - transformer_training - INFO - Main loop iteration: 8667
2025-04-25 13:51:50,390 - transformer_training - INFO - Main loop iteration: 8668
2025-04-25 13:51:50,791 - transformer_training - INFO - Main loop iteration: 8669
2025-04-25 13:51:51,251 - transformer_training - INFO - Main loop iteration: 8670
Iter 8670: loss 3.4294, lr 0.000926, 81922.90 tokens/sec
2025-04-25 13:51:51,702 - transformer_training - INFO - Main loop iteration: 8671
2025-04-25 13:51:52,201 - transformer_training - INFO - Main loop iteration: 8672
2025-04-25 13:51:52,602 - transformer_training - INFO - Main loop iteration: 8673
2025-04-25 13:51:53,063 - transformer_training - INFO - Main loop iteration: 8674
2025-04-25 13:51:53,513 - transformer_training - INFO - Main loop iteration: 8675
2025-04-25 13:51:54,012 - transformer_training - INFO - Main loop iteration: 8676
2025-04-25 13:51:54,413 - transformer_training - INFO - Main loop iteration: 8677
2025-04-25 13:51:54,874 - transformer_training - INFO - Main loop iteration: 8678
2025-04-25 13:51:55,324 - transformer_training - INFO - Main loop iteration: 8679
2025-04-25 13:51:55,823 - transformer_training - INFO - Main loop iteration: 8680
Iter 8680: loss 3.2887, lr 0.000926, 92044.71 tokens/sec
2025-04-25 13:51:56,224 - transformer_training - INFO - Main loop iteration: 8681
2025-04-25 13:51:56,685 - transformer_training - INFO - Main loop iteration: 8682
2025-04-25 13:51:57,135 - transformer_training - INFO - Main loop iteration: 8683
2025-04-25 13:51:57,634 - transformer_training - INFO - Main loop iteration: 8684
2025-04-25 13:51:58,035 - transformer_training - INFO - Main loop iteration: 8685
2025-04-25 13:51:58,496 - transformer_training - INFO - Main loop iteration: 8686
2025-04-25 13:51:58,946 - transformer_training - INFO - Main loop iteration: 8687
2025-04-25 13:51:59,445 - transformer_training - INFO - Main loop iteration: 8688
2025-04-25 13:51:59,846 - transformer_training - INFO - Main loop iteration: 8689
2025-04-25 13:52:00,307 - transformer_training - INFO - Main loop iteration: 8690
Iter 8690: loss 3.3939, lr 0.000926, 81936.49 tokens/sec
2025-04-25 13:52:00,757 - transformer_training - INFO - Main loop iteration: 8691
2025-04-25 13:52:01,256 - transformer_training - INFO - Main loop iteration: 8692
2025-04-25 13:52:01,657 - transformer_training - INFO - Main loop iteration: 8693
2025-04-25 13:52:02,118 - transformer_training - INFO - Main loop iteration: 8694
2025-04-25 13:52:02,569 - transformer_training - INFO - Main loop iteration: 8695
2025-04-25 13:52:03,166 - transformer_training - INFO - Main loop iteration: 8696
2025-04-25 13:52:03,567 - transformer_training - INFO - Main loop iteration: 8697
2025-04-25 13:52:04,028 - transformer_training - INFO - Main loop iteration: 8698
2025-04-25 13:52:04,478 - transformer_training - INFO - Main loop iteration: 8699
2025-04-25 13:52:04,977 - transformer_training - INFO - Main loop iteration: 8700
Iter 8700: loss 3.3641, lr 0.000925, 92018.69 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 8700: train loss 3.2998, val loss 3.2573
New best model saved with val loss: 3.2573
2025-04-25 13:52:23,233 - transformer_training - INFO - Main loop iteration: 8701
2025-04-25 13:52:23,647 - transformer_training - INFO - Main loop iteration: 8702
2025-04-25 13:52:24,097 - transformer_training - INFO - Main loop iteration: 8703
2025-04-25 13:52:24,595 - transformer_training - INFO - Main loop iteration: 8704
2025-04-25 13:52:24,995 - transformer_training - INFO - Main loop iteration: 8705
2025-04-25 13:52:25,456 - transformer_training - INFO - Main loop iteration: 8706
2025-04-25 13:52:25,907 - transformer_training - INFO - Main loop iteration: 8707
2025-04-25 13:52:26,405 - transformer_training - INFO - Main loop iteration: 8708
2025-04-25 13:52:26,806 - transformer_training - INFO - Main loop iteration: 8709
2025-04-25 13:52:27,266 - transformer_training - INFO - Main loop iteration: 8710
Iter 8710: loss 3.3265, lr 0.000925, 81898.08 tokens/sec
2025-04-25 13:52:27,717 - transformer_training - INFO - Main loop iteration: 8711
2025-04-25 13:52:28,215 - transformer_training - INFO - Main loop iteration: 8712
2025-04-25 13:52:28,616 - transformer_training - INFO - Main loop iteration: 8713
2025-04-25 13:52:29,076 - transformer_training - INFO - Main loop iteration: 8714
2025-04-25 13:52:29,527 - transformer_training - INFO - Main loop iteration: 8715
2025-04-25 13:52:30,025 - transformer_training - INFO - Main loop iteration: 8716
2025-04-25 13:52:30,427 - transformer_training - INFO - Main loop iteration: 8717
2025-04-25 13:52:30,887 - transformer_training - INFO - Main loop iteration: 8718
2025-04-25 13:52:31,337 - transformer_training - INFO - Main loop iteration: 8719
2025-04-25 13:52:31,835 - transformer_training - INFO - Main loop iteration: 8720
Iter 8720: loss 3.3288, lr 0.000925, 91879.37 tokens/sec
2025-04-25 13:52:32,237 - transformer_training - INFO - Main loop iteration: 8721
2025-04-25 13:52:32,698 - transformer_training - INFO - Main loop iteration: 8722
2025-04-25 13:52:33,148 - transformer_training - INFO - Main loop iteration: 8723
2025-04-25 13:52:33,647 - transformer_training - INFO - Main loop iteration: 8724
2025-04-25 13:52:34,047 - transformer_training - INFO - Main loop iteration: 8725
2025-04-25 13:52:34,508 - transformer_training - INFO - Main loop iteration: 8726
2025-04-25 13:52:34,958 - transformer_training - INFO - Main loop iteration: 8727
2025-04-25 13:52:35,457 - transformer_training - INFO - Main loop iteration: 8728
2025-04-25 13:52:35,858 - transformer_training - INFO - Main loop iteration: 8729
2025-04-25 13:52:36,319 - transformer_training - INFO - Main loop iteration: 8730
Iter 8730: loss 3.4186, lr 0.000925, 81917.60 tokens/sec
2025-04-25 13:52:36,769 - transformer_training - INFO - Main loop iteration: 8731
2025-04-25 13:52:37,268 - transformer_training - INFO - Main loop iteration: 8732
2025-04-25 13:52:37,668 - transformer_training - INFO - Main loop iteration: 8733
2025-04-25 13:52:38,129 - transformer_training - INFO - Main loop iteration: 8734
2025-04-25 13:52:38,580 - transformer_training - INFO - Main loop iteration: 8735
2025-04-25 13:52:39,078 - transformer_training - INFO - Main loop iteration: 8736
2025-04-25 13:52:39,479 - transformer_training - INFO - Main loop iteration: 8737
2025-04-25 13:52:39,940 - transformer_training - INFO - Main loop iteration: 8738
2025-04-25 13:52:40,390 - transformer_training - INFO - Main loop iteration: 8739
2025-04-25 13:52:40,889 - transformer_training - INFO - Main loop iteration: 8740
Iter 8740: loss 3.3508, lr 0.000924, 92016.39 tokens/sec
2025-04-25 13:52:41,290 - transformer_training - INFO - Main loop iteration: 8741
2025-04-25 13:52:41,751 - transformer_training - INFO - Main loop iteration: 8742
2025-04-25 13:52:42,201 - transformer_training - INFO - Main loop iteration: 8743
2025-04-25 13:52:42,701 - transformer_training - INFO - Main loop iteration: 8744
2025-04-25 13:52:43,102 - transformer_training - INFO - Main loop iteration: 8745
2025-04-25 13:52:43,563 - transformer_training - INFO - Main loop iteration: 8746
2025-04-25 13:52:44,013 - transformer_training - INFO - Main loop iteration: 8747
2025-04-25 13:52:44,512 - transformer_training - INFO - Main loop iteration: 8748
2025-04-25 13:52:44,912 - transformer_training - INFO - Main loop iteration: 8749
2025-04-25 13:52:45,373 - transformer_training - INFO - Main loop iteration: 8750
Iter 8750: loss 3.4527, lr 0.000924, 81924.16 tokens/sec
2025-04-25 13:52:45,823 - transformer_training - INFO - Main loop iteration: 8751
2025-04-25 13:52:46,322 - transformer_training - INFO - Main loop iteration: 8752
2025-04-25 13:52:46,723 - transformer_training - INFO - Main loop iteration: 8753
2025-04-25 13:52:47,183 - transformer_training - INFO - Main loop iteration: 8754
2025-04-25 13:52:47,634 - transformer_training - INFO - Main loop iteration: 8755
2025-04-25 13:52:48,133 - transformer_training - INFO - Main loop iteration: 8756
2025-04-25 13:52:48,534 - transformer_training - INFO - Main loop iteration: 8757
2025-04-25 13:52:48,994 - transformer_training - INFO - Main loop iteration: 8758
2025-04-25 13:52:49,444 - transformer_training - INFO - Main loop iteration: 8759
2025-04-25 13:52:49,943 - transformer_training - INFO - Main loop iteration: 8760
Iter 8760: loss 3.3840, lr 0.000924, 92041.15 tokens/sec
2025-04-25 13:52:50,344 - transformer_training - INFO - Main loop iteration: 8761
2025-04-25 13:52:50,805 - transformer_training - INFO - Main loop iteration: 8762
2025-04-25 13:52:51,256 - transformer_training - INFO - Main loop iteration: 8763
2025-04-25 13:52:51,754 - transformer_training - INFO - Main loop iteration: 8764
2025-04-25 13:52:52,155 - transformer_training - INFO - Main loop iteration: 8765
2025-04-25 13:52:52,616 - transformer_training - INFO - Main loop iteration: 8766
2025-04-25 13:52:53,066 - transformer_training - INFO - Main loop iteration: 8767
2025-04-25 13:52:53,565 - transformer_training - INFO - Main loop iteration: 8768
2025-04-25 13:52:53,966 - transformer_training - INFO - Main loop iteration: 8769
2025-04-25 13:52:54,427 - transformer_training - INFO - Main loop iteration: 8770
Iter 8770: loss 3.2395, lr 0.000924, 81950.86 tokens/sec
2025-04-25 13:52:54,877 - transformer_training - INFO - Main loop iteration: 8771
2025-04-25 13:52:55,375 - transformer_training - INFO - Main loop iteration: 8772
2025-04-25 13:52:55,776 - transformer_training - INFO - Main loop iteration: 8773
2025-04-25 13:52:56,237 - transformer_training - INFO - Main loop iteration: 8774
2025-04-25 13:52:56,688 - transformer_training - INFO - Main loop iteration: 8775
2025-04-25 13:52:57,186 - transformer_training - INFO - Main loop iteration: 8776
2025-04-25 13:52:57,587 - transformer_training - INFO - Main loop iteration: 8777
2025-04-25 13:52:58,048 - transformer_training - INFO - Main loop iteration: 8778
2025-04-25 13:52:58,499 - transformer_training - INFO - Main loop iteration: 8779
2025-04-25 13:52:58,997 - transformer_training - INFO - Main loop iteration: 8780
Iter 8780: loss 3.4396, lr 0.000924, 92050.52 tokens/sec
2025-04-25 13:52:59,398 - transformer_training - INFO - Main loop iteration: 8781
2025-04-25 13:52:59,859 - transformer_training - INFO - Main loop iteration: 8782
2025-04-25 13:53:00,309 - transformer_training - INFO - Main loop iteration: 8783
2025-04-25 13:53:00,808 - transformer_training - INFO - Main loop iteration: 8784
2025-04-25 13:53:01,209 - transformer_training - INFO - Main loop iteration: 8785
2025-04-25 13:53:01,669 - transformer_training - INFO - Main loop iteration: 8786
2025-04-25 13:53:02,120 - transformer_training - INFO - Main loop iteration: 8787
2025-04-25 13:53:02,619 - transformer_training - INFO - Main loop iteration: 8788
2025-04-25 13:53:03,019 - transformer_training - INFO - Main loop iteration: 8789
2025-04-25 13:53:03,480 - transformer_training - INFO - Main loop iteration: 8790
Iter 8790: loss 3.3172, lr 0.000923, 81886.98 tokens/sec
2025-04-25 13:53:03,931 - transformer_training - INFO - Main loop iteration: 8791
2025-04-25 13:53:04,429 - transformer_training - INFO - Main loop iteration: 8792
2025-04-25 13:53:04,830 - transformer_training - INFO - Main loop iteration: 8793
2025-04-25 13:53:05,290 - transformer_training - INFO - Main loop iteration: 8794
2025-04-25 13:53:05,741 - transformer_training - INFO - Main loop iteration: 8795
2025-04-25 13:53:06,240 - transformer_training - INFO - Main loop iteration: 8796
2025-04-25 13:53:06,641 - transformer_training - INFO - Main loop iteration: 8797
2025-04-25 13:53:07,102 - transformer_training - INFO - Main loop iteration: 8798
2025-04-25 13:53:07,552 - transformer_training - INFO - Main loop iteration: 8799
2025-04-25 13:53:08,051 - transformer_training - INFO - Main loop iteration: 8800
Iter 8800: loss 3.3044, lr 0.000923, 91961.72 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 8800: train loss 3.2940, val loss 3.2521
New best model saved with val loss: 3.2521
2025-04-25 13:53:25,545 - transformer_training - INFO - Main loop iteration: 8801
2025-04-25 13:53:25,958 - transformer_training - INFO - Main loop iteration: 8802
2025-04-25 13:53:26,408 - transformer_training - INFO - Main loop iteration: 8803
2025-04-25 13:53:26,907 - transformer_training - INFO - Main loop iteration: 8804
2025-04-25 13:53:27,307 - transformer_training - INFO - Main loop iteration: 8805
2025-04-25 13:53:27,768 - transformer_training - INFO - Main loop iteration: 8806
2025-04-25 13:53:28,218 - transformer_training - INFO - Main loop iteration: 8807
2025-04-25 13:53:28,717 - transformer_training - INFO - Main loop iteration: 8808
2025-04-25 13:53:29,118 - transformer_training - INFO - Main loop iteration: 8809
2025-04-25 13:53:29,578 - transformer_training - INFO - Main loop iteration: 8810
Iter 8810: loss 3.3770, lr 0.000923, 82006.11 tokens/sec
2025-04-25 13:53:30,028 - transformer_training - INFO - Main loop iteration: 8811
2025-04-25 13:53:30,527 - transformer_training - INFO - Main loop iteration: 8812
2025-04-25 13:53:30,927 - transformer_training - INFO - Main loop iteration: 8813
2025-04-25 13:53:31,387 - transformer_training - INFO - Main loop iteration: 8814
2025-04-25 13:53:31,838 - transformer_training - INFO - Main loop iteration: 8815
2025-04-25 13:53:32,337 - transformer_training - INFO - Main loop iteration: 8816
2025-04-25 13:53:32,738 - transformer_training - INFO - Main loop iteration: 8817
2025-04-25 13:53:33,199 - transformer_training - INFO - Main loop iteration: 8818
2025-04-25 13:53:33,649 - transformer_training - INFO - Main loop iteration: 8819
2025-04-25 13:53:34,148 - transformer_training - INFO - Main loop iteration: 8820
Iter 8820: loss 3.3080, lr 0.000923, 92013.27 tokens/sec
2025-04-25 13:53:34,549 - transformer_training - INFO - Main loop iteration: 8821
2025-04-25 13:53:35,010 - transformer_training - INFO - Main loop iteration: 8822
2025-04-25 13:53:35,460 - transformer_training - INFO - Main loop iteration: 8823
2025-04-25 13:53:35,960 - transformer_training - INFO - Main loop iteration: 8824
2025-04-25 13:53:36,360 - transformer_training - INFO - Main loop iteration: 8825
2025-04-25 13:53:36,821 - transformer_training - INFO - Main loop iteration: 8826
2025-04-25 13:53:37,272 - transformer_training - INFO - Main loop iteration: 8827
2025-04-25 13:53:37,770 - transformer_training - INFO - Main loop iteration: 8828
2025-04-25 13:53:38,172 - transformer_training - INFO - Main loop iteration: 8829
2025-04-25 13:53:38,633 - transformer_training - INFO - Main loop iteration: 8830
Iter 8830: loss 3.4183, lr 0.000923, 81904.33 tokens/sec
2025-04-25 13:53:39,084 - transformer_training - INFO - Main loop iteration: 8831
2025-04-25 13:53:39,582 - transformer_training - INFO - Main loop iteration: 8832
2025-04-25 13:53:39,983 - transformer_training - INFO - Main loop iteration: 8833
2025-04-25 13:53:40,444 - transformer_training - INFO - Main loop iteration: 8834
2025-04-25 13:53:40,895 - transformer_training - INFO - Main loop iteration: 8835
2025-04-25 13:53:41,394 - transformer_training - INFO - Main loop iteration: 8836
2025-04-25 13:53:41,795 - transformer_training - INFO - Main loop iteration: 8837
2025-04-25 13:53:42,256 - transformer_training - INFO - Main loop iteration: 8838
2025-04-25 13:53:42,706 - transformer_training - INFO - Main loop iteration: 8839
2025-04-25 13:53:43,205 - transformer_training - INFO - Main loop iteration: 8840
Iter 8840: loss 3.3809, lr 0.000922, 91932.03 tokens/sec
2025-04-25 13:53:43,606 - transformer_training - INFO - Main loop iteration: 8841
2025-04-25 13:53:44,068 - transformer_training - INFO - Main loop iteration: 8842
2025-04-25 13:53:44,518 - transformer_training - INFO - Main loop iteration: 8843
2025-04-25 13:53:45,017 - transformer_training - INFO - Main loop iteration: 8844
2025-04-25 13:53:45,418 - transformer_training - INFO - Main loop iteration: 8845
2025-04-25 13:53:45,879 - transformer_training - INFO - Main loop iteration: 8846
2025-04-25 13:53:46,329 - transformer_training - INFO - Main loop iteration: 8847
2025-04-25 13:53:46,828 - transformer_training - INFO - Main loop iteration: 8848
2025-04-25 13:53:47,229 - transformer_training - INFO - Main loop iteration: 8849
2025-04-25 13:53:47,690 - transformer_training - INFO - Main loop iteration: 8850
Iter 8850: loss 3.2970, lr 0.000922, 81822.06 tokens/sec
2025-04-25 13:53:48,142 - transformer_training - INFO - Main loop iteration: 8851
2025-04-25 13:53:48,640 - transformer_training - INFO - Main loop iteration: 8852
2025-04-25 13:53:49,041 - transformer_training - INFO - Main loop iteration: 8853
2025-04-25 13:53:49,502 - transformer_training - INFO - Main loop iteration: 8854
2025-04-25 13:53:49,952 - transformer_training - INFO - Main loop iteration: 8855
2025-04-25 13:53:50,451 - transformer_training - INFO - Main loop iteration: 8856
2025-04-25 13:53:50,852 - transformer_training - INFO - Main loop iteration: 8857
2025-04-25 13:53:51,313 - transformer_training - INFO - Main loop iteration: 8858
2025-04-25 13:53:51,763 - transformer_training - INFO - Main loop iteration: 8859
2025-04-25 13:53:52,263 - transformer_training - INFO - Main loop iteration: 8860
Iter 8860: loss 3.4431, lr 0.000922, 92043.45 tokens/sec
2025-04-25 13:53:52,663 - transformer_training - INFO - Main loop iteration: 8861
2025-04-25 13:53:53,124 - transformer_training - INFO - Main loop iteration: 8862
2025-04-25 13:53:53,574 - transformer_training - INFO - Main loop iteration: 8863
2025-04-25 13:53:54,073 - transformer_training - INFO - Main loop iteration: 8864
2025-04-25 13:53:54,474 - transformer_training - INFO - Main loop iteration: 8865
2025-04-25 13:53:54,935 - transformer_training - INFO - Main loop iteration: 8866
2025-04-25 13:53:55,385 - transformer_training - INFO - Main loop iteration: 8867
2025-04-25 13:53:55,884 - transformer_training - INFO - Main loop iteration: 8868
2025-04-25 13:53:56,285 - transformer_training - INFO - Main loop iteration: 8869
2025-04-25 13:53:56,746 - transformer_training - INFO - Main loop iteration: 8870
Iter 8870: loss 3.2880, lr 0.000922, 81830.77 tokens/sec
2025-04-25 13:53:57,197 - transformer_training - INFO - Main loop iteration: 8871
2025-04-25 13:53:57,696 - transformer_training - INFO - Main loop iteration: 8872
2025-04-25 13:53:58,097 - transformer_training - INFO - Main loop iteration: 8873
2025-04-25 13:53:58,558 - transformer_training - INFO - Main loop iteration: 8874
2025-04-25 13:53:59,008 - transformer_training - INFO - Main loop iteration: 8875
2025-04-25 13:53:59,507 - transformer_training - INFO - Main loop iteration: 8876
2025-04-25 13:53:59,908 - transformer_training - INFO - Main loop iteration: 8877
2025-04-25 13:54:00,370 - transformer_training - INFO - Main loop iteration: 8878
2025-04-25 13:54:00,820 - transformer_training - INFO - Main loop iteration: 8879
2025-04-25 13:54:01,319 - transformer_training - INFO - Main loop iteration: 8880
Iter 8880: loss 3.3434, lr 0.000921, 91984.64 tokens/sec
2025-04-25 13:54:01,720 - transformer_training - INFO - Main loop iteration: 8881
2025-04-25 13:54:02,181 - transformer_training - INFO - Main loop iteration: 8882
2025-04-25 13:54:02,631 - transformer_training - INFO - Main loop iteration: 8883
2025-04-25 13:54:03,131 - transformer_training - INFO - Main loop iteration: 8884
2025-04-25 13:54:03,532 - transformer_training - INFO - Main loop iteration: 8885
2025-04-25 13:54:03,993 - transformer_training - INFO - Main loop iteration: 8886
2025-04-25 13:54:04,444 - transformer_training - INFO - Main loop iteration: 8887
2025-04-25 13:54:04,942 - transformer_training - INFO - Main loop iteration: 8888
2025-04-25 13:54:05,343 - transformer_training - INFO - Main loop iteration: 8889
2025-04-25 13:54:05,804 - transformer_training - INFO - Main loop iteration: 8890
Iter 8890: loss 3.3515, lr 0.000921, 81930.50 tokens/sec
2025-04-25 13:54:06,255 - transformer_training - INFO - Main loop iteration: 8891
2025-04-25 13:54:06,755 - transformer_training - INFO - Main loop iteration: 8892
2025-04-25 13:54:07,155 - transformer_training - INFO - Main loop iteration: 8893
2025-04-25 13:54:07,616 - transformer_training - INFO - Main loop iteration: 8894
2025-04-25 13:54:08,067 - transformer_training - INFO - Main loop iteration: 8895
2025-04-25 13:54:08,566 - transformer_training - INFO - Main loop iteration: 8896
2025-04-25 13:54:08,966 - transformer_training - INFO - Main loop iteration: 8897
2025-04-25 13:54:09,427 - transformer_training - INFO - Main loop iteration: 8898
2025-04-25 13:54:09,878 - transformer_training - INFO - Main loop iteration: 8899
2025-04-25 13:54:10,377 - transformer_training - INFO - Main loop iteration: 8900
Iter 8900: loss 3.3004, lr 0.000921, 92023.62 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Iter 8900: train loss 3.2972, val loss 3.2480
New best model saved with val loss: 3.2480
2025-04-25 13:54:28,184 - transformer_training - INFO - Main loop iteration: 8901
2025-04-25 13:54:28,599 - transformer_training - INFO - Main loop iteration: 8902
2025-04-25 13:54:29,048 - transformer_training - INFO - Main loop iteration: 8903
2025-04-25 13:54:29,547 - transformer_training - INFO - Main loop iteration: 8904
2025-04-25 13:54:29,947 - transformer_training - INFO - Main loop iteration: 8905
2025-04-25 13:54:30,408 - transformer_training - INFO - Main loop iteration: 8906
2025-04-25 13:54:30,858 - transformer_training - INFO - Main loop iteration: 8907
2025-04-25 13:54:31,356 - transformer_training - INFO - Main loop iteration: 8908
2025-04-25 13:54:31,756 - transformer_training - INFO - Main loop iteration: 8909
2025-04-25 13:54:32,217 - transformer_training - INFO - Main loop iteration: 8910
Iter 8910: loss 3.2981, lr 0.000921, 81896.65 tokens/sec
2025-04-25 13:54:32,668 - transformer_training - INFO - Main loop iteration: 8911
2025-04-25 13:54:33,166 - transformer_training - INFO - Main loop iteration: 8912
2025-04-25 13:54:33,567 - transformer_training - INFO - Main loop iteration: 8913
2025-04-25 13:54:34,027 - transformer_training - INFO - Main loop iteration: 8914
2025-04-25 13:54:34,478 - transformer_training - INFO - Main loop iteration: 8915
2025-04-25 13:54:34,976 - transformer_training - INFO - Main loop iteration: 8916
2025-04-25 13:54:35,377 - transformer_training - INFO - Main loop iteration: 8917
2025-04-25 13:54:35,837 - transformer_training - INFO - Main loop iteration: 8918
2025-04-25 13:54:36,287 - transformer_training - INFO - Main loop iteration: 8919
2025-04-25 13:54:36,786 - transformer_training - INFO - Main loop iteration: 8920
Iter 8920: loss 3.3899, lr 0.000920, 92040.71 tokens/sec
2025-04-25 13:54:37,187 - transformer_training - INFO - Main loop iteration: 8921
2025-04-25 13:54:37,647 - transformer_training - INFO - Main loop iteration: 8922
2025-04-25 13:54:38,097 - transformer_training - INFO - Main loop iteration: 8923
2025-04-25 13:54:38,596 - transformer_training - INFO - Main loop iteration: 8924
2025-04-25 13:54:38,997 - transformer_training - INFO - Main loop iteration: 8925
2025-04-25 13:54:39,458 - transformer_training - INFO - Main loop iteration: 8926
2025-04-25 13:54:39,908 - transformer_training - INFO - Main loop iteration: 8927
2025-04-25 13:54:40,407 - transformer_training - INFO - Main loop iteration: 8928
2025-04-25 13:54:40,808 - transformer_training - INFO - Main loop iteration: 8929
2025-04-25 13:54:41,269 - transformer_training - INFO - Main loop iteration: 8930
Iter 8930: loss 3.3661, lr 0.000920, 81973.89 tokens/sec
2025-04-25 13:54:41,719 - transformer_training - INFO - Main loop iteration: 8931
2025-04-25 13:54:42,218 - transformer_training - INFO - Main loop iteration: 8932
2025-04-25 13:54:42,620 - transformer_training - INFO - Main loop iteration: 8933
2025-04-25 13:54:43,081 - transformer_training - INFO - Main loop iteration: 8934
2025-04-25 13:54:43,531 - transformer_training - INFO - Main loop iteration: 8935
2025-04-25 13:54:44,029 - transformer_training - INFO - Main loop iteration: 8936
2025-04-25 13:54:44,430 - transformer_training - INFO - Main loop iteration: 8937
2025-04-25 13:54:44,891 - transformer_training - INFO - Main loop iteration: 8938
2025-04-25 13:54:45,341 - transformer_training - INFO - Main loop iteration: 8939
2025-04-25 13:54:45,840 - transformer_training - INFO - Main loop iteration: 8940
Iter 8940: loss 3.3458, lr 0.000920, 91971.24 tokens/sec
2025-04-25 13:54:46,241 - transformer_training - INFO - Main loop iteration: 8941
2025-04-25 13:54:46,702 - transformer_training - INFO - Main loop iteration: 8942
2025-04-25 13:54:47,153 - transformer_training - INFO - Main loop iteration: 8943
2025-04-25 13:54:47,652 - transformer_training - INFO - Main loop iteration: 8944
2025-04-25 13:54:48,053 - transformer_training - INFO - Main loop iteration: 8945
2025-04-25 13:54:48,515 - transformer_training - INFO - Main loop iteration: 8946
2025-04-25 13:54:48,965 - transformer_training - INFO - Main loop iteration: 8947
2025-04-25 13:54:49,464 - transformer_training - INFO - Main loop iteration: 8948
2025-04-25 13:54:49,865 - transformer_training - INFO - Main loop iteration: 8949
2025-04-25 13:54:50,327 - transformer_training - INFO - Main loop iteration: 8950
Iter 8950: loss 3.4511, lr 0.000920, 81911.57 tokens/sec
2025-04-25 13:54:50,777 - transformer_training - INFO - Main loop iteration: 8951
2025-04-25 13:54:51,276 - transformer_training - INFO - Main loop iteration: 8952
2025-04-25 13:54:51,677 - transformer_training - INFO - Main loop iteration: 8953
2025-04-25 13:54:52,138 - transformer_training - INFO - Main loop iteration: 8954
2025-04-25 13:54:52,588 - transformer_training - INFO - Main loop iteration: 8955
2025-04-25 13:54:53,087 - transformer_training - INFO - Main loop iteration: 8956
2025-04-25 13:54:53,488 - transformer_training - INFO - Main loop iteration: 8957
2025-04-25 13:54:53,948 - transformer_training - INFO - Main loop iteration: 8958
2025-04-25 13:54:54,399 - transformer_training - INFO - Main loop iteration: 8959
2025-04-25 13:54:54,897 - transformer_training - INFO - Main loop iteration: 8960
Iter 8960: loss 3.2887, lr 0.000920, 92076.72 tokens/sec
2025-04-25 13:54:55,298 - transformer_training - INFO - Main loop iteration: 8961
2025-04-25 13:54:55,759 - transformer_training - INFO - Main loop iteration: 8962
2025-04-25 13:54:56,209 - transformer_training - INFO - Main loop iteration: 8963
2025-04-25 13:54:56,708 - transformer_training - INFO - Main loop iteration: 8964
2025-04-25 13:54:57,109 - transformer_training - INFO - Main loop iteration: 8965
2025-04-25 13:54:57,570 - transformer_training - INFO - Main loop iteration: 8966
2025-04-25 13:54:58,020 - transformer_training - INFO - Main loop iteration: 8967
2025-04-25 13:54:58,519 - transformer_training - INFO - Main loop iteration: 8968
2025-04-25 13:54:58,919 - transformer_training - INFO - Main loop iteration: 8969
2025-04-25 13:54:59,380 - transformer_training - INFO - Main loop iteration: 8970
Iter 8970: loss 3.3960, lr 0.000919, 81922.99 tokens/sec
2025-04-25 13:54:59,830 - transformer_training - INFO - Main loop iteration: 8971
2025-04-25 13:55:00,329 - transformer_training - INFO - Main loop iteration: 8972
2025-04-25 13:55:00,730 - transformer_training - INFO - Main loop iteration: 8973
2025-04-25 13:55:01,191 - transformer_training - INFO - Main loop iteration: 8974
2025-04-25 13:55:01,642 - transformer_training - INFO - Main loop iteration: 8975
2025-04-25 13:55:02,141 - transformer_training - INFO - Main loop iteration: 8976
2025-04-25 13:55:02,542 - transformer_training - INFO - Main loop iteration: 8977
2025-04-25 13:55:03,003 - transformer_training - INFO - Main loop iteration: 8978
2025-04-25 13:55:03,454 - transformer_training - INFO - Main loop iteration: 8979
2025-04-25 13:55:03,953 - transformer_training - INFO - Main loop iteration: 8980
Iter 8980: loss 3.4398, lr 0.000919, 91997.01 tokens/sec
2025-04-25 13:55:04,354 - transformer_training - INFO - Main loop iteration: 8981
2025-04-25 13:55:04,814 - transformer_training - INFO - Main loop iteration: 8982
2025-04-25 13:55:05,265 - transformer_training - INFO - Main loop iteration: 8983
2025-04-25 13:55:05,763 - transformer_training - INFO - Main loop iteration: 8984
2025-04-25 13:55:06,167 - transformer_training - INFO - Main loop iteration: 8985
2025-04-25 13:55:06,629 - transformer_training - INFO - Main loop iteration: 8986
2025-04-25 13:55:07,080 - transformer_training - INFO - Main loop iteration: 8987
2025-04-25 13:55:07,580 - transformer_training - INFO - Main loop iteration: 8988
2025-04-25 13:55:07,982 - transformer_training - INFO - Main loop iteration: 8989
2025-04-25 13:55:08,444 - transformer_training - INFO - Main loop iteration: 8990
Iter 8990: loss 3.3290, lr 0.000919, 81852.25 tokens/sec
2025-04-25 13:55:08,895 - transformer_training - INFO - Main loop iteration: 8991
2025-04-25 13:55:09,393 - transformer_training - INFO - Main loop iteration: 8992
2025-04-25 13:55:09,794 - transformer_training - INFO - Main loop iteration: 8993
2025-04-25 13:55:10,255 - transformer_training - INFO - Main loop iteration: 8994
2025-04-25 13:55:10,705 - transformer_training - INFO - Main loop iteration: 8995
2025-04-25 13:55:11,204 - transformer_training - INFO - Main loop iteration: 8996
2025-04-25 13:55:11,605 - transformer_training - INFO - Main loop iteration: 8997
2025-04-25 13:55:12,066 - transformer_training - INFO - Main loop iteration: 8998
2025-04-25 13:55:12,517 - transformer_training - INFO - Main loop iteration: 8999
2025-04-25 13:55:13,015 - transformer_training - INFO - Main loop iteration: 9000
Iter 9000: loss 3.3873, lr 0.000919, 91966.53 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9000: train loss 3.2936, val loss 3.2436
New best model saved with val loss: 3.2436
2025-04-25 13:55:32,501 - transformer_training - INFO - Main loop iteration: 9001
2025-04-25 13:55:32,914 - transformer_training - INFO - Main loop iteration: 9002
2025-04-25 13:55:33,364 - transformer_training - INFO - Main loop iteration: 9003
2025-04-25 13:55:33,862 - transformer_training - INFO - Main loop iteration: 9004
2025-04-25 13:55:34,262 - transformer_training - INFO - Main loop iteration: 9005
2025-04-25 13:55:34,723 - transformer_training - INFO - Main loop iteration: 9006
2025-04-25 13:55:35,173 - transformer_training - INFO - Main loop iteration: 9007
2025-04-25 13:55:35,671 - transformer_training - INFO - Main loop iteration: 9008
2025-04-25 13:55:36,072 - transformer_training - INFO - Main loop iteration: 9009
2025-04-25 13:55:36,533 - transformer_training - INFO - Main loop iteration: 9010
Iter 9010: loss 3.3886, lr 0.000918, 81948.17 tokens/sec
2025-04-25 13:55:36,983 - transformer_training - INFO - Main loop iteration: 9011
2025-04-25 13:55:37,482 - transformer_training - INFO - Main loop iteration: 9012
2025-04-25 13:55:37,883 - transformer_training - INFO - Main loop iteration: 9013
2025-04-25 13:55:38,344 - transformer_training - INFO - Main loop iteration: 9014
2025-04-25 13:55:38,794 - transformer_training - INFO - Main loop iteration: 9015
2025-04-25 13:55:39,293 - transformer_training - INFO - Main loop iteration: 9016
2025-04-25 13:55:39,694 - transformer_training - INFO - Main loop iteration: 9017
2025-04-25 13:55:40,154 - transformer_training - INFO - Main loop iteration: 9018
2025-04-25 13:55:40,604 - transformer_training - INFO - Main loop iteration: 9019
2025-04-25 13:55:41,103 - transformer_training - INFO - Main loop iteration: 9020
Iter 9020: loss 3.4607, lr 0.000918, 78133.88 tokens/sec
2025-04-25 13:55:41,575 - transformer_training - INFO - Main loop iteration: 9021
2025-04-25 13:55:42,036 - transformer_training - INFO - Main loop iteration: 9022
2025-04-25 13:55:42,487 - transformer_training - INFO - Main loop iteration: 9023
2025-04-25 13:55:42,986 - transformer_training - INFO - Main loop iteration: 9024
2025-04-25 13:55:43,386 - transformer_training - INFO - Main loop iteration: 9025
2025-04-25 13:55:43,846 - transformer_training - INFO - Main loop iteration: 9026
2025-04-25 13:55:44,297 - transformer_training - INFO - Main loop iteration: 9027
2025-04-25 13:55:44,798 - transformer_training - INFO - Main loop iteration: 9028
2025-04-25 13:55:45,198 - transformer_training - INFO - Main loop iteration: 9029
2025-04-25 13:55:45,658 - transformer_training - INFO - Main loop iteration: 9030
Iter 9030: loss 3.3046, lr 0.000918, 81901.51 tokens/sec
2025-04-25 13:55:46,109 - transformer_training - INFO - Main loop iteration: 9031
2025-04-25 13:55:46,607 - transformer_training - INFO - Main loop iteration: 9032
2025-04-25 13:55:47,010 - transformer_training - INFO - Main loop iteration: 9033
2025-04-25 13:55:47,471 - transformer_training - INFO - Main loop iteration: 9034
2025-04-25 13:55:47,922 - transformer_training - INFO - Main loop iteration: 9035
2025-04-25 13:55:48,422 - transformer_training - INFO - Main loop iteration: 9036
2025-04-25 13:55:48,823 - transformer_training - INFO - Main loop iteration: 9037
2025-04-25 13:55:49,283 - transformer_training - INFO - Main loop iteration: 9038
2025-04-25 13:55:49,734 - transformer_training - INFO - Main loop iteration: 9039
2025-04-25 13:55:50,232 - transformer_training - INFO - Main loop iteration: 9040
Iter 9040: loss 3.3564, lr 0.000918, 91971.35 tokens/sec
2025-04-25 13:55:50,634 - transformer_training - INFO - Main loop iteration: 9041
2025-04-25 13:55:51,094 - transformer_training - INFO - Main loop iteration: 9042
2025-04-25 13:55:51,545 - transformer_training - INFO - Main loop iteration: 9043
2025-04-25 13:55:52,044 - transformer_training - INFO - Main loop iteration: 9044
2025-04-25 13:55:52,445 - transformer_training - INFO - Main loop iteration: 9045
2025-04-25 13:55:52,906 - transformer_training - INFO - Main loop iteration: 9046
2025-04-25 13:55:53,357 - transformer_training - INFO - Main loop iteration: 9047
2025-04-25 13:55:53,856 - transformer_training - INFO - Main loop iteration: 9048
2025-04-25 13:55:54,257 - transformer_training - INFO - Main loop iteration: 9049
2025-04-25 13:55:54,718 - transformer_training - INFO - Main loop iteration: 9050
Iter 9050: loss 3.3353, lr 0.000918, 82077.24 tokens/sec
2025-04-25 13:55:55,168 - transformer_training - INFO - Main loop iteration: 9051
2025-04-25 13:55:55,667 - transformer_training - INFO - Main loop iteration: 9052
2025-04-25 13:55:56,068 - transformer_training - INFO - Main loop iteration: 9053
2025-04-25 13:55:56,528 - transformer_training - INFO - Main loop iteration: 9054
2025-04-25 13:55:56,978 - transformer_training - INFO - Main loop iteration: 9055
2025-04-25 13:55:57,477 - transformer_training - INFO - Main loop iteration: 9056
2025-04-25 13:55:57,878 - transformer_training - INFO - Main loop iteration: 9057
2025-04-25 13:55:58,339 - transformer_training - INFO - Main loop iteration: 9058
2025-04-25 13:55:58,789 - transformer_training - INFO - Main loop iteration: 9059
2025-04-25 13:55:59,288 - transformer_training - INFO - Main loop iteration: 9060
Iter 9060: loss 3.3795, lr 0.000917, 91995.97 tokens/sec
2025-04-25 13:55:59,689 - transformer_training - INFO - Main loop iteration: 9061
2025-04-25 13:56:00,149 - transformer_training - INFO - Main loop iteration: 9062
2025-04-25 13:56:00,600 - transformer_training - INFO - Main loop iteration: 9063
2025-04-25 13:56:01,099 - transformer_training - INFO - Main loop iteration: 9064
2025-04-25 13:56:01,500 - transformer_training - INFO - Main loop iteration: 9065
2025-04-25 13:56:01,961 - transformer_training - INFO - Main loop iteration: 9066
2025-04-25 13:56:02,411 - transformer_training - INFO - Main loop iteration: 9067
2025-04-25 13:56:02,910 - transformer_training - INFO - Main loop iteration: 9068
2025-04-25 13:56:03,311 - transformer_training - INFO - Main loop iteration: 9069
2025-04-25 13:56:03,772 - transformer_training - INFO - Main loop iteration: 9070
Iter 9070: loss 3.3672, lr 0.000917, 81961.68 tokens/sec
2025-04-25 13:56:04,222 - transformer_training - INFO - Main loop iteration: 9071
2025-04-25 13:56:04,721 - transformer_training - INFO - Main loop iteration: 9072
2025-04-25 13:56:05,122 - transformer_training - INFO - Main loop iteration: 9073
2025-04-25 13:56:05,583 - transformer_training - INFO - Main loop iteration: 9074
2025-04-25 13:56:06,034 - transformer_training - INFO - Main loop iteration: 9075
2025-04-25 13:56:06,532 - transformer_training - INFO - Main loop iteration: 9076
2025-04-25 13:56:06,933 - transformer_training - INFO - Main loop iteration: 9077
2025-04-25 13:56:07,394 - transformer_training - INFO - Main loop iteration: 9078
2025-04-25 13:56:07,844 - transformer_training - INFO - Main loop iteration: 9079
2025-04-25 13:56:08,344 - transformer_training - INFO - Main loop iteration: 9080
Iter 9080: loss 3.3903, lr 0.000917, 91968.50 tokens/sec
2025-04-25 13:56:08,745 - transformer_training - INFO - Main loop iteration: 9081
2025-04-25 13:56:09,205 - transformer_training - INFO - Main loop iteration: 9082
2025-04-25 13:56:09,655 - transformer_training - INFO - Main loop iteration: 9083
2025-04-25 13:56:10,154 - transformer_training - INFO - Main loop iteration: 9084
2025-04-25 13:56:10,555 - transformer_training - INFO - Main loop iteration: 9085
2025-04-25 13:56:11,016 - transformer_training - INFO - Main loop iteration: 9086
2025-04-25 13:56:11,466 - transformer_training - INFO - Main loop iteration: 9087
2025-04-25 13:56:11,964 - transformer_training - INFO - Main loop iteration: 9088
2025-04-25 13:56:12,365 - transformer_training - INFO - Main loop iteration: 9089
2025-04-25 13:56:12,826 - transformer_training - INFO - Main loop iteration: 9090
Iter 9090: loss 3.3511, lr 0.000917, 81900.38 tokens/sec
2025-04-25 13:56:13,277 - transformer_training - INFO - Main loop iteration: 9091
2025-04-25 13:56:13,776 - transformer_training - INFO - Main loop iteration: 9092
2025-04-25 13:56:14,176 - transformer_training - INFO - Main loop iteration: 9093
2025-04-25 13:56:14,637 - transformer_training - INFO - Main loop iteration: 9094
2025-04-25 13:56:15,088 - transformer_training - INFO - Main loop iteration: 9095
2025-04-25 13:56:15,587 - transformer_training - INFO - Main loop iteration: 9096
2025-04-25 13:56:15,987 - transformer_training - INFO - Main loop iteration: 9097
2025-04-25 13:56:16,449 - transformer_training - INFO - Main loop iteration: 9098
2025-04-25 13:56:16,899 - transformer_training - INFO - Main loop iteration: 9099
2025-04-25 13:56:17,399 - transformer_training - INFO - Main loop iteration: 9100
Iter 9100: loss 3.3492, lr 0.000916, 91973.70 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9100: train loss 3.2920, val loss 3.2411
New best model saved with val loss: 3.2411
2025-04-25 13:56:38,561 - transformer_training - INFO - Main loop iteration: 9101
2025-04-25 13:56:38,983 - transformer_training - INFO - Main loop iteration: 9102
2025-04-25 13:56:39,436 - transformer_training - INFO - Main loop iteration: 9103
2025-04-25 13:56:39,944 - transformer_training - INFO - Main loop iteration: 9104
2025-04-25 13:56:40,346 - transformer_training - INFO - Main loop iteration: 9105
2025-04-25 13:56:40,811 - transformer_training - INFO - Main loop iteration: 9106
2025-04-25 13:56:41,265 - transformer_training - INFO - Main loop iteration: 9107
2025-04-25 13:56:41,766 - transformer_training - INFO - Main loop iteration: 9108
2025-04-25 13:56:42,169 - transformer_training - INFO - Main loop iteration: 9109
2025-04-25 13:56:42,643 - transformer_training - INFO - Main loop iteration: 9110
Iter 9110: loss 3.3295, lr 0.000916, 81424.61 tokens/sec
2025-04-25 13:56:43,097 - transformer_training - INFO - Main loop iteration: 9111
2025-04-25 13:56:43,600 - transformer_training - INFO - Main loop iteration: 9112
2025-04-25 13:56:44,003 - transformer_training - INFO - Main loop iteration: 9113
2025-04-25 13:56:44,479 - transformer_training - INFO - Main loop iteration: 9114
2025-04-25 13:56:44,931 - transformer_training - INFO - Main loop iteration: 9115
2025-04-25 13:56:45,435 - transformer_training - INFO - Main loop iteration: 9116
2025-04-25 13:56:45,844 - transformer_training - INFO - Main loop iteration: 9117
2025-04-25 13:56:46,308 - transformer_training - INFO - Main loop iteration: 9118
2025-04-25 13:56:46,760 - transformer_training - INFO - Main loop iteration: 9119
2025-04-25 13:56:47,266 - transformer_training - INFO - Main loop iteration: 9120
Iter 9120: loss 3.3926, lr 0.000916, 91629.17 tokens/sec
2025-04-25 13:56:47,669 - transformer_training - INFO - Main loop iteration: 9121
2025-04-25 13:56:48,134 - transformer_training - INFO - Main loop iteration: 9122
2025-04-25 13:56:48,587 - transformer_training - INFO - Main loop iteration: 9123
2025-04-25 13:56:49,091 - transformer_training - INFO - Main loop iteration: 9124
2025-04-25 13:56:49,496 - transformer_training - INFO - Main loop iteration: 9125
2025-04-25 13:56:49,960 - transformer_training - INFO - Main loop iteration: 9126
2025-04-25 13:56:50,414 - transformer_training - INFO - Main loop iteration: 9127
2025-04-25 13:56:50,919 - transformer_training - INFO - Main loop iteration: 9128
2025-04-25 13:56:51,328 - transformer_training - INFO - Main loop iteration: 9129
2025-04-25 13:56:51,795 - transformer_training - INFO - Main loop iteration: 9130
Iter 9130: loss 3.4344, lr 0.000916, 81550.05 tokens/sec
2025-04-25 13:56:52,247 - transformer_training - INFO - Main loop iteration: 9131
2025-04-25 13:56:52,759 - transformer_training - INFO - Main loop iteration: 9132
2025-04-25 13:56:53,162 - transformer_training - INFO - Main loop iteration: 9133
2025-04-25 13:56:53,627 - transformer_training - INFO - Main loop iteration: 9134
2025-04-25 13:56:54,082 - transformer_training - INFO - Main loop iteration: 9135
2025-04-25 13:56:54,589 - transformer_training - INFO - Main loop iteration: 9136
2025-04-25 13:56:54,993 - transformer_training - INFO - Main loop iteration: 9137
2025-04-25 13:56:55,459 - transformer_training - INFO - Main loop iteration: 9138
2025-04-25 13:56:55,918 - transformer_training - INFO - Main loop iteration: 9139
2025-04-25 13:56:56,421 - transformer_training - INFO - Main loop iteration: 9140
Iter 9140: loss 3.3779, lr 0.000915, 91402.59 tokens/sec
2025-04-25 13:56:56,825 - transformer_training - INFO - Main loop iteration: 9141
2025-04-25 13:56:57,290 - transformer_training - INFO - Main loop iteration: 9142
2025-04-25 13:56:57,746 - transformer_training - INFO - Main loop iteration: 9143
2025-04-25 13:56:58,249 - transformer_training - INFO - Main loop iteration: 9144
2025-04-25 13:56:58,652 - transformer_training - INFO - Main loop iteration: 9145
2025-04-25 13:56:59,124 - transformer_training - INFO - Main loop iteration: 9146
2025-04-25 13:56:59,577 - transformer_training - INFO - Main loop iteration: 9147
2025-04-25 13:57:00,085 - transformer_training - INFO - Main loop iteration: 9148
2025-04-25 13:57:00,491 - transformer_training - INFO - Main loop iteration: 9149
2025-04-25 13:57:00,955 - transformer_training - INFO - Main loop iteration: 9150
Iter 9150: loss 3.4088, lr 0.000915, 81232.88 tokens/sec
2025-04-25 13:57:01,410 - transformer_training - INFO - Main loop iteration: 9151
2025-04-25 13:57:01,913 - transformer_training - INFO - Main loop iteration: 9152
2025-04-25 13:57:02,319 - transformer_training - INFO - Main loop iteration: 9153
2025-04-25 13:57:02,783 - transformer_training - INFO - Main loop iteration: 9154
2025-04-25 13:57:03,237 - transformer_training - INFO - Main loop iteration: 9155
2025-04-25 13:57:03,742 - transformer_training - INFO - Main loop iteration: 9156
2025-04-25 13:57:04,148 - transformer_training - INFO - Main loop iteration: 9157
2025-04-25 13:57:04,613 - transformer_training - INFO - Main loop iteration: 9158
2025-04-25 13:57:05,067 - transformer_training - INFO - Main loop iteration: 9159
2025-04-25 13:57:05,571 - transformer_training - INFO - Main loop iteration: 9160
Iter 9160: loss 3.3163, lr 0.000915, 89859.40 tokens/sec
2025-04-25 13:57:05,982 - transformer_training - INFO - Main loop iteration: 9161
2025-04-25 13:57:06,446 - transformer_training - INFO - Main loop iteration: 9162
2025-04-25 13:57:06,906 - transformer_training - INFO - Main loop iteration: 9163
2025-04-25 13:57:07,412 - transformer_training - INFO - Main loop iteration: 9164
2025-04-25 13:57:07,766 - transformer_training - INFO - Main loop iteration: 9165
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
2025-04-25 13:57:11,466 - transformer_training - INFO - Main loop iteration: 9166
2025-04-25 13:57:11,920 - transformer_training - INFO - Main loop iteration: 9167
2025-04-25 13:57:12,426 - transformer_training - INFO - Main loop iteration: 9168
2025-04-25 13:57:12,828 - transformer_training - INFO - Main loop iteration: 9169
2025-04-25 13:57:13,294 - transformer_training - INFO - Main loop iteration: 9170
Iter 9170: loss 3.1482, lr 0.000915, 81477.22 tokens/sec
2025-04-25 13:57:13,747 - transformer_training - INFO - Main loop iteration: 9171
2025-04-25 13:57:14,252 - transformer_training - INFO - Main loop iteration: 9172
2025-04-25 13:57:14,660 - transformer_training - INFO - Main loop iteration: 9173
2025-04-25 13:57:15,124 - transformer_training - INFO - Main loop iteration: 9174
2025-04-25 13:57:15,579 - transformer_training - INFO - Main loop iteration: 9175
2025-04-25 13:57:16,085 - transformer_training - INFO - Main loop iteration: 9176
2025-04-25 13:57:16,489 - transformer_training - INFO - Main loop iteration: 9177
2025-04-25 13:57:16,954 - transformer_training - INFO - Main loop iteration: 9178
2025-04-25 13:57:17,410 - transformer_training - INFO - Main loop iteration: 9179
2025-04-25 13:57:17,915 - transformer_training - INFO - Main loop iteration: 9180
Iter 9180: loss 3.1497, lr 0.000915, 91376.56 tokens/sec
2025-04-25 13:57:18,320 - transformer_training - INFO - Main loop iteration: 9181
2025-04-25 13:57:18,784 - transformer_training - INFO - Main loop iteration: 9182
2025-04-25 13:57:19,239 - transformer_training - INFO - Main loop iteration: 9183
2025-04-25 13:57:19,741 - transformer_training - INFO - Main loop iteration: 9184
2025-04-25 13:57:20,145 - transformer_training - INFO - Main loop iteration: 9185
2025-04-25 13:57:20,611 - transformer_training - INFO - Main loop iteration: 9186
2025-04-25 13:57:21,065 - transformer_training - INFO - Main loop iteration: 9187
2025-04-25 13:57:21,573 - transformer_training - INFO - Main loop iteration: 9188
2025-04-25 13:57:21,977 - transformer_training - INFO - Main loop iteration: 9189
2025-04-25 13:57:22,442 - transformer_training - INFO - Main loop iteration: 9190
Iter 9190: loss 3.2164, lr 0.000914, 81008.12 tokens/sec
2025-04-25 13:57:22,898 - transformer_training - INFO - Main loop iteration: 9191
2025-04-25 13:57:23,402 - transformer_training - INFO - Main loop iteration: 9192
2025-04-25 13:57:23,806 - transformer_training - INFO - Main loop iteration: 9193
2025-04-25 13:57:24,271 - transformer_training - INFO - Main loop iteration: 9194
2025-04-25 13:57:24,725 - transformer_training - INFO - Main loop iteration: 9195
2025-04-25 13:57:25,240 - transformer_training - INFO - Main loop iteration: 9196
2025-04-25 13:57:25,643 - transformer_training - INFO - Main loop iteration: 9197
2025-04-25 13:57:26,109 - transformer_training - INFO - Main loop iteration: 9198
2025-04-25 13:57:26,562 - transformer_training - INFO - Main loop iteration: 9199
2025-04-25 13:57:27,064 - transformer_training - INFO - Main loop iteration: 9200
Iter 9200: loss 3.2854, lr 0.000914, 91251.23 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9200: train loss 2.7292, val loss 3.2459
2025-04-25 13:57:48,776 - transformer_training - INFO - Main loop iteration: 9201
2025-04-25 13:57:49,186 - transformer_training - INFO - Main loop iteration: 9202
2025-04-25 13:57:49,637 - transformer_training - INFO - Main loop iteration: 9203
2025-04-25 13:57:50,148 - transformer_training - INFO - Main loop iteration: 9204
2025-04-25 13:57:50,548 - transformer_training - INFO - Main loop iteration: 9205
2025-04-25 13:57:51,011 - transformer_training - INFO - Main loop iteration: 9206
2025-04-25 13:57:51,462 - transformer_training - INFO - Main loop iteration: 9207
2025-04-25 13:57:51,971 - transformer_training - INFO - Main loop iteration: 9208
2025-04-25 13:57:52,372 - transformer_training - INFO - Main loop iteration: 9209
2025-04-25 13:57:52,832 - transformer_training - INFO - Main loop iteration: 9210
Iter 9210: loss 3.2330, lr 0.000914, 81992.02 tokens/sec
2025-04-25 13:57:53,283 - transformer_training - INFO - Main loop iteration: 9211
2025-04-25 13:57:53,780 - transformer_training - INFO - Main loop iteration: 9212
2025-04-25 13:57:54,182 - transformer_training - INFO - Main loop iteration: 9213
2025-04-25 13:57:54,643 - transformer_training - INFO - Main loop iteration: 9214
2025-04-25 13:57:55,093 - transformer_training - INFO - Main loop iteration: 9215
2025-04-25 13:57:55,591 - transformer_training - INFO - Main loop iteration: 9216
2025-04-25 13:57:55,993 - transformer_training - INFO - Main loop iteration: 9217
2025-04-25 13:57:56,453 - transformer_training - INFO - Main loop iteration: 9218
2025-04-25 13:57:56,903 - transformer_training - INFO - Main loop iteration: 9219
2025-04-25 13:57:57,401 - transformer_training - INFO - Main loop iteration: 9220
Iter 9220: loss 3.2406, lr 0.000914, 91879.80 tokens/sec
2025-04-25 13:57:57,803 - transformer_training - INFO - Main loop iteration: 9221
2025-04-25 13:57:58,263 - transformer_training - INFO - Main loop iteration: 9222
2025-04-25 13:57:58,714 - transformer_training - INFO - Main loop iteration: 9223
2025-04-25 13:57:59,230 - transformer_training - INFO - Main loop iteration: 9224
2025-04-25 13:57:59,631 - transformer_training - INFO - Main loop iteration: 9225
2025-04-25 13:58:00,091 - transformer_training - INFO - Main loop iteration: 9226
2025-04-25 13:58:00,541 - transformer_training - INFO - Main loop iteration: 9227
2025-04-25 13:58:01,040 - transformer_training - INFO - Main loop iteration: 9228
2025-04-25 13:58:01,441 - transformer_training - INFO - Main loop iteration: 9229
2025-04-25 13:58:01,901 - transformer_training - INFO - Main loop iteration: 9230
Iter 9230: loss 3.2320, lr 0.000913, 81976.02 tokens/sec
2025-04-25 13:58:02,351 - transformer_training - INFO - Main loop iteration: 9231
2025-04-25 13:58:02,849 - transformer_training - INFO - Main loop iteration: 9232
2025-04-25 13:58:03,250 - transformer_training - INFO - Main loop iteration: 9233
2025-04-25 13:58:03,711 - transformer_training - INFO - Main loop iteration: 9234
2025-04-25 13:58:04,162 - transformer_training - INFO - Main loop iteration: 9235
2025-04-25 13:58:04,660 - transformer_training - INFO - Main loop iteration: 9236
2025-04-25 13:58:05,061 - transformer_training - INFO - Main loop iteration: 9237
2025-04-25 13:58:05,522 - transformer_training - INFO - Main loop iteration: 9238
2025-04-25 13:58:05,972 - transformer_training - INFO - Main loop iteration: 9239
2025-04-25 13:58:06,471 - transformer_training - INFO - Main loop iteration: 9240
Iter 9240: loss 3.2064, lr 0.000913, 92060.22 tokens/sec
2025-04-25 13:58:06,872 - transformer_training - INFO - Main loop iteration: 9241
2025-04-25 13:58:07,332 - transformer_training - INFO - Main loop iteration: 9242
2025-04-25 13:58:07,782 - transformer_training - INFO - Main loop iteration: 9243
2025-04-25 13:58:08,281 - transformer_training - INFO - Main loop iteration: 9244
2025-04-25 13:58:08,682 - transformer_training - INFO - Main loop iteration: 9245
2025-04-25 13:58:09,143 - transformer_training - INFO - Main loop iteration: 9246
2025-04-25 13:58:09,593 - transformer_training - INFO - Main loop iteration: 9247
2025-04-25 13:58:10,092 - transformer_training - INFO - Main loop iteration: 9248
2025-04-25 13:58:10,494 - transformer_training - INFO - Main loop iteration: 9249
2025-04-25 13:58:10,954 - transformer_training - INFO - Main loop iteration: 9250
Iter 9250: loss 3.1707, lr 0.000913, 81849.18 tokens/sec
2025-04-25 13:58:11,405 - transformer_training - INFO - Main loop iteration: 9251
2025-04-25 13:58:11,905 - transformer_training - INFO - Main loop iteration: 9252
2025-04-25 13:58:12,308 - transformer_training - INFO - Main loop iteration: 9253
2025-04-25 13:58:12,770 - transformer_training - INFO - Main loop iteration: 9254
2025-04-25 13:58:13,221 - transformer_training - INFO - Main loop iteration: 9255
2025-04-25 13:58:13,723 - transformer_training - INFO - Main loop iteration: 9256
2025-04-25 13:58:14,127 - transformer_training - INFO - Main loop iteration: 9257
2025-04-25 13:58:14,589 - transformer_training - INFO - Main loop iteration: 9258
2025-04-25 13:58:15,039 - transformer_training - INFO - Main loop iteration: 9259
2025-04-25 13:58:15,544 - transformer_training - INFO - Main loop iteration: 9260
Iter 9260: loss 3.2396, lr 0.000913, 91398.49 tokens/sec
2025-04-25 13:58:15,948 - transformer_training - INFO - Main loop iteration: 9261
2025-04-25 13:58:16,413 - transformer_training - INFO - Main loop iteration: 9262
2025-04-25 13:58:16,868 - transformer_training - INFO - Main loop iteration: 9263
2025-04-25 13:58:17,372 - transformer_training - INFO - Main loop iteration: 9264
2025-04-25 13:58:17,773 - transformer_training - INFO - Main loop iteration: 9265
2025-04-25 13:58:18,237 - transformer_training - INFO - Main loop iteration: 9266
2025-04-25 13:58:18,688 - transformer_training - INFO - Main loop iteration: 9267
2025-04-25 13:58:19,187 - transformer_training - INFO - Main loop iteration: 9268
2025-04-25 13:58:19,588 - transformer_training - INFO - Main loop iteration: 9269
2025-04-25 13:58:20,050 - transformer_training - INFO - Main loop iteration: 9270
Iter 9270: loss 3.3606, lr 0.000913, 81866.21 tokens/sec
2025-04-25 13:58:20,501 - transformer_training - INFO - Main loop iteration: 9271
2025-04-25 13:58:20,999 - transformer_training - INFO - Main loop iteration: 9272
2025-04-25 13:58:21,400 - transformer_training - INFO - Main loop iteration: 9273
2025-04-25 13:58:21,862 - transformer_training - INFO - Main loop iteration: 9274
2025-04-25 13:58:22,313 - transformer_training - INFO - Main loop iteration: 9275
2025-04-25 13:58:22,814 - transformer_training - INFO - Main loop iteration: 9276
2025-04-25 13:58:23,216 - transformer_training - INFO - Main loop iteration: 9277
2025-04-25 13:58:23,677 - transformer_training - INFO - Main loop iteration: 9278
2025-04-25 13:58:24,127 - transformer_training - INFO - Main loop iteration: 9279
2025-04-25 13:58:24,625 - transformer_training - INFO - Main loop iteration: 9280
Iter 9280: loss 3.2416, lr 0.000912, 91916.67 tokens/sec
2025-04-25 13:58:25,026 - transformer_training - INFO - Main loop iteration: 9281
2025-04-25 13:58:25,488 - transformer_training - INFO - Main loop iteration: 9282
2025-04-25 13:58:25,938 - transformer_training - INFO - Main loop iteration: 9283
2025-04-25 13:58:26,437 - transformer_training - INFO - Main loop iteration: 9284
2025-04-25 13:58:26,839 - transformer_training - INFO - Main loop iteration: 9285
2025-04-25 13:58:27,300 - transformer_training - INFO - Main loop iteration: 9286
2025-04-25 13:58:27,750 - transformer_training - INFO - Main loop iteration: 9287
2025-04-25 13:58:28,248 - transformer_training - INFO - Main loop iteration: 9288
2025-04-25 13:58:28,650 - transformer_training - INFO - Main loop iteration: 9289
2025-04-25 13:58:29,111 - transformer_training - INFO - Main loop iteration: 9290
Iter 9290: loss 3.1849, lr 0.000912, 81904.02 tokens/sec
2025-04-25 13:58:29,562 - transformer_training - INFO - Main loop iteration: 9291
2025-04-25 13:58:30,060 - transformer_training - INFO - Main loop iteration: 9292
2025-04-25 13:58:30,462 - transformer_training - INFO - Main loop iteration: 9293
2025-04-25 13:58:30,923 - transformer_training - INFO - Main loop iteration: 9294
2025-04-25 13:58:31,373 - transformer_training - INFO - Main loop iteration: 9295
2025-04-25 13:58:31,872 - transformer_training - INFO - Main loop iteration: 9296
2025-04-25 13:58:32,273 - transformer_training - INFO - Main loop iteration: 9297
2025-04-25 13:58:32,734 - transformer_training - INFO - Main loop iteration: 9298
2025-04-25 13:58:33,185 - transformer_training - INFO - Main loop iteration: 9299
2025-04-25 13:58:33,684 - transformer_training - INFO - Main loop iteration: 9300
Iter 9300: loss 3.2429, lr 0.000912, 91872.49 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9300: train loss 2.7254, val loss 3.2471
2025-04-25 13:58:48,808 - transformer_training - INFO - Main loop iteration: 9301
2025-04-25 13:58:49,217 - transformer_training - INFO - Main loop iteration: 9302
2025-04-25 13:58:49,667 - transformer_training - INFO - Main loop iteration: 9303
2025-04-25 13:58:50,166 - transformer_training - INFO - Main loop iteration: 9304
2025-04-25 13:58:50,567 - transformer_training - INFO - Main loop iteration: 9305
2025-04-25 13:58:51,027 - transformer_training - INFO - Main loop iteration: 9306
2025-04-25 13:58:51,477 - transformer_training - INFO - Main loop iteration: 9307
2025-04-25 13:58:51,976 - transformer_training - INFO - Main loop iteration: 9308
2025-04-25 13:58:52,377 - transformer_training - INFO - Main loop iteration: 9309
2025-04-25 13:58:52,839 - transformer_training - INFO - Main loop iteration: 9310
Iter 9310: loss 3.1832, lr 0.000912, 82087.91 tokens/sec
2025-04-25 13:58:53,289 - transformer_training - INFO - Main loop iteration: 9311
2025-04-25 13:58:53,787 - transformer_training - INFO - Main loop iteration: 9312
2025-04-25 13:58:54,188 - transformer_training - INFO - Main loop iteration: 9313
2025-04-25 13:58:54,650 - transformer_training - INFO - Main loop iteration: 9314
2025-04-25 13:58:55,100 - transformer_training - INFO - Main loop iteration: 9315
2025-04-25 13:58:55,598 - transformer_training - INFO - Main loop iteration: 9316
2025-04-25 13:58:55,999 - transformer_training - INFO - Main loop iteration: 9317
2025-04-25 13:58:56,459 - transformer_training - INFO - Main loop iteration: 9318
2025-04-25 13:58:56,910 - transformer_training - INFO - Main loop iteration: 9319
2025-04-25 13:58:57,408 - transformer_training - INFO - Main loop iteration: 9320
Iter 9320: loss 3.1804, lr 0.000911, 91814.49 tokens/sec
2025-04-25 13:58:57,810 - transformer_training - INFO - Main loop iteration: 9321
2025-04-25 13:58:58,270 - transformer_training - INFO - Main loop iteration: 9322
2025-04-25 13:58:58,720 - transformer_training - INFO - Main loop iteration: 9323
2025-04-25 13:58:59,219 - transformer_training - INFO - Main loop iteration: 9324
2025-04-25 13:58:59,620 - transformer_training - INFO - Main loop iteration: 9325
2025-04-25 13:59:00,081 - transformer_training - INFO - Main loop iteration: 9326
2025-04-25 13:59:00,531 - transformer_training - INFO - Main loop iteration: 9327
2025-04-25 13:59:01,029 - transformer_training - INFO - Main loop iteration: 9328
2025-04-25 13:59:01,431 - transformer_training - INFO - Main loop iteration: 9329
2025-04-25 13:59:01,892 - transformer_training - INFO - Main loop iteration: 9330
Iter 9330: loss 3.2842, lr 0.000911, 81830.16 tokens/sec
2025-04-25 13:59:02,343 - transformer_training - INFO - Main loop iteration: 9331
2025-04-25 13:59:02,842 - transformer_training - INFO - Main loop iteration: 9332
2025-04-25 13:59:03,243 - transformer_training - INFO - Main loop iteration: 9333
2025-04-25 13:59:03,705 - transformer_training - INFO - Main loop iteration: 9334
2025-04-25 13:59:04,155 - transformer_training - INFO - Main loop iteration: 9335
2025-04-25 13:59:04,653 - transformer_training - INFO - Main loop iteration: 9336
2025-04-25 13:59:05,055 - transformer_training - INFO - Main loop iteration: 9337
2025-04-25 13:59:05,516 - transformer_training - INFO - Main loop iteration: 9338
2025-04-25 13:59:05,966 - transformer_training - INFO - Main loop iteration: 9339
2025-04-25 13:59:06,464 - transformer_training - INFO - Main loop iteration: 9340
Iter 9340: loss 3.0852, lr 0.000911, 91890.61 tokens/sec
2025-04-25 13:59:06,866 - transformer_training - INFO - Main loop iteration: 9341
2025-04-25 13:59:07,327 - transformer_training - INFO - Main loop iteration: 9342
2025-04-25 13:59:07,779 - transformer_training - INFO - Main loop iteration: 9343
2025-04-25 13:59:08,278 - transformer_training - INFO - Main loop iteration: 9344
2025-04-25 13:59:08,680 - transformer_training - INFO - Main loop iteration: 9345
2025-04-25 13:59:09,141 - transformer_training - INFO - Main loop iteration: 9346
2025-04-25 13:59:09,592 - transformer_training - INFO - Main loop iteration: 9347
2025-04-25 13:59:10,091 - transformer_training - INFO - Main loop iteration: 9348
2025-04-25 13:59:10,493 - transformer_training - INFO - Main loop iteration: 9349
2025-04-25 13:59:10,955 - transformer_training - INFO - Main loop iteration: 9350
Iter 9350: loss 3.3154, lr 0.000911, 81935.32 tokens/sec
2025-04-25 13:59:11,405 - transformer_training - INFO - Main loop iteration: 9351
2025-04-25 13:59:11,904 - transformer_training - INFO - Main loop iteration: 9352
2025-04-25 13:59:12,306 - transformer_training - INFO - Main loop iteration: 9353
2025-04-25 13:59:12,767 - transformer_training - INFO - Main loop iteration: 9354
2025-04-25 13:59:13,217 - transformer_training - INFO - Main loop iteration: 9355
2025-04-25 13:59:13,716 - transformer_training - INFO - Main loop iteration: 9356
2025-04-25 13:59:14,117 - transformer_training - INFO - Main loop iteration: 9357
2025-04-25 13:59:14,578 - transformer_training - INFO - Main loop iteration: 9358
2025-04-25 13:59:15,029 - transformer_training - INFO - Main loop iteration: 9359
2025-04-25 13:59:15,527 - transformer_training - INFO - Main loop iteration: 9360
Iter 9360: loss 3.2617, lr 0.000910, 91858.95 tokens/sec
2025-04-25 13:59:15,929 - transformer_training - INFO - Main loop iteration: 9361
2025-04-25 13:59:16,389 - transformer_training - INFO - Main loop iteration: 9362
2025-04-25 13:59:16,840 - transformer_training - INFO - Main loop iteration: 9363
2025-04-25 13:59:17,338 - transformer_training - INFO - Main loop iteration: 9364
2025-04-25 13:59:17,739 - transformer_training - INFO - Main loop iteration: 9365
2025-04-25 13:59:18,200 - transformer_training - INFO - Main loop iteration: 9366
2025-04-25 13:59:18,651 - transformer_training - INFO - Main loop iteration: 9367
2025-04-25 13:59:19,149 - transformer_training - INFO - Main loop iteration: 9368
2025-04-25 13:59:19,550 - transformer_training - INFO - Main loop iteration: 9369
2025-04-25 13:59:20,011 - transformer_training - INFO - Main loop iteration: 9370
Iter 9370: loss 3.2195, lr 0.000910, 81882.29 tokens/sec
2025-04-25 13:59:20,462 - transformer_training - INFO - Main loop iteration: 9371
2025-04-25 13:59:20,960 - transformer_training - INFO - Main loop iteration: 9372
2025-04-25 13:59:21,361 - transformer_training - INFO - Main loop iteration: 9373
2025-04-25 13:59:21,822 - transformer_training - INFO - Main loop iteration: 9374
2025-04-25 13:59:22,275 - transformer_training - INFO - Main loop iteration: 9375
2025-04-25 13:59:22,774 - transformer_training - INFO - Main loop iteration: 9376
2025-04-25 13:59:23,175 - transformer_training - INFO - Main loop iteration: 9377
2025-04-25 13:59:23,636 - transformer_training - INFO - Main loop iteration: 9378
2025-04-25 13:59:24,086 - transformer_training - INFO - Main loop iteration: 9379
2025-04-25 13:59:24,585 - transformer_training - INFO - Main loop iteration: 9380
Iter 9380: loss 3.2024, lr 0.000910, 91910.72 tokens/sec
2025-04-25 13:59:24,987 - transformer_training - INFO - Main loop iteration: 9381
2025-04-25 13:59:25,447 - transformer_training - INFO - Main loop iteration: 9382
2025-04-25 13:59:25,898 - transformer_training - INFO - Main loop iteration: 9383
2025-04-25 13:59:26,397 - transformer_training - INFO - Main loop iteration: 9384
2025-04-25 13:59:26,798 - transformer_training - INFO - Main loop iteration: 9385
2025-04-25 13:59:27,259 - transformer_training - INFO - Main loop iteration: 9386
2025-04-25 13:59:27,709 - transformer_training - INFO - Main loop iteration: 9387
2025-04-25 13:59:28,207 - transformer_training - INFO - Main loop iteration: 9388
2025-04-25 13:59:28,608 - transformer_training - INFO - Main loop iteration: 9389
2025-04-25 13:59:29,069 - transformer_training - INFO - Main loop iteration: 9390
Iter 9390: loss 3.2413, lr 0.000910, 81964.59 tokens/sec
2025-04-25 13:59:29,520 - transformer_training - INFO - Main loop iteration: 9391
2025-04-25 13:59:30,018 - transformer_training - INFO - Main loop iteration: 9392
2025-04-25 13:59:30,419 - transformer_training - INFO - Main loop iteration: 9393
2025-04-25 13:59:30,880 - transformer_training - INFO - Main loop iteration: 9394
2025-04-25 13:59:31,331 - transformer_training - INFO - Main loop iteration: 9395
2025-04-25 13:59:31,829 - transformer_training - INFO - Main loop iteration: 9396
2025-04-25 13:59:32,231 - transformer_training - INFO - Main loop iteration: 9397
2025-04-25 13:59:32,691 - transformer_training - INFO - Main loop iteration: 9398
2025-04-25 13:59:33,142 - transformer_training - INFO - Main loop iteration: 9399
2025-04-25 13:59:33,640 - transformer_training - INFO - Main loop iteration: 9400
Iter 9400: loss 3.2223, lr 0.000909, 91935.96 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9400: train loss 2.7983, val loss 3.2390
New best model saved with val loss: 3.2390
2025-04-25 13:59:50,973 - transformer_training - INFO - Main loop iteration: 9401
2025-04-25 13:59:51,382 - transformer_training - INFO - Main loop iteration: 9402
2025-04-25 13:59:51,832 - transformer_training - INFO - Main loop iteration: 9403
2025-04-25 13:59:52,331 - transformer_training - INFO - Main loop iteration: 9404
2025-04-25 13:59:52,731 - transformer_training - INFO - Main loop iteration: 9405
2025-04-25 13:59:53,191 - transformer_training - INFO - Main loop iteration: 9406
2025-04-25 13:59:53,640 - transformer_training - INFO - Main loop iteration: 9407
2025-04-25 13:59:54,139 - transformer_training - INFO - Main loop iteration: 9408
2025-04-25 13:59:54,539 - transformer_training - INFO - Main loop iteration: 9409
2025-04-25 13:59:55,000 - transformer_training - INFO - Main loop iteration: 9410
Iter 9410: loss 3.2645, lr 0.000909, 81895.13 tokens/sec
2025-04-25 13:59:55,451 - transformer_training - INFO - Main loop iteration: 9411
2025-04-25 13:59:55,949 - transformer_training - INFO - Main loop iteration: 9412
2025-04-25 13:59:56,350 - transformer_training - INFO - Main loop iteration: 9413
2025-04-25 13:59:56,810 - transformer_training - INFO - Main loop iteration: 9414
2025-04-25 13:59:57,260 - transformer_training - INFO - Main loop iteration: 9415
2025-04-25 13:59:57,759 - transformer_training - INFO - Main loop iteration: 9416
2025-04-25 13:59:58,160 - transformer_training - INFO - Main loop iteration: 9417
2025-04-25 13:59:58,620 - transformer_training - INFO - Main loop iteration: 9418
2025-04-25 13:59:59,070 - transformer_training - INFO - Main loop iteration: 9419
2025-04-25 13:59:59,569 - transformer_training - INFO - Main loop iteration: 9420
Iter 9420: loss 3.2663, lr 0.000909, 91871.07 tokens/sec
2025-04-25 13:59:59,970 - transformer_training - INFO - Main loop iteration: 9421
2025-04-25 14:00:00,432 - transformer_training - INFO - Main loop iteration: 9422
2025-04-25 14:00:00,882 - transformer_training - INFO - Main loop iteration: 9423
2025-04-25 14:00:01,381 - transformer_training - INFO - Main loop iteration: 9424
2025-04-25 14:00:01,782 - transformer_training - INFO - Main loop iteration: 9425
2025-04-25 14:00:02,243 - transformer_training - INFO - Main loop iteration: 9426
2025-04-25 14:00:02,694 - transformer_training - INFO - Main loop iteration: 9427
2025-04-25 14:00:03,192 - transformer_training - INFO - Main loop iteration: 9428
2025-04-25 14:00:03,593 - transformer_training - INFO - Main loop iteration: 9429
2025-04-25 14:00:04,054 - transformer_training - INFO - Main loop iteration: 9430
Iter 9430: loss 3.2175, lr 0.000909, 81939.53 tokens/sec
2025-04-25 14:00:04,504 - transformer_training - INFO - Main loop iteration: 9431
2025-04-25 14:00:05,002 - transformer_training - INFO - Main loop iteration: 9432
2025-04-25 14:00:05,403 - transformer_training - INFO - Main loop iteration: 9433
2025-04-25 14:00:05,864 - transformer_training - INFO - Main loop iteration: 9434
2025-04-25 14:00:06,314 - transformer_training - INFO - Main loop iteration: 9435
2025-04-25 14:00:06,813 - transformer_training - INFO - Main loop iteration: 9436
2025-04-25 14:00:07,214 - transformer_training - INFO - Main loop iteration: 9437
2025-04-25 14:00:07,675 - transformer_training - INFO - Main loop iteration: 9438
2025-04-25 14:00:08,126 - transformer_training - INFO - Main loop iteration: 9439
2025-04-25 14:00:08,627 - transformer_training - INFO - Main loop iteration: 9440
Iter 9440: loss 3.1822, lr 0.000908, 91986.56 tokens/sec
2025-04-25 14:00:09,028 - transformer_training - INFO - Main loop iteration: 9441
2025-04-25 14:00:09,488 - transformer_training - INFO - Main loop iteration: 9442
2025-04-25 14:00:09,939 - transformer_training - INFO - Main loop iteration: 9443
2025-04-25 14:00:10,438 - transformer_training - INFO - Main loop iteration: 9444
2025-04-25 14:00:10,839 - transformer_training - INFO - Main loop iteration: 9445
2025-04-25 14:00:11,300 - transformer_training - INFO - Main loop iteration: 9446
2025-04-25 14:00:11,751 - transformer_training - INFO - Main loop iteration: 9447
2025-04-25 14:00:12,250 - transformer_training - INFO - Main loop iteration: 9448
2025-04-25 14:00:12,652 - transformer_training - INFO - Main loop iteration: 9449
2025-04-25 14:00:13,112 - transformer_training - INFO - Main loop iteration: 9450
Iter 9450: loss 3.2427, lr 0.000908, 81962.85 tokens/sec
2025-04-25 14:00:13,563 - transformer_training - INFO - Main loop iteration: 9451
2025-04-25 14:00:14,062 - transformer_training - INFO - Main loop iteration: 9452
2025-04-25 14:00:14,463 - transformer_training - INFO - Main loop iteration: 9453
2025-04-25 14:00:14,924 - transformer_training - INFO - Main loop iteration: 9454
2025-04-25 14:00:15,375 - transformer_training - INFO - Main loop iteration: 9455
2025-04-25 14:00:15,874 - transformer_training - INFO - Main loop iteration: 9456
2025-04-25 14:00:16,275 - transformer_training - INFO - Main loop iteration: 9457
2025-04-25 14:00:16,736 - transformer_training - INFO - Main loop iteration: 9458
2025-04-25 14:00:17,186 - transformer_training - INFO - Main loop iteration: 9459
2025-04-25 14:00:17,685 - transformer_training - INFO - Main loop iteration: 9460
Iter 9460: loss 3.2221, lr 0.000908, 91909.84 tokens/sec
2025-04-25 14:00:18,086 - transformer_training - INFO - Main loop iteration: 9461
2025-04-25 14:00:18,547 - transformer_training - INFO - Main loop iteration: 9462
2025-04-25 14:00:18,998 - transformer_training - INFO - Main loop iteration: 9463
2025-04-25 14:00:19,496 - transformer_training - INFO - Main loop iteration: 9464
2025-04-25 14:00:19,898 - transformer_training - INFO - Main loop iteration: 9465
2025-04-25 14:00:20,359 - transformer_training - INFO - Main loop iteration: 9466
2025-04-25 14:00:20,810 - transformer_training - INFO - Main loop iteration: 9467
2025-04-25 14:00:21,309 - transformer_training - INFO - Main loop iteration: 9468
2025-04-25 14:00:21,710 - transformer_training - INFO - Main loop iteration: 9469
2025-04-25 14:00:22,172 - transformer_training - INFO - Main loop iteration: 9470
Iter 9470: loss 3.2979, lr 0.000908, 81900.46 tokens/sec
2025-04-25 14:00:22,623 - transformer_training - INFO - Main loop iteration: 9471
2025-04-25 14:00:23,121 - transformer_training - INFO - Main loop iteration: 9472
2025-04-25 14:00:23,522 - transformer_training - INFO - Main loop iteration: 9473
2025-04-25 14:00:23,984 - transformer_training - INFO - Main loop iteration: 9474
2025-04-25 14:00:24,434 - transformer_training - INFO - Main loop iteration: 9475
2025-04-25 14:00:24,934 - transformer_training - INFO - Main loop iteration: 9476
2025-04-25 14:00:25,335 - transformer_training - INFO - Main loop iteration: 9477
2025-04-25 14:00:25,797 - transformer_training - INFO - Main loop iteration: 9478
2025-04-25 14:00:26,248 - transformer_training - INFO - Main loop iteration: 9479
2025-04-25 14:00:26,748 - transformer_training - INFO - Main loop iteration: 9480
Iter 9480: loss 3.1937, lr 0.000908, 91889.85 tokens/sec
2025-04-25 14:00:27,150 - transformer_training - INFO - Main loop iteration: 9481
2025-04-25 14:00:27,611 - transformer_training - INFO - Main loop iteration: 9482
2025-04-25 14:00:28,061 - transformer_training - INFO - Main loop iteration: 9483
2025-04-25 14:00:28,560 - transformer_training - INFO - Main loop iteration: 9484
2025-04-25 14:00:28,961 - transformer_training - INFO - Main loop iteration: 9485
2025-04-25 14:00:29,423 - transformer_training - INFO - Main loop iteration: 9486
2025-04-25 14:00:29,873 - transformer_training - INFO - Main loop iteration: 9487
2025-04-25 14:00:30,372 - transformer_training - INFO - Main loop iteration: 9488
2025-04-25 14:00:30,773 - transformer_training - INFO - Main loop iteration: 9489
2025-04-25 14:00:31,234 - transformer_training - INFO - Main loop iteration: 9490
Iter 9490: loss 3.2676, lr 0.000907, 81905.97 tokens/sec
2025-04-25 14:00:31,685 - transformer_training - INFO - Main loop iteration: 9491
2025-04-25 14:00:32,184 - transformer_training - INFO - Main loop iteration: 9492
2025-04-25 14:00:32,586 - transformer_training - INFO - Main loop iteration: 9493
2025-04-25 14:00:33,047 - transformer_training - INFO - Main loop iteration: 9494
2025-04-25 14:00:33,498 - transformer_training - INFO - Main loop iteration: 9495
2025-04-25 14:00:33,997 - transformer_training - INFO - Main loop iteration: 9496
2025-04-25 14:00:34,398 - transformer_training - INFO - Main loop iteration: 9497
2025-04-25 14:00:34,859 - transformer_training - INFO - Main loop iteration: 9498
2025-04-25 14:00:35,309 - transformer_training - INFO - Main loop iteration: 9499
2025-04-25 14:00:35,808 - transformer_training - INFO - Main loop iteration: 9500
Iter 9500: loss 3.2622, lr 0.000907, 91713.09 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9500: train loss 2.8482, val loss 3.2294
New best model saved with val loss: 3.2294
2025-04-25 14:00:54,810 - transformer_training - INFO - Main loop iteration: 9501
2025-04-25 14:00:55,227 - transformer_training - INFO - Main loop iteration: 9502
2025-04-25 14:00:55,677 - transformer_training - INFO - Main loop iteration: 9503
2025-04-25 14:00:56,175 - transformer_training - INFO - Main loop iteration: 9504
2025-04-25 14:00:56,576 - transformer_training - INFO - Main loop iteration: 9505
2025-04-25 14:00:57,036 - transformer_training - INFO - Main loop iteration: 9506
2025-04-25 14:00:57,486 - transformer_training - INFO - Main loop iteration: 9507
2025-04-25 14:00:57,985 - transformer_training - INFO - Main loop iteration: 9508
2025-04-25 14:00:58,386 - transformer_training - INFO - Main loop iteration: 9509
2025-04-25 14:00:58,847 - transformer_training - INFO - Main loop iteration: 9510
Iter 9510: loss 3.2774, lr 0.000907, 82018.37 tokens/sec
2025-04-25 14:00:59,297 - transformer_training - INFO - Main loop iteration: 9511
2025-04-25 14:00:59,795 - transformer_training - INFO - Main loop iteration: 9512
2025-04-25 14:01:00,196 - transformer_training - INFO - Main loop iteration: 9513
2025-04-25 14:01:00,657 - transformer_training - INFO - Main loop iteration: 9514
2025-04-25 14:01:01,107 - transformer_training - INFO - Main loop iteration: 9515
2025-04-25 14:01:01,605 - transformer_training - INFO - Main loop iteration: 9516
2025-04-25 14:01:02,006 - transformer_training - INFO - Main loop iteration: 9517
2025-04-25 14:01:02,467 - transformer_training - INFO - Main loop iteration: 9518
2025-04-25 14:01:02,917 - transformer_training - INFO - Main loop iteration: 9519
2025-04-25 14:01:03,416 - transformer_training - INFO - Main loop iteration: 9520
Iter 9520: loss 3.2229, lr 0.000907, 91996.85 tokens/sec
2025-04-25 14:01:03,817 - transformer_training - INFO - Main loop iteration: 9521
2025-04-25 14:01:04,278 - transformer_training - INFO - Main loop iteration: 9522
2025-04-25 14:01:04,728 - transformer_training - INFO - Main loop iteration: 9523
2025-04-25 14:01:05,227 - transformer_training - INFO - Main loop iteration: 9524
2025-04-25 14:01:05,628 - transformer_training - INFO - Main loop iteration: 9525
2025-04-25 14:01:06,088 - transformer_training - INFO - Main loop iteration: 9526
2025-04-25 14:01:06,538 - transformer_training - INFO - Main loop iteration: 9527
2025-04-25 14:01:07,038 - transformer_training - INFO - Main loop iteration: 9528
2025-04-25 14:01:07,438 - transformer_training - INFO - Main loop iteration: 9529
2025-04-25 14:01:07,899 - transformer_training - INFO - Main loop iteration: 9530
Iter 9530: loss 3.2780, lr 0.000906, 81845.80 tokens/sec
2025-04-25 14:01:08,349 - transformer_training - INFO - Main loop iteration: 9531
2025-04-25 14:01:08,848 - transformer_training - INFO - Main loop iteration: 9532
2025-04-25 14:01:09,248 - transformer_training - INFO - Main loop iteration: 9533
2025-04-25 14:01:09,709 - transformer_training - INFO - Main loop iteration: 9534
2025-04-25 14:01:10,159 - transformer_training - INFO - Main loop iteration: 9535
2025-04-25 14:01:10,658 - transformer_training - INFO - Main loop iteration: 9536
2025-04-25 14:01:11,059 - transformer_training - INFO - Main loop iteration: 9537
2025-04-25 14:01:11,519 - transformer_training - INFO - Main loop iteration: 9538
2025-04-25 14:01:11,970 - transformer_training - INFO - Main loop iteration: 9539
2025-04-25 14:01:12,470 - transformer_training - INFO - Main loop iteration: 9540
Iter 9540: loss 3.1470, lr 0.000906, 91974.52 tokens/sec
2025-04-25 14:01:12,871 - transformer_training - INFO - Main loop iteration: 9541
2025-04-25 14:01:13,331 - transformer_training - INFO - Main loop iteration: 9542
2025-04-25 14:01:13,782 - transformer_training - INFO - Main loop iteration: 9543
2025-04-25 14:01:14,283 - transformer_training - INFO - Main loop iteration: 9544
2025-04-25 14:01:14,685 - transformer_training - INFO - Main loop iteration: 9545
2025-04-25 14:01:15,146 - transformer_training - INFO - Main loop iteration: 9546
2025-04-25 14:01:15,596 - transformer_training - INFO - Main loop iteration: 9547
2025-04-25 14:01:16,095 - transformer_training - INFO - Main loop iteration: 9548
2025-04-25 14:01:16,497 - transformer_training - INFO - Main loop iteration: 9549
2025-04-25 14:01:16,959 - transformer_training - INFO - Main loop iteration: 9550
Iter 9550: loss 3.1514, lr 0.000906, 81864.21 tokens/sec
2025-04-25 14:01:17,409 - transformer_training - INFO - Main loop iteration: 9551
2025-04-25 14:01:17,909 - transformer_training - INFO - Main loop iteration: 9552
2025-04-25 14:01:18,311 - transformer_training - INFO - Main loop iteration: 9553
2025-04-25 14:01:18,772 - transformer_training - INFO - Main loop iteration: 9554
2025-04-25 14:01:19,223 - transformer_training - INFO - Main loop iteration: 9555
2025-04-25 14:01:19,722 - transformer_training - INFO - Main loop iteration: 9556
2025-04-25 14:01:20,124 - transformer_training - INFO - Main loop iteration: 9557
2025-04-25 14:01:20,585 - transformer_training - INFO - Main loop iteration: 9558
2025-04-25 14:01:21,036 - transformer_training - INFO - Main loop iteration: 9559
2025-04-25 14:01:21,534 - transformer_training - INFO - Main loop iteration: 9560
Iter 9560: loss 3.2210, lr 0.000906, 91926.23 tokens/sec
2025-04-25 14:01:21,936 - transformer_training - INFO - Main loop iteration: 9561
2025-04-25 14:01:22,397 - transformer_training - INFO - Main loop iteration: 9562
2025-04-25 14:01:22,847 - transformer_training - INFO - Main loop iteration: 9563
2025-04-25 14:01:23,346 - transformer_training - INFO - Main loop iteration: 9564
2025-04-25 14:01:23,748 - transformer_training - INFO - Main loop iteration: 9565
2025-04-25 14:01:24,209 - transformer_training - INFO - Main loop iteration: 9566
2025-04-25 14:01:24,659 - transformer_training - INFO - Main loop iteration: 9567
2025-04-25 14:01:25,158 - transformer_training - INFO - Main loop iteration: 9568
2025-04-25 14:01:25,559 - transformer_training - INFO - Main loop iteration: 9569
2025-04-25 14:01:26,020 - transformer_training - INFO - Main loop iteration: 9570
Iter 9570: loss 3.2452, lr 0.000905, 81737.15 tokens/sec
2025-04-25 14:01:26,472 - transformer_training - INFO - Main loop iteration: 9571
2025-04-25 14:01:26,971 - transformer_training - INFO - Main loop iteration: 9572
2025-04-25 14:01:27,372 - transformer_training - INFO - Main loop iteration: 9573
2025-04-25 14:01:27,833 - transformer_training - INFO - Main loop iteration: 9574
2025-04-25 14:01:28,284 - transformer_training - INFO - Main loop iteration: 9575
2025-04-25 14:01:28,783 - transformer_training - INFO - Main loop iteration: 9576
2025-04-25 14:01:29,184 - transformer_training - INFO - Main loop iteration: 9577
2025-04-25 14:01:29,645 - transformer_training - INFO - Main loop iteration: 9578
2025-04-25 14:01:30,096 - transformer_training - INFO - Main loop iteration: 9579
2025-04-25 14:01:30,594 - transformer_training - INFO - Main loop iteration: 9580
Iter 9580: loss 3.3259, lr 0.000905, 91849.62 tokens/sec
2025-04-25 14:01:30,996 - transformer_training - INFO - Main loop iteration: 9581
2025-04-25 14:01:31,457 - transformer_training - INFO - Main loop iteration: 9582
2025-04-25 14:01:31,908 - transformer_training - INFO - Main loop iteration: 9583
2025-04-25 14:01:32,408 - transformer_training - INFO - Main loop iteration: 9584
2025-04-25 14:01:32,809 - transformer_training - INFO - Main loop iteration: 9585
2025-04-25 14:01:33,270 - transformer_training - INFO - Main loop iteration: 9586
2025-04-25 14:01:33,721 - transformer_training - INFO - Main loop iteration: 9587
2025-04-25 14:01:34,221 - transformer_training - INFO - Main loop iteration: 9588
2025-04-25 14:01:34,622 - transformer_training - INFO - Main loop iteration: 9589
2025-04-25 14:01:35,084 - transformer_training - INFO - Main loop iteration: 9590
Iter 9590: loss 3.2490, lr 0.000905, 81846.53 tokens/sec
2025-04-25 14:01:35,535 - transformer_training - INFO - Main loop iteration: 9591
2025-04-25 14:01:36,033 - transformer_training - INFO - Main loop iteration: 9592
2025-04-25 14:01:36,435 - transformer_training - INFO - Main loop iteration: 9593
2025-04-25 14:01:36,897 - transformer_training - INFO - Main loop iteration: 9594
2025-04-25 14:01:37,348 - transformer_training - INFO - Main loop iteration: 9595
2025-04-25 14:01:37,847 - transformer_training - INFO - Main loop iteration: 9596
2025-04-25 14:01:38,248 - transformer_training - INFO - Main loop iteration: 9597
2025-04-25 14:01:38,710 - transformer_training - INFO - Main loop iteration: 9598
2025-04-25 14:01:39,160 - transformer_training - INFO - Main loop iteration: 9599
2025-04-25 14:01:39,659 - transformer_training - INFO - Main loop iteration: 9600
Iter 9600: loss 3.2428, lr 0.000905, 91782.45 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
terminate called without an active exception
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9600: train loss 2.8754, val loss 3.2315
2025-04-25 14:01:55,767 - transformer_training - INFO - Main loop iteration: 9601
2025-04-25 14:01:56,177 - transformer_training - INFO - Main loop iteration: 9602
2025-04-25 14:01:56,628 - transformer_training - INFO - Main loop iteration: 9603
2025-04-25 14:01:57,127 - transformer_training - INFO - Main loop iteration: 9604
2025-04-25 14:01:57,528 - transformer_training - INFO - Main loop iteration: 9605
2025-04-25 14:01:57,989 - transformer_training - INFO - Main loop iteration: 9606
2025-04-25 14:01:58,439 - transformer_training - INFO - Main loop iteration: 9607
2025-04-25 14:01:58,938 - transformer_training - INFO - Main loop iteration: 9608
2025-04-25 14:01:59,338 - transformer_training - INFO - Main loop iteration: 9609
2025-04-25 14:01:59,799 - transformer_training - INFO - Main loop iteration: 9610
Iter 9610: loss 3.2195, lr 0.000904, 81936.27 tokens/sec
2025-04-25 14:02:00,250 - transformer_training - INFO - Main loop iteration: 9611
2025-04-25 14:02:00,751 - transformer_training - INFO - Main loop iteration: 9612
2025-04-25 14:02:01,150 - transformer_training - INFO - Main loop iteration: 9613
2025-04-25 14:02:01,611 - transformer_training - INFO - Main loop iteration: 9614
2025-04-25 14:02:02,062 - transformer_training - INFO - Main loop iteration: 9615
2025-04-25 14:02:02,562 - transformer_training - INFO - Main loop iteration: 9616
2025-04-25 14:02:02,963 - transformer_training - INFO - Main loop iteration: 9617
2025-04-25 14:02:03,424 - transformer_training - INFO - Main loop iteration: 9618
2025-04-25 14:02:03,873 - transformer_training - INFO - Main loop iteration: 9619
2025-04-25 14:02:04,372 - transformer_training - INFO - Main loop iteration: 9620
Iter 9620: loss 3.2266, lr 0.000904, 92026.41 tokens/sec
2025-04-25 14:02:04,773 - transformer_training - INFO - Main loop iteration: 9621
2025-04-25 14:02:05,234 - transformer_training - INFO - Main loop iteration: 9622
2025-04-25 14:02:05,684 - transformer_training - INFO - Main loop iteration: 9623
2025-04-25 14:02:06,184 - transformer_training - INFO - Main loop iteration: 9624
2025-04-25 14:02:06,586 - transformer_training - INFO - Main loop iteration: 9625
2025-04-25 14:02:07,048 - transformer_training - INFO - Main loop iteration: 9626
2025-04-25 14:02:07,498 - transformer_training - INFO - Main loop iteration: 9627
2025-04-25 14:02:07,999 - transformer_training - INFO - Main loop iteration: 9628
2025-04-25 14:02:08,399 - transformer_training - INFO - Main loop iteration: 9629
2025-04-25 14:02:08,859 - transformer_training - INFO - Main loop iteration: 9630
Iter 9630: loss 3.2878, lr 0.000904, 81870.93 tokens/sec
2025-04-25 14:02:09,310 - transformer_training - INFO - Main loop iteration: 9631
2025-04-25 14:02:09,809 - transformer_training - INFO - Main loop iteration: 9632
2025-04-25 14:02:10,209 - transformer_training - INFO - Main loop iteration: 9633
2025-04-25 14:02:10,670 - transformer_training - INFO - Main loop iteration: 9634
2025-04-25 14:02:11,122 - transformer_training - INFO - Main loop iteration: 9635
2025-04-25 14:02:11,621 - transformer_training - INFO - Main loop iteration: 9636
2025-04-25 14:02:12,022 - transformer_training - INFO - Main loop iteration: 9637
2025-04-25 14:02:12,483 - transformer_training - INFO - Main loop iteration: 9638
2025-04-25 14:02:12,934 - transformer_training - INFO - Main loop iteration: 9639
2025-04-25 14:02:13,433 - transformer_training - INFO - Main loop iteration: 9640
Iter 9640: loss 3.2324, lr 0.000904, 91918.04 tokens/sec
2025-04-25 14:02:13,834 - transformer_training - INFO - Main loop iteration: 9641
2025-04-25 14:02:14,295 - transformer_training - INFO - Main loop iteration: 9642
2025-04-25 14:02:14,745 - transformer_training - INFO - Main loop iteration: 9643
2025-04-25 14:02:15,244 - transformer_training - INFO - Main loop iteration: 9644
2025-04-25 14:02:15,646 - transformer_training - INFO - Main loop iteration: 9645
2025-04-25 14:02:16,107 - transformer_training - INFO - Main loop iteration: 9646
2025-04-25 14:02:16,558 - transformer_training - INFO - Main loop iteration: 9647
2025-04-25 14:02:17,056 - transformer_training - INFO - Main loop iteration: 9648
2025-04-25 14:02:17,457 - transformer_training - INFO - Main loop iteration: 9649
2025-04-25 14:02:17,918 - transformer_training - INFO - Main loop iteration: 9650
Iter 9650: loss 3.2470, lr 0.000903, 81772.86 tokens/sec
2025-04-25 14:02:18,370 - transformer_training - INFO - Main loop iteration: 9651
2025-04-25 14:02:18,869 - transformer_training - INFO - Main loop iteration: 9652
2025-04-25 14:02:19,270 - transformer_training - INFO - Main loop iteration: 9653
2025-04-25 14:02:19,730 - transformer_training - INFO - Main loop iteration: 9654
2025-04-25 14:02:20,181 - transformer_training - INFO - Main loop iteration: 9655
2025-04-25 14:02:20,680 - transformer_training - INFO - Main loop iteration: 9656
2025-04-25 14:02:21,081 - transformer_training - INFO - Main loop iteration: 9657
2025-04-25 14:02:21,542 - transformer_training - INFO - Main loop iteration: 9658
2025-04-25 14:02:21,993 - transformer_training - INFO - Main loop iteration: 9659
2025-04-25 14:02:22,495 - transformer_training - INFO - Main loop iteration: 9660
Iter 9660: loss 3.2746, lr 0.000903, 92304.79 tokens/sec
2025-04-25 14:02:22,895 - transformer_training - INFO - Main loop iteration: 9661
2025-04-25 14:02:23,356 - transformer_training - INFO - Main loop iteration: 9662
2025-04-25 14:02:23,806 - transformer_training - INFO - Main loop iteration: 9663
2025-04-25 14:02:24,305 - transformer_training - INFO - Main loop iteration: 9664
2025-04-25 14:02:24,706 - transformer_training - INFO - Main loop iteration: 9665
2025-04-25 14:02:25,167 - transformer_training - INFO - Main loop iteration: 9666
2025-04-25 14:02:25,618 - transformer_training - INFO - Main loop iteration: 9667
2025-04-25 14:02:26,116 - transformer_training - INFO - Main loop iteration: 9668
2025-04-25 14:02:26,518 - transformer_training - INFO - Main loop iteration: 9669
2025-04-25 14:02:26,979 - transformer_training - INFO - Main loop iteration: 9670
Iter 9670: loss 3.2724, lr 0.000903, 81880.69 tokens/sec
2025-04-25 14:02:27,430 - transformer_training - INFO - Main loop iteration: 9671
2025-04-25 14:02:27,929 - transformer_training - INFO - Main loop iteration: 9672
2025-04-25 14:02:28,330 - transformer_training - INFO - Main loop iteration: 9673
2025-04-25 14:02:28,791 - transformer_training - INFO - Main loop iteration: 9674
2025-04-25 14:02:29,243 - transformer_training - INFO - Main loop iteration: 9675
2025-04-25 14:02:29,742 - transformer_training - INFO - Main loop iteration: 9676
2025-04-25 14:02:30,143 - transformer_training - INFO - Main loop iteration: 9677
2025-04-25 14:02:30,604 - transformer_training - INFO - Main loop iteration: 9678
2025-04-25 14:02:31,055 - transformer_training - INFO - Main loop iteration: 9679
2025-04-25 14:02:31,555 - transformer_training - INFO - Main loop iteration: 9680
Iter 9680: loss 3.2212, lr 0.000903, 92045.86 tokens/sec
2025-04-25 14:02:31,956 - transformer_training - INFO - Main loop iteration: 9681
2025-04-25 14:02:32,418 - transformer_training - INFO - Main loop iteration: 9682
2025-04-25 14:02:32,868 - transformer_training - INFO - Main loop iteration: 9683
2025-04-25 14:02:33,367 - transformer_training - INFO - Main loop iteration: 9684
2025-04-25 14:02:33,768 - transformer_training - INFO - Main loop iteration: 9685
2025-04-25 14:02:34,229 - transformer_training - INFO - Main loop iteration: 9686
2025-04-25 14:02:34,680 - transformer_training - INFO - Main loop iteration: 9687
2025-04-25 14:02:35,179 - transformer_training - INFO - Main loop iteration: 9688
2025-04-25 14:02:35,580 - transformer_training - INFO - Main loop iteration: 9689
2025-04-25 14:02:36,041 - transformer_training - INFO - Main loop iteration: 9690
Iter 9690: loss 3.2873, lr 0.000902, 81827.99 tokens/sec
2025-04-25 14:02:36,492 - transformer_training - INFO - Main loop iteration: 9691
2025-04-25 14:02:36,991 - transformer_training - INFO - Main loop iteration: 9692
2025-04-25 14:02:37,392 - transformer_training - INFO - Main loop iteration: 9693
2025-04-25 14:02:37,854 - transformer_training - INFO - Main loop iteration: 9694
2025-04-25 14:02:38,305 - transformer_training - INFO - Main loop iteration: 9695
2025-04-25 14:02:38,804 - transformer_training - INFO - Main loop iteration: 9696
2025-04-25 14:02:39,205 - transformer_training - INFO - Main loop iteration: 9697
2025-04-25 14:02:39,667 - transformer_training - INFO - Main loop iteration: 9698
2025-04-25 14:02:40,118 - transformer_training - INFO - Main loop iteration: 9699
2025-04-25 14:02:40,617 - transformer_training - INFO - Main loop iteration: 9700
Iter 9700: loss 3.2851, lr 0.000902, 91770.63 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!Flash Attention is available!

Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9700: train loss 2.8980, val loss 3.2279
New best model saved with val loss: 3.2279
2025-04-25 14:02:57,685 - transformer_training - INFO - Main loop iteration: 9701
2025-04-25 14:02:58,097 - transformer_training - INFO - Main loop iteration: 9702
2025-04-25 14:02:58,545 - transformer_training - INFO - Main loop iteration: 9703
2025-04-25 14:02:59,044 - transformer_training - INFO - Main loop iteration: 9704
2025-04-25 14:02:59,446 - transformer_training - INFO - Main loop iteration: 9705
2025-04-25 14:02:59,906 - transformer_training - INFO - Main loop iteration: 9706
2025-04-25 14:03:00,356 - transformer_training - INFO - Main loop iteration: 9707
2025-04-25 14:03:00,855 - transformer_training - INFO - Main loop iteration: 9708
2025-04-25 14:03:01,256 - transformer_training - INFO - Main loop iteration: 9709
2025-04-25 14:03:01,717 - transformer_training - INFO - Main loop iteration: 9710
Iter 9710: loss 3.2915, lr 0.000902, 81882.90 tokens/sec
2025-04-25 14:03:02,167 - transformer_training - INFO - Main loop iteration: 9711
2025-04-25 14:03:02,666 - transformer_training - INFO - Main loop iteration: 9712
2025-04-25 14:03:03,067 - transformer_training - INFO - Main loop iteration: 9713
2025-04-25 14:03:03,528 - transformer_training - INFO - Main loop iteration: 9714
2025-04-25 14:03:03,979 - transformer_training - INFO - Main loop iteration: 9715
2025-04-25 14:03:04,478 - transformer_training - INFO - Main loop iteration: 9716
2025-04-25 14:03:04,879 - transformer_training - INFO - Main loop iteration: 9717
2025-04-25 14:03:05,341 - transformer_training - INFO - Main loop iteration: 9718
2025-04-25 14:03:05,792 - transformer_training - INFO - Main loop iteration: 9719
2025-04-25 14:03:06,290 - transformer_training - INFO - Main loop iteration: 9720
Iter 9720: loss 3.0745, lr 0.000902, 91903.61 tokens/sec
2025-04-25 14:03:06,691 - transformer_training - INFO - Main loop iteration: 9721
2025-04-25 14:03:07,153 - transformer_training - INFO - Main loop iteration: 9722
2025-04-25 14:03:07,603 - transformer_training - INFO - Main loop iteration: 9723
2025-04-25 14:03:08,102 - transformer_training - INFO - Main loop iteration: 9724
2025-04-25 14:03:08,503 - transformer_training - INFO - Main loop iteration: 9725
2025-04-25 14:03:08,965 - transformer_training - INFO - Main loop iteration: 9726
2025-04-25 14:03:09,416 - transformer_training - INFO - Main loop iteration: 9727
2025-04-25 14:03:09,914 - transformer_training - INFO - Main loop iteration: 9728
2025-04-25 14:03:10,316 - transformer_training - INFO - Main loop iteration: 9729
2025-04-25 14:03:10,777 - transformer_training - INFO - Main loop iteration: 9730
Iter 9730: loss 3.2868, lr 0.000901, 81923.46 tokens/sec
2025-04-25 14:03:11,228 - transformer_training - INFO - Main loop iteration: 9731
2025-04-25 14:03:11,727 - transformer_training - INFO - Main loop iteration: 9732
2025-04-25 14:03:12,129 - transformer_training - INFO - Main loop iteration: 9733
2025-04-25 14:03:12,591 - transformer_training - INFO - Main loop iteration: 9734
2025-04-25 14:03:13,042 - transformer_training - INFO - Main loop iteration: 9735
2025-04-25 14:03:13,541 - transformer_training - INFO - Main loop iteration: 9736
2025-04-25 14:03:13,942 - transformer_training - INFO - Main loop iteration: 9737
2025-04-25 14:03:14,501 - transformer_training - INFO - Main loop iteration: 9738
2025-04-25 14:03:14,952 - transformer_training - INFO - Main loop iteration: 9739
2025-04-25 14:03:15,451 - transformer_training - INFO - Main loop iteration: 9740
Iter 9740: loss 3.2629, lr 0.000901, 91914.92 tokens/sec
2025-04-25 14:03:15,852 - transformer_training - INFO - Main loop iteration: 9741
2025-04-25 14:03:16,313 - transformer_training - INFO - Main loop iteration: 9742
2025-04-25 14:03:16,764 - transformer_training - INFO - Main loop iteration: 9743
2025-04-25 14:03:17,264 - transformer_training - INFO - Main loop iteration: 9744
2025-04-25 14:03:17,665 - transformer_training - INFO - Main loop iteration: 9745
2025-04-25 14:03:18,126 - transformer_training - INFO - Main loop iteration: 9746
2025-04-25 14:03:18,577 - transformer_training - INFO - Main loop iteration: 9747
2025-04-25 14:03:19,076 - transformer_training - INFO - Main loop iteration: 9748
2025-04-25 14:03:19,478 - transformer_training - INFO - Main loop iteration: 9749
2025-04-25 14:03:19,939 - transformer_training - INFO - Main loop iteration: 9750
Iter 9750: loss 3.2035, lr 0.000901, 81821.67 tokens/sec
2025-04-25 14:03:20,390 - transformer_training - INFO - Main loop iteration: 9751
2025-04-25 14:03:20,889 - transformer_training - INFO - Main loop iteration: 9752
2025-04-25 14:03:21,290 - transformer_training - INFO - Main loop iteration: 9753
2025-04-25 14:03:21,751 - transformer_training - INFO - Main loop iteration: 9754
2025-04-25 14:03:22,203 - transformer_training - INFO - Main loop iteration: 9755
2025-04-25 14:03:22,701 - transformer_training - INFO - Main loop iteration: 9756
2025-04-25 14:03:23,103 - transformer_training - INFO - Main loop iteration: 9757
2025-04-25 14:03:23,565 - transformer_training - INFO - Main loop iteration: 9758
2025-04-25 14:03:24,016 - transformer_training - INFO - Main loop iteration: 9759
2025-04-25 14:03:24,516 - transformer_training - INFO - Main loop iteration: 9760
Iter 9760: loss 3.3029, lr 0.000901, 91847.33 tokens/sec
2025-04-25 14:03:24,917 - transformer_training - INFO - Main loop iteration: 9761
2025-04-25 14:03:25,378 - transformer_training - INFO - Main loop iteration: 9762
2025-04-25 14:03:25,829 - transformer_training - INFO - Main loop iteration: 9763
2025-04-25 14:03:26,328 - transformer_training - INFO - Main loop iteration: 9764
2025-04-25 14:03:26,729 - transformer_training - INFO - Main loop iteration: 9765
2025-04-25 14:03:27,191 - transformer_training - INFO - Main loop iteration: 9766
2025-04-25 14:03:27,642 - transformer_training - INFO - Main loop iteration: 9767
2025-04-25 14:03:28,140 - transformer_training - INFO - Main loop iteration: 9768
2025-04-25 14:03:28,543 - transformer_training - INFO - Main loop iteration: 9769
2025-04-25 14:03:29,004 - transformer_training - INFO - Main loop iteration: 9770
Iter 9770: loss 3.2074, lr 0.000900, 81947.00 tokens/sec
2025-04-25 14:03:29,454 - transformer_training - INFO - Main loop iteration: 9771
2025-04-25 14:03:29,952 - transformer_training - INFO - Main loop iteration: 9772
2025-04-25 14:03:30,353 - transformer_training - INFO - Main loop iteration: 9773
2025-04-25 14:03:30,814 - transformer_training - INFO - Main loop iteration: 9774
2025-04-25 14:03:31,265 - transformer_training - INFO - Main loop iteration: 9775
2025-04-25 14:03:31,764 - transformer_training - INFO - Main loop iteration: 9776
2025-04-25 14:03:32,166 - transformer_training - INFO - Main loop iteration: 9777
2025-04-25 14:03:32,627 - transformer_training - INFO - Main loop iteration: 9778
2025-04-25 14:03:33,078 - transformer_training - INFO - Main loop iteration: 9779
2025-04-25 14:03:33,577 - transformer_training - INFO - Main loop iteration: 9780
Iter 9780: loss 3.2496, lr 0.000900, 91860.64 tokens/sec
2025-04-25 14:03:33,978 - transformer_training - INFO - Main loop iteration: 9781
2025-04-25 14:03:34,439 - transformer_training - INFO - Main loop iteration: 9782
2025-04-25 14:03:34,890 - transformer_training - INFO - Main loop iteration: 9783
2025-04-25 14:03:35,389 - transformer_training - INFO - Main loop iteration: 9784
2025-04-25 14:03:35,791 - transformer_training - INFO - Main loop iteration: 9785
2025-04-25 14:03:36,253 - transformer_training - INFO - Main loop iteration: 9786
2025-04-25 14:03:36,703 - transformer_training - INFO - Main loop iteration: 9787
2025-04-25 14:03:37,203 - transformer_training - INFO - Main loop iteration: 9788
2025-04-25 14:03:37,605 - transformer_training - INFO - Main loop iteration: 9789
2025-04-25 14:03:38,066 - transformer_training - INFO - Main loop iteration: 9790
Iter 9790: loss 3.2307, lr 0.000900, 81845.02 tokens/sec
2025-04-25 14:03:38,517 - transformer_training - INFO - Main loop iteration: 9791
2025-04-25 14:03:39,016 - transformer_training - INFO - Main loop iteration: 9792
2025-04-25 14:03:39,418 - transformer_training - INFO - Main loop iteration: 9793
2025-04-25 14:03:39,880 - transformer_training - INFO - Main loop iteration: 9794
2025-04-25 14:03:40,330 - transformer_training - INFO - Main loop iteration: 9795
2025-04-25 14:03:40,829 - transformer_training - INFO - Main loop iteration: 9796
2025-04-25 14:03:41,234 - transformer_training - INFO - Main loop iteration: 9797
2025-04-25 14:03:41,694 - transformer_training - INFO - Main loop iteration: 9798
2025-04-25 14:03:42,145 - transformer_training - INFO - Main loop iteration: 9799
2025-04-25 14:03:42,645 - transformer_training - INFO - Main loop iteration: 9800
Iter 9800: loss 3.2363, lr 0.000900, 91750.80 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPTYour base folder is: /workspace/GPT

Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Iter 9800: train loss 2.9152, val loss 3.2245
New best model saved with val loss: 3.2245
2025-04-25 14:04:01,161 - transformer_training - INFO - Main loop iteration: 9801
2025-04-25 14:04:01,580 - transformer_training - INFO - Main loop iteration: 9802
2025-04-25 14:04:02,030 - transformer_training - INFO - Main loop iteration: 9803
2025-04-25 14:04:02,529 - transformer_training - INFO - Main loop iteration: 9804
2025-04-25 14:04:02,929 - transformer_training - INFO - Main loop iteration: 9805
2025-04-25 14:04:03,390 - transformer_training - INFO - Main loop iteration: 9806
2025-04-25 14:04:03,840 - transformer_training - INFO - Main loop iteration: 9807
2025-04-25 14:04:04,338 - transformer_training - INFO - Main loop iteration: 9808
2025-04-25 14:04:04,739 - transformer_training - INFO - Main loop iteration: 9809
2025-04-25 14:04:05,200 - transformer_training - INFO - Main loop iteration: 9810
Iter 9810: loss 3.2656, lr 0.000899, 81997.19 tokens/sec
2025-04-25 14:04:05,650 - transformer_training - INFO - Main loop iteration: 9811
2025-04-25 14:04:06,148 - transformer_training - INFO - Main loop iteration: 9812
2025-04-25 14:04:06,549 - transformer_training - INFO - Main loop iteration: 9813
2025-04-25 14:04:07,010 - transformer_training - INFO - Main loop iteration: 9814
2025-04-25 14:04:07,460 - transformer_training - INFO - Main loop iteration: 9815
2025-04-25 14:04:07,958 - transformer_training - INFO - Main loop iteration: 9816
2025-04-25 14:04:08,359 - transformer_training - INFO - Main loop iteration: 9817
2025-04-25 14:04:08,820 - transformer_training - INFO - Main loop iteration: 9818
2025-04-25 14:04:09,270 - transformer_training - INFO - Main loop iteration: 9819
2025-04-25 14:04:09,770 - transformer_training - INFO - Main loop iteration: 9820
Iter 9820: loss 3.2141, lr 0.000899, 92066.47 tokens/sec
2025-04-25 14:04:10,171 - transformer_training - INFO - Main loop iteration: 9821
2025-04-25 14:04:10,631 - transformer_training - INFO - Main loop iteration: 9822
2025-04-25 14:04:11,082 - transformer_training - INFO - Main loop iteration: 9823
2025-04-25 14:04:11,580 - transformer_training - INFO - Main loop iteration: 9824
2025-04-25 14:04:11,981 - transformer_training - INFO - Main loop iteration: 9825
2025-04-25 14:04:12,442 - transformer_training - INFO - Main loop iteration: 9826
2025-04-25 14:04:12,893 - transformer_training - INFO - Main loop iteration: 9827
2025-04-25 14:04:13,392 - transformer_training - INFO - Main loop iteration: 9828
2025-04-25 14:04:13,793 - transformer_training - INFO - Main loop iteration: 9829
2025-04-25 14:04:14,255 - transformer_training - INFO - Main loop iteration: 9830
Iter 9830: loss 3.2155, lr 0.000899, 81869.37 tokens/sec
2025-04-25 14:04:14,706 - transformer_training - INFO - Main loop iteration: 9831
2025-04-25 14:04:15,205 - transformer_training - INFO - Main loop iteration: 9832
2025-04-25 14:04:15,605 - transformer_training - INFO - Main loop iteration: 9833
2025-04-25 14:04:16,066 - transformer_training - INFO - Main loop iteration: 9834
2025-04-25 14:04:16,516 - transformer_training - INFO - Main loop iteration: 9835
2025-04-25 14:04:17,016 - transformer_training - INFO - Main loop iteration: 9836
2025-04-25 14:04:17,417 - transformer_training - INFO - Main loop iteration: 9837
2025-04-25 14:04:17,878 - transformer_training - INFO - Main loop iteration: 9838
2025-04-25 14:04:18,328 - transformer_training - INFO - Main loop iteration: 9839
2025-04-25 14:04:18,827 - transformer_training - INFO - Main loop iteration: 9840
Iter 9840: loss 3.0875, lr 0.000899, 91966.20 tokens/sec
2025-04-25 14:04:19,228 - transformer_training - INFO - Main loop iteration: 9841
2025-04-25 14:04:19,689 - transformer_training - INFO - Main loop iteration: 9842
2025-04-25 14:04:20,139 - transformer_training - INFO - Main loop iteration: 9843
2025-04-25 14:04:20,639 - transformer_training - INFO - Main loop iteration: 9844
2025-04-25 14:04:21,040 - transformer_training - INFO - Main loop iteration: 9845
2025-04-25 14:04:21,502 - transformer_training - INFO - Main loop iteration: 9846
2025-04-25 14:04:21,953 - transformer_training - INFO - Main loop iteration: 9847
2025-04-25 14:04:22,453 - transformer_training - INFO - Main loop iteration: 9848
2025-04-25 14:04:22,854 - transformer_training - INFO - Main loop iteration: 9849
2025-04-25 14:04:23,315 - transformer_training - INFO - Main loop iteration: 9850
Iter 9850: loss 3.2815, lr 0.000898, 81939.83 tokens/sec
2025-04-25 14:04:23,766 - transformer_training - INFO - Main loop iteration: 9851
2025-04-25 14:04:24,264 - transformer_training - INFO - Main loop iteration: 9852
2025-04-25 14:04:24,666 - transformer_training - INFO - Main loop iteration: 9853
2025-04-25 14:04:25,127 - transformer_training - INFO - Main loop iteration: 9854
2025-04-25 14:04:25,577 - transformer_training - INFO - Main loop iteration: 9855
2025-04-25 14:04:26,076 - transformer_training - INFO - Main loop iteration: 9856
2025-04-25 14:04:26,477 - transformer_training - INFO - Main loop iteration: 9857
2025-04-25 14:04:26,938 - transformer_training - INFO - Main loop iteration: 9858
2025-04-25 14:04:27,389 - transformer_training - INFO - Main loop iteration: 9859
2025-04-25 14:04:27,887 - transformer_training - INFO - Main loop iteration: 9860
Iter 9860: loss 3.2131, lr 0.000898, 91994.33 tokens/sec
2025-04-25 14:04:28,289 - transformer_training - INFO - Main loop iteration: 9861
2025-04-25 14:04:28,750 - transformer_training - INFO - Main loop iteration: 9862
2025-04-25 14:04:29,200 - transformer_training - INFO - Main loop iteration: 9863
2025-04-25 14:04:29,700 - transformer_training - INFO - Main loop iteration: 9864
2025-04-25 14:04:30,101 - transformer_training - INFO - Main loop iteration: 9865
2025-04-25 14:04:30,561 - transformer_training - INFO - Main loop iteration: 9866
2025-04-25 14:04:31,012 - transformer_training - INFO - Main loop iteration: 9867
2025-04-25 14:04:31,510 - transformer_training - INFO - Main loop iteration: 9868
2025-04-25 14:04:31,911 - transformer_training - INFO - Main loop iteration: 9869
2025-04-25 14:04:32,373 - transformer_training - INFO - Main loop iteration: 9870
Iter 9870: loss 3.2900, lr 0.000898, 81565.33 tokens/sec
2025-04-25 14:04:32,825 - transformer_training - INFO - Main loop iteration: 9871
2025-04-25 14:04:33,324 - transformer_training - INFO - Main loop iteration: 9872
2025-04-25 14:04:33,725 - transformer_training - INFO - Main loop iteration: 9873
2025-04-25 14:04:34,185 - transformer_training - INFO - Main loop iteration: 9874
2025-04-25 14:04:34,636 - transformer_training - INFO - Main loop iteration: 9875
2025-04-25 14:04:35,135 - transformer_training - INFO - Main loop iteration: 9876
2025-04-25 14:04:35,536 - transformer_training - INFO - Main loop iteration: 9877
2025-04-25 14:04:35,997 - transformer_training - INFO - Main loop iteration: 9878
2025-04-25 14:04:36,448 - transformer_training - INFO - Main loop iteration: 9879
2025-04-25 14:04:36,946 - transformer_training - INFO - Main loop iteration: 9880
Iter 9880: loss 3.3110, lr 0.000898, 91945.37 tokens/sec
2025-04-25 14:04:37,347 - transformer_training - INFO - Main loop iteration: 9881
2025-04-25 14:04:37,808 - transformer_training - INFO - Main loop iteration: 9882
2025-04-25 14:04:38,258 - transformer_training - INFO - Main loop iteration: 9883
2025-04-25 14:04:38,758 - transformer_training - INFO - Main loop iteration: 9884
2025-04-25 14:04:39,159 - transformer_training - INFO - Main loop iteration: 9885
2025-04-25 14:04:39,621 - transformer_training - INFO - Main loop iteration: 9886
2025-04-25 14:04:40,071 - transformer_training - INFO - Main loop iteration: 9887
2025-04-25 14:04:40,570 - transformer_training - INFO - Main loop iteration: 9888
2025-04-25 14:04:40,971 - transformer_training - INFO - Main loop iteration: 9889
2025-04-25 14:04:41,432 - transformer_training - INFO - Main loop iteration: 9890
Iter 9890: loss 3.3074, lr 0.000897, 81801.85 tokens/sec
2025-04-25 14:04:41,883 - transformer_training - INFO - Main loop iteration: 9891
2025-04-25 14:04:42,382 - transformer_training - INFO - Main loop iteration: 9892
2025-04-25 14:04:42,784 - transformer_training - INFO - Main loop iteration: 9893
2025-04-25 14:04:43,246 - transformer_training - INFO - Main loop iteration: 9894
2025-04-25 14:04:43,696 - transformer_training - INFO - Main loop iteration: 9895
2025-04-25 14:04:44,195 - transformer_training - INFO - Main loop iteration: 9896
2025-04-25 14:04:44,596 - transformer_training - INFO - Main loop iteration: 9897
2025-04-25 14:04:45,057 - transformer_training - INFO - Main loop iteration: 9898
2025-04-25 14:04:45,508 - transformer_training - INFO - Main loop iteration: 9899
2025-04-25 14:04:46,007 - transformer_training - INFO - Main loop iteration: 9900
Iter 9900: loss 3.1920, lr 0.000897, 92016.17 tokens/sec
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
terminate called without an active exception
Iter 9900: train loss 2.9368, val loss 3.2272
2025-04-25 14:05:01,991 - transformer_training - INFO - Main loop iteration: 9901
2025-04-25 14:05:02,400 - transformer_training - INFO - Main loop iteration: 9902
2025-04-25 14:05:02,851 - transformer_training - INFO - Main loop iteration: 9903
2025-04-25 14:05:03,350 - transformer_training - INFO - Main loop iteration: 9904
2025-04-25 14:05:03,751 - transformer_training - INFO - Main loop iteration: 9905
2025-04-25 14:05:04,212 - transformer_training - INFO - Main loop iteration: 9906
2025-04-25 14:05:04,662 - transformer_training - INFO - Main loop iteration: 9907
2025-04-25 14:05:05,161 - transformer_training - INFO - Main loop iteration: 9908
2025-04-25 14:05:05,561 - transformer_training - INFO - Main loop iteration: 9909
2025-04-25 14:05:06,024 - transformer_training - INFO - Main loop iteration: 9910
Iter 9910: loss 3.1321, lr 0.000897, 81979.54 tokens/sec
2025-04-25 14:05:06,475 - transformer_training - INFO - Main loop iteration: 9911
2025-04-25 14:05:06,973 - transformer_training - INFO - Main loop iteration: 9912
2025-04-25 14:05:07,374 - transformer_training - INFO - Main loop iteration: 9913
2025-04-25 14:05:07,836 - transformer_training - INFO - Main loop iteration: 9914
2025-04-25 14:05:08,286 - transformer_training - INFO - Main loop iteration: 9915
2025-04-25 14:05:08,785 - transformer_training - INFO - Main loop iteration: 9916
2025-04-25 14:05:09,186 - transformer_training - INFO - Main loop iteration: 9917
2025-04-25 14:05:09,647 - transformer_training - INFO - Main loop iteration: 9918
2025-04-25 14:05:10,097 - transformer_training - INFO - Main loop iteration: 9919
2025-04-25 14:05:10,596 - transformer_training - INFO - Main loop iteration: 9920
Iter 9920: loss 3.2489, lr 0.000897, 91899.90 tokens/sec
2025-04-25 14:05:10,997 - transformer_training - INFO - Main loop iteration: 9921
2025-04-25 14:05:11,459 - transformer_training - INFO - Main loop iteration: 9922
2025-04-25 14:05:11,909 - transformer_training - INFO - Main loop iteration: 9923
2025-04-25 14:05:12,410 - transformer_training - INFO - Main loop iteration: 9924
2025-04-25 14:05:12,811 - transformer_training - INFO - Main loop iteration: 9925
2025-04-25 14:05:13,273 - transformer_training - INFO - Main loop iteration: 9926
2025-04-25 14:05:13,724 - transformer_training - INFO - Main loop iteration: 9927
2025-04-25 14:05:14,222 - transformer_training - INFO - Main loop iteration: 9928
2025-04-25 14:05:14,624 - transformer_training - INFO - Main loop iteration: 9929
2025-04-25 14:05:15,085 - transformer_training - INFO - Main loop iteration: 9930
Iter 9930: loss 3.1498, lr 0.000896, 81813.49 tokens/sec
2025-04-25 14:05:15,536 - transformer_training - INFO - Main loop iteration: 9931
2025-04-25 14:05:16,035 - transformer_training - INFO - Main loop iteration: 9932
2025-04-25 14:05:16,436 - transformer_training - INFO - Main loop iteration: 9933
2025-04-25 14:05:16,897 - transformer_training - INFO - Main loop iteration: 9934
2025-04-25 14:05:17,348 - transformer_training - INFO - Main loop iteration: 9935
2025-04-25 14:05:17,847 - transformer_training - INFO - Main loop iteration: 9936
2025-04-25 14:05:18,249 - transformer_training - INFO - Main loop iteration: 9937
2025-04-25 14:05:18,710 - transformer_training - INFO - Main loop iteration: 9938
2025-04-25 14:05:19,161 - transformer_training - INFO - Main loop iteration: 9939
2025-04-25 14:05:19,660 - transformer_training - INFO - Main loop iteration: 9940
Iter 9940: loss 3.1954, lr 0.000896, 91879.04 tokens/sec
2025-04-25 14:05:20,061 - transformer_training - INFO - Main loop iteration: 9941
2025-04-25 14:05:20,522 - transformer_training - INFO - Main loop iteration: 9942
2025-04-25 14:05:20,973 - transformer_training - INFO - Main loop iteration: 9943
2025-04-25 14:05:21,471 - transformer_training - INFO - Main loop iteration: 9944
2025-04-25 14:05:21,873 - transformer_training - INFO - Main loop iteration: 9945
2025-04-25 14:05:22,334 - transformer_training - INFO - Main loop iteration: 9946
2025-04-25 14:05:22,784 - transformer_training - INFO - Main loop iteration: 9947
2025-04-25 14:05:23,282 - transformer_training - INFO - Main loop iteration: 9948
2025-04-25 14:05:23,684 - transformer_training - INFO - Main loop iteration: 9949
2025-04-25 14:05:24,144 - transformer_training - INFO - Main loop iteration: 9950
Iter 9950: loss 3.2571, lr 0.000896, 81902.81 tokens/sec
2025-04-25 14:05:24,595 - transformer_training - INFO - Main loop iteration: 9951
2025-04-25 14:05:25,093 - transformer_training - INFO - Main loop iteration: 9952
2025-04-25 14:05:25,495 - transformer_training - INFO - Main loop iteration: 9953
2025-04-25 14:05:25,956 - transformer_training - INFO - Main loop iteration: 9954
2025-04-25 14:05:26,406 - transformer_training - INFO - Main loop iteration: 9955
2025-04-25 14:05:26,905 - transformer_training - INFO - Main loop iteration: 9956
2025-04-25 14:05:27,306 - transformer_training - INFO - Main loop iteration: 9957
2025-04-25 14:05:27,769 - transformer_training - INFO - Main loop iteration: 9958
2025-04-25 14:05:28,219 - transformer_training - INFO - Main loop iteration: 9959
2025-04-25 14:05:28,719 - transformer_training - INFO - Main loop iteration: 9960
Iter 9960: loss 3.2127, lr 0.000896, 92061.48 tokens/sec
2025-04-25 14:05:29,120 - transformer_training - INFO - Main loop iteration: 9961
2025-04-25 14:05:29,581 - transformer_training - INFO - Main loop iteration: 9962
2025-04-25 14:05:30,031 - transformer_training - INFO - Main loop iteration: 9963
2025-04-25 14:05:30,531 - transformer_training - INFO - Main loop iteration: 9964
2025-04-25 14:05:30,931 - transformer_training - INFO - Main loop iteration: 9965
2025-04-25 14:05:31,393 - transformer_training - INFO - Main loop iteration: 9966
2025-04-25 14:05:31,844 - transformer_training - INFO - Main loop iteration: 9967
2025-04-25 14:05:32,343 - transformer_training - INFO - Main loop iteration: 9968
2025-04-25 14:05:32,744 - transformer_training - INFO - Main loop iteration: 9969
2025-04-25 14:05:33,205 - transformer_training - INFO - Main loop iteration: 9970
Iter 9970: loss 3.2471, lr 0.000895, 81939.57 tokens/sec
2025-04-25 14:05:33,656 - transformer_training - INFO - Main loop iteration: 9971
2025-04-25 14:05:34,156 - transformer_training - INFO - Main loop iteration: 9972
2025-04-25 14:05:34,557 - transformer_training - INFO - Main loop iteration: 9973
2025-04-25 14:05:35,018 - transformer_training - INFO - Main loop iteration: 9974
2025-04-25 14:05:35,469 - transformer_training - INFO - Main loop iteration: 9975
2025-04-25 14:05:35,968 - transformer_training - INFO - Main loop iteration: 9976
2025-04-25 14:05:36,369 - transformer_training - INFO - Main loop iteration: 9977
2025-04-25 14:05:36,830 - transformer_training - INFO - Main loop iteration: 9978
2025-04-25 14:05:37,281 - transformer_training - INFO - Main loop iteration: 9979
2025-04-25 14:05:37,780 - transformer_training - INFO - Main loop iteration: 9980
Iter 9980: loss 3.2617, lr 0.000895, 92053.64 tokens/sec
2025-04-25 14:05:38,181 - transformer_training - INFO - Main loop iteration: 9981
2025-04-25 14:05:38,642 - transformer_training - INFO - Main loop iteration: 9982
2025-04-25 14:05:39,093 - transformer_training - INFO - Main loop iteration: 9983
2025-04-25 14:05:39,592 - transformer_training - INFO - Main loop iteration: 9984
2025-04-25 14:05:39,994 - transformer_training - INFO - Main loop iteration: 9985
2025-04-25 14:05:40,455 - transformer_training - INFO - Main loop iteration: 9986
2025-04-25 14:05:40,905 - transformer_training - INFO - Main loop iteration: 9987
2025-04-25 14:05:41,406 - transformer_training - INFO - Main loop iteration: 9988
2025-04-25 14:05:41,806 - transformer_training - INFO - Main loop iteration: 9989
2025-04-25 14:05:42,268 - transformer_training - INFO - Main loop iteration: 9990
Iter 9990: loss 3.2731, lr 0.000895, 81959.85 tokens/sec
2025-04-25 14:05:42,719 - transformer_training - INFO - Main loop iteration: 9991
2025-04-25 14:05:43,218 - transformer_training - INFO - Main loop iteration: 9992
2025-04-25 14:05:43,620 - transformer_training - INFO - Main loop iteration: 9993
2025-04-25 14:05:44,081 - transformer_training - INFO - Main loop iteration: 9994
2025-04-25 14:05:44,532 - transformer_training - INFO - Main loop iteration: 9995
2025-04-25 14:05:45,031 - transformer_training - INFO - Main loop iteration: 9996
2025-04-25 14:05:45,433 - transformer_training - INFO - Main loop iteration: 9997
2025-04-25 14:05:45,894 - transformer_training - INFO - Main loop iteration: 9998
2025-04-25 14:05:46,344 - transformer_training - INFO - Main loop iteration: 9999
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Your base folder is: /workspace/GPT
Your base folder is: /workspace/GPT
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Tokenizer loaded from /workspace/GPT/tokenization/custom_tokenizer.json
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
Flash Attention is available!
terminate called without an active exception
Iter 9999: train loss 2.9452, val loss 3.2215
New best model saved with val loss: 3.2215
Training completed in 6331.64 seconds
Generated text: contributor Richard Henderson commented that " No ... n ons ense Delaware ' s radio graphy demonstrates that on Mr . Jennings , Jackson might be supposed to be negatively depressed . You almost will be bo ther ed to see this play staged here ... despite its determination to make a second printing run of hits the same way — of the stream of ten to fifteen . " Jackson expressed the opinion of the court stating , " I knew it was un sung and cl um sy in exped ies . " Several hotels reopened on December August 8 , 1988 . G row th - mate Lynn Price hed on ically remarked " G row a page around his frame in disgust with one of the events ". After model Patt y K eller asked her not to ask , " P ank ind , but we were always wonder ing what to do . Make - up , B ink er Point and dance in Tex ark ro be , we will make a certain scene . It ' s pretty dam n odd ity not a music library . " Without a copy to
Training completed!
